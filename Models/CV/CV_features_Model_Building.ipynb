{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gO5K_gGvDsQX"
      },
      "source": [
        "##CV features"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install advertools"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pjYfBJDeo9XU",
        "outputId": "26d40ba7-6d3e-46ec-906a-00bd80e330a6"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: advertools in /usr/local/lib/python3.7/dist-packages (0.13.1)\n",
            "Requirement already satisfied: pyasn1 in /usr/local/lib/python3.7/dist-packages (from advertools) (0.4.8)\n",
            "Requirement already satisfied: scrapy in /usr/local/lib/python3.7/dist-packages (from advertools) (2.6.1)\n",
            "Requirement already satisfied: twython in /usr/local/lib/python3.7/dist-packages (from advertools) (3.9.1)\n",
            "Requirement already satisfied: pyarrow in /usr/local/lib/python3.7/dist-packages (from advertools) (6.0.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from advertools) (1.3.5)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas->advertools) (1.21.6)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->advertools) (2022.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->advertools) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->advertools) (1.15.0)\n",
            "Requirement already satisfied: PyDispatcher>=2.0.5 in /usr/local/lib/python3.7/dist-packages (from scrapy->advertools) (2.0.5)\n",
            "Requirement already satisfied: queuelib>=1.4.2 in /usr/local/lib/python3.7/dist-packages (from scrapy->advertools) (1.6.2)\n",
            "Requirement already satisfied: parsel>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from scrapy->advertools) (1.6.0)\n",
            "Requirement already satisfied: pyOpenSSL>=16.2.0 in /usr/local/lib/python3.7/dist-packages (from scrapy->advertools) (22.0.0)\n",
            "Requirement already satisfied: cryptography>=2.0 in /usr/local/lib/python3.7/dist-packages (from scrapy->advertools) (37.0.2)\n",
            "Requirement already satisfied: zope.interface>=4.1.3 in /usr/local/lib/python3.7/dist-packages (from scrapy->advertools) (5.4.0)\n",
            "Requirement already satisfied: service-identity>=16.0.0 in /usr/local/lib/python3.7/dist-packages (from scrapy->advertools) (21.1.0)\n",
            "Requirement already satisfied: w3lib>=1.17.0 in /usr/local/lib/python3.7/dist-packages (from scrapy->advertools) (1.22.0)\n",
            "Requirement already satisfied: protego>=0.1.15 in /usr/local/lib/python3.7/dist-packages (from scrapy->advertools) (0.2.1)\n",
            "Requirement already satisfied: itemadapter>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from scrapy->advertools) (0.6.0)\n",
            "Requirement already satisfied: lxml>=3.5.0 in /usr/local/lib/python3.7/dist-packages (from scrapy->advertools) (4.2.6)\n",
            "Requirement already satisfied: itemloaders>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from scrapy->advertools) (1.0.4)\n",
            "Requirement already satisfied: cssselect>=0.9.1 in /usr/local/lib/python3.7/dist-packages (from scrapy->advertools) (1.1.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from scrapy->advertools) (57.4.0)\n",
            "Requirement already satisfied: Twisted>=17.9.0 in /usr/local/lib/python3.7/dist-packages (from scrapy->advertools) (22.4.0)\n",
            "Requirement already satisfied: tldextract in /usr/local/lib/python3.7/dist-packages (from scrapy->advertools) (3.3.0)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography>=2.0->scrapy->advertools) (1.15.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12->cryptography>=2.0->scrapy->advertools) (2.21)\n",
            "Requirement already satisfied: jmespath>=0.9.5 in /usr/local/lib/python3.7/dist-packages (from itemloaders>=1.0.1->scrapy->advertools) (1.0.0)\n",
            "Requirement already satisfied: pyasn1-modules in /usr/local/lib/python3.7/dist-packages (from service-identity>=16.0.0->scrapy->advertools) (0.2.8)\n",
            "Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.7/dist-packages (from service-identity>=16.0.0->scrapy->advertools) (21.4.0)\n",
            "Requirement already satisfied: Automat>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from Twisted>=17.9.0->scrapy->advertools) (20.2.0)\n",
            "Requirement already satisfied: hyperlink>=17.1.1 in /usr/local/lib/python3.7/dist-packages (from Twisted>=17.9.0->scrapy->advertools) (21.0.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.5 in /usr/local/lib/python3.7/dist-packages (from Twisted>=17.9.0->scrapy->advertools) (4.2.0)\n",
            "Requirement already satisfied: constantly>=15.1 in /usr/local/lib/python3.7/dist-packages (from Twisted>=17.9.0->scrapy->advertools) (15.1.0)\n",
            "Requirement already satisfied: incremental>=21.3.0 in /usr/local/lib/python3.7/dist-packages (from Twisted>=17.9.0->scrapy->advertools) (21.3.0)\n",
            "Requirement already satisfied: idna>=2.5 in /usr/local/lib/python3.7/dist-packages (from hyperlink>=17.1.1->Twisted>=17.9.0->scrapy->advertools) (2.10)\n",
            "Requirement already satisfied: filelock>=3.0.8 in /usr/local/lib/python3.7/dist-packages (from tldextract->scrapy->advertools) (3.7.0)\n",
            "Requirement already satisfied: requests>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from tldextract->scrapy->advertools) (2.23.0)\n",
            "Requirement already satisfied: requests-file>=1.4 in /usr/local/lib/python3.7/dist-packages (from tldextract->scrapy->advertools) (1.5.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.1.0->tldextract->scrapy->advertools) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.1.0->tldextract->scrapy->advertools) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.1.0->tldextract->scrapy->advertools) (3.0.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from twython->advertools) (1.3.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.4.0->twython->advertools) (3.2.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ntlk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QpKEKfXq37ux",
        "outputId": "b797ef51-de75-4650-feca-82119b8b0123"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: Could not find a version that satisfies the requirement ntlk (from versions: none)\u001b[0m\n",
            "\u001b[31mERROR: No matching distribution found for ntlk\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "UPGY-89r9Vqn"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import logging \n",
        "import gensim\n",
        "import datetime\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "import xgboost as xgb \n",
        "from time import time \n",
        "import pandas as pd\n",
        "import time\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "# Config\n",
        "import advertools as adv\n",
        "from tqdm import tqdm \n",
        "from utils import metrics\n",
        "from functools import reduce\n",
        "from utils import featureScore\n",
        "from utils import folderPath\n",
        "from textblob import TextBlob\n",
        "from sklearn.manifold import TSNE\n",
        "from collections import defaultdict\n",
        "from gensim.models import FastText\n",
        "from sklearn.metrics import r2_score\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.decomposition import PCA\n",
        "from typing import List, Callable, Dict\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from utils import removeColumnContainString\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from utils import hyperparameterTuning_RandomForest\n",
        "from utils import hyperparameterTuning_XGBoost\n",
        "from utils import hyperparameterTuning_MLP\n",
        "from utils import plot_feature_importance\n",
        "from sklearn.model_selection import train_test_split\n",
        "logging.basicConfig(format=\"%(levelname)s - %(asctime)s: %(message)s\", datefmt= '%H:%M:%S', level=logging.INFO)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S9-kaYaSn8Zz",
        "outputId": "c3869b2a-f7f7-4578-be3e-6b90a84ddc83"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "N7N0EfaKNLZf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "847be365-d176-439e-c935-1b34e983c5db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2882: DtypeWarning: Columns (26) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
          ]
        }
      ],
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/NLP/CvFeatures.csv')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YhCaW8l8zUi5",
        "outputId": "9dbe07b7-8ffa-4ac2-bf68-a561a624cb10"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Unnamed: 0', 'Unnamed: 0.1', 'image_type', 'account', 'caption',\n",
              "       'profile_name', 'profile_image_link', 'biography', 'id', 'external_url',\n",
              "       'following', 'likes', 'media_type', 'posts_count', 'followers',\n",
              "       'is_verified', 'datetime', 'image_url.1', 'url', 'comments',\n",
              "       'input_account', 'input_posts_number', 'input_date_of_post',\n",
              "       'input_post_type', 'input_stop_id', 'warning', 'error', 'tags',\n",
              "       'confidence_score', 'accent_color', 'is_bw', 'dominant_colors',\n",
              "       'bg_color', 'fore_color', 'industry', '_category', 'region'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "jZlJVhojy2xS",
        "outputId": "f20488c6-45c4-49c9-ed97-6c20e9053633"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Unnamed: 0  Unnamed: 0.1                          image_type  \\\n",
              "0               0             0  ['Ambiguous Clip', 'Not LineDraw']   \n",
              "1               1             1        ['Not Clip', 'Not LineDraw']   \n",
              "2               2             2        ['Not Clip', 'Not LineDraw']   \n",
              "3               3             3        ['Not Clip', 'Not LineDraw']   \n",
              "4               4             4  ['Ambiguous Clip', 'Not LineDraw']   \n",
              "...           ...           ...                                 ...   \n",
              "88511       88511         88511        ['Not Clip', 'Not LineDraw']   \n",
              "88512       88512         88512        ['Not Clip', 'Not LineDraw']   \n",
              "88513       88513         88513        ['Not Clip', 'Not LineDraw']   \n",
              "88514       88514         88514        ['Not Clip', 'Not LineDraw']   \n",
              "88515       88515         88515        ['Not Clip', 'Not LineDraw']   \n",
              "\n",
              "                 account                                            caption  \\\n",
              "0            yeastbakery  It’s our last Pizza Sunday at the arch today. ...   \n",
              "1            yeastbakery                       New cakes on our counters 😋😋   \n",
              "2            yeastbakery  🔺Opening Times for Half Term🔺: Hi everyone we ...   \n",
              "3            yeastbakery  New addition to our selection of sandwiches, o...   \n",
              "4            yeastbakery  We are currently closed as we move into our ne...   \n",
              "...                  ...                                                ...   \n",
              "88511  sandysfishmongers  There’s only one turkey and the best place to ...   \n",
              "88512  sandysfishmongers  Day one brochure tour !! #sandysfishmongers #b...   \n",
              "88513  sandysfishmongers  A unique amber coloured blue veined cheese , w...   \n",
              "88514                NaN                                                NaN   \n",
              "88515                NaN                                                NaN   \n",
              "\n",
              "                         profile_name  \\\n",
              "0                        Yeast Bakery   \n",
              "1                        Yeast Bakery   \n",
              "2                        Yeast Bakery   \n",
              "3                        Yeast Bakery   \n",
              "4                        Yeast Bakery   \n",
              "...                               ...   \n",
              "88511  Fishmongers/ButchersTwickenham   \n",
              "88512  Fishmongers/ButchersTwickenham   \n",
              "88513  Fishmongers/ButchersTwickenham   \n",
              "88514                             NaN   \n",
              "88515                             NaN   \n",
              "\n",
              "                                      profile_image_link  \\\n",
              "0      https://instagram.fman2-1.fna.fbcdn.net/v/t51....   \n",
              "1      https://instagram.fman2-1.fna.fbcdn.net/v/t51....   \n",
              "2      https://instagram.fman2-1.fna.fbcdn.net/v/t51....   \n",
              "3      https://instagram.fman2-1.fna.fbcdn.net/v/t51....   \n",
              "4      https://instagram.fman2-1.fna.fbcdn.net/v/t51....   \n",
              "...                                                  ...   \n",
              "88511  https://scontent-lcy1-1.cdninstagram.com/v/t51...   \n",
              "88512  https://scontent-lcy1-1.cdninstagram.com/v/t51...   \n",
              "88513  https://scontent-lcy1-1.cdninstagram.com/v/t51...   \n",
              "88514                                                NaN   \n",
              "88515                                                NaN   \n",
              "\n",
              "                                               biography            id  \\\n",
              "0      We are now open at our new site: Unit 1 Canal ...  2.620000e+18   \n",
              "1      We are now open at our new site: Unit 1 Canal ...  2.790000e+18   \n",
              "2      We are now open at our new site: Unit 1 Canal ...  2.690000e+18   \n",
              "3      We are now open at our new site: Unit 1 Canal ...  2.670000e+18   \n",
              "4      We are now open at our new site: Unit 1 Canal ...  2.620000e+18   \n",
              "...                                                  ...           ...   \n",
              "88511  Local Family Fishmongers & Butchers , fresh fi...  2.700000e+18   \n",
              "88512  Local Family Fishmongers & Butchers , fresh fi...  2.700000e+18   \n",
              "88513  Local Family Fishmongers & Butchers , fresh fi...  2.700000e+18   \n",
              "88514                                                NaN           NaN   \n",
              "88515                                                NaN           NaN   \n",
              "\n",
              "                      external_url  ...  \\\n",
              "0      http://www.yeastbakery.com/  ...   \n",
              "1      http://www.yeastbakery.com/  ...   \n",
              "2      http://www.yeastbakery.com/  ...   \n",
              "3      http://www.yeastbakery.com/  ...   \n",
              "4      http://www.yeastbakery.com/  ...   \n",
              "...                            ...  ...   \n",
              "88511       http://sandysfish.net/  ...   \n",
              "88512       http://sandysfish.net/  ...   \n",
              "88513       http://sandysfish.net/  ...   \n",
              "88514                          NaN  ...   \n",
              "88515                          NaN  ...   \n",
              "\n",
              "                                                    tags  \\\n",
              "0      ['text', 'font', 'graphics', 'screenshot', 'gr...   \n",
              "1      ['dessert', 'baked goods', 'baking', 'snack', ...   \n",
              "2      ['food', 'fruit', 'baked goods', 'breakfast', ...   \n",
              "3      ['food', 'bread', 'fast food', 'bun', 'america...   \n",
              "4      ['text', 'font', 'design', 'yellow', 'graphics...   \n",
              "...                                                  ...   \n",
              "88511                          ['text', 'food', 'snack']   \n",
              "88512                      ['text', 'poster', 'cartoon']   \n",
              "88513  ['text', 'yellow', 'packaging and labeling', '...   \n",
              "88514  ['sport', 'person', 'barbell', 'physical fitne...   \n",
              "88515  ['cosmetics', 'toiletry', 'eyelash', 'skin', '...   \n",
              "\n",
              "                                        confidence_score  \\\n",
              "0      [0.9980798959732056, 0.9481294751167297, 0.881...   \n",
              "1      [0.9897554516792297, 0.987897515296936, 0.9828...   \n",
              "2      [0.9808361530303955, 0.9546540379524231, 0.947...   \n",
              "3      [0.9958561658859253, 0.981575608253479, 0.9799...   \n",
              "4      [0.9993002414703369, 0.9640201926231384, 0.951...   \n",
              "...                                                  ...   \n",
              "88511  [0.9999812841415405, 0.9580191373825073, 0.915...   \n",
              "88512  [0.9999863505363464, 0.9184243679046631, 0.910...   \n",
              "88513  [0.9997624158859253, 0.9444339871406555, 0.854...   \n",
              "88514  [0.9959811568260193, 0.9808116555213928, 0.971...   \n",
              "88515  [0.974940299987793, 0.9452543258666992, 0.9450...   \n",
              "\n",
              "                                            accent_color  is_bw  \\\n",
              "0      [0.788235294117647, 0.00784313725490196, 0.007...      0   \n",
              "1      [0.6901960784313725, 0.14901960784313725, 0.10...      0   \n",
              "2      [0.6588235294117647, 0.4392156862745098, 0.141...      0   \n",
              "3      [0.24313725490196078, 0.12549019607843137, 0.0...      0   \n",
              "4      [0.792156862745098, 0.7372549019607844, 0.0039...      0   \n",
              "...                                                  ...    ...   \n",
              "88511  [0.6588235294117647, 0.00784313725490196, 0.71...      0   \n",
              "88512  [0.01568627450980392, 0.5098039215686274, 0.78...      0   \n",
              "88513  [0.01568627450980392, 0.2235294117647059, 0.43...      0   \n",
              "88514  [0.6862745098039216, 0.5215686274509804, 0.109...      0   \n",
              "88515  [0.6705882352941176, 0.27058823529411763, 0.12...      0   \n",
              "\n",
              "                                         dominant_colors  \\\n",
              "0           [1.0, 0.7529411764705882, 0.796078431372549]   \n",
              "1      [0.6470588235294118, 0.16470588235294117, 0.16...   \n",
              "2      [0.6470588235294118, 0.16470588235294117, 0.16...   \n",
              "3      [0.6470588235294118, 0.16470588235294117, 0.16...   \n",
              "4                                        [1.0, 1.0, 0.0]   \n",
              "...                                                  ...   \n",
              "88511      [0.5019607843137255, 0.0, 0.5019607843137255]   \n",
              "88512                                    [1.0, 1.0, 1.0]   \n",
              "88513                                    [1.0, 1.0, 0.0]   \n",
              "88514                                    [1.0, 1.0, 1.0]   \n",
              "88515       [1.0, 0.7529411764705882, 0.796078431372549]   \n",
              "\n",
              "                                                bg_color  \\\n",
              "0           [1.0, 0.7529411764705882, 0.796078431372549]   \n",
              "1      [0.6470588235294118, 0.16470588235294117, 0.16...   \n",
              "2      [0.6470588235294118, 0.16470588235294117, 0.16...   \n",
              "3      [0.6470588235294118, 0.16470588235294117, 0.16...   \n",
              "4                                        [1.0, 1.0, 0.0]   \n",
              "...                                                  ...   \n",
              "88511      [0.5019607843137255, 0.0, 0.5019607843137255]   \n",
              "88512                                    [1.0, 1.0, 1.0]   \n",
              "88513                                    [0.0, 0.0, 1.0]   \n",
              "88514                                    [1.0, 1.0, 1.0]   \n",
              "88515                                    [1.0, 1.0, 1.0]   \n",
              "\n",
              "                                              fore_color     industry  \\\n",
              "0           [1.0, 0.7529411764705882, 0.796078431372549]  hospitality   \n",
              "1                                        [0.0, 0.0, 0.0]  hospitality   \n",
              "2      [0.6470588235294118, 0.16470588235294117, 0.16...  hospitality   \n",
              "3      [0.6470588235294118, 0.16470588235294117, 0.16...  hospitality   \n",
              "4                                        [1.0, 1.0, 0.0]  hospitality   \n",
              "...                                                  ...          ...   \n",
              "88511  [0.5019607843137255, 0.5019607843137255, 0.501...       retail   \n",
              "88512                                    [1.0, 1.0, 1.0]       retail   \n",
              "88513                                    [1.0, 1.0, 0.0]       retail   \n",
              "88514                                    [1.0, 1.0, 1.0]          NaN   \n",
              "88515       [1.0, 0.7529411764705882, 0.796078431372549]          NaN   \n",
              "\n",
              "                    _category  region  \n",
              "0                      bakery      UK  \n",
              "1                      bakery      UK  \n",
              "2                      bakery      UK  \n",
              "3                      bakery      UK  \n",
              "4                      bakery      UK  \n",
              "...                       ...     ...  \n",
              "88511  fishmongers / butchers      UK  \n",
              "88512  fishmongers / butchers      UK  \n",
              "88513  fishmongers / butchers      UK  \n",
              "88514                     NaN     NaN  \n",
              "88515                     NaN     NaN  \n",
              "\n",
              "[88516 rows x 37 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-dc8f7e3c-6c01-44dd-84bf-0e2a900b90ed\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Unnamed: 0.1</th>\n",
              "      <th>image_type</th>\n",
              "      <th>account</th>\n",
              "      <th>caption</th>\n",
              "      <th>profile_name</th>\n",
              "      <th>profile_image_link</th>\n",
              "      <th>biography</th>\n",
              "      <th>id</th>\n",
              "      <th>external_url</th>\n",
              "      <th>...</th>\n",
              "      <th>tags</th>\n",
              "      <th>confidence_score</th>\n",
              "      <th>accent_color</th>\n",
              "      <th>is_bw</th>\n",
              "      <th>dominant_colors</th>\n",
              "      <th>bg_color</th>\n",
              "      <th>fore_color</th>\n",
              "      <th>industry</th>\n",
              "      <th>_category</th>\n",
              "      <th>region</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>['Ambiguous Clip', 'Not LineDraw']</td>\n",
              "      <td>yeastbakery</td>\n",
              "      <td>It’s our last Pizza Sunday at the arch today. ...</td>\n",
              "      <td>Yeast Bakery</td>\n",
              "      <td>https://instagram.fman2-1.fna.fbcdn.net/v/t51....</td>\n",
              "      <td>We are now open at our new site: Unit 1 Canal ...</td>\n",
              "      <td>2.620000e+18</td>\n",
              "      <td>http://www.yeastbakery.com/</td>\n",
              "      <td>...</td>\n",
              "      <td>['text', 'font', 'graphics', 'screenshot', 'gr...</td>\n",
              "      <td>[0.9980798959732056, 0.9481294751167297, 0.881...</td>\n",
              "      <td>[0.788235294117647, 0.00784313725490196, 0.007...</td>\n",
              "      <td>0</td>\n",
              "      <td>[1.0, 0.7529411764705882, 0.796078431372549]</td>\n",
              "      <td>[1.0, 0.7529411764705882, 0.796078431372549]</td>\n",
              "      <td>[1.0, 0.7529411764705882, 0.796078431372549]</td>\n",
              "      <td>hospitality</td>\n",
              "      <td>bakery</td>\n",
              "      <td>UK</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>['Not Clip', 'Not LineDraw']</td>\n",
              "      <td>yeastbakery</td>\n",
              "      <td>New cakes on our counters 😋😋</td>\n",
              "      <td>Yeast Bakery</td>\n",
              "      <td>https://instagram.fman2-1.fna.fbcdn.net/v/t51....</td>\n",
              "      <td>We are now open at our new site: Unit 1 Canal ...</td>\n",
              "      <td>2.790000e+18</td>\n",
              "      <td>http://www.yeastbakery.com/</td>\n",
              "      <td>...</td>\n",
              "      <td>['dessert', 'baked goods', 'baking', 'snack', ...</td>\n",
              "      <td>[0.9897554516792297, 0.987897515296936, 0.9828...</td>\n",
              "      <td>[0.6901960784313725, 0.14901960784313725, 0.10...</td>\n",
              "      <td>0</td>\n",
              "      <td>[0.6470588235294118, 0.16470588235294117, 0.16...</td>\n",
              "      <td>[0.6470588235294118, 0.16470588235294117, 0.16...</td>\n",
              "      <td>[0.0, 0.0, 0.0]</td>\n",
              "      <td>hospitality</td>\n",
              "      <td>bakery</td>\n",
              "      <td>UK</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>['Not Clip', 'Not LineDraw']</td>\n",
              "      <td>yeastbakery</td>\n",
              "      <td>🔺Opening Times for Half Term🔺: Hi everyone we ...</td>\n",
              "      <td>Yeast Bakery</td>\n",
              "      <td>https://instagram.fman2-1.fna.fbcdn.net/v/t51....</td>\n",
              "      <td>We are now open at our new site: Unit 1 Canal ...</td>\n",
              "      <td>2.690000e+18</td>\n",
              "      <td>http://www.yeastbakery.com/</td>\n",
              "      <td>...</td>\n",
              "      <td>['food', 'fruit', 'baked goods', 'breakfast', ...</td>\n",
              "      <td>[0.9808361530303955, 0.9546540379524231, 0.947...</td>\n",
              "      <td>[0.6588235294117647, 0.4392156862745098, 0.141...</td>\n",
              "      <td>0</td>\n",
              "      <td>[0.6470588235294118, 0.16470588235294117, 0.16...</td>\n",
              "      <td>[0.6470588235294118, 0.16470588235294117, 0.16...</td>\n",
              "      <td>[0.6470588235294118, 0.16470588235294117, 0.16...</td>\n",
              "      <td>hospitality</td>\n",
              "      <td>bakery</td>\n",
              "      <td>UK</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>['Not Clip', 'Not LineDraw']</td>\n",
              "      <td>yeastbakery</td>\n",
              "      <td>New addition to our selection of sandwiches, o...</td>\n",
              "      <td>Yeast Bakery</td>\n",
              "      <td>https://instagram.fman2-1.fna.fbcdn.net/v/t51....</td>\n",
              "      <td>We are now open at our new site: Unit 1 Canal ...</td>\n",
              "      <td>2.670000e+18</td>\n",
              "      <td>http://www.yeastbakery.com/</td>\n",
              "      <td>...</td>\n",
              "      <td>['food', 'bread', 'fast food', 'bun', 'america...</td>\n",
              "      <td>[0.9958561658859253, 0.981575608253479, 0.9799...</td>\n",
              "      <td>[0.24313725490196078, 0.12549019607843137, 0.0...</td>\n",
              "      <td>0</td>\n",
              "      <td>[0.6470588235294118, 0.16470588235294117, 0.16...</td>\n",
              "      <td>[0.6470588235294118, 0.16470588235294117, 0.16...</td>\n",
              "      <td>[0.6470588235294118, 0.16470588235294117, 0.16...</td>\n",
              "      <td>hospitality</td>\n",
              "      <td>bakery</td>\n",
              "      <td>UK</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>['Ambiguous Clip', 'Not LineDraw']</td>\n",
              "      <td>yeastbakery</td>\n",
              "      <td>We are currently closed as we move into our ne...</td>\n",
              "      <td>Yeast Bakery</td>\n",
              "      <td>https://instagram.fman2-1.fna.fbcdn.net/v/t51....</td>\n",
              "      <td>We are now open at our new site: Unit 1 Canal ...</td>\n",
              "      <td>2.620000e+18</td>\n",
              "      <td>http://www.yeastbakery.com/</td>\n",
              "      <td>...</td>\n",
              "      <td>['text', 'font', 'design', 'yellow', 'graphics...</td>\n",
              "      <td>[0.9993002414703369, 0.9640201926231384, 0.951...</td>\n",
              "      <td>[0.792156862745098, 0.7372549019607844, 0.0039...</td>\n",
              "      <td>0</td>\n",
              "      <td>[1.0, 1.0, 0.0]</td>\n",
              "      <td>[1.0, 1.0, 0.0]</td>\n",
              "      <td>[1.0, 1.0, 0.0]</td>\n",
              "      <td>hospitality</td>\n",
              "      <td>bakery</td>\n",
              "      <td>UK</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88511</th>\n",
              "      <td>88511</td>\n",
              "      <td>88511</td>\n",
              "      <td>['Not Clip', 'Not LineDraw']</td>\n",
              "      <td>sandysfishmongers</td>\n",
              "      <td>There’s only one turkey and the best place to ...</td>\n",
              "      <td>Fishmongers/ButchersTwickenham</td>\n",
              "      <td>https://scontent-lcy1-1.cdninstagram.com/v/t51...</td>\n",
              "      <td>Local Family Fishmongers &amp; Butchers , fresh fi...</td>\n",
              "      <td>2.700000e+18</td>\n",
              "      <td>http://sandysfish.net/</td>\n",
              "      <td>...</td>\n",
              "      <td>['text', 'food', 'snack']</td>\n",
              "      <td>[0.9999812841415405, 0.9580191373825073, 0.915...</td>\n",
              "      <td>[0.6588235294117647, 0.00784313725490196, 0.71...</td>\n",
              "      <td>0</td>\n",
              "      <td>[0.5019607843137255, 0.0, 0.5019607843137255]</td>\n",
              "      <td>[0.5019607843137255, 0.0, 0.5019607843137255]</td>\n",
              "      <td>[0.5019607843137255, 0.5019607843137255, 0.501...</td>\n",
              "      <td>retail</td>\n",
              "      <td>fishmongers / butchers</td>\n",
              "      <td>UK</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88512</th>\n",
              "      <td>88512</td>\n",
              "      <td>88512</td>\n",
              "      <td>['Not Clip', 'Not LineDraw']</td>\n",
              "      <td>sandysfishmongers</td>\n",
              "      <td>Day one brochure tour !! #sandysfishmongers #b...</td>\n",
              "      <td>Fishmongers/ButchersTwickenham</td>\n",
              "      <td>https://scontent-lcy1-1.cdninstagram.com/v/t51...</td>\n",
              "      <td>Local Family Fishmongers &amp; Butchers , fresh fi...</td>\n",
              "      <td>2.700000e+18</td>\n",
              "      <td>http://sandysfish.net/</td>\n",
              "      <td>...</td>\n",
              "      <td>['text', 'poster', 'cartoon']</td>\n",
              "      <td>[0.9999863505363464, 0.9184243679046631, 0.910...</td>\n",
              "      <td>[0.01568627450980392, 0.5098039215686274, 0.78...</td>\n",
              "      <td>0</td>\n",
              "      <td>[1.0, 1.0, 1.0]</td>\n",
              "      <td>[1.0, 1.0, 1.0]</td>\n",
              "      <td>[1.0, 1.0, 1.0]</td>\n",
              "      <td>retail</td>\n",
              "      <td>fishmongers / butchers</td>\n",
              "      <td>UK</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88513</th>\n",
              "      <td>88513</td>\n",
              "      <td>88513</td>\n",
              "      <td>['Not Clip', 'Not LineDraw']</td>\n",
              "      <td>sandysfishmongers</td>\n",
              "      <td>A unique amber coloured blue veined cheese , w...</td>\n",
              "      <td>Fishmongers/ButchersTwickenham</td>\n",
              "      <td>https://scontent-lcy1-1.cdninstagram.com/v/t51...</td>\n",
              "      <td>Local Family Fishmongers &amp; Butchers , fresh fi...</td>\n",
              "      <td>2.700000e+18</td>\n",
              "      <td>http://sandysfish.net/</td>\n",
              "      <td>...</td>\n",
              "      <td>['text', 'yellow', 'packaging and labeling', '...</td>\n",
              "      <td>[0.9997624158859253, 0.9444339871406555, 0.854...</td>\n",
              "      <td>[0.01568627450980392, 0.2235294117647059, 0.43...</td>\n",
              "      <td>0</td>\n",
              "      <td>[1.0, 1.0, 0.0]</td>\n",
              "      <td>[0.0, 0.0, 1.0]</td>\n",
              "      <td>[1.0, 1.0, 0.0]</td>\n",
              "      <td>retail</td>\n",
              "      <td>fishmongers / butchers</td>\n",
              "      <td>UK</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88514</th>\n",
              "      <td>88514</td>\n",
              "      <td>88514</td>\n",
              "      <td>['Not Clip', 'Not LineDraw']</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>['sport', 'person', 'barbell', 'physical fitne...</td>\n",
              "      <td>[0.9959811568260193, 0.9808116555213928, 0.971...</td>\n",
              "      <td>[0.6862745098039216, 0.5215686274509804, 0.109...</td>\n",
              "      <td>0</td>\n",
              "      <td>[1.0, 1.0, 1.0]</td>\n",
              "      <td>[1.0, 1.0, 1.0]</td>\n",
              "      <td>[1.0, 1.0, 1.0]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88515</th>\n",
              "      <td>88515</td>\n",
              "      <td>88515</td>\n",
              "      <td>['Not Clip', 'Not LineDraw']</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>['cosmetics', 'toiletry', 'eyelash', 'skin', '...</td>\n",
              "      <td>[0.974940299987793, 0.9452543258666992, 0.9450...</td>\n",
              "      <td>[0.6705882352941176, 0.27058823529411763, 0.12...</td>\n",
              "      <td>0</td>\n",
              "      <td>[1.0, 0.7529411764705882, 0.796078431372549]</td>\n",
              "      <td>[1.0, 1.0, 1.0]</td>\n",
              "      <td>[1.0, 0.7529411764705882, 0.796078431372549]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>88516 rows × 37 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dc8f7e3c-6c01-44dd-84bf-0e2a900b90ed')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-dc8f7e3c-6c01-44dd-84bf-0e2a900b90ed button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-dc8f7e3c-6c01-44dd-84bf-0e2a900b90ed');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "k0BV3Au1RiDV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a9476b1-caa5-45eb-85da-c34831232fb7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        }
      ],
      "source": [
        "df.drop(df.columns.difference(['account','profile_name','biography','image_type','caption','comments','tags','following','confidence_score','accent_color','is_bw','dominant_colors','bg_color','fore_color','posts_count','followers','tags','confidence_score','accent_color','is_bw','dominant_colors','bg_color','fore_color','industry','datetime','likes']), 1, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "21QZUTcnoXlf",
        "outputId": "12072f58-4cf9-4280-bdd0-26e5c541c700"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                               image_type            account  \\\n",
              "0      ['Ambiguous Clip', 'Not LineDraw']        yeastbakery   \n",
              "1            ['Not Clip', 'Not LineDraw']        yeastbakery   \n",
              "2            ['Not Clip', 'Not LineDraw']        yeastbakery   \n",
              "3            ['Not Clip', 'Not LineDraw']        yeastbakery   \n",
              "4      ['Ambiguous Clip', 'Not LineDraw']        yeastbakery   \n",
              "...                                   ...                ...   \n",
              "88511        ['Not Clip', 'Not LineDraw']  sandysfishmongers   \n",
              "88512        ['Not Clip', 'Not LineDraw']  sandysfishmongers   \n",
              "88513        ['Not Clip', 'Not LineDraw']  sandysfishmongers   \n",
              "88514        ['Not Clip', 'Not LineDraw']                NaN   \n",
              "88515        ['Not Clip', 'Not LineDraw']                NaN   \n",
              "\n",
              "                                                 caption  \\\n",
              "0      It’s our last Pizza Sunday at the arch today. ...   \n",
              "1                           New cakes on our counters 😋😋   \n",
              "2      🔺Opening Times for Half Term🔺: Hi everyone we ...   \n",
              "3      New addition to our selection of sandwiches, o...   \n",
              "4      We are currently closed as we move into our ne...   \n",
              "...                                                  ...   \n",
              "88511  There’s only one turkey and the best place to ...   \n",
              "88512  Day one brochure tour !! #sandysfishmongers #b...   \n",
              "88513  A unique amber coloured blue veined cheese , w...   \n",
              "88514                                                NaN   \n",
              "88515                                                NaN   \n",
              "\n",
              "                         profile_name  \\\n",
              "0                        Yeast Bakery   \n",
              "1                        Yeast Bakery   \n",
              "2                        Yeast Bakery   \n",
              "3                        Yeast Bakery   \n",
              "4                        Yeast Bakery   \n",
              "...                               ...   \n",
              "88511  Fishmongers/ButchersTwickenham   \n",
              "88512  Fishmongers/ButchersTwickenham   \n",
              "88513  Fishmongers/ButchersTwickenham   \n",
              "88514                             NaN   \n",
              "88515                             NaN   \n",
              "\n",
              "                                               biography  following  likes  \\\n",
              "0      We are now open at our new site: Unit 1 Canal ...      352.0   29.0   \n",
              "1      We are now open at our new site: Unit 1 Canal ...      352.0   44.0   \n",
              "2      We are now open at our new site: Unit 1 Canal ...      352.0  209.0   \n",
              "3      We are now open at our new site: Unit 1 Canal ...      352.0   95.0   \n",
              "4      We are now open at our new site: Unit 1 Canal ...      352.0  101.0   \n",
              "...                                                  ...        ...    ...   \n",
              "88511  Local Family Fishmongers & Butchers , fresh fi...      579.0    8.0   \n",
              "88512  Local Family Fishmongers & Butchers , fresh fi...      579.0    9.0   \n",
              "88513  Local Family Fishmongers & Butchers , fresh fi...      579.0   11.0   \n",
              "88514                                                NaN        NaN    NaN   \n",
              "88515                                                NaN        NaN    NaN   \n",
              "\n",
              "       posts_count  followers      datetime  comments  \\\n",
              "0            280.0     8702.0  1.626600e+12       0.0   \n",
              "1            280.0     8702.0  1.646920e+12       0.0   \n",
              "2            280.0     8702.0  1.634730e+12       9.0   \n",
              "3            280.0     8702.0  1.633090e+12       3.0   \n",
              "4            280.0     8702.0  1.626930e+12       6.0   \n",
              "...            ...        ...           ...       ...   \n",
              "88511       1863.0     2321.0  1.636550e+12       0.0   \n",
              "88512       1863.0     2321.0  1.636550e+12       0.0   \n",
              "88513       1863.0     2321.0  1.636540e+12       2.0   \n",
              "88514          NaN        NaN           NaN       NaN   \n",
              "88515          NaN        NaN           NaN       NaN   \n",
              "\n",
              "                                                    tags  \\\n",
              "0      ['text', 'font', 'graphics', 'screenshot', 'gr...   \n",
              "1      ['dessert', 'baked goods', 'baking', 'snack', ...   \n",
              "2      ['food', 'fruit', 'baked goods', 'breakfast', ...   \n",
              "3      ['food', 'bread', 'fast food', 'bun', 'america...   \n",
              "4      ['text', 'font', 'design', 'yellow', 'graphics...   \n",
              "...                                                  ...   \n",
              "88511                          ['text', 'food', 'snack']   \n",
              "88512                      ['text', 'poster', 'cartoon']   \n",
              "88513  ['text', 'yellow', 'packaging and labeling', '...   \n",
              "88514  ['sport', 'person', 'barbell', 'physical fitne...   \n",
              "88515  ['cosmetics', 'toiletry', 'eyelash', 'skin', '...   \n",
              "\n",
              "                                        confidence_score  \\\n",
              "0      [0.9980798959732056, 0.9481294751167297, 0.881...   \n",
              "1      [0.9897554516792297, 0.987897515296936, 0.9828...   \n",
              "2      [0.9808361530303955, 0.9546540379524231, 0.947...   \n",
              "3      [0.9958561658859253, 0.981575608253479, 0.9799...   \n",
              "4      [0.9993002414703369, 0.9640201926231384, 0.951...   \n",
              "...                                                  ...   \n",
              "88511  [0.9999812841415405, 0.9580191373825073, 0.915...   \n",
              "88512  [0.9999863505363464, 0.9184243679046631, 0.910...   \n",
              "88513  [0.9997624158859253, 0.9444339871406555, 0.854...   \n",
              "88514  [0.9959811568260193, 0.9808116555213928, 0.971...   \n",
              "88515  [0.974940299987793, 0.9452543258666992, 0.9450...   \n",
              "\n",
              "                                            accent_color  is_bw  \\\n",
              "0      [0.788235294117647, 0.00784313725490196, 0.007...      0   \n",
              "1      [0.6901960784313725, 0.14901960784313725, 0.10...      0   \n",
              "2      [0.6588235294117647, 0.4392156862745098, 0.141...      0   \n",
              "3      [0.24313725490196078, 0.12549019607843137, 0.0...      0   \n",
              "4      [0.792156862745098, 0.7372549019607844, 0.0039...      0   \n",
              "...                                                  ...    ...   \n",
              "88511  [0.6588235294117647, 0.00784313725490196, 0.71...      0   \n",
              "88512  [0.01568627450980392, 0.5098039215686274, 0.78...      0   \n",
              "88513  [0.01568627450980392, 0.2235294117647059, 0.43...      0   \n",
              "88514  [0.6862745098039216, 0.5215686274509804, 0.109...      0   \n",
              "88515  [0.6705882352941176, 0.27058823529411763, 0.12...      0   \n",
              "\n",
              "                                         dominant_colors  \\\n",
              "0           [1.0, 0.7529411764705882, 0.796078431372549]   \n",
              "1      [0.6470588235294118, 0.16470588235294117, 0.16...   \n",
              "2      [0.6470588235294118, 0.16470588235294117, 0.16...   \n",
              "3      [0.6470588235294118, 0.16470588235294117, 0.16...   \n",
              "4                                        [1.0, 1.0, 0.0]   \n",
              "...                                                  ...   \n",
              "88511      [0.5019607843137255, 0.0, 0.5019607843137255]   \n",
              "88512                                    [1.0, 1.0, 1.0]   \n",
              "88513                                    [1.0, 1.0, 0.0]   \n",
              "88514                                    [1.0, 1.0, 1.0]   \n",
              "88515       [1.0, 0.7529411764705882, 0.796078431372549]   \n",
              "\n",
              "                                                bg_color  \\\n",
              "0           [1.0, 0.7529411764705882, 0.796078431372549]   \n",
              "1      [0.6470588235294118, 0.16470588235294117, 0.16...   \n",
              "2      [0.6470588235294118, 0.16470588235294117, 0.16...   \n",
              "3      [0.6470588235294118, 0.16470588235294117, 0.16...   \n",
              "4                                        [1.0, 1.0, 0.0]   \n",
              "...                                                  ...   \n",
              "88511      [0.5019607843137255, 0.0, 0.5019607843137255]   \n",
              "88512                                    [1.0, 1.0, 1.0]   \n",
              "88513                                    [0.0, 0.0, 1.0]   \n",
              "88514                                    [1.0, 1.0, 1.0]   \n",
              "88515                                    [1.0, 1.0, 1.0]   \n",
              "\n",
              "                                              fore_color     industry  \n",
              "0           [1.0, 0.7529411764705882, 0.796078431372549]  hospitality  \n",
              "1                                        [0.0, 0.0, 0.0]  hospitality  \n",
              "2      [0.6470588235294118, 0.16470588235294117, 0.16...  hospitality  \n",
              "3      [0.6470588235294118, 0.16470588235294117, 0.16...  hospitality  \n",
              "4                                        [1.0, 1.0, 0.0]  hospitality  \n",
              "...                                                  ...          ...  \n",
              "88511  [0.5019607843137255, 0.5019607843137255, 0.501...       retail  \n",
              "88512                                    [1.0, 1.0, 1.0]       retail  \n",
              "88513                                    [1.0, 1.0, 0.0]       retail  \n",
              "88514                                    [1.0, 1.0, 1.0]          NaN  \n",
              "88515       [1.0, 0.7529411764705882, 0.796078431372549]          NaN  \n",
              "\n",
              "[88516 rows x 19 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-cefadd55-a125-40f6-82eb-883c9189774b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_type</th>\n",
              "      <th>account</th>\n",
              "      <th>caption</th>\n",
              "      <th>profile_name</th>\n",
              "      <th>biography</th>\n",
              "      <th>following</th>\n",
              "      <th>likes</th>\n",
              "      <th>posts_count</th>\n",
              "      <th>followers</th>\n",
              "      <th>datetime</th>\n",
              "      <th>comments</th>\n",
              "      <th>tags</th>\n",
              "      <th>confidence_score</th>\n",
              "      <th>accent_color</th>\n",
              "      <th>is_bw</th>\n",
              "      <th>dominant_colors</th>\n",
              "      <th>bg_color</th>\n",
              "      <th>fore_color</th>\n",
              "      <th>industry</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>['Ambiguous Clip', 'Not LineDraw']</td>\n",
              "      <td>yeastbakery</td>\n",
              "      <td>It’s our last Pizza Sunday at the arch today. ...</td>\n",
              "      <td>Yeast Bakery</td>\n",
              "      <td>We are now open at our new site: Unit 1 Canal ...</td>\n",
              "      <td>352.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>280.0</td>\n",
              "      <td>8702.0</td>\n",
              "      <td>1.626600e+12</td>\n",
              "      <td>0.0</td>\n",
              "      <td>['text', 'font', 'graphics', 'screenshot', 'gr...</td>\n",
              "      <td>[0.9980798959732056, 0.9481294751167297, 0.881...</td>\n",
              "      <td>[0.788235294117647, 0.00784313725490196, 0.007...</td>\n",
              "      <td>0</td>\n",
              "      <td>[1.0, 0.7529411764705882, 0.796078431372549]</td>\n",
              "      <td>[1.0, 0.7529411764705882, 0.796078431372549]</td>\n",
              "      <td>[1.0, 0.7529411764705882, 0.796078431372549]</td>\n",
              "      <td>hospitality</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>['Not Clip', 'Not LineDraw']</td>\n",
              "      <td>yeastbakery</td>\n",
              "      <td>New cakes on our counters 😋😋</td>\n",
              "      <td>Yeast Bakery</td>\n",
              "      <td>We are now open at our new site: Unit 1 Canal ...</td>\n",
              "      <td>352.0</td>\n",
              "      <td>44.0</td>\n",
              "      <td>280.0</td>\n",
              "      <td>8702.0</td>\n",
              "      <td>1.646920e+12</td>\n",
              "      <td>0.0</td>\n",
              "      <td>['dessert', 'baked goods', 'baking', 'snack', ...</td>\n",
              "      <td>[0.9897554516792297, 0.987897515296936, 0.9828...</td>\n",
              "      <td>[0.6901960784313725, 0.14901960784313725, 0.10...</td>\n",
              "      <td>0</td>\n",
              "      <td>[0.6470588235294118, 0.16470588235294117, 0.16...</td>\n",
              "      <td>[0.6470588235294118, 0.16470588235294117, 0.16...</td>\n",
              "      <td>[0.0, 0.0, 0.0]</td>\n",
              "      <td>hospitality</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>['Not Clip', 'Not LineDraw']</td>\n",
              "      <td>yeastbakery</td>\n",
              "      <td>🔺Opening Times for Half Term🔺: Hi everyone we ...</td>\n",
              "      <td>Yeast Bakery</td>\n",
              "      <td>We are now open at our new site: Unit 1 Canal ...</td>\n",
              "      <td>352.0</td>\n",
              "      <td>209.0</td>\n",
              "      <td>280.0</td>\n",
              "      <td>8702.0</td>\n",
              "      <td>1.634730e+12</td>\n",
              "      <td>9.0</td>\n",
              "      <td>['food', 'fruit', 'baked goods', 'breakfast', ...</td>\n",
              "      <td>[0.9808361530303955, 0.9546540379524231, 0.947...</td>\n",
              "      <td>[0.6588235294117647, 0.4392156862745098, 0.141...</td>\n",
              "      <td>0</td>\n",
              "      <td>[0.6470588235294118, 0.16470588235294117, 0.16...</td>\n",
              "      <td>[0.6470588235294118, 0.16470588235294117, 0.16...</td>\n",
              "      <td>[0.6470588235294118, 0.16470588235294117, 0.16...</td>\n",
              "      <td>hospitality</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>['Not Clip', 'Not LineDraw']</td>\n",
              "      <td>yeastbakery</td>\n",
              "      <td>New addition to our selection of sandwiches, o...</td>\n",
              "      <td>Yeast Bakery</td>\n",
              "      <td>We are now open at our new site: Unit 1 Canal ...</td>\n",
              "      <td>352.0</td>\n",
              "      <td>95.0</td>\n",
              "      <td>280.0</td>\n",
              "      <td>8702.0</td>\n",
              "      <td>1.633090e+12</td>\n",
              "      <td>3.0</td>\n",
              "      <td>['food', 'bread', 'fast food', 'bun', 'america...</td>\n",
              "      <td>[0.9958561658859253, 0.981575608253479, 0.9799...</td>\n",
              "      <td>[0.24313725490196078, 0.12549019607843137, 0.0...</td>\n",
              "      <td>0</td>\n",
              "      <td>[0.6470588235294118, 0.16470588235294117, 0.16...</td>\n",
              "      <td>[0.6470588235294118, 0.16470588235294117, 0.16...</td>\n",
              "      <td>[0.6470588235294118, 0.16470588235294117, 0.16...</td>\n",
              "      <td>hospitality</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>['Ambiguous Clip', 'Not LineDraw']</td>\n",
              "      <td>yeastbakery</td>\n",
              "      <td>We are currently closed as we move into our ne...</td>\n",
              "      <td>Yeast Bakery</td>\n",
              "      <td>We are now open at our new site: Unit 1 Canal ...</td>\n",
              "      <td>352.0</td>\n",
              "      <td>101.0</td>\n",
              "      <td>280.0</td>\n",
              "      <td>8702.0</td>\n",
              "      <td>1.626930e+12</td>\n",
              "      <td>6.0</td>\n",
              "      <td>['text', 'font', 'design', 'yellow', 'graphics...</td>\n",
              "      <td>[0.9993002414703369, 0.9640201926231384, 0.951...</td>\n",
              "      <td>[0.792156862745098, 0.7372549019607844, 0.0039...</td>\n",
              "      <td>0</td>\n",
              "      <td>[1.0, 1.0, 0.0]</td>\n",
              "      <td>[1.0, 1.0, 0.0]</td>\n",
              "      <td>[1.0, 1.0, 0.0]</td>\n",
              "      <td>hospitality</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88511</th>\n",
              "      <td>['Not Clip', 'Not LineDraw']</td>\n",
              "      <td>sandysfishmongers</td>\n",
              "      <td>There’s only one turkey and the best place to ...</td>\n",
              "      <td>Fishmongers/ButchersTwickenham</td>\n",
              "      <td>Local Family Fishmongers &amp; Butchers , fresh fi...</td>\n",
              "      <td>579.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>1863.0</td>\n",
              "      <td>2321.0</td>\n",
              "      <td>1.636550e+12</td>\n",
              "      <td>0.0</td>\n",
              "      <td>['text', 'food', 'snack']</td>\n",
              "      <td>[0.9999812841415405, 0.9580191373825073, 0.915...</td>\n",
              "      <td>[0.6588235294117647, 0.00784313725490196, 0.71...</td>\n",
              "      <td>0</td>\n",
              "      <td>[0.5019607843137255, 0.0, 0.5019607843137255]</td>\n",
              "      <td>[0.5019607843137255, 0.0, 0.5019607843137255]</td>\n",
              "      <td>[0.5019607843137255, 0.5019607843137255, 0.501...</td>\n",
              "      <td>retail</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88512</th>\n",
              "      <td>['Not Clip', 'Not LineDraw']</td>\n",
              "      <td>sandysfishmongers</td>\n",
              "      <td>Day one brochure tour !! #sandysfishmongers #b...</td>\n",
              "      <td>Fishmongers/ButchersTwickenham</td>\n",
              "      <td>Local Family Fishmongers &amp; Butchers , fresh fi...</td>\n",
              "      <td>579.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>1863.0</td>\n",
              "      <td>2321.0</td>\n",
              "      <td>1.636550e+12</td>\n",
              "      <td>0.0</td>\n",
              "      <td>['text', 'poster', 'cartoon']</td>\n",
              "      <td>[0.9999863505363464, 0.9184243679046631, 0.910...</td>\n",
              "      <td>[0.01568627450980392, 0.5098039215686274, 0.78...</td>\n",
              "      <td>0</td>\n",
              "      <td>[1.0, 1.0, 1.0]</td>\n",
              "      <td>[1.0, 1.0, 1.0]</td>\n",
              "      <td>[1.0, 1.0, 1.0]</td>\n",
              "      <td>retail</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88513</th>\n",
              "      <td>['Not Clip', 'Not LineDraw']</td>\n",
              "      <td>sandysfishmongers</td>\n",
              "      <td>A unique amber coloured blue veined cheese , w...</td>\n",
              "      <td>Fishmongers/ButchersTwickenham</td>\n",
              "      <td>Local Family Fishmongers &amp; Butchers , fresh fi...</td>\n",
              "      <td>579.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>1863.0</td>\n",
              "      <td>2321.0</td>\n",
              "      <td>1.636540e+12</td>\n",
              "      <td>2.0</td>\n",
              "      <td>['text', 'yellow', 'packaging and labeling', '...</td>\n",
              "      <td>[0.9997624158859253, 0.9444339871406555, 0.854...</td>\n",
              "      <td>[0.01568627450980392, 0.2235294117647059, 0.43...</td>\n",
              "      <td>0</td>\n",
              "      <td>[1.0, 1.0, 0.0]</td>\n",
              "      <td>[0.0, 0.0, 1.0]</td>\n",
              "      <td>[1.0, 1.0, 0.0]</td>\n",
              "      <td>retail</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88514</th>\n",
              "      <td>['Not Clip', 'Not LineDraw']</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>['sport', 'person', 'barbell', 'physical fitne...</td>\n",
              "      <td>[0.9959811568260193, 0.9808116555213928, 0.971...</td>\n",
              "      <td>[0.6862745098039216, 0.5215686274509804, 0.109...</td>\n",
              "      <td>0</td>\n",
              "      <td>[1.0, 1.0, 1.0]</td>\n",
              "      <td>[1.0, 1.0, 1.0]</td>\n",
              "      <td>[1.0, 1.0, 1.0]</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88515</th>\n",
              "      <td>['Not Clip', 'Not LineDraw']</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>['cosmetics', 'toiletry', 'eyelash', 'skin', '...</td>\n",
              "      <td>[0.974940299987793, 0.9452543258666992, 0.9450...</td>\n",
              "      <td>[0.6705882352941176, 0.27058823529411763, 0.12...</td>\n",
              "      <td>0</td>\n",
              "      <td>[1.0, 0.7529411764705882, 0.796078431372549]</td>\n",
              "      <td>[1.0, 1.0, 1.0]</td>\n",
              "      <td>[1.0, 0.7529411764705882, 0.796078431372549]</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>88516 rows × 19 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cefadd55-a125-40f6-82eb-883c9189774b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-cefadd55-a125-40f6-82eb-883c9189774b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-cefadd55-a125-40f6-82eb-883c9189774b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = df[df['account'].notna()]\n",
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Q8lAB4Ij0bcj",
        "outputId": "5071eccc-62a6-41ef-dbd3-ff744094447e"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                               image_type            account  \\\n",
              "0      ['Ambiguous Clip', 'Not LineDraw']        yeastbakery   \n",
              "1            ['Not Clip', 'Not LineDraw']        yeastbakery   \n",
              "2            ['Not Clip', 'Not LineDraw']        yeastbakery   \n",
              "3            ['Not Clip', 'Not LineDraw']        yeastbakery   \n",
              "4      ['Ambiguous Clip', 'Not LineDraw']        yeastbakery   \n",
              "...                                   ...                ...   \n",
              "88509        ['Not Clip', 'Not LineDraw']  sandysfishmongers   \n",
              "88510        ['Not Clip', 'Not LineDraw']  sandysfishmongers   \n",
              "88511        ['Not Clip', 'Not LineDraw']  sandysfishmongers   \n",
              "88512        ['Not Clip', 'Not LineDraw']  sandysfishmongers   \n",
              "88513        ['Not Clip', 'Not LineDraw']  sandysfishmongers   \n",
              "\n",
              "                                                 caption  \\\n",
              "0      It’s our last Pizza Sunday at the arch today. ...   \n",
              "1                           New cakes on our counters 😋😋   \n",
              "2      🔺Opening Times for Half Term🔺: Hi everyone we ...   \n",
              "3      New addition to our selection of sandwiches, o...   \n",
              "4      We are currently closed as we move into our ne...   \n",
              "...                                                  ...   \n",
              "88509  Day 2 Christmas brochure tour Day one brochure...   \n",
              "88510                #ArmisticeDay #poppy #lestwerespect   \n",
              "88511  There’s only one turkey and the best place to ...   \n",
              "88512  Day one brochure tour !! #sandysfishmongers #b...   \n",
              "88513  A unique amber coloured blue veined cheese , w...   \n",
              "\n",
              "                         profile_name  \\\n",
              "0                        Yeast Bakery   \n",
              "1                        Yeast Bakery   \n",
              "2                        Yeast Bakery   \n",
              "3                        Yeast Bakery   \n",
              "4                        Yeast Bakery   \n",
              "...                               ...   \n",
              "88509  Fishmongers/ButchersTwickenham   \n",
              "88510  Fishmongers/ButchersTwickenham   \n",
              "88511  Fishmongers/ButchersTwickenham   \n",
              "88512  Fishmongers/ButchersTwickenham   \n",
              "88513  Fishmongers/ButchersTwickenham   \n",
              "\n",
              "                                               biography  following  likes  \\\n",
              "0      We are now open at our new site: Unit 1 Canal ...      352.0   29.0   \n",
              "1      We are now open at our new site: Unit 1 Canal ...      352.0   44.0   \n",
              "2      We are now open at our new site: Unit 1 Canal ...      352.0  209.0   \n",
              "3      We are now open at our new site: Unit 1 Canal ...      352.0   95.0   \n",
              "4      We are now open at our new site: Unit 1 Canal ...      352.0  101.0   \n",
              "...                                                  ...        ...    ...   \n",
              "88509  Local Family Fishmongers & Butchers , fresh fi...      579.0   10.0   \n",
              "88510  Local Family Fishmongers & Butchers , fresh fi...      579.0   50.0   \n",
              "88511  Local Family Fishmongers & Butchers , fresh fi...      579.0    8.0   \n",
              "88512  Local Family Fishmongers & Butchers , fresh fi...      579.0    9.0   \n",
              "88513  Local Family Fishmongers & Butchers , fresh fi...      579.0   11.0   \n",
              "\n",
              "       posts_count  followers      datetime  comments  \\\n",
              "0            280.0     8702.0  1.626600e+12       0.0   \n",
              "1            280.0     8702.0  1.646920e+12       0.0   \n",
              "2            280.0     8702.0  1.634730e+12       9.0   \n",
              "3            280.0     8702.0  1.633090e+12       3.0   \n",
              "4            280.0     8702.0  1.626930e+12       6.0   \n",
              "...            ...        ...           ...       ...   \n",
              "88509       1863.0     2321.0  1.636710e+12       1.0   \n",
              "88510       1863.0     2321.0  1.636620e+12       0.0   \n",
              "88511       1863.0     2321.0  1.636550e+12       0.0   \n",
              "88512       1863.0     2321.0  1.636550e+12       0.0   \n",
              "88513       1863.0     2321.0  1.636540e+12       2.0   \n",
              "\n",
              "                                                    tags  \\\n",
              "0      ['text', 'font', 'graphics', 'screenshot', 'gr...   \n",
              "1      ['dessert', 'baked goods', 'baking', 'snack', ...   \n",
              "2      ['food', 'fruit', 'baked goods', 'breakfast', ...   \n",
              "3      ['food', 'bread', 'fast food', 'bun', 'america...   \n",
              "4      ['text', 'font', 'design', 'yellow', 'graphics...   \n",
              "...                                                  ...   \n",
              "88509  ['text', 'book', 'screenshot', 'brochure', 'pr...   \n",
              "88510  ['building', 'text', 'electronic signage', 'ch...   \n",
              "88511                          ['text', 'food', 'snack']   \n",
              "88512                      ['text', 'poster', 'cartoon']   \n",
              "88513  ['text', 'yellow', 'packaging and labeling', '...   \n",
              "\n",
              "                                        confidence_score  \\\n",
              "0      [0.9980798959732056, 0.9481294751167297, 0.881...   \n",
              "1      [0.9897554516792297, 0.987897515296936, 0.9828...   \n",
              "2      [0.9808361530303955, 0.9546540379524231, 0.947...   \n",
              "3      [0.9958561658859253, 0.981575608253479, 0.9799...   \n",
              "4      [0.9993002414703369, 0.9640201926231384, 0.951...   \n",
              "...                                                  ...   \n",
              "88509  [0.9999996423721313, 0.9184167385101318, 0.910...   \n",
              "88510  [0.9849988222122192, 0.9520490169525146, 0.921...   \n",
              "88511  [0.9999812841415405, 0.9580191373825073, 0.915...   \n",
              "88512  [0.9999863505363464, 0.9184243679046631, 0.910...   \n",
              "88513  [0.9997624158859253, 0.9444339871406555, 0.854...   \n",
              "\n",
              "                                            accent_color  is_bw  \\\n",
              "0      [0.788235294117647, 0.00784313725490196, 0.007...      0   \n",
              "1      [0.6901960784313725, 0.14901960784313725, 0.10...      0   \n",
              "2      [0.6588235294117647, 0.4392156862745098, 0.141...      0   \n",
              "3      [0.24313725490196078, 0.12549019607843137, 0.0...      0   \n",
              "4      [0.792156862745098, 0.7372549019607844, 0.0039...      0   \n",
              "...                                                  ...    ...   \n",
              "88509  [0.011764705882352941, 0.5019607843137255, 0.7...      0   \n",
              "88510  [0.6470588235294118, 0.1568627450980392, 0.149...      0   \n",
              "88511  [0.6588235294117647, 0.00784313725490196, 0.71...      0   \n",
              "88512  [0.01568627450980392, 0.5098039215686274, 0.78...      0   \n",
              "88513  [0.01568627450980392, 0.2235294117647059, 0.43...      0   \n",
              "\n",
              "                                         dominant_colors  \\\n",
              "0           [1.0, 0.7529411764705882, 0.796078431372549]   \n",
              "1      [0.6470588235294118, 0.16470588235294117, 0.16...   \n",
              "2      [0.6470588235294118, 0.16470588235294117, 0.16...   \n",
              "3      [0.6470588235294118, 0.16470588235294117, 0.16...   \n",
              "4                                        [1.0, 1.0, 0.0]   \n",
              "...                                                  ...   \n",
              "88509                                    [1.0, 1.0, 1.0]   \n",
              "88510  [0.5019607843137255, 0.5019607843137255, 0.501...   \n",
              "88511      [0.5019607843137255, 0.0, 0.5019607843137255]   \n",
              "88512                                    [1.0, 1.0, 1.0]   \n",
              "88513                                    [1.0, 1.0, 0.0]   \n",
              "\n",
              "                                                bg_color  \\\n",
              "0           [1.0, 0.7529411764705882, 0.796078431372549]   \n",
              "1      [0.6470588235294118, 0.16470588235294117, 0.16...   \n",
              "2      [0.6470588235294118, 0.16470588235294117, 0.16...   \n",
              "3      [0.6470588235294118, 0.16470588235294117, 0.16...   \n",
              "4                                        [1.0, 1.0, 0.0]   \n",
              "...                                                  ...   \n",
              "88509                                    [0.0, 0.0, 1.0]   \n",
              "88510                                    [0.0, 0.0, 0.0]   \n",
              "88511      [0.5019607843137255, 0.0, 0.5019607843137255]   \n",
              "88512                                    [1.0, 1.0, 1.0]   \n",
              "88513                                    [0.0, 0.0, 1.0]   \n",
              "\n",
              "                                              fore_color     industry  \n",
              "0           [1.0, 0.7529411764705882, 0.796078431372549]  hospitality  \n",
              "1                                        [0.0, 0.0, 0.0]  hospitality  \n",
              "2      [0.6470588235294118, 0.16470588235294117, 0.16...  hospitality  \n",
              "3      [0.6470588235294118, 0.16470588235294117, 0.16...  hospitality  \n",
              "4                                        [1.0, 1.0, 0.0]  hospitality  \n",
              "...                                                  ...          ...  \n",
              "88509                                    [1.0, 1.0, 1.0]       retail  \n",
              "88510                                    [1.0, 0.0, 0.0]       retail  \n",
              "88511  [0.5019607843137255, 0.5019607843137255, 0.501...       retail  \n",
              "88512                                    [1.0, 1.0, 1.0]       retail  \n",
              "88513                                    [1.0, 1.0, 0.0]       retail  \n",
              "\n",
              "[88514 rows x 19 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c9da45ed-ec40-456f-ad85-a880660eff87\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_type</th>\n",
              "      <th>account</th>\n",
              "      <th>caption</th>\n",
              "      <th>profile_name</th>\n",
              "      <th>biography</th>\n",
              "      <th>following</th>\n",
              "      <th>likes</th>\n",
              "      <th>posts_count</th>\n",
              "      <th>followers</th>\n",
              "      <th>datetime</th>\n",
              "      <th>comments</th>\n",
              "      <th>tags</th>\n",
              "      <th>confidence_score</th>\n",
              "      <th>accent_color</th>\n",
              "      <th>is_bw</th>\n",
              "      <th>dominant_colors</th>\n",
              "      <th>bg_color</th>\n",
              "      <th>fore_color</th>\n",
              "      <th>industry</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>['Ambiguous Clip', 'Not LineDraw']</td>\n",
              "      <td>yeastbakery</td>\n",
              "      <td>It’s our last Pizza Sunday at the arch today. ...</td>\n",
              "      <td>Yeast Bakery</td>\n",
              "      <td>We are now open at our new site: Unit 1 Canal ...</td>\n",
              "      <td>352.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>280.0</td>\n",
              "      <td>8702.0</td>\n",
              "      <td>1.626600e+12</td>\n",
              "      <td>0.0</td>\n",
              "      <td>['text', 'font', 'graphics', 'screenshot', 'gr...</td>\n",
              "      <td>[0.9980798959732056, 0.9481294751167297, 0.881...</td>\n",
              "      <td>[0.788235294117647, 0.00784313725490196, 0.007...</td>\n",
              "      <td>0</td>\n",
              "      <td>[1.0, 0.7529411764705882, 0.796078431372549]</td>\n",
              "      <td>[1.0, 0.7529411764705882, 0.796078431372549]</td>\n",
              "      <td>[1.0, 0.7529411764705882, 0.796078431372549]</td>\n",
              "      <td>hospitality</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>['Not Clip', 'Not LineDraw']</td>\n",
              "      <td>yeastbakery</td>\n",
              "      <td>New cakes on our counters 😋😋</td>\n",
              "      <td>Yeast Bakery</td>\n",
              "      <td>We are now open at our new site: Unit 1 Canal ...</td>\n",
              "      <td>352.0</td>\n",
              "      <td>44.0</td>\n",
              "      <td>280.0</td>\n",
              "      <td>8702.0</td>\n",
              "      <td>1.646920e+12</td>\n",
              "      <td>0.0</td>\n",
              "      <td>['dessert', 'baked goods', 'baking', 'snack', ...</td>\n",
              "      <td>[0.9897554516792297, 0.987897515296936, 0.9828...</td>\n",
              "      <td>[0.6901960784313725, 0.14901960784313725, 0.10...</td>\n",
              "      <td>0</td>\n",
              "      <td>[0.6470588235294118, 0.16470588235294117, 0.16...</td>\n",
              "      <td>[0.6470588235294118, 0.16470588235294117, 0.16...</td>\n",
              "      <td>[0.0, 0.0, 0.0]</td>\n",
              "      <td>hospitality</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>['Not Clip', 'Not LineDraw']</td>\n",
              "      <td>yeastbakery</td>\n",
              "      <td>🔺Opening Times for Half Term🔺: Hi everyone we ...</td>\n",
              "      <td>Yeast Bakery</td>\n",
              "      <td>We are now open at our new site: Unit 1 Canal ...</td>\n",
              "      <td>352.0</td>\n",
              "      <td>209.0</td>\n",
              "      <td>280.0</td>\n",
              "      <td>8702.0</td>\n",
              "      <td>1.634730e+12</td>\n",
              "      <td>9.0</td>\n",
              "      <td>['food', 'fruit', 'baked goods', 'breakfast', ...</td>\n",
              "      <td>[0.9808361530303955, 0.9546540379524231, 0.947...</td>\n",
              "      <td>[0.6588235294117647, 0.4392156862745098, 0.141...</td>\n",
              "      <td>0</td>\n",
              "      <td>[0.6470588235294118, 0.16470588235294117, 0.16...</td>\n",
              "      <td>[0.6470588235294118, 0.16470588235294117, 0.16...</td>\n",
              "      <td>[0.6470588235294118, 0.16470588235294117, 0.16...</td>\n",
              "      <td>hospitality</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>['Not Clip', 'Not LineDraw']</td>\n",
              "      <td>yeastbakery</td>\n",
              "      <td>New addition to our selection of sandwiches, o...</td>\n",
              "      <td>Yeast Bakery</td>\n",
              "      <td>We are now open at our new site: Unit 1 Canal ...</td>\n",
              "      <td>352.0</td>\n",
              "      <td>95.0</td>\n",
              "      <td>280.0</td>\n",
              "      <td>8702.0</td>\n",
              "      <td>1.633090e+12</td>\n",
              "      <td>3.0</td>\n",
              "      <td>['food', 'bread', 'fast food', 'bun', 'america...</td>\n",
              "      <td>[0.9958561658859253, 0.981575608253479, 0.9799...</td>\n",
              "      <td>[0.24313725490196078, 0.12549019607843137, 0.0...</td>\n",
              "      <td>0</td>\n",
              "      <td>[0.6470588235294118, 0.16470588235294117, 0.16...</td>\n",
              "      <td>[0.6470588235294118, 0.16470588235294117, 0.16...</td>\n",
              "      <td>[0.6470588235294118, 0.16470588235294117, 0.16...</td>\n",
              "      <td>hospitality</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>['Ambiguous Clip', 'Not LineDraw']</td>\n",
              "      <td>yeastbakery</td>\n",
              "      <td>We are currently closed as we move into our ne...</td>\n",
              "      <td>Yeast Bakery</td>\n",
              "      <td>We are now open at our new site: Unit 1 Canal ...</td>\n",
              "      <td>352.0</td>\n",
              "      <td>101.0</td>\n",
              "      <td>280.0</td>\n",
              "      <td>8702.0</td>\n",
              "      <td>1.626930e+12</td>\n",
              "      <td>6.0</td>\n",
              "      <td>['text', 'font', 'design', 'yellow', 'graphics...</td>\n",
              "      <td>[0.9993002414703369, 0.9640201926231384, 0.951...</td>\n",
              "      <td>[0.792156862745098, 0.7372549019607844, 0.0039...</td>\n",
              "      <td>0</td>\n",
              "      <td>[1.0, 1.0, 0.0]</td>\n",
              "      <td>[1.0, 1.0, 0.0]</td>\n",
              "      <td>[1.0, 1.0, 0.0]</td>\n",
              "      <td>hospitality</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88509</th>\n",
              "      <td>['Not Clip', 'Not LineDraw']</td>\n",
              "      <td>sandysfishmongers</td>\n",
              "      <td>Day 2 Christmas brochure tour Day one brochure...</td>\n",
              "      <td>Fishmongers/ButchersTwickenham</td>\n",
              "      <td>Local Family Fishmongers &amp; Butchers , fresh fi...</td>\n",
              "      <td>579.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>1863.0</td>\n",
              "      <td>2321.0</td>\n",
              "      <td>1.636710e+12</td>\n",
              "      <td>1.0</td>\n",
              "      <td>['text', 'book', 'screenshot', 'brochure', 'pr...</td>\n",
              "      <td>[0.9999996423721313, 0.9184167385101318, 0.910...</td>\n",
              "      <td>[0.011764705882352941, 0.5019607843137255, 0.7...</td>\n",
              "      <td>0</td>\n",
              "      <td>[1.0, 1.0, 1.0]</td>\n",
              "      <td>[0.0, 0.0, 1.0]</td>\n",
              "      <td>[1.0, 1.0, 1.0]</td>\n",
              "      <td>retail</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88510</th>\n",
              "      <td>['Not Clip', 'Not LineDraw']</td>\n",
              "      <td>sandysfishmongers</td>\n",
              "      <td>#ArmisticeDay #poppy #lestwerespect</td>\n",
              "      <td>Fishmongers/ButchersTwickenham</td>\n",
              "      <td>Local Family Fishmongers &amp; Butchers , fresh fi...</td>\n",
              "      <td>579.0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>1863.0</td>\n",
              "      <td>2321.0</td>\n",
              "      <td>1.636620e+12</td>\n",
              "      <td>0.0</td>\n",
              "      <td>['building', 'text', 'electronic signage', 'ch...</td>\n",
              "      <td>[0.9849988222122192, 0.9520490169525146, 0.921...</td>\n",
              "      <td>[0.6470588235294118, 0.1568627450980392, 0.149...</td>\n",
              "      <td>0</td>\n",
              "      <td>[0.5019607843137255, 0.5019607843137255, 0.501...</td>\n",
              "      <td>[0.0, 0.0, 0.0]</td>\n",
              "      <td>[1.0, 0.0, 0.0]</td>\n",
              "      <td>retail</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88511</th>\n",
              "      <td>['Not Clip', 'Not LineDraw']</td>\n",
              "      <td>sandysfishmongers</td>\n",
              "      <td>There’s only one turkey and the best place to ...</td>\n",
              "      <td>Fishmongers/ButchersTwickenham</td>\n",
              "      <td>Local Family Fishmongers &amp; Butchers , fresh fi...</td>\n",
              "      <td>579.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>1863.0</td>\n",
              "      <td>2321.0</td>\n",
              "      <td>1.636550e+12</td>\n",
              "      <td>0.0</td>\n",
              "      <td>['text', 'food', 'snack']</td>\n",
              "      <td>[0.9999812841415405, 0.9580191373825073, 0.915...</td>\n",
              "      <td>[0.6588235294117647, 0.00784313725490196, 0.71...</td>\n",
              "      <td>0</td>\n",
              "      <td>[0.5019607843137255, 0.0, 0.5019607843137255]</td>\n",
              "      <td>[0.5019607843137255, 0.0, 0.5019607843137255]</td>\n",
              "      <td>[0.5019607843137255, 0.5019607843137255, 0.501...</td>\n",
              "      <td>retail</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88512</th>\n",
              "      <td>['Not Clip', 'Not LineDraw']</td>\n",
              "      <td>sandysfishmongers</td>\n",
              "      <td>Day one brochure tour !! #sandysfishmongers #b...</td>\n",
              "      <td>Fishmongers/ButchersTwickenham</td>\n",
              "      <td>Local Family Fishmongers &amp; Butchers , fresh fi...</td>\n",
              "      <td>579.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>1863.0</td>\n",
              "      <td>2321.0</td>\n",
              "      <td>1.636550e+12</td>\n",
              "      <td>0.0</td>\n",
              "      <td>['text', 'poster', 'cartoon']</td>\n",
              "      <td>[0.9999863505363464, 0.9184243679046631, 0.910...</td>\n",
              "      <td>[0.01568627450980392, 0.5098039215686274, 0.78...</td>\n",
              "      <td>0</td>\n",
              "      <td>[1.0, 1.0, 1.0]</td>\n",
              "      <td>[1.0, 1.0, 1.0]</td>\n",
              "      <td>[1.0, 1.0, 1.0]</td>\n",
              "      <td>retail</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88513</th>\n",
              "      <td>['Not Clip', 'Not LineDraw']</td>\n",
              "      <td>sandysfishmongers</td>\n",
              "      <td>A unique amber coloured blue veined cheese , w...</td>\n",
              "      <td>Fishmongers/ButchersTwickenham</td>\n",
              "      <td>Local Family Fishmongers &amp; Butchers , fresh fi...</td>\n",
              "      <td>579.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>1863.0</td>\n",
              "      <td>2321.0</td>\n",
              "      <td>1.636540e+12</td>\n",
              "      <td>2.0</td>\n",
              "      <td>['text', 'yellow', 'packaging and labeling', '...</td>\n",
              "      <td>[0.9997624158859253, 0.9444339871406555, 0.854...</td>\n",
              "      <td>[0.01568627450980392, 0.2235294117647059, 0.43...</td>\n",
              "      <td>0</td>\n",
              "      <td>[1.0, 1.0, 0.0]</td>\n",
              "      <td>[0.0, 0.0, 1.0]</td>\n",
              "      <td>[1.0, 1.0, 0.0]</td>\n",
              "      <td>retail</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>88514 rows × 19 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c9da45ed-ec40-456f-ad85-a880660eff87')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c9da45ed-ec40-456f-ad85-a880660eff87 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c9da45ed-ec40-456f-ad85-a880660eff87');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.to_csv('CV.csv')"
      ],
      "metadata": {
        "id": "ui8CFVRs1-y-"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# df=pd.read_csv('/content/drive/MyDrive/NLP/CV.csv')"
      ],
      "metadata": {
        "id": "CnfziC5h2E9_"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# df"
      ],
      "metadata": {
        "id": "hDxBdgQKS7qK"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['caption_length'] = data['caption'].str.len()\n",
        "data['biography_length'] = data['biography'].str.len()\n",
        "# df['caption_upper'] = df['caption'].str.findall(r'[A-Z]').str.len()\n",
        "data['po_co'] = data['posts_count']/(data['comments']+1)\n",
        "data['pof'] = data['posts_count']/(data['following']+1)\n",
        "data['user_count'] = data.groupby('account')['posts_count'].transform('count')\n",
        "data['profile_name_len'] = data['profile_name'].str.len()\n",
        "data['fol'] = data['followers']/(data['following']+1)\n",
        "data['act'] = data['comments']/(data['followers']+1)\n",
        "data['pos'] = data['posts_count']/(data['followers']+1)\n",
        "data['comments_max'] = data.groupby('account')['comments'].transform('max')\n",
        "data['comments_min'] = data.groupby('account')['comments'].transform('min')\n",
        "data['comments_mean'] = data.groupby('account')['comments'].transform('mean')\n",
        "data['comments_std'] = data.groupby('account')['comments'].transform('std')\n",
        "data['comments_followers']=data['comments']*data['followers']\n",
        "data['followers_comments_mean']=data['comments_mean']*data['followers']\n",
        "data['fol2']=data['fol']*data['fol']\n",
        "data['fol_pos']=data['fol']*data['pos']\n",
        "data['fol_pow'] = data['followers']*(data['following'])\n",
        "data['po_co_pow'] = data['posts_count']*(data['comments'])\n",
        "data['comments_mean_diff'] = data['comments'] / (data['comments_mean']+1)"
      ],
      "metadata": {
        "id": "1OKteTUTOZZ5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c5aefa7-414a-4977-9398-8fad6e887c3f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  import sys\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  # Remove the CWD from sys.path while we load stuff.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if sys.path[0] == '':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  del sys.path[0]\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  from ipykernel import kernelapp as app\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:20: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:21: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "2Yb4gN3_uc-N",
        "outputId": "e5ccfe21-933f-4eaf-8a67-2389b6b8421f"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                               image_type            account  \\\n",
              "0      ['Ambiguous Clip', 'Not LineDraw']        yeastbakery   \n",
              "1            ['Not Clip', 'Not LineDraw']        yeastbakery   \n",
              "2            ['Not Clip', 'Not LineDraw']        yeastbakery   \n",
              "3            ['Not Clip', 'Not LineDraw']        yeastbakery   \n",
              "4      ['Ambiguous Clip', 'Not LineDraw']        yeastbakery   \n",
              "...                                   ...                ...   \n",
              "88509        ['Not Clip', 'Not LineDraw']  sandysfishmongers   \n",
              "88510        ['Not Clip', 'Not LineDraw']  sandysfishmongers   \n",
              "88511        ['Not Clip', 'Not LineDraw']  sandysfishmongers   \n",
              "88512        ['Not Clip', 'Not LineDraw']  sandysfishmongers   \n",
              "88513        ['Not Clip', 'Not LineDraw']  sandysfishmongers   \n",
              "\n",
              "                                                 caption  \\\n",
              "0      It’s our last Pizza Sunday at the arch today. ...   \n",
              "1                           New cakes on our counters 😋😋   \n",
              "2      🔺Opening Times for Half Term🔺: Hi everyone we ...   \n",
              "3      New addition to our selection of sandwiches, o...   \n",
              "4      We are currently closed as we move into our ne...   \n",
              "...                                                  ...   \n",
              "88509  Day 2 Christmas brochure tour Day one brochure...   \n",
              "88510                #ArmisticeDay #poppy #lestwerespect   \n",
              "88511  There’s only one turkey and the best place to ...   \n",
              "88512  Day one brochure tour !! #sandysfishmongers #b...   \n",
              "88513  A unique amber coloured blue veined cheese , w...   \n",
              "\n",
              "                         profile_name  \\\n",
              "0                        Yeast Bakery   \n",
              "1                        Yeast Bakery   \n",
              "2                        Yeast Bakery   \n",
              "3                        Yeast Bakery   \n",
              "4                        Yeast Bakery   \n",
              "...                               ...   \n",
              "88509  Fishmongers/ButchersTwickenham   \n",
              "88510  Fishmongers/ButchersTwickenham   \n",
              "88511  Fishmongers/ButchersTwickenham   \n",
              "88512  Fishmongers/ButchersTwickenham   \n",
              "88513  Fishmongers/ButchersTwickenham   \n",
              "\n",
              "                                               biography  following  likes  \\\n",
              "0      We are now open at our new site: Unit 1 Canal ...      352.0   29.0   \n",
              "1      We are now open at our new site: Unit 1 Canal ...      352.0   44.0   \n",
              "2      We are now open at our new site: Unit 1 Canal ...      352.0  209.0   \n",
              "3      We are now open at our new site: Unit 1 Canal ...      352.0   95.0   \n",
              "4      We are now open at our new site: Unit 1 Canal ...      352.0  101.0   \n",
              "...                                                  ...        ...    ...   \n",
              "88509  Local Family Fishmongers & Butchers , fresh fi...      579.0   10.0   \n",
              "88510  Local Family Fishmongers & Butchers , fresh fi...      579.0   50.0   \n",
              "88511  Local Family Fishmongers & Butchers , fresh fi...      579.0    8.0   \n",
              "88512  Local Family Fishmongers & Butchers , fresh fi...      579.0    9.0   \n",
              "88513  Local Family Fishmongers & Butchers , fresh fi...      579.0   11.0   \n",
              "\n",
              "       posts_count  followers      datetime  ...  comments_min comments_mean  \\\n",
              "0            280.0     8702.0  1.626600e+12  ...           0.0       5.85000   \n",
              "1            280.0     8702.0  1.646920e+12  ...           0.0       5.85000   \n",
              "2            280.0     8702.0  1.634730e+12  ...           0.0       5.85000   \n",
              "3            280.0     8702.0  1.633090e+12  ...           0.0       5.85000   \n",
              "4            280.0     8702.0  1.626930e+12  ...           0.0       5.85000   \n",
              "...            ...        ...           ...  ...           ...           ...   \n",
              "88509       1863.0     2321.0  1.636710e+12  ...           0.0       0.81982   \n",
              "88510       1863.0     2321.0  1.636620e+12  ...           0.0       0.81982   \n",
              "88511       1863.0     2321.0  1.636550e+12  ...           0.0       0.81982   \n",
              "88512       1863.0     2321.0  1.636550e+12  ...           0.0       0.81982   \n",
              "88513       1863.0     2321.0  1.636540e+12  ...           0.0       0.81982   \n",
              "\n",
              "      comments_std comments_followers  followers_comments_mean        fol2  \\\n",
              "0         8.949624                0.0             50906.700000  607.699315   \n",
              "1         8.949624                0.0             50906.700000  607.699315   \n",
              "2         8.949624            78318.0             50906.700000  607.699315   \n",
              "3         8.949624            26106.0             50906.700000  607.699315   \n",
              "4         8.949624            52212.0             50906.700000  607.699315   \n",
              "...            ...                ...                      ...         ...   \n",
              "88509     1.063427             2321.0              1902.801802   16.013796   \n",
              "88510     1.063427                0.0              1902.801802   16.013796   \n",
              "88511     1.063427                0.0              1902.801802   16.013796   \n",
              "88512     1.063427                0.0              1902.801802   16.013796   \n",
              "88513     1.063427             4642.0              1902.801802   16.013796   \n",
              "\n",
              "        fol_pos    fol_pow po_co_pow  comments_mean_diff  \n",
              "0      0.793110  3063104.0       0.0            0.000000  \n",
              "1      0.793110  3063104.0       0.0            0.000000  \n",
              "2      0.793110  3063104.0    2520.0            1.313869  \n",
              "3      0.793110  3063104.0     840.0            0.437956  \n",
              "4      0.793110  3063104.0    1680.0            0.875912  \n",
              "...         ...        ...       ...                 ...  \n",
              "88509  3.210686  1343859.0    1863.0            0.549505  \n",
              "88510  3.210686  1343859.0       0.0            0.000000  \n",
              "88511  3.210686  1343859.0       0.0            0.000000  \n",
              "88512  3.210686  1343859.0       0.0            0.000000  \n",
              "88513  3.210686  1343859.0    3726.0            1.099010  \n",
              "\n",
              "[88514 rows x 39 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-16fba2f0-5514-4812-bccd-60cc58da2639\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_type</th>\n",
              "      <th>account</th>\n",
              "      <th>caption</th>\n",
              "      <th>profile_name</th>\n",
              "      <th>biography</th>\n",
              "      <th>following</th>\n",
              "      <th>likes</th>\n",
              "      <th>posts_count</th>\n",
              "      <th>followers</th>\n",
              "      <th>datetime</th>\n",
              "      <th>...</th>\n",
              "      <th>comments_min</th>\n",
              "      <th>comments_mean</th>\n",
              "      <th>comments_std</th>\n",
              "      <th>comments_followers</th>\n",
              "      <th>followers_comments_mean</th>\n",
              "      <th>fol2</th>\n",
              "      <th>fol_pos</th>\n",
              "      <th>fol_pow</th>\n",
              "      <th>po_co_pow</th>\n",
              "      <th>comments_mean_diff</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>['Ambiguous Clip', 'Not LineDraw']</td>\n",
              "      <td>yeastbakery</td>\n",
              "      <td>It’s our last Pizza Sunday at the arch today. ...</td>\n",
              "      <td>Yeast Bakery</td>\n",
              "      <td>We are now open at our new site: Unit 1 Canal ...</td>\n",
              "      <td>352.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>280.0</td>\n",
              "      <td>8702.0</td>\n",
              "      <td>1.626600e+12</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.85000</td>\n",
              "      <td>8.949624</td>\n",
              "      <td>0.0</td>\n",
              "      <td>50906.700000</td>\n",
              "      <td>607.699315</td>\n",
              "      <td>0.793110</td>\n",
              "      <td>3063104.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>['Not Clip', 'Not LineDraw']</td>\n",
              "      <td>yeastbakery</td>\n",
              "      <td>New cakes on our counters 😋😋</td>\n",
              "      <td>Yeast Bakery</td>\n",
              "      <td>We are now open at our new site: Unit 1 Canal ...</td>\n",
              "      <td>352.0</td>\n",
              "      <td>44.0</td>\n",
              "      <td>280.0</td>\n",
              "      <td>8702.0</td>\n",
              "      <td>1.646920e+12</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.85000</td>\n",
              "      <td>8.949624</td>\n",
              "      <td>0.0</td>\n",
              "      <td>50906.700000</td>\n",
              "      <td>607.699315</td>\n",
              "      <td>0.793110</td>\n",
              "      <td>3063104.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>['Not Clip', 'Not LineDraw']</td>\n",
              "      <td>yeastbakery</td>\n",
              "      <td>🔺Opening Times for Half Term🔺: Hi everyone we ...</td>\n",
              "      <td>Yeast Bakery</td>\n",
              "      <td>We are now open at our new site: Unit 1 Canal ...</td>\n",
              "      <td>352.0</td>\n",
              "      <td>209.0</td>\n",
              "      <td>280.0</td>\n",
              "      <td>8702.0</td>\n",
              "      <td>1.634730e+12</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.85000</td>\n",
              "      <td>8.949624</td>\n",
              "      <td>78318.0</td>\n",
              "      <td>50906.700000</td>\n",
              "      <td>607.699315</td>\n",
              "      <td>0.793110</td>\n",
              "      <td>3063104.0</td>\n",
              "      <td>2520.0</td>\n",
              "      <td>1.313869</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>['Not Clip', 'Not LineDraw']</td>\n",
              "      <td>yeastbakery</td>\n",
              "      <td>New addition to our selection of sandwiches, o...</td>\n",
              "      <td>Yeast Bakery</td>\n",
              "      <td>We are now open at our new site: Unit 1 Canal ...</td>\n",
              "      <td>352.0</td>\n",
              "      <td>95.0</td>\n",
              "      <td>280.0</td>\n",
              "      <td>8702.0</td>\n",
              "      <td>1.633090e+12</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.85000</td>\n",
              "      <td>8.949624</td>\n",
              "      <td>26106.0</td>\n",
              "      <td>50906.700000</td>\n",
              "      <td>607.699315</td>\n",
              "      <td>0.793110</td>\n",
              "      <td>3063104.0</td>\n",
              "      <td>840.0</td>\n",
              "      <td>0.437956</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>['Ambiguous Clip', 'Not LineDraw']</td>\n",
              "      <td>yeastbakery</td>\n",
              "      <td>We are currently closed as we move into our ne...</td>\n",
              "      <td>Yeast Bakery</td>\n",
              "      <td>We are now open at our new site: Unit 1 Canal ...</td>\n",
              "      <td>352.0</td>\n",
              "      <td>101.0</td>\n",
              "      <td>280.0</td>\n",
              "      <td>8702.0</td>\n",
              "      <td>1.626930e+12</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.85000</td>\n",
              "      <td>8.949624</td>\n",
              "      <td>52212.0</td>\n",
              "      <td>50906.700000</td>\n",
              "      <td>607.699315</td>\n",
              "      <td>0.793110</td>\n",
              "      <td>3063104.0</td>\n",
              "      <td>1680.0</td>\n",
              "      <td>0.875912</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88509</th>\n",
              "      <td>['Not Clip', 'Not LineDraw']</td>\n",
              "      <td>sandysfishmongers</td>\n",
              "      <td>Day 2 Christmas brochure tour Day one brochure...</td>\n",
              "      <td>Fishmongers/ButchersTwickenham</td>\n",
              "      <td>Local Family Fishmongers &amp; Butchers , fresh fi...</td>\n",
              "      <td>579.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>1863.0</td>\n",
              "      <td>2321.0</td>\n",
              "      <td>1.636710e+12</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.81982</td>\n",
              "      <td>1.063427</td>\n",
              "      <td>2321.0</td>\n",
              "      <td>1902.801802</td>\n",
              "      <td>16.013796</td>\n",
              "      <td>3.210686</td>\n",
              "      <td>1343859.0</td>\n",
              "      <td>1863.0</td>\n",
              "      <td>0.549505</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88510</th>\n",
              "      <td>['Not Clip', 'Not LineDraw']</td>\n",
              "      <td>sandysfishmongers</td>\n",
              "      <td>#ArmisticeDay #poppy #lestwerespect</td>\n",
              "      <td>Fishmongers/ButchersTwickenham</td>\n",
              "      <td>Local Family Fishmongers &amp; Butchers , fresh fi...</td>\n",
              "      <td>579.0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>1863.0</td>\n",
              "      <td>2321.0</td>\n",
              "      <td>1.636620e+12</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.81982</td>\n",
              "      <td>1.063427</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1902.801802</td>\n",
              "      <td>16.013796</td>\n",
              "      <td>3.210686</td>\n",
              "      <td>1343859.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88511</th>\n",
              "      <td>['Not Clip', 'Not LineDraw']</td>\n",
              "      <td>sandysfishmongers</td>\n",
              "      <td>There’s only one turkey and the best place to ...</td>\n",
              "      <td>Fishmongers/ButchersTwickenham</td>\n",
              "      <td>Local Family Fishmongers &amp; Butchers , fresh fi...</td>\n",
              "      <td>579.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>1863.0</td>\n",
              "      <td>2321.0</td>\n",
              "      <td>1.636550e+12</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.81982</td>\n",
              "      <td>1.063427</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1902.801802</td>\n",
              "      <td>16.013796</td>\n",
              "      <td>3.210686</td>\n",
              "      <td>1343859.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88512</th>\n",
              "      <td>['Not Clip', 'Not LineDraw']</td>\n",
              "      <td>sandysfishmongers</td>\n",
              "      <td>Day one brochure tour !! #sandysfishmongers #b...</td>\n",
              "      <td>Fishmongers/ButchersTwickenham</td>\n",
              "      <td>Local Family Fishmongers &amp; Butchers , fresh fi...</td>\n",
              "      <td>579.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>1863.0</td>\n",
              "      <td>2321.0</td>\n",
              "      <td>1.636550e+12</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.81982</td>\n",
              "      <td>1.063427</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1902.801802</td>\n",
              "      <td>16.013796</td>\n",
              "      <td>3.210686</td>\n",
              "      <td>1343859.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88513</th>\n",
              "      <td>['Not Clip', 'Not LineDraw']</td>\n",
              "      <td>sandysfishmongers</td>\n",
              "      <td>A unique amber coloured blue veined cheese , w...</td>\n",
              "      <td>Fishmongers/ButchersTwickenham</td>\n",
              "      <td>Local Family Fishmongers &amp; Butchers , fresh fi...</td>\n",
              "      <td>579.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>1863.0</td>\n",
              "      <td>2321.0</td>\n",
              "      <td>1.636540e+12</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.81982</td>\n",
              "      <td>1.063427</td>\n",
              "      <td>4642.0</td>\n",
              "      <td>1902.801802</td>\n",
              "      <td>16.013796</td>\n",
              "      <td>3.210686</td>\n",
              "      <td>1343859.0</td>\n",
              "      <td>3726.0</td>\n",
              "      <td>1.099010</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>88514 rows × 39 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-16fba2f0-5514-4812-bccd-60cc58da2639')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-16fba2f0-5514-4812-bccd-60cc58da2639 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-16fba2f0-5514-4812-bccd-60cc58da2639');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(data.account.unique())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_KOIkg-31dmC",
        "outputId": "78b96d6c-a1c2-4d9c-c1f3-54e88156c500"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "981"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# df.drop(['account'], axis = 1,inplace=True)\n",
        "# df.drop(['caption'], axis = 1,inplace=True)\n",
        "\n",
        "data.drop(['profile_name'], axis = 1,inplace=True)\n",
        "data.drop(['biography'], axis = 1,inplace=True)"
      ],
      "metadata": {
        "id": "-1dT6cVSaJB_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75727a3c-dfb3-4f58-a3c3-0bdeb6ac94a6"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py:4913: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  errors=errors,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ySQ05ib6D-2O",
        "outputId": "7792c4e0-e603-4300-cb1e-a75fdbead048"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                         Total Missing Values  Missing %\n",
              "image_type                                  0   0.000000\n",
              "account                                     0   0.000000\n",
              "caption                                   330   0.372822\n",
              "following                                   0   0.000000\n",
              "likes                                       0   0.000000\n",
              "posts_count                                 0   0.000000\n",
              "followers                                   0   0.000000\n",
              "datetime                                    0   0.000000\n",
              "comments                                    0   0.000000\n",
              "tags                                        0   0.000000\n",
              "confidence_score                            0   0.000000\n",
              "accent_color                                0   0.000000\n",
              "is_bw                                       0   0.000000\n",
              "dominant_colors                             0   0.000000\n",
              "bg_color                                    0   0.000000\n",
              "fore_color                                  0   0.000000\n",
              "industry                                41907  47.345053\n",
              "caption_length                            330   0.372822\n",
              "biography_length                         1645   1.858463\n",
              "po_co                                       0   0.000000\n",
              "pof                                         0   0.000000\n",
              "user_count                                  0   0.000000\n",
              "profile_name_len                          426   0.481280\n",
              "fol                                         0   0.000000\n",
              "act                                         0   0.000000\n",
              "pos                                         0   0.000000\n",
              "comments_max                                0   0.000000\n",
              "comments_min                                0   0.000000\n",
              "comments_mean                               0   0.000000\n",
              "comments_std                                3   0.003389\n",
              "comments_followers                          0   0.000000\n",
              "followers_comments_mean                     0   0.000000\n",
              "fol2                                        0   0.000000\n",
              "fol_pos                                     0   0.000000\n",
              "fol_pow                                     0   0.000000\n",
              "po_co_pow                                   0   0.000000\n",
              "comments_mean_diff                          0   0.000000"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-51f6aeae-da91-4050-96da-a2f07f0a532b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Total Missing Values</th>\n",
              "      <th>Missing %</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>image_type</th>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>account</th>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>caption</th>\n",
              "      <td>330</td>\n",
              "      <td>0.372822</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>following</th>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>likes</th>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>posts_count</th>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>followers</th>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>datetime</th>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>comments</th>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>tags</th>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>confidence_score</th>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>accent_color</th>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>is_bw</th>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>dominant_colors</th>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>bg_color</th>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>fore_color</th>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>industry</th>\n",
              "      <td>41907</td>\n",
              "      <td>47.345053</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>caption_length</th>\n",
              "      <td>330</td>\n",
              "      <td>0.372822</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>biography_length</th>\n",
              "      <td>1645</td>\n",
              "      <td>1.858463</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>po_co</th>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>pof</th>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>user_count</th>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>profile_name_len</th>\n",
              "      <td>426</td>\n",
              "      <td>0.481280</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>fol</th>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>act</th>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>pos</th>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>comments_max</th>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>comments_min</th>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>comments_mean</th>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>comments_std</th>\n",
              "      <td>3</td>\n",
              "      <td>0.003389</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>comments_followers</th>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>followers_comments_mean</th>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>fol2</th>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>fol_pos</th>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>fol_pow</th>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>po_co_pow</th>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>comments_mean_diff</th>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-51f6aeae-da91-4050-96da-a2f07f0a532b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-51f6aeae-da91-4050-96da-a2f07f0a532b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-51f6aeae-da91-4050-96da-a2f07f0a532b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "#calculating missing values in the dataset\n",
        "def missing_Values(data):\n",
        "  missing_values = data.isnull().sum()\n",
        "  missing_per = (missing_values/data.shape[0])*100\n",
        "  missing_table = pd.concat([missing_values,missing_per], axis=1, ignore_index=True) \n",
        "  missing_table.rename(columns={0:'Total Missing Values',1:'Missing %'}, inplace=True)\n",
        "  return missing_table\n",
        "\n",
        "missing_Values(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "NFwMDejGFY-V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4160aa2-2b4b-41b3-af75-6f4a25cf9318"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ]
        }
      ],
      "source": [
        "#fill the missing values with zero\n",
        "\n",
        "data['likes'] = data['likes'].fillna(0)\n",
        "data['biography_length'] = data['biography_length'].fillna(0)\n",
        "data['profile_name_len'] = data['profile_name_len'].fillna(0)\n",
        "data['caption_length'] = data['caption_length'].fillna(0)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#calculating missing values in the dataset\n",
        "missing_Values(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "zsdgZlWZ6BBh",
        "outputId": "ca4bd976-b56d-4f8c-e013-7f9c1dfd494d"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                         Total Missing Values  Missing %\n",
              "image_type                                  0   0.000000\n",
              "account                                     0   0.000000\n",
              "caption                                   330   0.372822\n",
              "following                                   0   0.000000\n",
              "likes                                       0   0.000000\n",
              "posts_count                                 0   0.000000\n",
              "followers                                   0   0.000000\n",
              "datetime                                    0   0.000000\n",
              "comments                                    0   0.000000\n",
              "tags                                        0   0.000000\n",
              "confidence_score                            0   0.000000\n",
              "accent_color                                0   0.000000\n",
              "is_bw                                       0   0.000000\n",
              "dominant_colors                             0   0.000000\n",
              "bg_color                                    0   0.000000\n",
              "fore_color                                  0   0.000000\n",
              "industry                                41907  47.345053\n",
              "caption_length                              0   0.000000\n",
              "biography_length                            0   0.000000\n",
              "po_co                                       0   0.000000\n",
              "pof                                         0   0.000000\n",
              "user_count                                  0   0.000000\n",
              "profile_name_len                            0   0.000000\n",
              "fol                                         0   0.000000\n",
              "act                                         0   0.000000\n",
              "pos                                         0   0.000000\n",
              "comments_max                                0   0.000000\n",
              "comments_min                                0   0.000000\n",
              "comments_mean                               0   0.000000\n",
              "comments_std                                3   0.003389\n",
              "comments_followers                          0   0.000000\n",
              "followers_comments_mean                     0   0.000000\n",
              "fol2                                        0   0.000000\n",
              "fol_pos                                     0   0.000000\n",
              "fol_pow                                     0   0.000000\n",
              "po_co_pow                                   0   0.000000\n",
              "comments_mean_diff                          0   0.000000"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f8c4aef1-4753-4c98-bfd2-4f2093da7627\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Total Missing Values</th>\n",
              "      <th>Missing %</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>image_type</th>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>account</th>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>caption</th>\n",
              "      <td>330</td>\n",
              "      <td>0.372822</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>following</th>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>likes</th>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>posts_count</th>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>followers</th>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>datetime</th>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>comments</th>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>tags</th>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>confidence_score</th>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>accent_color</th>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>is_bw</th>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>dominant_colors</th>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>bg_color</th>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>fore_color</th>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>industry</th>\n",
              "      <td>41907</td>\n",
              "      <td>47.345053</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>caption_length</th>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>biography_length</th>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>po_co</th>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>pof</th>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>user_count</th>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>profile_name_len</th>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>fol</th>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>act</th>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>pos</th>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>comments_max</th>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>comments_min</th>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>comments_mean</th>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>comments_std</th>\n",
              "      <td>3</td>\n",
              "      <td>0.003389</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>comments_followers</th>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>followers_comments_mean</th>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>fol2</th>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>fol_pos</th>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>fol_pow</th>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>po_co_pow</th>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>comments_mean_diff</th>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f8c4aef1-4753-4c98-bfd2-4f2093da7627')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f8c4aef1-4753-4c98-bfd2-4f2093da7627 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f8c4aef1-4753-4c98-bfd2-4f2093da7627');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MetaFeatures"
      ],
      "metadata": {
        "id": "UiF6gFlMu13z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df1=data"
      ],
      "metadata": {
        "id": "sH-db7sso22e"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1 = df[df['datetime'].notna()]"
      ],
      "metadata": {
        "id": "lcYdmws2u4Li"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import datetime\n",
        "def timeStampConversion(x):\n",
        "    return datetime.datetime.fromtimestamp(int(x)/1000)\n",
        "\n",
        "df1['datetime'] = pd.to_numeric(df1['datetime'], downcast=\"float\")\n",
        "df1['datetime'] = df1['datetime'].apply(lambda x: timeStampConversion(x)) \n",
        "df1[\"datetime\"] = pd.to_datetime(df1[\"datetime\"])"
      ],
      "metadata": {
        "id": "Vy-00dQXvD64",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a72ac67-d022-41e6-89e5-891616481f9b"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  import sys\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df1['Dow'] = df1['datetime'].dt.weekday\n",
        "df1['Hod']= df1['datetime'].dt.hour\n",
        "df1['Date']= df1['datetime'].dt.date"
      ],
      "metadata": {
        "id": "nfxTAAfwxkZp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac50ddff-79b6-40eb-d047-5773c3b4fa96"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df1['mon']=(df1['Dow']==0).astype(int)\n",
        "df1['tue']=(df1['Dow']==1).astype(int)\n",
        "df1['wed']=(df1['Dow']==2).astype(int)\n",
        "df1['thu']=(df1['Dow']==3).astype(int)\n",
        "df1['fri']=(df1['Dow']==4).astype(int)  \n",
        "df1['sat']=(df1['Dow']==5).astype(int)\n",
        "df1['sun']=(df1['Dow']==6).astype(int)"
      ],
      "metadata": {
        "id": "Pxy7DllmwcL6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4970289f-d848-44ef-839c-e2395fa1975a"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  import sys\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 988
        },
        "id": "N3nv1lPVyrn8",
        "outputId": "6c3c0ff6-ff90-494c-bbf9-b44fc7f8b853"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                               image_type            account  \\\n",
              "0      ['Ambiguous Clip', 'Not LineDraw']        yeastbakery   \n",
              "1            ['Not Clip', 'Not LineDraw']        yeastbakery   \n",
              "2            ['Not Clip', 'Not LineDraw']        yeastbakery   \n",
              "3            ['Not Clip', 'Not LineDraw']        yeastbakery   \n",
              "4      ['Ambiguous Clip', 'Not LineDraw']        yeastbakery   \n",
              "...                                   ...                ...   \n",
              "88509        ['Not Clip', 'Not LineDraw']  sandysfishmongers   \n",
              "88510        ['Not Clip', 'Not LineDraw']  sandysfishmongers   \n",
              "88511        ['Not Clip', 'Not LineDraw']  sandysfishmongers   \n",
              "88512        ['Not Clip', 'Not LineDraw']  sandysfishmongers   \n",
              "88513        ['Not Clip', 'Not LineDraw']  sandysfishmongers   \n",
              "\n",
              "                                                 caption  \\\n",
              "0      It’s our last Pizza Sunday at the arch today. ...   \n",
              "1                           New cakes on our counters 😋😋   \n",
              "2      🔺Opening Times for Half Term🔺: Hi everyone we ...   \n",
              "3      New addition to our selection of sandwiches, o...   \n",
              "4      We are currently closed as we move into our ne...   \n",
              "...                                                  ...   \n",
              "88509  Day 2 Christmas brochure tour Day one brochure...   \n",
              "88510                #ArmisticeDay #poppy #lestwerespect   \n",
              "88511  There’s only one turkey and the best place to ...   \n",
              "88512  Day one brochure tour !! #sandysfishmongers #b...   \n",
              "88513  A unique amber coloured blue veined cheese , w...   \n",
              "\n",
              "                         profile_name  \\\n",
              "0                        Yeast Bakery   \n",
              "1                        Yeast Bakery   \n",
              "2                        Yeast Bakery   \n",
              "3                        Yeast Bakery   \n",
              "4                        Yeast Bakery   \n",
              "...                               ...   \n",
              "88509  Fishmongers/ButchersTwickenham   \n",
              "88510  Fishmongers/ButchersTwickenham   \n",
              "88511  Fishmongers/ButchersTwickenham   \n",
              "88512  Fishmongers/ButchersTwickenham   \n",
              "88513  Fishmongers/ButchersTwickenham   \n",
              "\n",
              "                                               biography  following  likes  \\\n",
              "0      We are now open at our new site: Unit 1 Canal ...      352.0   29.0   \n",
              "1      We are now open at our new site: Unit 1 Canal ...      352.0   44.0   \n",
              "2      We are now open at our new site: Unit 1 Canal ...      352.0  209.0   \n",
              "3      We are now open at our new site: Unit 1 Canal ...      352.0   95.0   \n",
              "4      We are now open at our new site: Unit 1 Canal ...      352.0  101.0   \n",
              "...                                                  ...        ...    ...   \n",
              "88509  Local Family Fishmongers & Butchers , fresh fi...      579.0   10.0   \n",
              "88510  Local Family Fishmongers & Butchers , fresh fi...      579.0   50.0   \n",
              "88511  Local Family Fishmongers & Butchers , fresh fi...      579.0    8.0   \n",
              "88512  Local Family Fishmongers & Butchers , fresh fi...      579.0    9.0   \n",
              "88513  Local Family Fishmongers & Butchers , fresh fi...      579.0   11.0   \n",
              "\n",
              "       posts_count  followers                datetime  ...  Dow Hod  \\\n",
              "0            280.0     8702.0 2021-07-18 09:19:41.056  ...    6   9   \n",
              "1            280.0     8702.0 2022-03-10 13:45:42.144  ...    3  13   \n",
              "2            280.0     8702.0 2021-10-20 11:39:44.000  ...    2  11   \n",
              "3            280.0     8702.0 2021-10-01 12:06:51.136  ...    4  12   \n",
              "4            280.0     8702.0 2021-07-22 05:00:20.352  ...    3   5   \n",
              "...            ...        ...                     ...  ...  ...  ..   \n",
              "88509       1863.0     2321.0 2021-11-12 09:39:17.632  ...    4   9   \n",
              "88510       1863.0     2321.0 2021-11-11 08:40:42.240  ...    3   8   \n",
              "88511       1863.0     2321.0 2021-11-10 13:14:09.792  ...    2  13   \n",
              "88512       1863.0     2321.0 2021-11-10 13:14:09.792  ...    2  13   \n",
              "88513       1863.0     2321.0 2021-11-10 10:25:57.248  ...    2  10   \n",
              "\n",
              "             Date mon  tue wed thu fri sat  sun  \n",
              "0      2021-07-18   0    0   0   0   0   0    1  \n",
              "1      2022-03-10   0    0   0   1   0   0    0  \n",
              "2      2021-10-20   0    0   1   0   0   0    0  \n",
              "3      2021-10-01   0    0   0   0   1   0    0  \n",
              "4      2021-07-22   0    0   0   1   0   0    0  \n",
              "...           ...  ..  ...  ..  ..  ..  ..  ...  \n",
              "88509  2021-11-12   0    0   0   0   1   0    0  \n",
              "88510  2021-11-11   0    0   0   1   0   0    0  \n",
              "88511  2021-11-10   0    0   1   0   0   0    0  \n",
              "88512  2021-11-10   0    0   1   0   0   0    0  \n",
              "88513  2021-11-10   0    0   1   0   0   0    0  \n",
              "\n",
              "[88514 rows x 29 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0db644ec-6ce7-44c4-8b4f-eff8ac85fea2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_type</th>\n",
              "      <th>account</th>\n",
              "      <th>caption</th>\n",
              "      <th>profile_name</th>\n",
              "      <th>biography</th>\n",
              "      <th>following</th>\n",
              "      <th>likes</th>\n",
              "      <th>posts_count</th>\n",
              "      <th>followers</th>\n",
              "      <th>datetime</th>\n",
              "      <th>...</th>\n",
              "      <th>Dow</th>\n",
              "      <th>Hod</th>\n",
              "      <th>Date</th>\n",
              "      <th>mon</th>\n",
              "      <th>tue</th>\n",
              "      <th>wed</th>\n",
              "      <th>thu</th>\n",
              "      <th>fri</th>\n",
              "      <th>sat</th>\n",
              "      <th>sun</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>['Ambiguous Clip', 'Not LineDraw']</td>\n",
              "      <td>yeastbakery</td>\n",
              "      <td>It’s our last Pizza Sunday at the arch today. ...</td>\n",
              "      <td>Yeast Bakery</td>\n",
              "      <td>We are now open at our new site: Unit 1 Canal ...</td>\n",
              "      <td>352.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>280.0</td>\n",
              "      <td>8702.0</td>\n",
              "      <td>2021-07-18 09:19:41.056</td>\n",
              "      <td>...</td>\n",
              "      <td>6</td>\n",
              "      <td>9</td>\n",
              "      <td>2021-07-18</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>['Not Clip', 'Not LineDraw']</td>\n",
              "      <td>yeastbakery</td>\n",
              "      <td>New cakes on our counters 😋😋</td>\n",
              "      <td>Yeast Bakery</td>\n",
              "      <td>We are now open at our new site: Unit 1 Canal ...</td>\n",
              "      <td>352.0</td>\n",
              "      <td>44.0</td>\n",
              "      <td>280.0</td>\n",
              "      <td>8702.0</td>\n",
              "      <td>2022-03-10 13:45:42.144</td>\n",
              "      <td>...</td>\n",
              "      <td>3</td>\n",
              "      <td>13</td>\n",
              "      <td>2022-03-10</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>['Not Clip', 'Not LineDraw']</td>\n",
              "      <td>yeastbakery</td>\n",
              "      <td>🔺Opening Times for Half Term🔺: Hi everyone we ...</td>\n",
              "      <td>Yeast Bakery</td>\n",
              "      <td>We are now open at our new site: Unit 1 Canal ...</td>\n",
              "      <td>352.0</td>\n",
              "      <td>209.0</td>\n",
              "      <td>280.0</td>\n",
              "      <td>8702.0</td>\n",
              "      <td>2021-10-20 11:39:44.000</td>\n",
              "      <td>...</td>\n",
              "      <td>2</td>\n",
              "      <td>11</td>\n",
              "      <td>2021-10-20</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>['Not Clip', 'Not LineDraw']</td>\n",
              "      <td>yeastbakery</td>\n",
              "      <td>New addition to our selection of sandwiches, o...</td>\n",
              "      <td>Yeast Bakery</td>\n",
              "      <td>We are now open at our new site: Unit 1 Canal ...</td>\n",
              "      <td>352.0</td>\n",
              "      <td>95.0</td>\n",
              "      <td>280.0</td>\n",
              "      <td>8702.0</td>\n",
              "      <td>2021-10-01 12:06:51.136</td>\n",
              "      <td>...</td>\n",
              "      <td>4</td>\n",
              "      <td>12</td>\n",
              "      <td>2021-10-01</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>['Ambiguous Clip', 'Not LineDraw']</td>\n",
              "      <td>yeastbakery</td>\n",
              "      <td>We are currently closed as we move into our ne...</td>\n",
              "      <td>Yeast Bakery</td>\n",
              "      <td>We are now open at our new site: Unit 1 Canal ...</td>\n",
              "      <td>352.0</td>\n",
              "      <td>101.0</td>\n",
              "      <td>280.0</td>\n",
              "      <td>8702.0</td>\n",
              "      <td>2021-07-22 05:00:20.352</td>\n",
              "      <td>...</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>2021-07-22</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88509</th>\n",
              "      <td>['Not Clip', 'Not LineDraw']</td>\n",
              "      <td>sandysfishmongers</td>\n",
              "      <td>Day 2 Christmas brochure tour Day one brochure...</td>\n",
              "      <td>Fishmongers/ButchersTwickenham</td>\n",
              "      <td>Local Family Fishmongers &amp; Butchers , fresh fi...</td>\n",
              "      <td>579.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>1863.0</td>\n",
              "      <td>2321.0</td>\n",
              "      <td>2021-11-12 09:39:17.632</td>\n",
              "      <td>...</td>\n",
              "      <td>4</td>\n",
              "      <td>9</td>\n",
              "      <td>2021-11-12</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88510</th>\n",
              "      <td>['Not Clip', 'Not LineDraw']</td>\n",
              "      <td>sandysfishmongers</td>\n",
              "      <td>#ArmisticeDay #poppy #lestwerespect</td>\n",
              "      <td>Fishmongers/ButchersTwickenham</td>\n",
              "      <td>Local Family Fishmongers &amp; Butchers , fresh fi...</td>\n",
              "      <td>579.0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>1863.0</td>\n",
              "      <td>2321.0</td>\n",
              "      <td>2021-11-11 08:40:42.240</td>\n",
              "      <td>...</td>\n",
              "      <td>3</td>\n",
              "      <td>8</td>\n",
              "      <td>2021-11-11</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88511</th>\n",
              "      <td>['Not Clip', 'Not LineDraw']</td>\n",
              "      <td>sandysfishmongers</td>\n",
              "      <td>There’s only one turkey and the best place to ...</td>\n",
              "      <td>Fishmongers/ButchersTwickenham</td>\n",
              "      <td>Local Family Fishmongers &amp; Butchers , fresh fi...</td>\n",
              "      <td>579.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>1863.0</td>\n",
              "      <td>2321.0</td>\n",
              "      <td>2021-11-10 13:14:09.792</td>\n",
              "      <td>...</td>\n",
              "      <td>2</td>\n",
              "      <td>13</td>\n",
              "      <td>2021-11-10</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88512</th>\n",
              "      <td>['Not Clip', 'Not LineDraw']</td>\n",
              "      <td>sandysfishmongers</td>\n",
              "      <td>Day one brochure tour !! #sandysfishmongers #b...</td>\n",
              "      <td>Fishmongers/ButchersTwickenham</td>\n",
              "      <td>Local Family Fishmongers &amp; Butchers , fresh fi...</td>\n",
              "      <td>579.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>1863.0</td>\n",
              "      <td>2321.0</td>\n",
              "      <td>2021-11-10 13:14:09.792</td>\n",
              "      <td>...</td>\n",
              "      <td>2</td>\n",
              "      <td>13</td>\n",
              "      <td>2021-11-10</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88513</th>\n",
              "      <td>['Not Clip', 'Not LineDraw']</td>\n",
              "      <td>sandysfishmongers</td>\n",
              "      <td>A unique amber coloured blue veined cheese , w...</td>\n",
              "      <td>Fishmongers/ButchersTwickenham</td>\n",
              "      <td>Local Family Fishmongers &amp; Butchers , fresh fi...</td>\n",
              "      <td>579.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>1863.0</td>\n",
              "      <td>2321.0</td>\n",
              "      <td>2021-11-10 10:25:57.248</td>\n",
              "      <td>...</td>\n",
              "      <td>2</td>\n",
              "      <td>10</td>\n",
              "      <td>2021-11-10</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>88514 rows × 29 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0db644ec-6ce7-44c4-8b4f-eff8ac85fea2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0db644ec-6ce7-44c4-8b4f-eff8ac85fea2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0db644ec-6ce7-44c4-8b4f-eff8ac85fea2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.get_dummies(df1, columns=['industry'])"
      ],
      "metadata": {
        "id": "MUM0vpIT0osS"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "7lN3zawW1Tw5",
        "outputId": "89baa91f-d289-4b9a-c680-d0296bcd8fab"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                               image_type            account  \\\n",
              "0      ['Ambiguous Clip', 'Not LineDraw']        yeastbakery   \n",
              "1            ['Not Clip', 'Not LineDraw']        yeastbakery   \n",
              "2            ['Not Clip', 'Not LineDraw']        yeastbakery   \n",
              "3            ['Not Clip', 'Not LineDraw']        yeastbakery   \n",
              "4      ['Ambiguous Clip', 'Not LineDraw']        yeastbakery   \n",
              "...                                   ...                ...   \n",
              "88509        ['Not Clip', 'Not LineDraw']  sandysfishmongers   \n",
              "88510        ['Not Clip', 'Not LineDraw']  sandysfishmongers   \n",
              "88511        ['Not Clip', 'Not LineDraw']  sandysfishmongers   \n",
              "88512        ['Not Clip', 'Not LineDraw']  sandysfishmongers   \n",
              "88513        ['Not Clip', 'Not LineDraw']  sandysfishmongers   \n",
              "\n",
              "                                                 caption  \\\n",
              "0      It’s our last Pizza Sunday at the arch today. ...   \n",
              "1                           New cakes on our counters 😋😋   \n",
              "2      🔺Opening Times for Half Term🔺: Hi everyone we ...   \n",
              "3      New addition to our selection of sandwiches, o...   \n",
              "4      We are currently closed as we move into our ne...   \n",
              "...                                                  ...   \n",
              "88509  Day 2 Christmas brochure tour Day one brochure...   \n",
              "88510                #ArmisticeDay #poppy #lestwerespect   \n",
              "88511  There’s only one turkey and the best place to ...   \n",
              "88512  Day one brochure tour !! #sandysfishmongers #b...   \n",
              "88513  A unique amber coloured blue veined cheese , w...   \n",
              "\n",
              "                         profile_name  \\\n",
              "0                        Yeast Bakery   \n",
              "1                        Yeast Bakery   \n",
              "2                        Yeast Bakery   \n",
              "3                        Yeast Bakery   \n",
              "4                        Yeast Bakery   \n",
              "...                               ...   \n",
              "88509  Fishmongers/ButchersTwickenham   \n",
              "88510  Fishmongers/ButchersTwickenham   \n",
              "88511  Fishmongers/ButchersTwickenham   \n",
              "88512  Fishmongers/ButchersTwickenham   \n",
              "88513  Fishmongers/ButchersTwickenham   \n",
              "\n",
              "                                               biography  following  likes  \\\n",
              "0      We are now open at our new site: Unit 1 Canal ...      352.0   29.0   \n",
              "1      We are now open at our new site: Unit 1 Canal ...      352.0   44.0   \n",
              "2      We are now open at our new site: Unit 1 Canal ...      352.0  209.0   \n",
              "3      We are now open at our new site: Unit 1 Canal ...      352.0   95.0   \n",
              "4      We are now open at our new site: Unit 1 Canal ...      352.0  101.0   \n",
              "...                                                  ...        ...    ...   \n",
              "88509  Local Family Fishmongers & Butchers , fresh fi...      579.0   10.0   \n",
              "88510  Local Family Fishmongers & Butchers , fresh fi...      579.0   50.0   \n",
              "88511  Local Family Fishmongers & Butchers , fresh fi...      579.0    8.0   \n",
              "88512  Local Family Fishmongers & Butchers , fresh fi...      579.0    9.0   \n",
              "88513  Local Family Fishmongers & Butchers , fresh fi...      579.0   11.0   \n",
              "\n",
              "       posts_count  followers                datetime  ...  sat sun  \\\n",
              "0            280.0     8702.0 2021-07-18 09:19:41.056  ...    0   1   \n",
              "1            280.0     8702.0 2022-03-10 13:45:42.144  ...    0   0   \n",
              "2            280.0     8702.0 2021-10-20 11:39:44.000  ...    0   0   \n",
              "3            280.0     8702.0 2021-10-01 12:06:51.136  ...    0   0   \n",
              "4            280.0     8702.0 2021-07-22 05:00:20.352  ...    0   0   \n",
              "...            ...        ...                     ...  ...  ...  ..   \n",
              "88509       1863.0     2321.0 2021-11-12 09:39:17.632  ...    0   0   \n",
              "88510       1863.0     2321.0 2021-11-11 08:40:42.240  ...    0   0   \n",
              "88511       1863.0     2321.0 2021-11-10 13:14:09.792  ...    0   0   \n",
              "88512       1863.0     2321.0 2021-11-10 13:14:09.792  ...    0   0   \n",
              "88513       1863.0     2321.0 2021-11-10 10:25:57.248  ...    0   0   \n",
              "\n",
              "      industry_childcare industry_cosmetics  industry_fashion  \\\n",
              "0                      0                  0                 0   \n",
              "1                      0                  0                 0   \n",
              "2                      0                  0                 0   \n",
              "3                      0                  0                 0   \n",
              "4                      0                  0                 0   \n",
              "...                  ...                ...               ...   \n",
              "88509                  0                  0                 0   \n",
              "88510                  0                  0                 0   \n",
              "88511                  0                  0                 0   \n",
              "88512                  0                  0                 0   \n",
              "88513                  0                  0                 0   \n",
              "\n",
              "      industry_fitness industry_hospitality industry_real estate  \\\n",
              "0                    0                    1                    0   \n",
              "1                    0                    1                    0   \n",
              "2                    0                    1                    0   \n",
              "3                    0                    1                    0   \n",
              "4                    0                    1                    0   \n",
              "...                ...                  ...                  ...   \n",
              "88509                0                    0                    0   \n",
              "88510                0                    0                    0   \n",
              "88511                0                    0                    0   \n",
              "88512                0                    0                    0   \n",
              "88513                0                    0                    0   \n",
              "\n",
              "       industry_retail  industry_sport & recreation  \n",
              "0                    0                            0  \n",
              "1                    0                            0  \n",
              "2                    0                            0  \n",
              "3                    0                            0  \n",
              "4                    0                            0  \n",
              "...                ...                          ...  \n",
              "88509                1                            0  \n",
              "88510                1                            0  \n",
              "88511                1                            0  \n",
              "88512                1                            0  \n",
              "88513                1                            0  \n",
              "\n",
              "[88514 rows x 36 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-10be7dd0-bebc-40ac-ae19-f058ff121146\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_type</th>\n",
              "      <th>account</th>\n",
              "      <th>caption</th>\n",
              "      <th>profile_name</th>\n",
              "      <th>biography</th>\n",
              "      <th>following</th>\n",
              "      <th>likes</th>\n",
              "      <th>posts_count</th>\n",
              "      <th>followers</th>\n",
              "      <th>datetime</th>\n",
              "      <th>...</th>\n",
              "      <th>sat</th>\n",
              "      <th>sun</th>\n",
              "      <th>industry_childcare</th>\n",
              "      <th>industry_cosmetics</th>\n",
              "      <th>industry_fashion</th>\n",
              "      <th>industry_fitness</th>\n",
              "      <th>industry_hospitality</th>\n",
              "      <th>industry_real estate</th>\n",
              "      <th>industry_retail</th>\n",
              "      <th>industry_sport &amp; recreation</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>['Ambiguous Clip', 'Not LineDraw']</td>\n",
              "      <td>yeastbakery</td>\n",
              "      <td>It’s our last Pizza Sunday at the arch today. ...</td>\n",
              "      <td>Yeast Bakery</td>\n",
              "      <td>We are now open at our new site: Unit 1 Canal ...</td>\n",
              "      <td>352.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>280.0</td>\n",
              "      <td>8702.0</td>\n",
              "      <td>2021-07-18 09:19:41.056</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>['Not Clip', 'Not LineDraw']</td>\n",
              "      <td>yeastbakery</td>\n",
              "      <td>New cakes on our counters 😋😋</td>\n",
              "      <td>Yeast Bakery</td>\n",
              "      <td>We are now open at our new site: Unit 1 Canal ...</td>\n",
              "      <td>352.0</td>\n",
              "      <td>44.0</td>\n",
              "      <td>280.0</td>\n",
              "      <td>8702.0</td>\n",
              "      <td>2022-03-10 13:45:42.144</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>['Not Clip', 'Not LineDraw']</td>\n",
              "      <td>yeastbakery</td>\n",
              "      <td>🔺Opening Times for Half Term🔺: Hi everyone we ...</td>\n",
              "      <td>Yeast Bakery</td>\n",
              "      <td>We are now open at our new site: Unit 1 Canal ...</td>\n",
              "      <td>352.0</td>\n",
              "      <td>209.0</td>\n",
              "      <td>280.0</td>\n",
              "      <td>8702.0</td>\n",
              "      <td>2021-10-20 11:39:44.000</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>['Not Clip', 'Not LineDraw']</td>\n",
              "      <td>yeastbakery</td>\n",
              "      <td>New addition to our selection of sandwiches, o...</td>\n",
              "      <td>Yeast Bakery</td>\n",
              "      <td>We are now open at our new site: Unit 1 Canal ...</td>\n",
              "      <td>352.0</td>\n",
              "      <td>95.0</td>\n",
              "      <td>280.0</td>\n",
              "      <td>8702.0</td>\n",
              "      <td>2021-10-01 12:06:51.136</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>['Ambiguous Clip', 'Not LineDraw']</td>\n",
              "      <td>yeastbakery</td>\n",
              "      <td>We are currently closed as we move into our ne...</td>\n",
              "      <td>Yeast Bakery</td>\n",
              "      <td>We are now open at our new site: Unit 1 Canal ...</td>\n",
              "      <td>352.0</td>\n",
              "      <td>101.0</td>\n",
              "      <td>280.0</td>\n",
              "      <td>8702.0</td>\n",
              "      <td>2021-07-22 05:00:20.352</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88509</th>\n",
              "      <td>['Not Clip', 'Not LineDraw']</td>\n",
              "      <td>sandysfishmongers</td>\n",
              "      <td>Day 2 Christmas brochure tour Day one brochure...</td>\n",
              "      <td>Fishmongers/ButchersTwickenham</td>\n",
              "      <td>Local Family Fishmongers &amp; Butchers , fresh fi...</td>\n",
              "      <td>579.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>1863.0</td>\n",
              "      <td>2321.0</td>\n",
              "      <td>2021-11-12 09:39:17.632</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88510</th>\n",
              "      <td>['Not Clip', 'Not LineDraw']</td>\n",
              "      <td>sandysfishmongers</td>\n",
              "      <td>#ArmisticeDay #poppy #lestwerespect</td>\n",
              "      <td>Fishmongers/ButchersTwickenham</td>\n",
              "      <td>Local Family Fishmongers &amp; Butchers , fresh fi...</td>\n",
              "      <td>579.0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>1863.0</td>\n",
              "      <td>2321.0</td>\n",
              "      <td>2021-11-11 08:40:42.240</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88511</th>\n",
              "      <td>['Not Clip', 'Not LineDraw']</td>\n",
              "      <td>sandysfishmongers</td>\n",
              "      <td>There’s only one turkey and the best place to ...</td>\n",
              "      <td>Fishmongers/ButchersTwickenham</td>\n",
              "      <td>Local Family Fishmongers &amp; Butchers , fresh fi...</td>\n",
              "      <td>579.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>1863.0</td>\n",
              "      <td>2321.0</td>\n",
              "      <td>2021-11-10 13:14:09.792</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88512</th>\n",
              "      <td>['Not Clip', 'Not LineDraw']</td>\n",
              "      <td>sandysfishmongers</td>\n",
              "      <td>Day one brochure tour !! #sandysfishmongers #b...</td>\n",
              "      <td>Fishmongers/ButchersTwickenham</td>\n",
              "      <td>Local Family Fishmongers &amp; Butchers , fresh fi...</td>\n",
              "      <td>579.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>1863.0</td>\n",
              "      <td>2321.0</td>\n",
              "      <td>2021-11-10 13:14:09.792</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88513</th>\n",
              "      <td>['Not Clip', 'Not LineDraw']</td>\n",
              "      <td>sandysfishmongers</td>\n",
              "      <td>A unique amber coloured blue veined cheese , w...</td>\n",
              "      <td>Fishmongers/ButchersTwickenham</td>\n",
              "      <td>Local Family Fishmongers &amp; Butchers , fresh fi...</td>\n",
              "      <td>579.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>1863.0</td>\n",
              "      <td>2321.0</td>\n",
              "      <td>2021-11-10 10:25:57.248</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>88514 rows × 36 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-10be7dd0-bebc-40ac-ae19-f058ff121146')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-10be7dd0-bebc-40ac-ae19-f058ff121146 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-10be7dd0-bebc-40ac-ae19-f058ff121146');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dropped = ['industry_fashion','industry_retail','industry_childcare','industry_fitness','industry_sport & recreation','industry_childcare','industry_real estate','Date','Dow','datetime']\n",
        "df.drop(dropped,axis=1,inplace=True)\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "kZyJa5tBxvTw",
        "outputId": "ac2b89a1-1dc7-437f-c028-b964684a2afa"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                               image_type            account  \\\n",
              "0      ['Ambiguous Clip', 'Not LineDraw']        yeastbakery   \n",
              "1            ['Not Clip', 'Not LineDraw']        yeastbakery   \n",
              "2            ['Not Clip', 'Not LineDraw']        yeastbakery   \n",
              "3            ['Not Clip', 'Not LineDraw']        yeastbakery   \n",
              "4      ['Ambiguous Clip', 'Not LineDraw']        yeastbakery   \n",
              "...                                   ...                ...   \n",
              "88509        ['Not Clip', 'Not LineDraw']  sandysfishmongers   \n",
              "88510        ['Not Clip', 'Not LineDraw']  sandysfishmongers   \n",
              "88511        ['Not Clip', 'Not LineDraw']  sandysfishmongers   \n",
              "88512        ['Not Clip', 'Not LineDraw']  sandysfishmongers   \n",
              "88513        ['Not Clip', 'Not LineDraw']  sandysfishmongers   \n",
              "\n",
              "                                                 caption  \\\n",
              "0      It’s our last Pizza Sunday at the arch today. ...   \n",
              "1                           New cakes on our counters 😋😋   \n",
              "2      🔺Opening Times for Half Term🔺: Hi everyone we ...   \n",
              "3      New addition to our selection of sandwiches, o...   \n",
              "4      We are currently closed as we move into our ne...   \n",
              "...                                                  ...   \n",
              "88509  Day 2 Christmas brochure tour Day one brochure...   \n",
              "88510                #ArmisticeDay #poppy #lestwerespect   \n",
              "88511  There’s only one turkey and the best place to ...   \n",
              "88512  Day one brochure tour !! #sandysfishmongers #b...   \n",
              "88513  A unique amber coloured blue veined cheese , w...   \n",
              "\n",
              "                         profile_name  \\\n",
              "0                        Yeast Bakery   \n",
              "1                        Yeast Bakery   \n",
              "2                        Yeast Bakery   \n",
              "3                        Yeast Bakery   \n",
              "4                        Yeast Bakery   \n",
              "...                               ...   \n",
              "88509  Fishmongers/ButchersTwickenham   \n",
              "88510  Fishmongers/ButchersTwickenham   \n",
              "88511  Fishmongers/ButchersTwickenham   \n",
              "88512  Fishmongers/ButchersTwickenham   \n",
              "88513  Fishmongers/ButchersTwickenham   \n",
              "\n",
              "                                               biography  following  likes  \\\n",
              "0      We are now open at our new site: Unit 1 Canal ...      352.0   29.0   \n",
              "1      We are now open at our new site: Unit 1 Canal ...      352.0   44.0   \n",
              "2      We are now open at our new site: Unit 1 Canal ...      352.0  209.0   \n",
              "3      We are now open at our new site: Unit 1 Canal ...      352.0   95.0   \n",
              "4      We are now open at our new site: Unit 1 Canal ...      352.0  101.0   \n",
              "...                                                  ...        ...    ...   \n",
              "88509  Local Family Fishmongers & Butchers , fresh fi...      579.0   10.0   \n",
              "88510  Local Family Fishmongers & Butchers , fresh fi...      579.0   50.0   \n",
              "88511  Local Family Fishmongers & Butchers , fresh fi...      579.0    8.0   \n",
              "88512  Local Family Fishmongers & Butchers , fresh fi...      579.0    9.0   \n",
              "88513  Local Family Fishmongers & Butchers , fresh fi...      579.0   11.0   \n",
              "\n",
              "       posts_count  followers  comments  ... Hod mon tue  wed thu fri sat  \\\n",
              "0            280.0     8702.0       0.0  ...   9   0   0    0   0   0   0   \n",
              "1            280.0     8702.0       0.0  ...  13   0   0    0   1   0   0   \n",
              "2            280.0     8702.0       9.0  ...  11   0   0    1   0   0   0   \n",
              "3            280.0     8702.0       3.0  ...  12   0   0    0   0   1   0   \n",
              "4            280.0     8702.0       6.0  ...   5   0   0    0   1   0   0   \n",
              "...            ...        ...       ...  ...  ..  ..  ..  ...  ..  ..  ..   \n",
              "88509       1863.0     2321.0       1.0  ...   9   0   0    0   0   1   0   \n",
              "88510       1863.0     2321.0       0.0  ...   8   0   0    0   1   0   0   \n",
              "88511       1863.0     2321.0       0.0  ...  13   0   0    1   0   0   0   \n",
              "88512       1863.0     2321.0       0.0  ...  13   0   0    1   0   0   0   \n",
              "88513       1863.0     2321.0       2.0  ...  10   0   0    1   0   0   0   \n",
              "\n",
              "       sun  industry_cosmetics  industry_hospitality  \n",
              "0        1                   0                     1  \n",
              "1        0                   0                     1  \n",
              "2        0                   0                     1  \n",
              "3        0                   0                     1  \n",
              "4        0                   0                     1  \n",
              "...    ...                 ...                   ...  \n",
              "88509    0                   0                     0  \n",
              "88510    0                   0                     0  \n",
              "88511    0                   0                     0  \n",
              "88512    0                   0                     0  \n",
              "88513    0                   0                     0  \n",
              "\n",
              "[88514 rows x 27 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-20f54973-c43a-42b9-80b1-22a30d1a4912\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_type</th>\n",
              "      <th>account</th>\n",
              "      <th>caption</th>\n",
              "      <th>profile_name</th>\n",
              "      <th>biography</th>\n",
              "      <th>following</th>\n",
              "      <th>likes</th>\n",
              "      <th>posts_count</th>\n",
              "      <th>followers</th>\n",
              "      <th>comments</th>\n",
              "      <th>...</th>\n",
              "      <th>Hod</th>\n",
              "      <th>mon</th>\n",
              "      <th>tue</th>\n",
              "      <th>wed</th>\n",
              "      <th>thu</th>\n",
              "      <th>fri</th>\n",
              "      <th>sat</th>\n",
              "      <th>sun</th>\n",
              "      <th>industry_cosmetics</th>\n",
              "      <th>industry_hospitality</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>['Ambiguous Clip', 'Not LineDraw']</td>\n",
              "      <td>yeastbakery</td>\n",
              "      <td>It’s our last Pizza Sunday at the arch today. ...</td>\n",
              "      <td>Yeast Bakery</td>\n",
              "      <td>We are now open at our new site: Unit 1 Canal ...</td>\n",
              "      <td>352.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>280.0</td>\n",
              "      <td>8702.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>['Not Clip', 'Not LineDraw']</td>\n",
              "      <td>yeastbakery</td>\n",
              "      <td>New cakes on our counters 😋😋</td>\n",
              "      <td>Yeast Bakery</td>\n",
              "      <td>We are now open at our new site: Unit 1 Canal ...</td>\n",
              "      <td>352.0</td>\n",
              "      <td>44.0</td>\n",
              "      <td>280.0</td>\n",
              "      <td>8702.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>13</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>['Not Clip', 'Not LineDraw']</td>\n",
              "      <td>yeastbakery</td>\n",
              "      <td>🔺Opening Times for Half Term🔺: Hi everyone we ...</td>\n",
              "      <td>Yeast Bakery</td>\n",
              "      <td>We are now open at our new site: Unit 1 Canal ...</td>\n",
              "      <td>352.0</td>\n",
              "      <td>209.0</td>\n",
              "      <td>280.0</td>\n",
              "      <td>8702.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>...</td>\n",
              "      <td>11</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>['Not Clip', 'Not LineDraw']</td>\n",
              "      <td>yeastbakery</td>\n",
              "      <td>New addition to our selection of sandwiches, o...</td>\n",
              "      <td>Yeast Bakery</td>\n",
              "      <td>We are now open at our new site: Unit 1 Canal ...</td>\n",
              "      <td>352.0</td>\n",
              "      <td>95.0</td>\n",
              "      <td>280.0</td>\n",
              "      <td>8702.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>...</td>\n",
              "      <td>12</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>['Ambiguous Clip', 'Not LineDraw']</td>\n",
              "      <td>yeastbakery</td>\n",
              "      <td>We are currently closed as we move into our ne...</td>\n",
              "      <td>Yeast Bakery</td>\n",
              "      <td>We are now open at our new site: Unit 1 Canal ...</td>\n",
              "      <td>352.0</td>\n",
              "      <td>101.0</td>\n",
              "      <td>280.0</td>\n",
              "      <td>8702.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>...</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88509</th>\n",
              "      <td>['Not Clip', 'Not LineDraw']</td>\n",
              "      <td>sandysfishmongers</td>\n",
              "      <td>Day 2 Christmas brochure tour Day one brochure...</td>\n",
              "      <td>Fishmongers/ButchersTwickenham</td>\n",
              "      <td>Local Family Fishmongers &amp; Butchers , fresh fi...</td>\n",
              "      <td>579.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>1863.0</td>\n",
              "      <td>2321.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88510</th>\n",
              "      <td>['Not Clip', 'Not LineDraw']</td>\n",
              "      <td>sandysfishmongers</td>\n",
              "      <td>#ArmisticeDay #poppy #lestwerespect</td>\n",
              "      <td>Fishmongers/ButchersTwickenham</td>\n",
              "      <td>Local Family Fishmongers &amp; Butchers , fresh fi...</td>\n",
              "      <td>579.0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>1863.0</td>\n",
              "      <td>2321.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88511</th>\n",
              "      <td>['Not Clip', 'Not LineDraw']</td>\n",
              "      <td>sandysfishmongers</td>\n",
              "      <td>There’s only one turkey and the best place to ...</td>\n",
              "      <td>Fishmongers/ButchersTwickenham</td>\n",
              "      <td>Local Family Fishmongers &amp; Butchers , fresh fi...</td>\n",
              "      <td>579.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>1863.0</td>\n",
              "      <td>2321.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>13</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88512</th>\n",
              "      <td>['Not Clip', 'Not LineDraw']</td>\n",
              "      <td>sandysfishmongers</td>\n",
              "      <td>Day one brochure tour !! #sandysfishmongers #b...</td>\n",
              "      <td>Fishmongers/ButchersTwickenham</td>\n",
              "      <td>Local Family Fishmongers &amp; Butchers , fresh fi...</td>\n",
              "      <td>579.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>1863.0</td>\n",
              "      <td>2321.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>13</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88513</th>\n",
              "      <td>['Not Clip', 'Not LineDraw']</td>\n",
              "      <td>sandysfishmongers</td>\n",
              "      <td>A unique amber coloured blue veined cheese , w...</td>\n",
              "      <td>Fishmongers/ButchersTwickenham</td>\n",
              "      <td>Local Family Fishmongers &amp; Butchers , fresh fi...</td>\n",
              "      <td>579.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>1863.0</td>\n",
              "      <td>2321.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>...</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>88514 rows × 27 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-20f54973-c43a-42b9-80b1-22a30d1a4912')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-20f54973-c43a-42b9-80b1-22a30d1a4912 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-20f54973-c43a-42b9-80b1-22a30d1a4912');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## NLP"
      ],
      "metadata": {
        "id": "JJTzbetdo1CJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data=df.astype(str)\n",
        "def sentiment_analysis(caption):\n",
        "    def getSubjectivity(text):\n",
        "        return TextBlob(text).sentiment.subjectivity\n",
        "  \n",
        "    #Create a function to get the polarity\n",
        "    def getPolarity(caption):\n",
        "        return TextBlob(caption).sentiment.polarity\n",
        "  \n",
        "    #Create two new columns 'Subjectivity' & 'Polarity'\n",
        "    data['TextBlob_Subjectivity'] = data['caption'].apply(getSubjectivity)\n",
        "    data ['TextBlob_Polarity'] =  data['caption'].apply(getPolarity)\n",
        "    return df\n",
        "\n",
        "sentiment_analysis(data['caption'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "gRDXORK4o2Nz",
        "outputId": "c37e2337-e2de-4ed0-8981-88a47558b24b"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                               image_type            account  \\\n",
              "0      ['Ambiguous Clip', 'Not LineDraw']        yeastbakery   \n",
              "1            ['Not Clip', 'Not LineDraw']        yeastbakery   \n",
              "2            ['Not Clip', 'Not LineDraw']        yeastbakery   \n",
              "3            ['Not Clip', 'Not LineDraw']        yeastbakery   \n",
              "4      ['Ambiguous Clip', 'Not LineDraw']        yeastbakery   \n",
              "...                                   ...                ...   \n",
              "88509        ['Not Clip', 'Not LineDraw']  sandysfishmongers   \n",
              "88510        ['Not Clip', 'Not LineDraw']  sandysfishmongers   \n",
              "88511        ['Not Clip', 'Not LineDraw']  sandysfishmongers   \n",
              "88512        ['Not Clip', 'Not LineDraw']  sandysfishmongers   \n",
              "88513        ['Not Clip', 'Not LineDraw']  sandysfishmongers   \n",
              "\n",
              "                                                 caption  \\\n",
              "0      It’s our last Pizza Sunday at the arch today. ...   \n",
              "1                           New cakes on our counters 😋😋   \n",
              "2      🔺Opening Times for Half Term🔺: Hi everyone we ...   \n",
              "3      New addition to our selection of sandwiches, o...   \n",
              "4      We are currently closed as we move into our ne...   \n",
              "...                                                  ...   \n",
              "88509  Day 2 Christmas brochure tour Day one brochure...   \n",
              "88510                #ArmisticeDay #poppy #lestwerespect   \n",
              "88511  There’s only one turkey and the best place to ...   \n",
              "88512  Day one brochure tour !! #sandysfishmongers #b...   \n",
              "88513  A unique amber coloured blue veined cheese , w...   \n",
              "\n",
              "                         profile_name  \\\n",
              "0                        Yeast Bakery   \n",
              "1                        Yeast Bakery   \n",
              "2                        Yeast Bakery   \n",
              "3                        Yeast Bakery   \n",
              "4                        Yeast Bakery   \n",
              "...                               ...   \n",
              "88509  Fishmongers/ButchersTwickenham   \n",
              "88510  Fishmongers/ButchersTwickenham   \n",
              "88511  Fishmongers/ButchersTwickenham   \n",
              "88512  Fishmongers/ButchersTwickenham   \n",
              "88513  Fishmongers/ButchersTwickenham   \n",
              "\n",
              "                                               biography  following  likes  \\\n",
              "0      We are now open at our new site: Unit 1 Canal ...      352.0   29.0   \n",
              "1      We are now open at our new site: Unit 1 Canal ...      352.0   44.0   \n",
              "2      We are now open at our new site: Unit 1 Canal ...      352.0  209.0   \n",
              "3      We are now open at our new site: Unit 1 Canal ...      352.0   95.0   \n",
              "4      We are now open at our new site: Unit 1 Canal ...      352.0  101.0   \n",
              "...                                                  ...        ...    ...   \n",
              "88509  Local Family Fishmongers & Butchers , fresh fi...      579.0   10.0   \n",
              "88510  Local Family Fishmongers & Butchers , fresh fi...      579.0   50.0   \n",
              "88511  Local Family Fishmongers & Butchers , fresh fi...      579.0    8.0   \n",
              "88512  Local Family Fishmongers & Butchers , fresh fi...      579.0    9.0   \n",
              "88513  Local Family Fishmongers & Butchers , fresh fi...      579.0   11.0   \n",
              "\n",
              "       posts_count  followers  comments  ... Hod mon tue  wed thu fri sat  \\\n",
              "0            280.0     8702.0       0.0  ...   9   0   0    0   0   0   0   \n",
              "1            280.0     8702.0       0.0  ...  13   0   0    0   1   0   0   \n",
              "2            280.0     8702.0       9.0  ...  11   0   0    1   0   0   0   \n",
              "3            280.0     8702.0       3.0  ...  12   0   0    0   0   1   0   \n",
              "4            280.0     8702.0       6.0  ...   5   0   0    0   1   0   0   \n",
              "...            ...        ...       ...  ...  ..  ..  ..  ...  ..  ..  ..   \n",
              "88509       1863.0     2321.0       1.0  ...   9   0   0    0   0   1   0   \n",
              "88510       1863.0     2321.0       0.0  ...   8   0   0    0   1   0   0   \n",
              "88511       1863.0     2321.0       0.0  ...  13   0   0    1   0   0   0   \n",
              "88512       1863.0     2321.0       0.0  ...  13   0   0    1   0   0   0   \n",
              "88513       1863.0     2321.0       2.0  ...  10   0   0    1   0   0   0   \n",
              "\n",
              "       sun  industry_cosmetics  industry_hospitality  \n",
              "0        1                   0                     1  \n",
              "1        0                   0                     1  \n",
              "2        0                   0                     1  \n",
              "3        0                   0                     1  \n",
              "4        0                   0                     1  \n",
              "...    ...                 ...                   ...  \n",
              "88509    0                   0                     0  \n",
              "88510    0                   0                     0  \n",
              "88511    0                   0                     0  \n",
              "88512    0                   0                     0  \n",
              "88513    0                   0                     0  \n",
              "\n",
              "[88514 rows x 27 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1406dece-8e9e-4b42-8f56-354ee8c38288\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_type</th>\n",
              "      <th>account</th>\n",
              "      <th>caption</th>\n",
              "      <th>profile_name</th>\n",
              "      <th>biography</th>\n",
              "      <th>following</th>\n",
              "      <th>likes</th>\n",
              "      <th>posts_count</th>\n",
              "      <th>followers</th>\n",
              "      <th>comments</th>\n",
              "      <th>...</th>\n",
              "      <th>Hod</th>\n",
              "      <th>mon</th>\n",
              "      <th>tue</th>\n",
              "      <th>wed</th>\n",
              "      <th>thu</th>\n",
              "      <th>fri</th>\n",
              "      <th>sat</th>\n",
              "      <th>sun</th>\n",
              "      <th>industry_cosmetics</th>\n",
              "      <th>industry_hospitality</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>['Ambiguous Clip', 'Not LineDraw']</td>\n",
              "      <td>yeastbakery</td>\n",
              "      <td>It’s our last Pizza Sunday at the arch today. ...</td>\n",
              "      <td>Yeast Bakery</td>\n",
              "      <td>We are now open at our new site: Unit 1 Canal ...</td>\n",
              "      <td>352.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>280.0</td>\n",
              "      <td>8702.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>['Not Clip', 'Not LineDraw']</td>\n",
              "      <td>yeastbakery</td>\n",
              "      <td>New cakes on our counters 😋😋</td>\n",
              "      <td>Yeast Bakery</td>\n",
              "      <td>We are now open at our new site: Unit 1 Canal ...</td>\n",
              "      <td>352.0</td>\n",
              "      <td>44.0</td>\n",
              "      <td>280.0</td>\n",
              "      <td>8702.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>13</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>['Not Clip', 'Not LineDraw']</td>\n",
              "      <td>yeastbakery</td>\n",
              "      <td>🔺Opening Times for Half Term🔺: Hi everyone we ...</td>\n",
              "      <td>Yeast Bakery</td>\n",
              "      <td>We are now open at our new site: Unit 1 Canal ...</td>\n",
              "      <td>352.0</td>\n",
              "      <td>209.0</td>\n",
              "      <td>280.0</td>\n",
              "      <td>8702.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>...</td>\n",
              "      <td>11</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>['Not Clip', 'Not LineDraw']</td>\n",
              "      <td>yeastbakery</td>\n",
              "      <td>New addition to our selection of sandwiches, o...</td>\n",
              "      <td>Yeast Bakery</td>\n",
              "      <td>We are now open at our new site: Unit 1 Canal ...</td>\n",
              "      <td>352.0</td>\n",
              "      <td>95.0</td>\n",
              "      <td>280.0</td>\n",
              "      <td>8702.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>...</td>\n",
              "      <td>12</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>['Ambiguous Clip', 'Not LineDraw']</td>\n",
              "      <td>yeastbakery</td>\n",
              "      <td>We are currently closed as we move into our ne...</td>\n",
              "      <td>Yeast Bakery</td>\n",
              "      <td>We are now open at our new site: Unit 1 Canal ...</td>\n",
              "      <td>352.0</td>\n",
              "      <td>101.0</td>\n",
              "      <td>280.0</td>\n",
              "      <td>8702.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>...</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88509</th>\n",
              "      <td>['Not Clip', 'Not LineDraw']</td>\n",
              "      <td>sandysfishmongers</td>\n",
              "      <td>Day 2 Christmas brochure tour Day one brochure...</td>\n",
              "      <td>Fishmongers/ButchersTwickenham</td>\n",
              "      <td>Local Family Fishmongers &amp; Butchers , fresh fi...</td>\n",
              "      <td>579.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>1863.0</td>\n",
              "      <td>2321.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88510</th>\n",
              "      <td>['Not Clip', 'Not LineDraw']</td>\n",
              "      <td>sandysfishmongers</td>\n",
              "      <td>#ArmisticeDay #poppy #lestwerespect</td>\n",
              "      <td>Fishmongers/ButchersTwickenham</td>\n",
              "      <td>Local Family Fishmongers &amp; Butchers , fresh fi...</td>\n",
              "      <td>579.0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>1863.0</td>\n",
              "      <td>2321.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88511</th>\n",
              "      <td>['Not Clip', 'Not LineDraw']</td>\n",
              "      <td>sandysfishmongers</td>\n",
              "      <td>There’s only one turkey and the best place to ...</td>\n",
              "      <td>Fishmongers/ButchersTwickenham</td>\n",
              "      <td>Local Family Fishmongers &amp; Butchers , fresh fi...</td>\n",
              "      <td>579.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>1863.0</td>\n",
              "      <td>2321.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>13</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88512</th>\n",
              "      <td>['Not Clip', 'Not LineDraw']</td>\n",
              "      <td>sandysfishmongers</td>\n",
              "      <td>Day one brochure tour !! #sandysfishmongers #b...</td>\n",
              "      <td>Fishmongers/ButchersTwickenham</td>\n",
              "      <td>Local Family Fishmongers &amp; Butchers , fresh fi...</td>\n",
              "      <td>579.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>1863.0</td>\n",
              "      <td>2321.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>13</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88513</th>\n",
              "      <td>['Not Clip', 'Not LineDraw']</td>\n",
              "      <td>sandysfishmongers</td>\n",
              "      <td>A unique amber coloured blue veined cheese , w...</td>\n",
              "      <td>Fishmongers/ButchersTwickenham</td>\n",
              "      <td>Local Family Fishmongers &amp; Butchers , fresh fi...</td>\n",
              "      <td>579.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>1863.0</td>\n",
              "      <td>2321.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>...</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>88514 rows × 27 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1406dece-8e9e-4b42-8f56-354ee8c38288')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1406dece-8e9e-4b42-8f56-354ee8c38288 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1406dece-8e9e-4b42-8f56-354ee8c38288');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hashtag_summary = adv.extract_hashtags(data['caption'])\n",
        "emoji_summary = adv.extract_emoji(data['caption'])\n",
        "mention_summary = adv.extract_mentions(data['caption'])\n",
        "\n",
        "extracted =  (data.assign(hashtags=hashtag_summary['hashtags'],\n",
        "         hashcounts=hashtag_summary['hashtag_counts'],\n",
        "         mentions=mention_summary['mentions'],\n",
        "         mention_count=mention_summary['mention_counts'],\n",
        "        emoji=emoji_summary['emoji'],\n",
        "        emoji_text=emoji_summary['emoji_text'],\n",
        "        emoji_count=emoji_summary['emoji_counts'] \n",
        "         ))\n",
        "\n",
        "extracted.head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 716
        },
        "id": "ySMwH14W2UHb",
        "outputId": "a6c3fe9e-e986-4e29-a8e3-495651f54d51"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                           image_type      account  \\\n",
              "0  ['Ambiguous Clip', 'Not LineDraw']  yeastbakery   \n",
              "1        ['Not Clip', 'Not LineDraw']  yeastbakery   \n",
              "2        ['Not Clip', 'Not LineDraw']  yeastbakery   \n",
              "3        ['Not Clip', 'Not LineDraw']  yeastbakery   \n",
              "4  ['Ambiguous Clip', 'Not LineDraw']  yeastbakery   \n",
              "\n",
              "                                             caption  profile_name  \\\n",
              "0  It’s our last Pizza Sunday at the arch today. ...  Yeast Bakery   \n",
              "1                       New cakes on our counters 😋😋  Yeast Bakery   \n",
              "2  🔺Opening Times for Half Term🔺: Hi everyone we ...  Yeast Bakery   \n",
              "3  New addition to our selection of sandwiches, o...  Yeast Bakery   \n",
              "4  We are currently closed as we move into our ne...  Yeast Bakery   \n",
              "\n",
              "                                           biography following  likes  \\\n",
              "0  We are now open at our new site: Unit 1 Canal ...     352.0   29.0   \n",
              "1  We are now open at our new site: Unit 1 Canal ...     352.0   44.0   \n",
              "2  We are now open at our new site: Unit 1 Canal ...     352.0  209.0   \n",
              "3  We are now open at our new site: Unit 1 Canal ...     352.0   95.0   \n",
              "4  We are now open at our new site: Unit 1 Canal ...     352.0  101.0   \n",
              "\n",
              "  posts_count followers comments  ... industry_hospitality  \\\n",
              "0       280.0    8702.0      0.0  ...                    1   \n",
              "1       280.0    8702.0      0.0  ...                    1   \n",
              "2       280.0    8702.0      9.0  ...                    1   \n",
              "3       280.0    8702.0      3.0  ...                    1   \n",
              "4       280.0    8702.0      6.0  ...                    1   \n",
              "\n",
              "  TextBlob_Subjectivity TextBlob_Polarity  \\\n",
              "0              0.233333          0.200000   \n",
              "1              0.454545          0.136364   \n",
              "2              0.147222         -0.080556   \n",
              "3              0.477273          0.085227   \n",
              "4              0.444719          0.174416   \n",
              "\n",
              "                                            hashtags hashcounts mentions  \\\n",
              "0                                                 []          0       []   \n",
              "1                                                 []          0       []   \n",
              "2                                                 []          0       []   \n",
              "3                                                 []          0       []   \n",
              "4  [#yeastbakery, #eastlondon, #eastlondonfood, #...          4       []   \n",
              "\n",
              "  mention_count               emoji  \\\n",
              "0             0  [🍕, 🍕, 🍕, 🥐, 🥐, 🥐]   \n",
              "1             0              [😋, 😋]   \n",
              "2             0              [🔺, 🔺]   \n",
              "3             0                  []   \n",
              "4             0                  []   \n",
              "\n",
              "                                          emoji_text emoji_count  \n",
              "0  [pizza, pizza, pizza, croissant, croissant, cr...           6  \n",
              "1           [face savoring food, face savoring food]           2  \n",
              "2  [red triangle pointed up, red triangle pointed...           2  \n",
              "3                                                 []           0  \n",
              "4                                                 []           0  \n",
              "\n",
              "[5 rows x 36 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6defe012-a251-45d3-bac9-6a12a7d3ac81\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_type</th>\n",
              "      <th>account</th>\n",
              "      <th>caption</th>\n",
              "      <th>profile_name</th>\n",
              "      <th>biography</th>\n",
              "      <th>following</th>\n",
              "      <th>likes</th>\n",
              "      <th>posts_count</th>\n",
              "      <th>followers</th>\n",
              "      <th>comments</th>\n",
              "      <th>...</th>\n",
              "      <th>industry_hospitality</th>\n",
              "      <th>TextBlob_Subjectivity</th>\n",
              "      <th>TextBlob_Polarity</th>\n",
              "      <th>hashtags</th>\n",
              "      <th>hashcounts</th>\n",
              "      <th>mentions</th>\n",
              "      <th>mention_count</th>\n",
              "      <th>emoji</th>\n",
              "      <th>emoji_text</th>\n",
              "      <th>emoji_count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>['Ambiguous Clip', 'Not LineDraw']</td>\n",
              "      <td>yeastbakery</td>\n",
              "      <td>It’s our last Pizza Sunday at the arch today. ...</td>\n",
              "      <td>Yeast Bakery</td>\n",
              "      <td>We are now open at our new site: Unit 1 Canal ...</td>\n",
              "      <td>352.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>280.0</td>\n",
              "      <td>8702.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.233333</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>[]</td>\n",
              "      <td>0</td>\n",
              "      <td>[]</td>\n",
              "      <td>0</td>\n",
              "      <td>[🍕, 🍕, 🍕, 🥐, 🥐, 🥐]</td>\n",
              "      <td>[pizza, pizza, pizza, croissant, croissant, cr...</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>['Not Clip', 'Not LineDraw']</td>\n",
              "      <td>yeastbakery</td>\n",
              "      <td>New cakes on our counters 😋😋</td>\n",
              "      <td>Yeast Bakery</td>\n",
              "      <td>We are now open at our new site: Unit 1 Canal ...</td>\n",
              "      <td>352.0</td>\n",
              "      <td>44.0</td>\n",
              "      <td>280.0</td>\n",
              "      <td>8702.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.454545</td>\n",
              "      <td>0.136364</td>\n",
              "      <td>[]</td>\n",
              "      <td>0</td>\n",
              "      <td>[]</td>\n",
              "      <td>0</td>\n",
              "      <td>[😋, 😋]</td>\n",
              "      <td>[face savoring food, face savoring food]</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>['Not Clip', 'Not LineDraw']</td>\n",
              "      <td>yeastbakery</td>\n",
              "      <td>🔺Opening Times for Half Term🔺: Hi everyone we ...</td>\n",
              "      <td>Yeast Bakery</td>\n",
              "      <td>We are now open at our new site: Unit 1 Canal ...</td>\n",
              "      <td>352.0</td>\n",
              "      <td>209.0</td>\n",
              "      <td>280.0</td>\n",
              "      <td>8702.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.147222</td>\n",
              "      <td>-0.080556</td>\n",
              "      <td>[]</td>\n",
              "      <td>0</td>\n",
              "      <td>[]</td>\n",
              "      <td>0</td>\n",
              "      <td>[🔺, 🔺]</td>\n",
              "      <td>[red triangle pointed up, red triangle pointed...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>['Not Clip', 'Not LineDraw']</td>\n",
              "      <td>yeastbakery</td>\n",
              "      <td>New addition to our selection of sandwiches, o...</td>\n",
              "      <td>Yeast Bakery</td>\n",
              "      <td>We are now open at our new site: Unit 1 Canal ...</td>\n",
              "      <td>352.0</td>\n",
              "      <td>95.0</td>\n",
              "      <td>280.0</td>\n",
              "      <td>8702.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.477273</td>\n",
              "      <td>0.085227</td>\n",
              "      <td>[]</td>\n",
              "      <td>0</td>\n",
              "      <td>[]</td>\n",
              "      <td>0</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>['Ambiguous Clip', 'Not LineDraw']</td>\n",
              "      <td>yeastbakery</td>\n",
              "      <td>We are currently closed as we move into our ne...</td>\n",
              "      <td>Yeast Bakery</td>\n",
              "      <td>We are now open at our new site: Unit 1 Canal ...</td>\n",
              "      <td>352.0</td>\n",
              "      <td>101.0</td>\n",
              "      <td>280.0</td>\n",
              "      <td>8702.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.444719</td>\n",
              "      <td>0.174416</td>\n",
              "      <td>[#yeastbakery, #eastlondon, #eastlondonfood, #...</td>\n",
              "      <td>4</td>\n",
              "      <td>[]</td>\n",
              "      <td>0</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 36 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6defe012-a251-45d3-bac9-6a12a7d3ac81')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6defe012-a251-45d3-bac9-6a12a7d3ac81 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6defe012-a251-45d3-bac9-6a12a7d3ac81');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##Hashtag popularity\n",
        "\n",
        "def captionLength(i):\n",
        "    return len(i)\n",
        "\n",
        "caption_length = extracted['caption'].apply(captionLength)\n",
        "extracted['caption_length'] = caption_length\n",
        "\n",
        "\n",
        "#Converting the columns into the float datatype\n",
        "a=['followers']\n",
        "for i in a:\n",
        "  extracted[i]= extracted[i].astype(str).astype(float)\n",
        "extracted\n",
        "\n",
        "\n",
        "\n",
        "word_freq_hash = adv.word_frequency(extracted['hashtags'].str.join(' '), extracted['followers'].fillna(0))\n",
        "word_freq_hash.head()\n",
        "# type(word_freq_hash.word)\n",
        "\n",
        "d=pd.Series(word_freq_hash.rel_value.values,index=word_freq_hash.word.values ).to_dict()\n",
        "\n",
        "\n",
        "def countHashtags(tags):\n",
        "      if len(tags)==0:\n",
        "        return 0\n",
        "      sum = 0\n",
        "      for i in tags:\n",
        "        sum += (d.get(i))\n",
        "      return sum/len(tags)\n",
        "\n",
        "hashtag_average = extracted['hashtags'].apply(countHashtags)\n",
        "extracted['hashtag_popularity'] = hashtag_average"
      ],
      "metadata": {
        "id": "FgYnMmoX3FQ2"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "REPLACE_mentions = re.compile('@[A-Za-z0-9_]+')\n",
        "REPLACE_hashtags=re.compile('#[A-Za-z0-9_]+')\n",
        "REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,;]')\n",
        "GOOD_SYMBOLS_RE = re.compile('[^0-9a-z #+_]')\n",
        "\n",
        "try:\n",
        "    STOPWORDS = set(stopwords.words('english'))\n",
        "except LookupError:\n",
        "    nltk.download('stopwords')\n",
        "    STOPWORDS = set(stopwords.words('english'))\n",
        "\n",
        "def lower(text: str) -> str:\n",
        "    \"\"\"\n",
        "    Transforms given text to lower case.\n",
        "    Example:\n",
        "    Input: 'I really like New York city'\n",
        "    Output: 'i really like new your city'\n",
        "    \"\"\"\n",
        "\n",
        "    return text.lower()\n",
        "\n",
        "def replace_special_characters(text: str) -> str:\n",
        "    \"\"\"\n",
        "    Replaces special characters, such as paranthesis,\n",
        "    with spacing character\n",
        "    \"\"\"\n",
        "\n",
        "    return REPLACE_BY_SPACE_RE.sub(' ', text)\n",
        "\n",
        "def replace_br(text: str) -> str:\n",
        "    \"\"\"\n",
        "    Replaces br characters\n",
        "    \"\"\"\n",
        "\n",
        "    return text.replace('br', '')\n",
        "\n",
        "def filter_out_uncommon_symbols(text: str) -> str:\n",
        "    \"\"\"\n",
        "    Removes any special character that is not in the\n",
        "    good symbols list (check regular expression)\n",
        "    \"\"\"\n",
        "\n",
        "    return GOOD_SYMBOLS_RE.sub('', text)\n",
        "\n",
        "def remove_stopwords(text: str) -> str:\n",
        "    return ' '.join([x for x in text.split() if x and x not in STOPWORDS])\n",
        "\n",
        "\n",
        "def strip_text(text: str) -> str:\n",
        "    \"\"\"\n",
        "    Removes any left or right spacing (including carriage return) from text.\n",
        "    Example:\n",
        "    Input: '  This assignment is cool\\n'\n",
        "    Output: 'This assignment is cool'\n",
        "    \"\"\"\n",
        "\n",
        "    return text.strip()\n",
        "\n",
        "def remove_brackets_from_list(text:str)->str:\n",
        "    \"\"\"\n",
        "    Remove the [] brackets from the each of the list\n",
        "    \"\"\"\n",
        "    return text\n",
        "\n",
        "# def translation(text: str) -> str:\n",
        "  \n",
        "#     \"\"\"\n",
        "#     Replaces any non english words to the english language\n",
        "#     \"\"\"\n",
        "#     translator = Translator()\n",
        "#     res=translator.translate(text, dest='en')\n",
        "#     return res.text\n",
        "\n",
        "\n",
        "def clean_mention(text:str)-> str:\n",
        "    return REPLACE_mentions.sub(' ', text)\n",
        "\n",
        "def clean_hashtags(text:str)-> str:\n",
        "    return REPLACE_hashtags.sub(' ', text)"
      ],
      "metadata": {
        "id": "hrpOgHch3XxV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eaeba03e-46fa-429b-a2b6-8ae190df2525"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "PREPROCESSING_PIPELINE = [\n",
        "                          clean_mention,\n",
        "                          clean_hashtags,\n",
        "                          # translation\n",
        "                          lower,\n",
        "                          replace_special_characters,\n",
        "                          replace_br,\n",
        "                          filter_out_uncommon_symbols,\n",
        "                          remove_stopwords,\n",
        "                          strip_text\n",
        "                          ]\n",
        "\n",
        "PREPROCESSING_PIPELINE1 = [remove_brackets_from_list]\n",
        "\n",
        "# Anchor method\n",
        "\n",
        "def text_prepare1(text: str,filter_methods = None) -> str:\n",
        "    \"\"\"\n",
        "    Applies a list of pre-processing functions in sequence (reduce).\n",
        "    Note that the order is important here!\n",
        "    \"\"\"\n",
        "    filter_methods = filter_methods if filter_methods is not None else PREPROCESSING_PIPELINE1\n",
        "    return reduce(lambda txt, f: f(txt), filter_methods, text)\n",
        "\n",
        "def text_prepare(text: str, filter_methods: List[Callable[[str], str]] = None) -> str:\n",
        "    \"\"\"\n",
        "    Applies a list of pre-processing functions in sequence (reduce).\n",
        "    Note that the order is important here!\n",
        "    \"\"\"\n",
        "    filter_methods = filter_methods if filter_methods is not None else PREPROCESSING_PIPELINE\n",
        "    return reduce(lambda txt, f: f(txt), filter_methods, text)\n",
        "\n",
        "# Pre-processing\n",
        "\n",
        "print('Pre-processing text...')\n",
        "print('[Debug] Before:\\n{}'.format(extracted.caption[:10]))\n",
        "\n",
        "L=['hashtags','emoji_text','mentions']\n",
        "# L=['hashtags','mentions']\n",
        "A=['caption']\n",
        "\n",
        "# Replace each sentence with its pre-processed version\n",
        "extracted['caption'] = extracted['caption'].apply(lambda txt: text_prepare(txt))\n",
        "\n",
        "for i in L:\n",
        "  extracted[i]=extracted[i].apply(lambda txt: text_prepare1(str(txt)[1:-1]))\n",
        "\n",
        "print('[Debug] After:\\n{}'.format(extracted.caption[:10]))\n",
        "print()\n",
        "\n",
        "print(\"Pre-processing completed!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U2ajqUlZ3Yl9",
        "outputId": "cd1a7745-ce80-4598-e518-c0c27cb35ffb"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pre-processing text...\n",
            "[Debug] Before:\n",
            "0    It’s our last Pizza Sunday at the arch today. ...\n",
            "1                         New cakes on our counters 😋😋\n",
            "2    🔺Opening Times for Half Term🔺: Hi everyone we ...\n",
            "3    New addition to our selection of sandwiches, o...\n",
            "4    We are currently closed as we move into our ne...\n",
            "5    Weekend treats…\\nIncluding the return of our “...\n",
            "6    New vegan “Chocolate & Toasted Almond Cake wit...\n",
            "7    Posted @withregram • @londoncoffeeshops Pastri...\n",
            "8    We are looking for experienced part-time baris...\n",
            "9    Posted @withregram • @marthadelacey Thrilled f...\n",
            "Name: caption, dtype: object\n",
            "[Debug] After:\n",
            "0    last pizza sunday arch today pizzas available ...\n",
            "1                                   new cakes counters\n",
            "2    opening times half term hi everyone wanted let...\n",
            "3    new addition selection sandwiches roasted aube...\n",
            "4    currently closed move new exciting space aroun...\n",
            "5    weekend treatsincluding return coconut custard...\n",
            "6    new vegan chocolate toasted almond cake chocol...\n",
            "7    posted pastries heaven absolutely feel love ca...\n",
            "8    looking experienced parttime baristas join gro...\n",
            "9    posted thrilled folk purveyors favourite custa...\n",
            "Name: caption, dtype: object\n",
            "\n",
            "Pre-processing completed!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Hashtags\n",
        "extracted['hashtag_max'] = extracted.groupby('account')['hashcounts'].transform('max')\n",
        "extracted['hashtag_min'] = extracted.groupby('account')['hashcounts'].transform('min')\n",
        "extracted['hashtag_mean'] = extracted.groupby('account')['hashcounts'].transform('mean')\n",
        "extracted['hashtag_std'] = extracted.groupby('account')['hashcounts'].transform('std')\n",
        "extracted['biography_length'] = extracted['biography'].str.len()\n",
        "extracted['profile_name_len'] = extracted['profile_name'].str.len()\n",
        "\n"
      ],
      "metadata": {
        "id": "5h3xlu4v3i0F"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "extracted.drop('account',1,inplace=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P-TYhxzJ_aMm",
        "outputId": "f8d4f1f4-9c3b-4b42-9e22-31aea954a744"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z43faC01a3Ll",
        "outputId": "ca1f59cb-e3e9-474b-fc77-9e2e675dd238"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pre-processing text...\n",
            "[Debug] Before:\n",
            "0    ['text', 'font', 'graphics', 'screenshot', 'gr...\n",
            "1    ['dessert', 'baked goods', 'baking', 'snack', ...\n",
            "2    ['food', 'fruit', 'baked goods', 'breakfast', ...\n",
            "3    ['food', 'bread', 'fast food', 'bun', 'america...\n",
            "4    ['text', 'font', 'design', 'yellow', 'graphics...\n",
            "5    ['snack', 'baked goods', 'baking', 'dessert', ...\n",
            "6    ['dessert', 'baked goods', 'baking', 'sweetnes...\n",
            "7    ['text', 'food', 'shelf', 'countertop', 'indoo...\n",
            "8    ['text', 'table', 'food', 'bakery', 'clothing'...\n",
            "9    ['baked goods', 'sweetness', 'food', 'baking',...\n",
            "Name: tags, dtype: object\n",
            "[Debug] After:\n",
            "0    text ,  font ,  graphics ,  screenshot ,  grap...\n",
            "1    dessert ,  baked goods ,  baking ,  snack ,  f...\n",
            "2    food ,  fruit ,  baked goods ,  breakfast ,  c...\n",
            "3    food ,  bread ,  fast food ,  bun ,  american ...\n",
            "4    text ,  font ,  design ,  yellow ,  graphics ,...\n",
            "5    snack ,  baked goods ,  baking ,  dessert ,  b...\n",
            "6    dessert ,  baked goods ,  baking ,  sweetness ...\n",
            "7    text ,  food ,  shelf ,  countertop ,  indoor ...\n",
            "8    text ,  table ,  food ,  bakery ,  clothing , ...\n",
            "9    baked goods ,  sweetness ,  food ,  baking ,  ...\n",
            "Name: tags, dtype: object\n",
            "\n",
            "Pre-processing completed!\n"
          ]
        }
      ],
      "source": [
        "REPLACE_BY_SPACE_RE = re.compile('[^a-zA-Z_0-9,.]')\n",
        "\n",
        "def strip_text(text: str) -> str:\n",
        "    \"\"\"\n",
        "    Removes any left or right spacing (including carriage return) from text.\n",
        "    Example:\n",
        "    Input: '  This assignment is cool\\n'\n",
        "    Output: 'This assignment is cool'\n",
        "    \"\"\"\n",
        "\n",
        "    return text.strip()\n",
        "\n",
        "\n",
        "def replace_br(text: str) -> str:\n",
        "    \"\"\"\n",
        "    Replaces br characters\n",
        "    \"\"\"\n",
        "\n",
        "    return text.replace(\"'\", \"\")\n",
        "\n",
        "\n",
        "def replace_special_characters(text: str) -> str:\n",
        "    \"\"\"\n",
        "    Replaces special characters, such as paranthesis,\n",
        "    with spacing character\n",
        "    \"\"\"\n",
        "\n",
        "    return REPLACE_BY_SPACE_RE.sub(' ', text)\n",
        "\n",
        "\n",
        "from typing import List, Callable, Dict\n",
        "\n",
        "PREPROCESSING_PIPELINE = [\n",
        "                          replace_special_characters,\n",
        "                          strip_text\n",
        "                          ]\n",
        "\n",
        "\n",
        "\n",
        "def text_prepare(text: str, filter_methods: List[Callable[[str], str]] = None) -> str:\n",
        "    \"\"\"\n",
        "    Applies a list of pre-processing functions in sequence (reduce).\n",
        "    Note that the order is important here!\n",
        "    \"\"\"\n",
        "    filter_methods = filter_methods if filter_methods is not None else PREPROCESSING_PIPELINE\n",
        "    return reduce(lambda txt, f: f(txt), filter_methods, text)\n",
        "\n",
        "# Pre-processing\n",
        "\n",
        "print('Pre-processing text...')\n",
        "print('[Debug] Before:\\n{}'.format(extracted.tags[:10]))\n",
        "\n",
        "L=['tags','confidence_score','accent_color','dominant_colors','bg_color','fore_color']\n",
        "\n",
        "A=['tags']\n",
        "\n",
        "for i in L:\n",
        "  extracted[i]=extracted[i].apply(lambda txt: text_prepare(str(txt)[1:-1]))\n",
        "\n",
        "print('[Debug] After:\\n{}'.format(extracted.tags[:10]))\n",
        "print()\n",
        "\n",
        "print(\"Pre-processing completed!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "bnJgDxCV87dy"
      },
      "outputs": [],
      "source": [
        "extracted['image_type']=extracted['image_type'].apply(lambda txt: text_prepare(str(txt)[1:-1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "NK72dM5ioXmW"
      },
      "outputs": [],
      "source": [
        "df = pd.get_dummies(extracted, columns=['image_type'])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "WFWgSEDRlUIS",
        "outputId": "df06ab63-4830-4da7-f9b1-d51f3084b689"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                 caption  \\\n",
              "0      last pizza sunday arch today pizzas available ...   \n",
              "1                                     new cakes counters   \n",
              "2      opening times half term hi everyone wanted let...   \n",
              "3      new addition selection sandwiches roasted aube...   \n",
              "4      currently closed move new exciting space aroun...   \n",
              "...                                                  ...   \n",
              "88509  day 2 christmas ochure tour day one ochure tour #   \n",
              "88510                                                      \n",
              "88511  theres one turkey best place buy sandys make c...   \n",
              "88512                              day one ochure tour #   \n",
              "88513  unique amber coloured blue veined cheese soft ...   \n",
              "\n",
              "                         profile_name  \\\n",
              "0                        Yeast Bakery   \n",
              "1                        Yeast Bakery   \n",
              "2                        Yeast Bakery   \n",
              "3                        Yeast Bakery   \n",
              "4                        Yeast Bakery   \n",
              "...                               ...   \n",
              "88509  Fishmongers/ButchersTwickenham   \n",
              "88510  Fishmongers/ButchersTwickenham   \n",
              "88511  Fishmongers/ButchersTwickenham   \n",
              "88512  Fishmongers/ButchersTwickenham   \n",
              "88513  Fishmongers/ButchersTwickenham   \n",
              "\n",
              "                                               biography following  likes  \\\n",
              "0      We are now open at our new site: Unit 1 Canal ...     352.0   29.0   \n",
              "1      We are now open at our new site: Unit 1 Canal ...     352.0   44.0   \n",
              "2      We are now open at our new site: Unit 1 Canal ...     352.0  209.0   \n",
              "3      We are now open at our new site: Unit 1 Canal ...     352.0   95.0   \n",
              "4      We are now open at our new site: Unit 1 Canal ...     352.0  101.0   \n",
              "...                                                  ...       ...    ...   \n",
              "88509  Local Family Fishmongers & Butchers , fresh fi...     579.0   10.0   \n",
              "88510  Local Family Fishmongers & Butchers , fresh fi...     579.0   50.0   \n",
              "88511  Local Family Fishmongers & Butchers , fresh fi...     579.0    8.0   \n",
              "88512  Local Family Fishmongers & Butchers , fresh fi...     579.0    9.0   \n",
              "88513  Local Family Fishmongers & Butchers , fresh fi...     579.0   11.0   \n",
              "\n",
              "      posts_count  followers comments  \\\n",
              "0           280.0     8702.0      0.0   \n",
              "1           280.0     8702.0      0.0   \n",
              "2           280.0     8702.0      9.0   \n",
              "3           280.0     8702.0      3.0   \n",
              "4           280.0     8702.0      6.0   \n",
              "...           ...        ...      ...   \n",
              "88509      1863.0     2321.0      1.0   \n",
              "88510      1863.0     2321.0      0.0   \n",
              "88511      1863.0     2321.0      0.0   \n",
              "88512      1863.0     2321.0      0.0   \n",
              "88513      1863.0     2321.0      2.0   \n",
              "\n",
              "                                                    tags  \\\n",
              "0      text ,  font ,  graphics ,  screenshot ,  grap...   \n",
              "1      dessert ,  baked goods ,  baking ,  snack ,  f...   \n",
              "2      food ,  fruit ,  baked goods ,  breakfast ,  c...   \n",
              "3      food ,  bread ,  fast food ,  bun ,  american ...   \n",
              "4      text ,  font ,  design ,  yellow ,  graphics ,...   \n",
              "...                                                  ...   \n",
              "88509  text ,  book ,  screenshot ,  brochure ,  prin...   \n",
              "88510  building ,  text ,  electronic signage ,  chri...   \n",
              "88511                              text ,  food ,  snack   \n",
              "88512                          text ,  poster ,  cartoon   \n",
              "88513  text ,  yellow ,  packaging and labeling ,  fo...   \n",
              "\n",
              "                                        confidence_score  ...  \\\n",
              "0      0.9980798959732056, 0.9481294751167297, 0.8818...  ...   \n",
              "1      0.9897554516792297, 0.987897515296936, 0.98287...  ...   \n",
              "2      0.9808361530303955, 0.9546540379524231, 0.9477...  ...   \n",
              "3      0.9958561658859253, 0.981575608253479, 0.97992...  ...   \n",
              "4      0.9993002414703369, 0.9640201926231384, 0.9513...  ...   \n",
              "...                                                  ...  ...   \n",
              "88509  0.9999996423721313, 0.9184167385101318, 0.9103...  ...   \n",
              "88510  0.9849988222122192, 0.9520490169525146, 0.9216...  ...   \n",
              "88511  0.9999812841415405, 0.9580191373825073, 0.9157...  ...   \n",
              "88512  0.9999863505363464, 0.9184243679046631, 0.9104...  ...   \n",
              "88513  0.9997624158859253, 0.9444339871406555, 0.8540...  ...   \n",
              "\n",
              "      biography_length profile_name_len image_type_Ambiguous Clip ,  LineDraw  \\\n",
              "0                  149               12                                     0   \n",
              "1                  149               12                                     0   \n",
              "2                  149               12                                     0   \n",
              "3                  149               12                                     0   \n",
              "4                  149               12                                     0   \n",
              "...                ...              ...                                   ...   \n",
              "88509              150               30                                     0   \n",
              "88510              150               30                                     0   \n",
              "88511              150               30                                     0   \n",
              "88512              150               30                                     0   \n",
              "88513              150               30                                     0   \n",
              "\n",
              "      image_type_Ambiguous Clip ,  Not LineDraw  \\\n",
              "0                                             1   \n",
              "1                                             0   \n",
              "2                                             0   \n",
              "3                                             0   \n",
              "4                                             1   \n",
              "...                                         ...   \n",
              "88509                                         0   \n",
              "88510                                         0   \n",
              "88511                                         0   \n",
              "88512                                         0   \n",
              "88513                                         0   \n",
              "\n",
              "      image_type_Good Clip ,  LineDraw image_type_Good Clip ,  Not LineDraw  \\\n",
              "0                                    0                                    0   \n",
              "1                                    0                                    0   \n",
              "2                                    0                                    0   \n",
              "3                                    0                                    0   \n",
              "4                                    0                                    0   \n",
              "...                                ...                                  ...   \n",
              "88509                                0                                    0   \n",
              "88510                                0                                    0   \n",
              "88511                                0                                    0   \n",
              "88512                                0                                    0   \n",
              "88513                                0                                    0   \n",
              "\n",
              "      image_type_Normal Clip ,  LineDraw  \\\n",
              "0                                      0   \n",
              "1                                      0   \n",
              "2                                      0   \n",
              "3                                      0   \n",
              "4                                      0   \n",
              "...                                  ...   \n",
              "88509                                  0   \n",
              "88510                                  0   \n",
              "88511                                  0   \n",
              "88512                                  0   \n",
              "88513                                  0   \n",
              "\n",
              "      image_type_Normal Clip ,  Not LineDraw image_type_Not Clip ,  LineDraw  \\\n",
              "0                                          0                               0   \n",
              "1                                          0                               0   \n",
              "2                                          0                               0   \n",
              "3                                          0                               0   \n",
              "4                                          0                               0   \n",
              "...                                      ...                             ...   \n",
              "88509                                      0                               0   \n",
              "88510                                      0                               0   \n",
              "88511                                      0                               0   \n",
              "88512                                      0                               0   \n",
              "88513                                      0                               0   \n",
              "\n",
              "      image_type_Not Clip ,  Not LineDraw  \n",
              "0                                       0  \n",
              "1                                       1  \n",
              "2                                       1  \n",
              "3                                       1  \n",
              "4                                       0  \n",
              "...                                   ...  \n",
              "88509                                   1  \n",
              "88510                                   1  \n",
              "88511                                   1  \n",
              "88512                                   1  \n",
              "88513                                   1  \n",
              "\n",
              "[88514 rows x 50 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9dd62925-9efc-490e-bcee-66d286b53edf\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>caption</th>\n",
              "      <th>profile_name</th>\n",
              "      <th>biography</th>\n",
              "      <th>following</th>\n",
              "      <th>likes</th>\n",
              "      <th>posts_count</th>\n",
              "      <th>followers</th>\n",
              "      <th>comments</th>\n",
              "      <th>tags</th>\n",
              "      <th>confidence_score</th>\n",
              "      <th>...</th>\n",
              "      <th>biography_length</th>\n",
              "      <th>profile_name_len</th>\n",
              "      <th>image_type_Ambiguous Clip ,  LineDraw</th>\n",
              "      <th>image_type_Ambiguous Clip ,  Not LineDraw</th>\n",
              "      <th>image_type_Good Clip ,  LineDraw</th>\n",
              "      <th>image_type_Good Clip ,  Not LineDraw</th>\n",
              "      <th>image_type_Normal Clip ,  LineDraw</th>\n",
              "      <th>image_type_Normal Clip ,  Not LineDraw</th>\n",
              "      <th>image_type_Not Clip ,  LineDraw</th>\n",
              "      <th>image_type_Not Clip ,  Not LineDraw</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>last pizza sunday arch today pizzas available ...</td>\n",
              "      <td>Yeast Bakery</td>\n",
              "      <td>We are now open at our new site: Unit 1 Canal ...</td>\n",
              "      <td>352.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>280.0</td>\n",
              "      <td>8702.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>text ,  font ,  graphics ,  screenshot ,  grap...</td>\n",
              "      <td>0.9980798959732056, 0.9481294751167297, 0.8818...</td>\n",
              "      <td>...</td>\n",
              "      <td>149</td>\n",
              "      <td>12</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>new cakes counters</td>\n",
              "      <td>Yeast Bakery</td>\n",
              "      <td>We are now open at our new site: Unit 1 Canal ...</td>\n",
              "      <td>352.0</td>\n",
              "      <td>44.0</td>\n",
              "      <td>280.0</td>\n",
              "      <td>8702.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>dessert ,  baked goods ,  baking ,  snack ,  f...</td>\n",
              "      <td>0.9897554516792297, 0.987897515296936, 0.98287...</td>\n",
              "      <td>...</td>\n",
              "      <td>149</td>\n",
              "      <td>12</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>opening times half term hi everyone wanted let...</td>\n",
              "      <td>Yeast Bakery</td>\n",
              "      <td>We are now open at our new site: Unit 1 Canal ...</td>\n",
              "      <td>352.0</td>\n",
              "      <td>209.0</td>\n",
              "      <td>280.0</td>\n",
              "      <td>8702.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>food ,  fruit ,  baked goods ,  breakfast ,  c...</td>\n",
              "      <td>0.9808361530303955, 0.9546540379524231, 0.9477...</td>\n",
              "      <td>...</td>\n",
              "      <td>149</td>\n",
              "      <td>12</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>new addition selection sandwiches roasted aube...</td>\n",
              "      <td>Yeast Bakery</td>\n",
              "      <td>We are now open at our new site: Unit 1 Canal ...</td>\n",
              "      <td>352.0</td>\n",
              "      <td>95.0</td>\n",
              "      <td>280.0</td>\n",
              "      <td>8702.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>food ,  bread ,  fast food ,  bun ,  american ...</td>\n",
              "      <td>0.9958561658859253, 0.981575608253479, 0.97992...</td>\n",
              "      <td>...</td>\n",
              "      <td>149</td>\n",
              "      <td>12</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>currently closed move new exciting space aroun...</td>\n",
              "      <td>Yeast Bakery</td>\n",
              "      <td>We are now open at our new site: Unit 1 Canal ...</td>\n",
              "      <td>352.0</td>\n",
              "      <td>101.0</td>\n",
              "      <td>280.0</td>\n",
              "      <td>8702.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>text ,  font ,  design ,  yellow ,  graphics ,...</td>\n",
              "      <td>0.9993002414703369, 0.9640201926231384, 0.9513...</td>\n",
              "      <td>...</td>\n",
              "      <td>149</td>\n",
              "      <td>12</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88509</th>\n",
              "      <td>day 2 christmas ochure tour day one ochure tour #</td>\n",
              "      <td>Fishmongers/ButchersTwickenham</td>\n",
              "      <td>Local Family Fishmongers &amp; Butchers , fresh fi...</td>\n",
              "      <td>579.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>1863.0</td>\n",
              "      <td>2321.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>text ,  book ,  screenshot ,  brochure ,  prin...</td>\n",
              "      <td>0.9999996423721313, 0.9184167385101318, 0.9103...</td>\n",
              "      <td>...</td>\n",
              "      <td>150</td>\n",
              "      <td>30</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88510</th>\n",
              "      <td></td>\n",
              "      <td>Fishmongers/ButchersTwickenham</td>\n",
              "      <td>Local Family Fishmongers &amp; Butchers , fresh fi...</td>\n",
              "      <td>579.0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>1863.0</td>\n",
              "      <td>2321.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>building ,  text ,  electronic signage ,  chri...</td>\n",
              "      <td>0.9849988222122192, 0.9520490169525146, 0.9216...</td>\n",
              "      <td>...</td>\n",
              "      <td>150</td>\n",
              "      <td>30</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88511</th>\n",
              "      <td>theres one turkey best place buy sandys make c...</td>\n",
              "      <td>Fishmongers/ButchersTwickenham</td>\n",
              "      <td>Local Family Fishmongers &amp; Butchers , fresh fi...</td>\n",
              "      <td>579.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>1863.0</td>\n",
              "      <td>2321.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>text ,  food ,  snack</td>\n",
              "      <td>0.9999812841415405, 0.9580191373825073, 0.9157...</td>\n",
              "      <td>...</td>\n",
              "      <td>150</td>\n",
              "      <td>30</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88512</th>\n",
              "      <td>day one ochure tour #</td>\n",
              "      <td>Fishmongers/ButchersTwickenham</td>\n",
              "      <td>Local Family Fishmongers &amp; Butchers , fresh fi...</td>\n",
              "      <td>579.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>1863.0</td>\n",
              "      <td>2321.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>text ,  poster ,  cartoon</td>\n",
              "      <td>0.9999863505363464, 0.9184243679046631, 0.9104...</td>\n",
              "      <td>...</td>\n",
              "      <td>150</td>\n",
              "      <td>30</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88513</th>\n",
              "      <td>unique amber coloured blue veined cheese soft ...</td>\n",
              "      <td>Fishmongers/ButchersTwickenham</td>\n",
              "      <td>Local Family Fishmongers &amp; Butchers , fresh fi...</td>\n",
              "      <td>579.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>1863.0</td>\n",
              "      <td>2321.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>text ,  yellow ,  packaging and labeling ,  fo...</td>\n",
              "      <td>0.9997624158859253, 0.9444339871406555, 0.8540...</td>\n",
              "      <td>...</td>\n",
              "      <td>150</td>\n",
              "      <td>30</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>88514 rows × 50 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9dd62925-9efc-490e-bcee-66d286b53edf')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9dd62925-9efc-490e-bcee-66d286b53edf button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9dd62925-9efc-490e-bcee-66d286b53edf');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "Kalj66ZKYH5y"
      },
      "outputs": [],
      "source": [
        "# for i in df1['confidence_score']:\n",
        "\n",
        "def convert_str2int(i):\n",
        "  n = []\n",
        "  y = i.split(', ')\n",
        "  if len(y[0]) == 0:\n",
        "    return []\n",
        "  for j in range(len(y)):\n",
        "    n.append(float(y[j]))\n",
        "  return n\n",
        "\n",
        "df['confidence_score'] = df['confidence_score'].apply(convert_str2int)\n",
        "df['accent_color'] = df['accent_color'].apply(convert_str2int)\n",
        "df['dominant_colors'] = df['dominant_colors'].apply(convert_str2int)\n",
        "df['bg_color'] = df['bg_color'].apply(convert_str2int)\n",
        "df['fore_color'] = df['fore_color'].apply(convert_str2int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "7XVPCQW59Aq0",
        "outputId": "657da20d-8d00-40ca-96e7-7e7578e74b57"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                 caption  \\\n",
              "0      last pizza sunday arch today pizzas available ...   \n",
              "1                                     new cakes counters   \n",
              "2      opening times half term hi everyone wanted let...   \n",
              "3      new addition selection sandwiches roasted aube...   \n",
              "4      currently closed move new exciting space aroun...   \n",
              "...                                                  ...   \n",
              "88509  day 2 christmas ochure tour day one ochure tour #   \n",
              "88510                                                      \n",
              "88511  theres one turkey best place buy sandys make c...   \n",
              "88512                              day one ochure tour #   \n",
              "88513  unique amber coloured blue veined cheese soft ...   \n",
              "\n",
              "                         profile_name  \\\n",
              "0                        Yeast Bakery   \n",
              "1                        Yeast Bakery   \n",
              "2                        Yeast Bakery   \n",
              "3                        Yeast Bakery   \n",
              "4                        Yeast Bakery   \n",
              "...                               ...   \n",
              "88509  Fishmongers/ButchersTwickenham   \n",
              "88510  Fishmongers/ButchersTwickenham   \n",
              "88511  Fishmongers/ButchersTwickenham   \n",
              "88512  Fishmongers/ButchersTwickenham   \n",
              "88513  Fishmongers/ButchersTwickenham   \n",
              "\n",
              "                                               biography following  likes  \\\n",
              "0      We are now open at our new site: Unit 1 Canal ...     352.0   29.0   \n",
              "1      We are now open at our new site: Unit 1 Canal ...     352.0   44.0   \n",
              "2      We are now open at our new site: Unit 1 Canal ...     352.0  209.0   \n",
              "3      We are now open at our new site: Unit 1 Canal ...     352.0   95.0   \n",
              "4      We are now open at our new site: Unit 1 Canal ...     352.0  101.0   \n",
              "...                                                  ...       ...    ...   \n",
              "88509  Local Family Fishmongers & Butchers , fresh fi...     579.0   10.0   \n",
              "88510  Local Family Fishmongers & Butchers , fresh fi...     579.0   50.0   \n",
              "88511  Local Family Fishmongers & Butchers , fresh fi...     579.0    8.0   \n",
              "88512  Local Family Fishmongers & Butchers , fresh fi...     579.0    9.0   \n",
              "88513  Local Family Fishmongers & Butchers , fresh fi...     579.0   11.0   \n",
              "\n",
              "      posts_count  followers comments  \\\n",
              "0           280.0     8702.0      0.0   \n",
              "1           280.0     8702.0      0.0   \n",
              "2           280.0     8702.0      9.0   \n",
              "3           280.0     8702.0      3.0   \n",
              "4           280.0     8702.0      6.0   \n",
              "...           ...        ...      ...   \n",
              "88509      1863.0     2321.0      1.0   \n",
              "88510      1863.0     2321.0      0.0   \n",
              "88511      1863.0     2321.0      0.0   \n",
              "88512      1863.0     2321.0      0.0   \n",
              "88513      1863.0     2321.0      2.0   \n",
              "\n",
              "                                                    tags  \\\n",
              "0      text ,  font ,  graphics ,  screenshot ,  grap...   \n",
              "1      dessert ,  baked goods ,  baking ,  snack ,  f...   \n",
              "2      food ,  fruit ,  baked goods ,  breakfast ,  c...   \n",
              "3      food ,  bread ,  fast food ,  bun ,  american ...   \n",
              "4      text ,  font ,  design ,  yellow ,  graphics ,...   \n",
              "...                                                  ...   \n",
              "88509  text ,  book ,  screenshot ,  brochure ,  prin...   \n",
              "88510  building ,  text ,  electronic signage ,  chri...   \n",
              "88511                              text ,  food ,  snack   \n",
              "88512                          text ,  poster ,  cartoon   \n",
              "88513  text ,  yellow ,  packaging and labeling ,  fo...   \n",
              "\n",
              "                                        confidence_score  ...  \\\n",
              "0      [0.9980798959732056, 0.9481294751167297, 0.881...  ...   \n",
              "1      [0.9897554516792297, 0.987897515296936, 0.9828...  ...   \n",
              "2      [0.9808361530303955, 0.9546540379524231, 0.947...  ...   \n",
              "3      [0.9958561658859253, 0.981575608253479, 0.9799...  ...   \n",
              "4      [0.9993002414703369, 0.9640201926231384, 0.951...  ...   \n",
              "...                                                  ...  ...   \n",
              "88509  [0.9999996423721313, 0.9184167385101318, 0.910...  ...   \n",
              "88510  [0.9849988222122192, 0.9520490169525146, 0.921...  ...   \n",
              "88511  [0.9999812841415405, 0.9580191373825073, 0.915...  ...   \n",
              "88512  [0.9999863505363464, 0.9184243679046631, 0.910...  ...   \n",
              "88513  [0.9997624158859253, 0.9444339871406555, 0.854...  ...   \n",
              "\n",
              "      biography_length profile_name_len image_type_Ambiguous Clip ,  LineDraw  \\\n",
              "0                  149               12                                     0   \n",
              "1                  149               12                                     0   \n",
              "2                  149               12                                     0   \n",
              "3                  149               12                                     0   \n",
              "4                  149               12                                     0   \n",
              "...                ...              ...                                   ...   \n",
              "88509              150               30                                     0   \n",
              "88510              150               30                                     0   \n",
              "88511              150               30                                     0   \n",
              "88512              150               30                                     0   \n",
              "88513              150               30                                     0   \n",
              "\n",
              "      image_type_Ambiguous Clip ,  Not LineDraw  \\\n",
              "0                                             1   \n",
              "1                                             0   \n",
              "2                                             0   \n",
              "3                                             0   \n",
              "4                                             1   \n",
              "...                                         ...   \n",
              "88509                                         0   \n",
              "88510                                         0   \n",
              "88511                                         0   \n",
              "88512                                         0   \n",
              "88513                                         0   \n",
              "\n",
              "      image_type_Good Clip ,  LineDraw image_type_Good Clip ,  Not LineDraw  \\\n",
              "0                                    0                                    0   \n",
              "1                                    0                                    0   \n",
              "2                                    0                                    0   \n",
              "3                                    0                                    0   \n",
              "4                                    0                                    0   \n",
              "...                                ...                                  ...   \n",
              "88509                                0                                    0   \n",
              "88510                                0                                    0   \n",
              "88511                                0                                    0   \n",
              "88512                                0                                    0   \n",
              "88513                                0                                    0   \n",
              "\n",
              "      image_type_Normal Clip ,  LineDraw  \\\n",
              "0                                      0   \n",
              "1                                      0   \n",
              "2                                      0   \n",
              "3                                      0   \n",
              "4                                      0   \n",
              "...                                  ...   \n",
              "88509                                  0   \n",
              "88510                                  0   \n",
              "88511                                  0   \n",
              "88512                                  0   \n",
              "88513                                  0   \n",
              "\n",
              "      image_type_Normal Clip ,  Not LineDraw image_type_Not Clip ,  LineDraw  \\\n",
              "0                                          0                               0   \n",
              "1                                          0                               0   \n",
              "2                                          0                               0   \n",
              "3                                          0                               0   \n",
              "4                                          0                               0   \n",
              "...                                      ...                             ...   \n",
              "88509                                      0                               0   \n",
              "88510                                      0                               0   \n",
              "88511                                      0                               0   \n",
              "88512                                      0                               0   \n",
              "88513                                      0                               0   \n",
              "\n",
              "      image_type_Not Clip ,  Not LineDraw  \n",
              "0                                       0  \n",
              "1                                       1  \n",
              "2                                       1  \n",
              "3                                       1  \n",
              "4                                       0  \n",
              "...                                   ...  \n",
              "88509                                   1  \n",
              "88510                                   1  \n",
              "88511                                   1  \n",
              "88512                                   1  \n",
              "88513                                   1  \n",
              "\n",
              "[88514 rows x 50 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-74969432-f544-40a7-a242-b100e514048d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>caption</th>\n",
              "      <th>profile_name</th>\n",
              "      <th>biography</th>\n",
              "      <th>following</th>\n",
              "      <th>likes</th>\n",
              "      <th>posts_count</th>\n",
              "      <th>followers</th>\n",
              "      <th>comments</th>\n",
              "      <th>tags</th>\n",
              "      <th>confidence_score</th>\n",
              "      <th>...</th>\n",
              "      <th>biography_length</th>\n",
              "      <th>profile_name_len</th>\n",
              "      <th>image_type_Ambiguous Clip ,  LineDraw</th>\n",
              "      <th>image_type_Ambiguous Clip ,  Not LineDraw</th>\n",
              "      <th>image_type_Good Clip ,  LineDraw</th>\n",
              "      <th>image_type_Good Clip ,  Not LineDraw</th>\n",
              "      <th>image_type_Normal Clip ,  LineDraw</th>\n",
              "      <th>image_type_Normal Clip ,  Not LineDraw</th>\n",
              "      <th>image_type_Not Clip ,  LineDraw</th>\n",
              "      <th>image_type_Not Clip ,  Not LineDraw</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>last pizza sunday arch today pizzas available ...</td>\n",
              "      <td>Yeast Bakery</td>\n",
              "      <td>We are now open at our new site: Unit 1 Canal ...</td>\n",
              "      <td>352.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>280.0</td>\n",
              "      <td>8702.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>text ,  font ,  graphics ,  screenshot ,  grap...</td>\n",
              "      <td>[0.9980798959732056, 0.9481294751167297, 0.881...</td>\n",
              "      <td>...</td>\n",
              "      <td>149</td>\n",
              "      <td>12</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>new cakes counters</td>\n",
              "      <td>Yeast Bakery</td>\n",
              "      <td>We are now open at our new site: Unit 1 Canal ...</td>\n",
              "      <td>352.0</td>\n",
              "      <td>44.0</td>\n",
              "      <td>280.0</td>\n",
              "      <td>8702.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>dessert ,  baked goods ,  baking ,  snack ,  f...</td>\n",
              "      <td>[0.9897554516792297, 0.987897515296936, 0.9828...</td>\n",
              "      <td>...</td>\n",
              "      <td>149</td>\n",
              "      <td>12</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>opening times half term hi everyone wanted let...</td>\n",
              "      <td>Yeast Bakery</td>\n",
              "      <td>We are now open at our new site: Unit 1 Canal ...</td>\n",
              "      <td>352.0</td>\n",
              "      <td>209.0</td>\n",
              "      <td>280.0</td>\n",
              "      <td>8702.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>food ,  fruit ,  baked goods ,  breakfast ,  c...</td>\n",
              "      <td>[0.9808361530303955, 0.9546540379524231, 0.947...</td>\n",
              "      <td>...</td>\n",
              "      <td>149</td>\n",
              "      <td>12</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>new addition selection sandwiches roasted aube...</td>\n",
              "      <td>Yeast Bakery</td>\n",
              "      <td>We are now open at our new site: Unit 1 Canal ...</td>\n",
              "      <td>352.0</td>\n",
              "      <td>95.0</td>\n",
              "      <td>280.0</td>\n",
              "      <td>8702.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>food ,  bread ,  fast food ,  bun ,  american ...</td>\n",
              "      <td>[0.9958561658859253, 0.981575608253479, 0.9799...</td>\n",
              "      <td>...</td>\n",
              "      <td>149</td>\n",
              "      <td>12</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>currently closed move new exciting space aroun...</td>\n",
              "      <td>Yeast Bakery</td>\n",
              "      <td>We are now open at our new site: Unit 1 Canal ...</td>\n",
              "      <td>352.0</td>\n",
              "      <td>101.0</td>\n",
              "      <td>280.0</td>\n",
              "      <td>8702.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>text ,  font ,  design ,  yellow ,  graphics ,...</td>\n",
              "      <td>[0.9993002414703369, 0.9640201926231384, 0.951...</td>\n",
              "      <td>...</td>\n",
              "      <td>149</td>\n",
              "      <td>12</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88509</th>\n",
              "      <td>day 2 christmas ochure tour day one ochure tour #</td>\n",
              "      <td>Fishmongers/ButchersTwickenham</td>\n",
              "      <td>Local Family Fishmongers &amp; Butchers , fresh fi...</td>\n",
              "      <td>579.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>1863.0</td>\n",
              "      <td>2321.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>text ,  book ,  screenshot ,  brochure ,  prin...</td>\n",
              "      <td>[0.9999996423721313, 0.9184167385101318, 0.910...</td>\n",
              "      <td>...</td>\n",
              "      <td>150</td>\n",
              "      <td>30</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88510</th>\n",
              "      <td></td>\n",
              "      <td>Fishmongers/ButchersTwickenham</td>\n",
              "      <td>Local Family Fishmongers &amp; Butchers , fresh fi...</td>\n",
              "      <td>579.0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>1863.0</td>\n",
              "      <td>2321.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>building ,  text ,  electronic signage ,  chri...</td>\n",
              "      <td>[0.9849988222122192, 0.9520490169525146, 0.921...</td>\n",
              "      <td>...</td>\n",
              "      <td>150</td>\n",
              "      <td>30</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88511</th>\n",
              "      <td>theres one turkey best place buy sandys make c...</td>\n",
              "      <td>Fishmongers/ButchersTwickenham</td>\n",
              "      <td>Local Family Fishmongers &amp; Butchers , fresh fi...</td>\n",
              "      <td>579.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>1863.0</td>\n",
              "      <td>2321.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>text ,  food ,  snack</td>\n",
              "      <td>[0.9999812841415405, 0.9580191373825073, 0.915...</td>\n",
              "      <td>...</td>\n",
              "      <td>150</td>\n",
              "      <td>30</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88512</th>\n",
              "      <td>day one ochure tour #</td>\n",
              "      <td>Fishmongers/ButchersTwickenham</td>\n",
              "      <td>Local Family Fishmongers &amp; Butchers , fresh fi...</td>\n",
              "      <td>579.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>1863.0</td>\n",
              "      <td>2321.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>text ,  poster ,  cartoon</td>\n",
              "      <td>[0.9999863505363464, 0.9184243679046631, 0.910...</td>\n",
              "      <td>...</td>\n",
              "      <td>150</td>\n",
              "      <td>30</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88513</th>\n",
              "      <td>unique amber coloured blue veined cheese soft ...</td>\n",
              "      <td>Fishmongers/ButchersTwickenham</td>\n",
              "      <td>Local Family Fishmongers &amp; Butchers , fresh fi...</td>\n",
              "      <td>579.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>1863.0</td>\n",
              "      <td>2321.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>text ,  yellow ,  packaging and labeling ,  fo...</td>\n",
              "      <td>[0.9997624158859253, 0.9444339871406555, 0.854...</td>\n",
              "      <td>...</td>\n",
              "      <td>150</td>\n",
              "      <td>30</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>88514 rows × 50 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-74969432-f544-40a7-a242-b100e514048d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-74969432-f544-40a7-a242-b100e514048d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-74969432-f544-40a7-a242-b100e514048d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gqQtfQRFWnB8",
        "outputId": "95d6452c-38b1-4084-edb2-c00e516262ed"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['text ',\n",
              " ' font ',\n",
              " ' graphics ',\n",
              " ' screenshot ',\n",
              " ' graphic design ',\n",
              " ' design ',\n",
              " ' typography']"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ],
      "source": [
        "def convert_str2list(i):\n",
        "  n = []\n",
        "  y = i.split(', ')\n",
        "  for j in range(len(y)):\n",
        "    n.append(str(y[j]))\n",
        "  return n\n",
        "df['tags'] = df['tags'].apply(convert_str2list)\n",
        "df['tags'][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bi7yKyHlzX5l",
        "outputId": "dc816980-4a4d-41e6-94a8-3e2557dda56a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.9938297271728516,\n",
              " 0.9784528613090515,\n",
              " 0.977806806564331,\n",
              " 0.966992974281311,\n",
              " 0.9616279602050781,\n",
              " 0.9515609741210938,\n",
              " 0.9280351400375366,\n",
              " 0.912075936794281,\n",
              " 0.9083282947540283,\n",
              " 0.9079588651657104,\n",
              " 0.8951475620269775,\n",
              " 0.8874362707138062,\n",
              " 0.8836393356323242,\n",
              " 0.8746436834335327,\n",
              " 0.8713182210922241,\n",
              " 0.8668385744094849,\n",
              " 0.8426526784896851,\n",
              " 0.786042332649231,\n",
              " 0.5681669116020203]"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ],
      "source": [
        "df['confidence_score'][6]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "_oMjJJjIepvW"
      },
      "outputs": [],
      "source": [
        "def trim_lowConfidence_tags(tag_column):\n",
        "  for scoreList in df['confidence_score']:\n",
        "    for score_index in range(len(scoreList)):\n",
        "      if scoreList[score_index]<0.5:\n",
        "        return tag_column[:score_index]\n",
        "\n",
        "df['tags'] = df['tags'].apply(trim_lowConfidence_tags)  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "lkwMwfyezuCd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "626d794f-5115-4c6a-eef5-9c98de201ebf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        }
      ],
      "source": [
        "df.drop('confidence_score',1,inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DbCwM3oXz3hO",
        "outputId": "b21dae01-0ce9-4b20-99cf-2773017915bc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.6470588235294118, 0.16470588235294117, 0.16470588235294117]"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ],
      "source": [
        "df.dominant_colors[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qG2M7A_C32NR",
        "outputId": "ba379b0e-9317-4bf7-83d7-99372b657a03"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0         [1.0, 0.7529411764705882, 0.796078431372549]\n",
              "1    [0.6470588235294118, 0.16470588235294117, 0.16...\n",
              "2    [0.6470588235294118, 0.16470588235294117, 0.16...\n",
              "Name: dominant_colors, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ],
      "source": [
        "df['dominant_colors'][:3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "D1XGUWcl0U1d"
      },
      "outputs": [],
      "source": [
        "def separate_column(column):\n",
        "  if len(column)>0:\n",
        "    return column[0]\n",
        "  else:\n",
        "    return []\n",
        "\n",
        "df['dominant_colors_R'] = df['dominant_colors'].apply(separate_column)  \n",
        "df['accent_color_R'] = df['accent_color'].apply(separate_column)  \n",
        "df['bg_color_R'] = df['bg_color'].apply(separate_column)  \n",
        "df['fore_color_R'] = df['fore_color'].apply(separate_column)  "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ENIZEORG7pK9",
        "outputId": "fab483a4-2a23-43e6-dbfd-49fa803d9319"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                 caption  \\\n",
              "0      last pizza sunday arch today pizzas available ...   \n",
              "1                                     new cakes counters   \n",
              "2      opening times half term hi everyone wanted let...   \n",
              "3      new addition selection sandwiches roasted aube...   \n",
              "4      currently closed move new exciting space aroun...   \n",
              "...                                                  ...   \n",
              "88509  day 2 christmas ochure tour day one ochure tour #   \n",
              "88510                                                      \n",
              "88511  theres one turkey best place buy sandys make c...   \n",
              "88512                              day one ochure tour #   \n",
              "88513  unique amber coloured blue veined cheese soft ...   \n",
              "\n",
              "                         profile_name  \\\n",
              "0                        Yeast Bakery   \n",
              "1                        Yeast Bakery   \n",
              "2                        Yeast Bakery   \n",
              "3                        Yeast Bakery   \n",
              "4                        Yeast Bakery   \n",
              "...                               ...   \n",
              "88509  Fishmongers/ButchersTwickenham   \n",
              "88510  Fishmongers/ButchersTwickenham   \n",
              "88511  Fishmongers/ButchersTwickenham   \n",
              "88512  Fishmongers/ButchersTwickenham   \n",
              "88513  Fishmongers/ButchersTwickenham   \n",
              "\n",
              "                                               biography following  likes  \\\n",
              "0      We are now open at our new site: Unit 1 Canal ...     352.0   29.0   \n",
              "1      We are now open at our new site: Unit 1 Canal ...     352.0   44.0   \n",
              "2      We are now open at our new site: Unit 1 Canal ...     352.0  209.0   \n",
              "3      We are now open at our new site: Unit 1 Canal ...     352.0   95.0   \n",
              "4      We are now open at our new site: Unit 1 Canal ...     352.0  101.0   \n",
              "...                                                  ...       ...    ...   \n",
              "88509  Local Family Fishmongers & Butchers , fresh fi...     579.0   10.0   \n",
              "88510  Local Family Fishmongers & Butchers , fresh fi...     579.0   50.0   \n",
              "88511  Local Family Fishmongers & Butchers , fresh fi...     579.0    8.0   \n",
              "88512  Local Family Fishmongers & Butchers , fresh fi...     579.0    9.0   \n",
              "88513  Local Family Fishmongers & Butchers , fresh fi...     579.0   11.0   \n",
              "\n",
              "      posts_count  followers comments  \\\n",
              "0           280.0     8702.0      0.0   \n",
              "1           280.0     8702.0      0.0   \n",
              "2           280.0     8702.0      9.0   \n",
              "3           280.0     8702.0      3.0   \n",
              "4           280.0     8702.0      6.0   \n",
              "...           ...        ...      ...   \n",
              "88509      1863.0     2321.0      1.0   \n",
              "88510      1863.0     2321.0      0.0   \n",
              "88511      1863.0     2321.0      0.0   \n",
              "88512      1863.0     2321.0      0.0   \n",
              "88513      1863.0     2321.0      2.0   \n",
              "\n",
              "                                                    tags  \\\n",
              "0      [text ,  font ,  graphics ,  screenshot ,  gra...   \n",
              "1      [dessert ,  baked goods ,  baking ,  snack ,  ...   \n",
              "2      [food ,  fruit ,  baked goods ,  breakfast ,  ...   \n",
              "3      [food ,  bread ,  fast food ,  bun ,  american...   \n",
              "4      [text ,  font ,  design ,  yellow ,  graphics ...   \n",
              "...                                                  ...   \n",
              "88509  [text ,  book ,  screenshot ,  brochure ,  pri...   \n",
              "88510  [building ,  text ,  electronic signage ,  chr...   \n",
              "88511                            [text ,  food ,  snack]   \n",
              "88512                        [text ,  poster ,  cartoon]   \n",
              "88513  [text ,  yellow ,  packaging and labeling ,  f...   \n",
              "\n",
              "                                            accent_color  ...  \\\n",
              "0      [0.788235294117647, 0.00784313725490196, 0.007...  ...   \n",
              "1      [0.6901960784313725, 0.14901960784313725, 0.10...  ...   \n",
              "2      [0.6588235294117647, 0.4392156862745098, 0.141...  ...   \n",
              "3      [0.24313725490196078, 0.12549019607843137, 0.0...  ...   \n",
              "4      [0.792156862745098, 0.7372549019607844, 0.0039...  ...   \n",
              "...                                                  ...  ...   \n",
              "88509  [0.011764705882352941, 0.5019607843137255, 0.7...  ...   \n",
              "88510  [0.6470588235294118, 0.1568627450980392, 0.149...  ...   \n",
              "88511  [0.6588235294117647, 0.00784313725490196, 0.71...  ...   \n",
              "88512  [0.01568627450980392, 0.5098039215686274, 0.78...  ...   \n",
              "88513  [0.01568627450980392, 0.2235294117647059, 0.43...  ...   \n",
              "\n",
              "      image_type_Good Clip ,  LineDraw image_type_Good Clip ,  Not LineDraw  \\\n",
              "0                                    0                                    0   \n",
              "1                                    0                                    0   \n",
              "2                                    0                                    0   \n",
              "3                                    0                                    0   \n",
              "4                                    0                                    0   \n",
              "...                                ...                                  ...   \n",
              "88509                                0                                    0   \n",
              "88510                                0                                    0   \n",
              "88511                                0                                    0   \n",
              "88512                                0                                    0   \n",
              "88513                                0                                    0   \n",
              "\n",
              "      image_type_Normal Clip ,  LineDraw  \\\n",
              "0                                      0   \n",
              "1                                      0   \n",
              "2                                      0   \n",
              "3                                      0   \n",
              "4                                      0   \n",
              "...                                  ...   \n",
              "88509                                  0   \n",
              "88510                                  0   \n",
              "88511                                  0   \n",
              "88512                                  0   \n",
              "88513                                  0   \n",
              "\n",
              "      image_type_Normal Clip ,  Not LineDraw image_type_Not Clip ,  LineDraw  \\\n",
              "0                                          0                               0   \n",
              "1                                          0                               0   \n",
              "2                                          0                               0   \n",
              "3                                          0                               0   \n",
              "4                                          0                               0   \n",
              "...                                      ...                             ...   \n",
              "88509                                      0                               0   \n",
              "88510                                      0                               0   \n",
              "88511                                      0                               0   \n",
              "88512                                      0                               0   \n",
              "88513                                      0                               0   \n",
              "\n",
              "      image_type_Not Clip ,  Not LineDraw dominant_colors_R accent_color_R  \\\n",
              "0                                       0          1.000000       0.788235   \n",
              "1                                       1          0.647059       0.690196   \n",
              "2                                       1          0.647059       0.658824   \n",
              "3                                       1          0.647059       0.243137   \n",
              "4                                       0          1.000000       0.792157   \n",
              "...                                   ...               ...            ...   \n",
              "88509                                   1          1.000000       0.011765   \n",
              "88510                                   1          0.501961       0.647059   \n",
              "88511                                   1          0.501961       0.658824   \n",
              "88512                                   1          1.000000       0.015686   \n",
              "88513                                   1          1.000000       0.015686   \n",
              "\n",
              "      bg_color_R fore_color_R  \n",
              "0       1.000000     1.000000  \n",
              "1       0.647059     0.000000  \n",
              "2       0.647059     0.647059  \n",
              "3       0.647059     0.647059  \n",
              "4       1.000000     1.000000  \n",
              "...          ...          ...  \n",
              "88509   0.000000     1.000000  \n",
              "88510   0.000000     1.000000  \n",
              "88511   0.501961     0.501961  \n",
              "88512   1.000000     1.000000  \n",
              "88513   0.000000     1.000000  \n",
              "\n",
              "[88514 rows x 53 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0900f430-e67c-4a6c-9b50-a1ac5d567d88\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>caption</th>\n",
              "      <th>profile_name</th>\n",
              "      <th>biography</th>\n",
              "      <th>following</th>\n",
              "      <th>likes</th>\n",
              "      <th>posts_count</th>\n",
              "      <th>followers</th>\n",
              "      <th>comments</th>\n",
              "      <th>tags</th>\n",
              "      <th>accent_color</th>\n",
              "      <th>...</th>\n",
              "      <th>image_type_Good Clip ,  LineDraw</th>\n",
              "      <th>image_type_Good Clip ,  Not LineDraw</th>\n",
              "      <th>image_type_Normal Clip ,  LineDraw</th>\n",
              "      <th>image_type_Normal Clip ,  Not LineDraw</th>\n",
              "      <th>image_type_Not Clip ,  LineDraw</th>\n",
              "      <th>image_type_Not Clip ,  Not LineDraw</th>\n",
              "      <th>dominant_colors_R</th>\n",
              "      <th>accent_color_R</th>\n",
              "      <th>bg_color_R</th>\n",
              "      <th>fore_color_R</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>last pizza sunday arch today pizzas available ...</td>\n",
              "      <td>Yeast Bakery</td>\n",
              "      <td>We are now open at our new site: Unit 1 Canal ...</td>\n",
              "      <td>352.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>280.0</td>\n",
              "      <td>8702.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>[text ,  font ,  graphics ,  screenshot ,  gra...</td>\n",
              "      <td>[0.788235294117647, 0.00784313725490196, 0.007...</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.788235</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>new cakes counters</td>\n",
              "      <td>Yeast Bakery</td>\n",
              "      <td>We are now open at our new site: Unit 1 Canal ...</td>\n",
              "      <td>352.0</td>\n",
              "      <td>44.0</td>\n",
              "      <td>280.0</td>\n",
              "      <td>8702.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>[dessert ,  baked goods ,  baking ,  snack ,  ...</td>\n",
              "      <td>[0.6901960784313725, 0.14901960784313725, 0.10...</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.647059</td>\n",
              "      <td>0.690196</td>\n",
              "      <td>0.647059</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>opening times half term hi everyone wanted let...</td>\n",
              "      <td>Yeast Bakery</td>\n",
              "      <td>We are now open at our new site: Unit 1 Canal ...</td>\n",
              "      <td>352.0</td>\n",
              "      <td>209.0</td>\n",
              "      <td>280.0</td>\n",
              "      <td>8702.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>[food ,  fruit ,  baked goods ,  breakfast ,  ...</td>\n",
              "      <td>[0.6588235294117647, 0.4392156862745098, 0.141...</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.647059</td>\n",
              "      <td>0.658824</td>\n",
              "      <td>0.647059</td>\n",
              "      <td>0.647059</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>new addition selection sandwiches roasted aube...</td>\n",
              "      <td>Yeast Bakery</td>\n",
              "      <td>We are now open at our new site: Unit 1 Canal ...</td>\n",
              "      <td>352.0</td>\n",
              "      <td>95.0</td>\n",
              "      <td>280.0</td>\n",
              "      <td>8702.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>[food ,  bread ,  fast food ,  bun ,  american...</td>\n",
              "      <td>[0.24313725490196078, 0.12549019607843137, 0.0...</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.647059</td>\n",
              "      <td>0.243137</td>\n",
              "      <td>0.647059</td>\n",
              "      <td>0.647059</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>currently closed move new exciting space aroun...</td>\n",
              "      <td>Yeast Bakery</td>\n",
              "      <td>We are now open at our new site: Unit 1 Canal ...</td>\n",
              "      <td>352.0</td>\n",
              "      <td>101.0</td>\n",
              "      <td>280.0</td>\n",
              "      <td>8702.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>[text ,  font ,  design ,  yellow ,  graphics ...</td>\n",
              "      <td>[0.792156862745098, 0.7372549019607844, 0.0039...</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.792157</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88509</th>\n",
              "      <td>day 2 christmas ochure tour day one ochure tour #</td>\n",
              "      <td>Fishmongers/ButchersTwickenham</td>\n",
              "      <td>Local Family Fishmongers &amp; Butchers , fresh fi...</td>\n",
              "      <td>579.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>1863.0</td>\n",
              "      <td>2321.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>[text ,  book ,  screenshot ,  brochure ,  pri...</td>\n",
              "      <td>[0.011764705882352941, 0.5019607843137255, 0.7...</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.011765</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88510</th>\n",
              "      <td></td>\n",
              "      <td>Fishmongers/ButchersTwickenham</td>\n",
              "      <td>Local Family Fishmongers &amp; Butchers , fresh fi...</td>\n",
              "      <td>579.0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>1863.0</td>\n",
              "      <td>2321.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>[building ,  text ,  electronic signage ,  chr...</td>\n",
              "      <td>[0.6470588235294118, 0.1568627450980392, 0.149...</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.501961</td>\n",
              "      <td>0.647059</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88511</th>\n",
              "      <td>theres one turkey best place buy sandys make c...</td>\n",
              "      <td>Fishmongers/ButchersTwickenham</td>\n",
              "      <td>Local Family Fishmongers &amp; Butchers , fresh fi...</td>\n",
              "      <td>579.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>1863.0</td>\n",
              "      <td>2321.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>[text ,  food ,  snack]</td>\n",
              "      <td>[0.6588235294117647, 0.00784313725490196, 0.71...</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.501961</td>\n",
              "      <td>0.658824</td>\n",
              "      <td>0.501961</td>\n",
              "      <td>0.501961</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88512</th>\n",
              "      <td>day one ochure tour #</td>\n",
              "      <td>Fishmongers/ButchersTwickenham</td>\n",
              "      <td>Local Family Fishmongers &amp; Butchers , fresh fi...</td>\n",
              "      <td>579.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>1863.0</td>\n",
              "      <td>2321.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>[text ,  poster ,  cartoon]</td>\n",
              "      <td>[0.01568627450980392, 0.5098039215686274, 0.78...</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.015686</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88513</th>\n",
              "      <td>unique amber coloured blue veined cheese soft ...</td>\n",
              "      <td>Fishmongers/ButchersTwickenham</td>\n",
              "      <td>Local Family Fishmongers &amp; Butchers , fresh fi...</td>\n",
              "      <td>579.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>1863.0</td>\n",
              "      <td>2321.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>[text ,  yellow ,  packaging and labeling ,  f...</td>\n",
              "      <td>[0.01568627450980392, 0.2235294117647059, 0.43...</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.015686</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>88514 rows × 53 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0900f430-e67c-4a6c-9b50-a1ac5d567d88')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0900f430-e67c-4a6c-9b50-a1ac5d567d88 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0900f430-e67c-4a6c-9b50-a1ac5d567d88');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "DOfR-uGM6z81"
      },
      "outputs": [],
      "source": [
        "dropped = ['accent_color', 'dominant_colors', 'bg_color','fore_color']\n",
        "data = df.drop(dropped,axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "0aQZRcUGoXmp",
        "outputId": "8e9e8af0-b6ca-4557-9020-5f1f4c37b41a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                 caption  \\\n",
              "0      last pizza sunday arch today pizzas available ...   \n",
              "1                                     new cakes counters   \n",
              "2      opening times half term hi everyone wanted let...   \n",
              "3      new addition selection sandwiches roasted aube...   \n",
              "4      currently closed move new exciting space aroun...   \n",
              "...                                                  ...   \n",
              "88509  day 2 christmas ochure tour day one ochure tour #   \n",
              "88510                                                      \n",
              "88511  theres one turkey best place buy sandys make c...   \n",
              "88512                              day one ochure tour #   \n",
              "88513  unique amber coloured blue veined cheese soft ...   \n",
              "\n",
              "                         profile_name  \\\n",
              "0                        Yeast Bakery   \n",
              "1                        Yeast Bakery   \n",
              "2                        Yeast Bakery   \n",
              "3                        Yeast Bakery   \n",
              "4                        Yeast Bakery   \n",
              "...                               ...   \n",
              "88509  Fishmongers/ButchersTwickenham   \n",
              "88510  Fishmongers/ButchersTwickenham   \n",
              "88511  Fishmongers/ButchersTwickenham   \n",
              "88512  Fishmongers/ButchersTwickenham   \n",
              "88513  Fishmongers/ButchersTwickenham   \n",
              "\n",
              "                                               biography following  likes  \\\n",
              "0      We are now open at our new site: Unit 1 Canal ...     352.0   29.0   \n",
              "1      We are now open at our new site: Unit 1 Canal ...     352.0   44.0   \n",
              "2      We are now open at our new site: Unit 1 Canal ...     352.0  209.0   \n",
              "3      We are now open at our new site: Unit 1 Canal ...     352.0   95.0   \n",
              "4      We are now open at our new site: Unit 1 Canal ...     352.0  101.0   \n",
              "...                                                  ...       ...    ...   \n",
              "88509  Local Family Fishmongers & Butchers , fresh fi...     579.0   10.0   \n",
              "88510  Local Family Fishmongers & Butchers , fresh fi...     579.0   50.0   \n",
              "88511  Local Family Fishmongers & Butchers , fresh fi...     579.0    8.0   \n",
              "88512  Local Family Fishmongers & Butchers , fresh fi...     579.0    9.0   \n",
              "88513  Local Family Fishmongers & Butchers , fresh fi...     579.0   11.0   \n",
              "\n",
              "      posts_count  followers comments  \\\n",
              "0           280.0     8702.0      0.0   \n",
              "1           280.0     8702.0      0.0   \n",
              "2           280.0     8702.0      9.0   \n",
              "3           280.0     8702.0      3.0   \n",
              "4           280.0     8702.0      6.0   \n",
              "...           ...        ...      ...   \n",
              "88509      1863.0     2321.0      1.0   \n",
              "88510      1863.0     2321.0      0.0   \n",
              "88511      1863.0     2321.0      0.0   \n",
              "88512      1863.0     2321.0      0.0   \n",
              "88513      1863.0     2321.0      2.0   \n",
              "\n",
              "                                                    tags is_bw  ...  \\\n",
              "0      [text ,  font ,  graphics ,  screenshot ,  gra...     0  ...   \n",
              "1      [dessert ,  baked goods ,  baking ,  snack ,  ...     0  ...   \n",
              "2      [food ,  fruit ,  baked goods ,  breakfast ,  ...     0  ...   \n",
              "3      [food ,  bread ,  fast food ,  bun ,  american...     0  ...   \n",
              "4      [text ,  font ,  design ,  yellow ,  graphics ...     0  ...   \n",
              "...                                                  ...   ...  ...   \n",
              "88509  [text ,  book ,  screenshot ,  brochure ,  pri...     0  ...   \n",
              "88510  [building ,  text ,  electronic signage ,  chr...     0  ...   \n",
              "88511                            [text ,  food ,  snack]     0  ...   \n",
              "88512                        [text ,  poster ,  cartoon]     0  ...   \n",
              "88513  [text ,  yellow ,  packaging and labeling ,  f...     0  ...   \n",
              "\n",
              "      image_type_Good Clip ,  LineDraw image_type_Good Clip ,  Not LineDraw  \\\n",
              "0                                    0                                    0   \n",
              "1                                    0                                    0   \n",
              "2                                    0                                    0   \n",
              "3                                    0                                    0   \n",
              "4                                    0                                    0   \n",
              "...                                ...                                  ...   \n",
              "88509                                0                                    0   \n",
              "88510                                0                                    0   \n",
              "88511                                0                                    0   \n",
              "88512                                0                                    0   \n",
              "88513                                0                                    0   \n",
              "\n",
              "      image_type_Normal Clip ,  LineDraw  \\\n",
              "0                                      0   \n",
              "1                                      0   \n",
              "2                                      0   \n",
              "3                                      0   \n",
              "4                                      0   \n",
              "...                                  ...   \n",
              "88509                                  0   \n",
              "88510                                  0   \n",
              "88511                                  0   \n",
              "88512                                  0   \n",
              "88513                                  0   \n",
              "\n",
              "      image_type_Normal Clip ,  Not LineDraw image_type_Not Clip ,  LineDraw  \\\n",
              "0                                          0                               0   \n",
              "1                                          0                               0   \n",
              "2                                          0                               0   \n",
              "3                                          0                               0   \n",
              "4                                          0                               0   \n",
              "...                                      ...                             ...   \n",
              "88509                                      0                               0   \n",
              "88510                                      0                               0   \n",
              "88511                                      0                               0   \n",
              "88512                                      0                               0   \n",
              "88513                                      0                               0   \n",
              "\n",
              "      image_type_Not Clip ,  Not LineDraw dominant_colors_R accent_color_R  \\\n",
              "0                                       0          1.000000       0.788235   \n",
              "1                                       1          0.647059       0.690196   \n",
              "2                                       1          0.647059       0.658824   \n",
              "3                                       1          0.647059       0.243137   \n",
              "4                                       0          1.000000       0.792157   \n",
              "...                                   ...               ...            ...   \n",
              "88509                                   1          1.000000       0.011765   \n",
              "88510                                   1          0.501961       0.647059   \n",
              "88511                                   1          0.501961       0.658824   \n",
              "88512                                   1          1.000000       0.015686   \n",
              "88513                                   1          1.000000       0.015686   \n",
              "\n",
              "      bg_color_R fore_color_R  \n",
              "0       1.000000     1.000000  \n",
              "1       0.647059     0.000000  \n",
              "2       0.647059     0.647059  \n",
              "3       0.647059     0.647059  \n",
              "4       1.000000     1.000000  \n",
              "...          ...          ...  \n",
              "88509   0.000000     1.000000  \n",
              "88510   0.000000     1.000000  \n",
              "88511   0.501961     0.501961  \n",
              "88512   1.000000     1.000000  \n",
              "88513   0.000000     1.000000  \n",
              "\n",
              "[88514 rows x 49 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fc6cdf4d-42b0-4848-827f-1ebfbf356960\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>caption</th>\n",
              "      <th>profile_name</th>\n",
              "      <th>biography</th>\n",
              "      <th>following</th>\n",
              "      <th>likes</th>\n",
              "      <th>posts_count</th>\n",
              "      <th>followers</th>\n",
              "      <th>comments</th>\n",
              "      <th>tags</th>\n",
              "      <th>is_bw</th>\n",
              "      <th>...</th>\n",
              "      <th>image_type_Good Clip ,  LineDraw</th>\n",
              "      <th>image_type_Good Clip ,  Not LineDraw</th>\n",
              "      <th>image_type_Normal Clip ,  LineDraw</th>\n",
              "      <th>image_type_Normal Clip ,  Not LineDraw</th>\n",
              "      <th>image_type_Not Clip ,  LineDraw</th>\n",
              "      <th>image_type_Not Clip ,  Not LineDraw</th>\n",
              "      <th>dominant_colors_R</th>\n",
              "      <th>accent_color_R</th>\n",
              "      <th>bg_color_R</th>\n",
              "      <th>fore_color_R</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>last pizza sunday arch today pizzas available ...</td>\n",
              "      <td>Yeast Bakery</td>\n",
              "      <td>We are now open at our new site: Unit 1 Canal ...</td>\n",
              "      <td>352.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>280.0</td>\n",
              "      <td>8702.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>[text ,  font ,  graphics ,  screenshot ,  gra...</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.788235</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>new cakes counters</td>\n",
              "      <td>Yeast Bakery</td>\n",
              "      <td>We are now open at our new site: Unit 1 Canal ...</td>\n",
              "      <td>352.0</td>\n",
              "      <td>44.0</td>\n",
              "      <td>280.0</td>\n",
              "      <td>8702.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>[dessert ,  baked goods ,  baking ,  snack ,  ...</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.647059</td>\n",
              "      <td>0.690196</td>\n",
              "      <td>0.647059</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>opening times half term hi everyone wanted let...</td>\n",
              "      <td>Yeast Bakery</td>\n",
              "      <td>We are now open at our new site: Unit 1 Canal ...</td>\n",
              "      <td>352.0</td>\n",
              "      <td>209.0</td>\n",
              "      <td>280.0</td>\n",
              "      <td>8702.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>[food ,  fruit ,  baked goods ,  breakfast ,  ...</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.647059</td>\n",
              "      <td>0.658824</td>\n",
              "      <td>0.647059</td>\n",
              "      <td>0.647059</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>new addition selection sandwiches roasted aube...</td>\n",
              "      <td>Yeast Bakery</td>\n",
              "      <td>We are now open at our new site: Unit 1 Canal ...</td>\n",
              "      <td>352.0</td>\n",
              "      <td>95.0</td>\n",
              "      <td>280.0</td>\n",
              "      <td>8702.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>[food ,  bread ,  fast food ,  bun ,  american...</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.647059</td>\n",
              "      <td>0.243137</td>\n",
              "      <td>0.647059</td>\n",
              "      <td>0.647059</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>currently closed move new exciting space aroun...</td>\n",
              "      <td>Yeast Bakery</td>\n",
              "      <td>We are now open at our new site: Unit 1 Canal ...</td>\n",
              "      <td>352.0</td>\n",
              "      <td>101.0</td>\n",
              "      <td>280.0</td>\n",
              "      <td>8702.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>[text ,  font ,  design ,  yellow ,  graphics ...</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.792157</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88509</th>\n",
              "      <td>day 2 christmas ochure tour day one ochure tour #</td>\n",
              "      <td>Fishmongers/ButchersTwickenham</td>\n",
              "      <td>Local Family Fishmongers &amp; Butchers , fresh fi...</td>\n",
              "      <td>579.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>1863.0</td>\n",
              "      <td>2321.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>[text ,  book ,  screenshot ,  brochure ,  pri...</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.011765</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88510</th>\n",
              "      <td></td>\n",
              "      <td>Fishmongers/ButchersTwickenham</td>\n",
              "      <td>Local Family Fishmongers &amp; Butchers , fresh fi...</td>\n",
              "      <td>579.0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>1863.0</td>\n",
              "      <td>2321.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>[building ,  text ,  electronic signage ,  chr...</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.501961</td>\n",
              "      <td>0.647059</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88511</th>\n",
              "      <td>theres one turkey best place buy sandys make c...</td>\n",
              "      <td>Fishmongers/ButchersTwickenham</td>\n",
              "      <td>Local Family Fishmongers &amp; Butchers , fresh fi...</td>\n",
              "      <td>579.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>1863.0</td>\n",
              "      <td>2321.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>[text ,  food ,  snack]</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.501961</td>\n",
              "      <td>0.658824</td>\n",
              "      <td>0.501961</td>\n",
              "      <td>0.501961</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88512</th>\n",
              "      <td>day one ochure tour #</td>\n",
              "      <td>Fishmongers/ButchersTwickenham</td>\n",
              "      <td>Local Family Fishmongers &amp; Butchers , fresh fi...</td>\n",
              "      <td>579.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>1863.0</td>\n",
              "      <td>2321.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>[text ,  poster ,  cartoon]</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.015686</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88513</th>\n",
              "      <td>unique amber coloured blue veined cheese soft ...</td>\n",
              "      <td>Fishmongers/ButchersTwickenham</td>\n",
              "      <td>Local Family Fishmongers &amp; Butchers , fresh fi...</td>\n",
              "      <td>579.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>1863.0</td>\n",
              "      <td>2321.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>[text ,  yellow ,  packaging and labeling ,  f...</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.015686</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>88514 rows × 49 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fc6cdf4d-42b0-4848-827f-1ebfbf356960')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-fc6cdf4d-42b0-4848-827f-1ebfbf356960 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-fc6cdf4d-42b0-4848-827f-1ebfbf356960');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ],
      "source": [
        "data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C_vmSou7hgYK"
      },
      "source": [
        "##FastText"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Image Tags"
      ],
      "metadata": {
        "id": "jFDR6x5zuLlQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data['tags']=data['tags'].apply(lambda txt: text_prepare(str(txt)[1:-1]))\n",
        "tokenized_tag = data['tags'].apply(lambda x: x.split()[1:-1])"
      ],
      "metadata": {
        "id": "35kmDPXMteix"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "hQnjzC68hjgE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fbf29f58-f722-4db9-a77f-548085eae677"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-22 23:29:12,935 | WARNING | base_any2vec.py:723 | __init__ | consider setting layer size to a multiple of 4 for greater performance\n",
            "2022-05-22 23:29:12,936 | INFO | word2vec.py:1567 | scan_vocab | collecting all words and their counts\n",
            "2022-05-22 23:29:12,947 | INFO | word2vec.py:1552 | _scan_vocab | PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
            "2022-05-22 23:29:12,981 | INFO | word2vec.py:1552 | _scan_vocab | PROGRESS: at sentence #10000, processed 184916 words, keeping 2209 word types\n",
            "2022-05-22 23:29:13,023 | INFO | word2vec.py:1552 | _scan_vocab | PROGRESS: at sentence #20000, processed 375164 words, keeping 2671 word types\n",
            "2022-05-22 23:29:13,062 | INFO | word2vec.py:1552 | _scan_vocab | PROGRESS: at sentence #30000, processed 562939 words, keeping 2938 word types\n",
            "2022-05-22 23:29:13,101 | INFO | word2vec.py:1552 | _scan_vocab | PROGRESS: at sentence #40000, processed 754746 words, keeping 3128 word types\n",
            "2022-05-22 23:29:13,138 | INFO | word2vec.py:1552 | _scan_vocab | PROGRESS: at sentence #50000, processed 941580 words, keeping 3261 word types\n",
            "2022-05-22 23:29:13,174 | INFO | word2vec.py:1552 | _scan_vocab | PROGRESS: at sentence #60000, processed 1134158 words, keeping 3405 word types\n",
            "2022-05-22 23:29:13,211 | INFO | word2vec.py:1552 | _scan_vocab | PROGRESS: at sentence #70000, processed 1323170 words, keeping 3506 word types\n",
            "2022-05-22 23:29:13,245 | INFO | word2vec.py:1552 | _scan_vocab | PROGRESS: at sentence #80000, processed 1513335 words, keeping 3611 word types\n",
            "2022-05-22 23:29:13,272 | INFO | word2vec.py:1575 | scan_vocab | collected 3667 word types from a corpus of 1673757 raw words and 88514 sentences\n",
            "2022-05-22 23:29:13,273 | INFO | word2vec.py:1626 | prepare_vocab | Loading a fresh vocabulary\n",
            "2022-05-22 23:29:13,282 | INFO | word2vec.py:1650 | prepare_vocab | effective_min_count=2 retains 3100 unique words (84% of original 3667, drops 567)\n",
            "2022-05-22 23:29:13,284 | INFO | word2vec.py:1656 | prepare_vocab | effective_min_count=2 leaves 1673190 word corpus (99% of original 1673757, drops 567)\n",
            "2022-05-22 23:29:13,293 | INFO | word2vec.py:1715 | prepare_vocab | deleting the raw counts dictionary of 3667 items\n",
            "2022-05-22 23:29:13,296 | INFO | word2vec.py:1718 | prepare_vocab | sample=0.001 downsamples 46 most-common words\n",
            "2022-05-22 23:29:13,301 | INFO | word2vec.py:1721 | prepare_vocab | downsampling leaves estimated 741111 word corpus (44.3% of prior 1673190)\n",
            "2022-05-22 23:29:13,337 | INFO | fasttext.py:551 | estimate_memory | estimated required memory for 3100 words, 31159 buckets and 50 dimensions: 9667080 bytes\n",
            "2022-05-22 23:29:13,339 | INFO | word2vec.py:1834 | reset_weights | resetting layer weights\n",
            "2022-05-22 23:29:14,031 | INFO | fasttext.py:1011 | init_ngrams_weights | Total number of ngrams is 31159\n",
            "2022-05-22 23:29:14,226 | INFO | base_any2vec.py:1210 | _check_training_sanity | training model with 32 workers on 3100 vocabulary and 50 features, using sg=1 hs=0 sample=0.001 negative=10 window=2\n",
            "2022-05-22 23:29:15,349 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 1 - PROGRESS: at 3.03% examples, 19920 words/s, in_qsize 51, out_qsize 12\n",
            "2022-05-22 23:29:16,419 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 1 - PROGRESS: at 24.74% examples, 83046 words/s, in_qsize 62, out_qsize 1\n",
            "2022-05-22 23:29:17,468 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 1 - PROGRESS: at 46.07% examples, 105250 words/s, in_qsize 61, out_qsize 2\n",
            "2022-05-22 23:29:18,479 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 1 - PROGRESS: at 72.35% examples, 125839 words/s, in_qsize 47, out_qsize 0\n",
            "2022-05-22 23:29:18,802 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 31 more threads\n",
            "2022-05-22 23:29:18,871 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 30 more threads\n",
            "2022-05-22 23:29:19,170 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 29 more threads\n",
            "2022-05-22 23:29:19,247 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 28 more threads\n",
            "2022-05-22 23:29:19,299 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 27 more threads\n",
            "2022-05-22 23:29:19,303 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 26 more threads\n",
            "2022-05-22 23:29:19,307 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 25 more threads\n",
            "2022-05-22 23:29:19,309 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 24 more threads\n",
            "2022-05-22 23:29:19,315 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 23 more threads\n",
            "2022-05-22 23:29:19,344 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 22 more threads\n",
            "2022-05-22 23:29:19,345 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 21 more threads\n",
            "2022-05-22 23:29:19,348 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 20 more threads\n",
            "2022-05-22 23:29:19,362 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 19 more threads\n",
            "2022-05-22 23:29:19,373 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 18 more threads\n",
            "2022-05-22 23:29:19,385 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 17 more threads\n",
            "2022-05-22 23:29:19,389 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 16 more threads\n",
            "2022-05-22 23:29:19,395 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 15 more threads\n",
            "2022-05-22 23:29:19,424 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 14 more threads\n",
            "2022-05-22 23:29:19,433 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 13 more threads\n",
            "2022-05-22 23:29:19,438 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 12 more threads\n",
            "2022-05-22 23:29:19,469 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 11 more threads\n",
            "2022-05-22 23:29:19,472 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 10 more threads\n",
            "2022-05-22 23:29:19,482 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 1 - PROGRESS: at 94.72% examples, 133601 words/s, in_qsize 2, out_qsize 15\n",
            "2022-05-22 23:29:19,487 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 9 more threads\n",
            "2022-05-22 23:29:19,492 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 8 more threads\n",
            "2022-05-22 23:29:19,497 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 7 more threads\n",
            "2022-05-22 23:29:19,501 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 6 more threads\n",
            "2022-05-22 23:29:19,506 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 5 more threads\n",
            "2022-05-22 23:29:19,510 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 4 more threads\n",
            "2022-05-22 23:29:19,523 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 3 more threads\n",
            "2022-05-22 23:29:19,538 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 2 more threads\n",
            "2022-05-22 23:29:19,539 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 1 more threads\n",
            "2022-05-22 23:29:19,543 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 0 more threads\n",
            "2022-05-22 23:29:19,546 | INFO | base_any2vec.py:1346 | _log_epoch_end | EPOCH - 1 : training on 1673757 raw words (740653 effective words) took 5.3s, 139599 effective words/s\n",
            "2022-05-22 23:29:20,817 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 2 - PROGRESS: at 4.29% examples, 25532 words/s, in_qsize 59, out_qsize 4\n",
            "2022-05-22 23:29:21,918 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 2 - PROGRESS: at 26.49% examples, 84646 words/s, in_qsize 62, out_qsize 1\n",
            "2022-05-22 23:29:22,924 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 2 - PROGRESS: at 47.26% examples, 105573 words/s, in_qsize 63, out_qsize 0\n",
            "2022-05-22 23:29:23,955 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 2 - PROGRESS: at 65.78% examples, 112117 words/s, in_qsize 55, out_qsize 3\n",
            "2022-05-22 23:29:24,399 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 31 more threads\n",
            "2022-05-22 23:29:24,461 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 30 more threads\n",
            "2022-05-22 23:29:24,492 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 29 more threads\n",
            "2022-05-22 23:29:24,512 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 28 more threads\n",
            "2022-05-22 23:29:24,707 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 27 more threads\n",
            "2022-05-22 23:29:24,753 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 26 more threads\n",
            "2022-05-22 23:29:24,759 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 25 more threads\n",
            "2022-05-22 23:29:24,771 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 24 more threads\n",
            "2022-05-22 23:29:24,791 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 23 more threads\n",
            "2022-05-22 23:29:24,838 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 22 more threads\n",
            "2022-05-22 23:29:24,854 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 21 more threads\n",
            "2022-05-22 23:29:24,868 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 20 more threads\n",
            "2022-05-22 23:29:24,872 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 19 more threads\n",
            "2022-05-22 23:29:24,889 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 18 more threads\n",
            "2022-05-22 23:29:24,917 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 17 more threads\n",
            "2022-05-22 23:29:24,922 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 16 more threads\n",
            "2022-05-22 23:29:24,934 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 15 more threads\n",
            "2022-05-22 23:29:24,936 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 14 more threads\n",
            "2022-05-22 23:29:24,966 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 2 - PROGRESS: at 92.28% examples, 127831 words/s, in_qsize 12, out_qsize 3\n",
            "2022-05-22 23:29:24,968 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 13 more threads\n",
            "2022-05-22 23:29:24,974 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 12 more threads\n",
            "2022-05-22 23:29:24,986 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 11 more threads\n",
            "2022-05-22 23:29:24,993 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 10 more threads\n",
            "2022-05-22 23:29:25,010 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 9 more threads\n",
            "2022-05-22 23:29:25,011 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 8 more threads\n",
            "2022-05-22 23:29:25,015 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 7 more threads\n",
            "2022-05-22 23:29:25,018 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 6 more threads\n",
            "2022-05-22 23:29:25,022 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 5 more threads\n",
            "2022-05-22 23:29:25,045 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 4 more threads\n",
            "2022-05-22 23:29:25,047 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 3 more threads\n",
            "2022-05-22 23:29:25,050 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 2 more threads\n",
            "2022-05-22 23:29:25,054 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 1 more threads\n",
            "2022-05-22 23:29:25,059 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 0 more threads\n",
            "2022-05-22 23:29:25,063 | INFO | base_any2vec.py:1346 | _log_epoch_end | EPOCH - 2 : training on 1673757 raw words (741238 effective words) took 5.4s, 136215 effective words/s\n",
            "2022-05-22 23:29:26,291 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 3 - PROGRESS: at 2.44% examples, 15358 words/s, in_qsize 51, out_qsize 12\n",
            "2022-05-22 23:29:27,369 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 3 - PROGRESS: at 23.48% examples, 77041 words/s, in_qsize 44, out_qsize 19\n",
            "2022-05-22 23:29:28,453 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 3 - PROGRESS: at 45.13% examples, 99528 words/s, in_qsize 64, out_qsize 6\n",
            "2022-05-22 23:29:29,455 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 3 - PROGRESS: at 78.81% examples, 134741 words/s, in_qsize 34, out_qsize 2\n",
            "2022-05-22 23:29:30,014 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 31 more threads\n",
            "2022-05-22 23:29:30,041 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 30 more threads\n",
            "2022-05-22 23:29:30,079 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 29 more threads\n",
            "2022-05-22 23:29:30,111 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 28 more threads\n",
            "2022-05-22 23:29:30,221 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 27 more threads\n",
            "2022-05-22 23:29:30,228 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 26 more threads\n",
            "2022-05-22 23:29:30,265 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 25 more threads\n",
            "2022-05-22 23:29:30,277 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 24 more threads\n",
            "2022-05-22 23:29:30,296 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 23 more threads\n",
            "2022-05-22 23:29:30,325 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 22 more threads\n",
            "2022-05-22 23:29:30,350 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 21 more threads\n",
            "2022-05-22 23:29:30,362 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 20 more threads\n",
            "2022-05-22 23:29:30,368 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 19 more threads\n",
            "2022-05-22 23:29:30,374 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 18 more threads\n",
            "2022-05-22 23:29:30,386 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 17 more threads\n",
            "2022-05-22 23:29:30,409 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 16 more threads\n",
            "2022-05-22 23:29:30,412 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 15 more threads\n",
            "2022-05-22 23:29:30,414 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 14 more threads\n",
            "2022-05-22 23:29:30,418 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 13 more threads\n",
            "2022-05-22 23:29:30,420 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 12 more threads\n",
            "2022-05-22 23:29:30,434 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 11 more threads\n",
            "2022-05-22 23:29:30,436 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 10 more threads\n",
            "2022-05-22 23:29:30,444 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 9 more threads\n",
            "2022-05-22 23:29:30,447 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 8 more threads\n",
            "2022-05-22 23:29:30,455 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 7 more threads\n",
            "2022-05-22 23:29:30,456 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 3 - PROGRESS: at 96.27% examples, 134144 words/s, in_qsize 0, out_qsize 13\n",
            "2022-05-22 23:29:30,464 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 6 more threads\n",
            "2022-05-22 23:29:30,468 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 5 more threads\n",
            "2022-05-22 23:29:30,475 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 4 more threads\n",
            "2022-05-22 23:29:30,479 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 3 more threads\n",
            "2022-05-22 23:29:30,480 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 2 more threads\n",
            "2022-05-22 23:29:30,481 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 1 more threads\n",
            "2022-05-22 23:29:30,487 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 0 more threads\n",
            "2022-05-22 23:29:30,489 | INFO | base_any2vec.py:1346 | _log_epoch_end | EPOCH - 3 : training on 1673757 raw words (740832 effective words) took 5.4s, 138296 effective words/s\n",
            "2022-05-22 23:29:31,557 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 4 - PROGRESS: at 3.03% examples, 21300 words/s, in_qsize 49, out_qsize 2\n",
            "2022-05-22 23:29:32,582 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 4 - PROGRESS: at 22.88% examples, 81408 words/s, in_qsize 60, out_qsize 3\n",
            "2022-05-22 23:29:33,749 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 4 - PROGRESS: at 47.87% examples, 109464 words/s, in_qsize 64, out_qsize 0\n",
            "2022-05-22 23:29:34,872 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 4 - PROGRESS: at 68.65% examples, 116818 words/s, in_qsize 50, out_qsize 3\n",
            "2022-05-22 23:29:35,375 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 31 more threads\n",
            "2022-05-22 23:29:35,500 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 30 more threads\n",
            "2022-05-22 23:29:35,508 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 29 more threads\n",
            "2022-05-22 23:29:35,516 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 28 more threads\n",
            "2022-05-22 23:29:35,542 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 27 more threads\n",
            "2022-05-22 23:29:35,560 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 26 more threads\n",
            "2022-05-22 23:29:35,570 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 25 more threads\n",
            "2022-05-22 23:29:35,607 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 24 more threads\n",
            "2022-05-22 23:29:35,648 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 23 more threads\n",
            "2022-05-22 23:29:35,673 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 22 more threads\n",
            "2022-05-22 23:29:35,695 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 21 more threads\n",
            "2022-05-22 23:29:35,705 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 20 more threads\n",
            "2022-05-22 23:29:35,714 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 19 more threads\n",
            "2022-05-22 23:29:35,720 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 18 more threads\n",
            "2022-05-22 23:29:35,734 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 17 more threads\n",
            "2022-05-22 23:29:35,747 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 16 more threads\n",
            "2022-05-22 23:29:35,753 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 15 more threads\n",
            "2022-05-22 23:29:35,765 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 14 more threads\n",
            "2022-05-22 23:29:35,775 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 13 more threads\n",
            "2022-05-22 23:29:35,800 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 12 more threads\n",
            "2022-05-22 23:29:35,801 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 11 more threads\n",
            "2022-05-22 23:29:35,807 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 10 more threads\n",
            "2022-05-22 23:29:35,808 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 9 more threads\n",
            "2022-05-22 23:29:35,816 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 8 more threads\n",
            "2022-05-22 23:29:35,825 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 7 more threads\n",
            "2022-05-22 23:29:35,853 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 6 more threads\n",
            "2022-05-22 23:29:35,864 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 5 more threads\n",
            "2022-05-22 23:29:35,865 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 4 more threads\n",
            "2022-05-22 23:29:35,868 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 3 more threads\n",
            "2022-05-22 23:29:35,872 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 2 more threads\n",
            "2022-05-22 23:29:35,875 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 4 - PROGRESS: at 99.39% examples, 137625 words/s, in_qsize 0, out_qsize 3\n",
            "2022-05-22 23:29:35,878 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 1 more threads\n",
            "2022-05-22 23:29:35,881 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 0 more threads\n",
            "2022-05-22 23:29:35,885 | INFO | base_any2vec.py:1346 | _log_epoch_end | EPOCH - 4 : training on 1673757 raw words (741346 effective words) took 5.4s, 138210 effective words/s\n",
            "2022-05-22 23:29:36,951 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 5 - PROGRESS: at 6.11% examples, 43040 words/s, in_qsize 62, out_qsize 1\n",
            "2022-05-22 23:29:38,036 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 5 - PROGRESS: at 26.52% examples, 91940 words/s, in_qsize 63, out_qsize 0\n",
            "2022-05-22 23:29:39,249 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 5 - PROGRESS: at 47.29% examples, 104892 words/s, in_qsize 63, out_qsize 0\n",
            "2022-05-22 23:29:40,287 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 5 - PROGRESS: at 68.14% examples, 115408 words/s, in_qsize 53, out_qsize 1\n",
            "2022-05-22 23:29:40,483 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 31 more threads\n",
            "2022-05-22 23:29:40,493 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 30 more threads\n",
            "2022-05-22 23:29:40,531 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 29 more threads\n",
            "2022-05-22 23:29:40,553 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 28 more threads\n",
            "2022-05-22 23:29:40,675 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 27 more threads\n",
            "2022-05-22 23:29:40,742 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 26 more threads\n",
            "2022-05-22 23:29:40,943 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 25 more threads\n",
            "2022-05-22 23:29:40,954 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 24 more threads\n",
            "2022-05-22 23:29:40,999 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 23 more threads\n",
            "2022-05-22 23:29:41,062 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 22 more threads\n",
            "2022-05-22 23:29:41,089 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 21 more threads\n",
            "2022-05-22 23:29:41,093 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 20 more threads\n",
            "2022-05-22 23:29:41,103 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 19 more threads\n",
            "2022-05-22 23:29:41,107 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 18 more threads\n",
            "2022-05-22 23:29:41,114 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 17 more threads\n",
            "2022-05-22 23:29:41,119 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 16 more threads\n",
            "2022-05-22 23:29:41,162 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 15 more threads\n",
            "2022-05-22 23:29:41,163 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 14 more threads\n",
            "2022-05-22 23:29:41,165 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 13 more threads\n",
            "2022-05-22 23:29:41,168 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 12 more threads\n",
            "2022-05-22 23:29:41,169 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 11 more threads\n",
            "2022-05-22 23:29:41,172 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 10 more threads\n",
            "2022-05-22 23:29:41,185 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 9 more threads\n",
            "2022-05-22 23:29:41,193 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 8 more threads\n",
            "2022-05-22 23:29:41,204 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 7 more threads\n",
            "2022-05-22 23:29:41,206 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 6 more threads\n",
            "2022-05-22 23:29:41,212 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 5 more threads\n",
            "2022-05-22 23:29:41,213 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 4 more threads\n",
            "2022-05-22 23:29:41,216 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 3 more threads\n",
            "2022-05-22 23:29:41,220 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 2 more threads\n",
            "2022-05-22 23:29:41,222 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 1 more threads\n",
            "2022-05-22 23:29:41,230 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 0 more threads\n",
            "2022-05-22 23:29:41,231 | INFO | base_any2vec.py:1346 | _log_epoch_end | EPOCH - 5 : training on 1673757 raw words (741241 effective words) took 5.3s, 139699 effective words/s\n",
            "2022-05-22 23:29:41,232 | INFO | base_any2vec.py:1382 | _log_train_end | training on a 8368785 raw words (3705310 effective words) took 27.0s, 137205 effective words/s\n",
            "2022-05-22 23:29:41,490 | INFO | word2vec.py:1567 | scan_vocab | collecting all words and their counts\n",
            "2022-05-22 23:29:41,502 | INFO | word2vec.py:1552 | _scan_vocab | PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
            "2022-05-22 23:29:41,602 | INFO | word2vec.py:1552 | _scan_vocab | PROGRESS: at sentence #10000, processed 184916 words, keeping 2209 word types\n",
            "2022-05-22 23:29:41,662 | INFO | word2vec.py:1552 | _scan_vocab | PROGRESS: at sentence #20000, processed 375164 words, keeping 2671 word types\n",
            "2022-05-22 23:29:41,733 | INFO | word2vec.py:1552 | _scan_vocab | PROGRESS: at sentence #30000, processed 562939 words, keeping 2938 word types\n",
            "2022-05-22 23:29:41,828 | INFO | word2vec.py:1552 | _scan_vocab | PROGRESS: at sentence #40000, processed 754746 words, keeping 3128 word types\n",
            "2022-05-22 23:29:41,891 | INFO | word2vec.py:1552 | _scan_vocab | PROGRESS: at sentence #50000, processed 941580 words, keeping 3261 word types\n",
            "2022-05-22 23:29:41,948 | INFO | word2vec.py:1552 | _scan_vocab | PROGRESS: at sentence #60000, processed 1134158 words, keeping 3405 word types\n",
            "2022-05-22 23:29:42,009 | INFO | word2vec.py:1552 | _scan_vocab | PROGRESS: at sentence #70000, processed 1323170 words, keeping 3506 word types\n",
            "2022-05-22 23:29:42,158 | INFO | word2vec.py:1552 | _scan_vocab | PROGRESS: at sentence #80000, processed 1513335 words, keeping 3611 word types\n",
            "2022-05-22 23:29:42,265 | INFO | word2vec.py:1575 | scan_vocab | collected 3667 word types from a corpus of 1673757 raw words and 88514 sentences\n",
            "2022-05-22 23:29:42,267 | INFO | word2vec.py:1659 | prepare_vocab | Updating model with new vocabulary\n",
            "2022-05-22 23:29:42,276 | INFO | word2vec.py:1685 | prepare_vocab | New added 3100 unique words (45% of original 6767) and increased the count of 3100 pre-existing words (45% of original 6767)\n",
            "2022-05-22 23:29:42,307 | INFO | word2vec.py:1715 | prepare_vocab | deleting the raw counts dictionary of 3667 items\n",
            "2022-05-22 23:29:42,309 | INFO | word2vec.py:1718 | prepare_vocab | sample=0.001 downsamples 92 most-common words\n",
            "2022-05-22 23:29:42,311 | INFO | word2vec.py:1721 | prepare_vocab | downsampling leaves estimated 1482223 word corpus (88.6% of prior 1673190)\n",
            "2022-05-22 23:29:42,372 | INFO | fasttext.py:551 | estimate_memory | estimated required memory for 3100 words, 31159 buckets and 50 dimensions: 9667080 bytes\n",
            "2022-05-22 23:29:42,375 | INFO | word2vec.py:1850 | update_weights | updating layer weights\n",
            "2022-05-22 23:29:42,477 | INFO | fasttext.py:1030 | init_ngrams_weights | Number of new ngrams is 0\n",
            "2022-05-22 23:29:42,483 | WARNING | base_any2vec.py:1182 | _check_training_sanity | Effective 'alpha' higher than previous training cycles\n",
            "2022-05-22 23:29:42,485 | INFO | base_any2vec.py:1210 | _check_training_sanity | training model with 32 workers on 3100 vocabulary and 50 features, using sg=1 hs=0 sample=0.001 negative=10 window=2\n",
            "2022-05-22 23:29:43,677 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 1 - PROGRESS: at 8.63% examples, 54651 words/s, in_qsize 52, out_qsize 3\n",
            "2022-05-22 23:29:44,694 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 1 - PROGRESS: at 30.09% examples, 102877 words/s, in_qsize 61, out_qsize 2\n",
            "2022-05-22 23:29:45,748 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 1 - PROGRESS: at 48.46% examples, 111766 words/s, in_qsize 63, out_qsize 0\n",
            "2022-05-22 23:29:46,886 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 1 - PROGRESS: at 72.79% examples, 124285 words/s, in_qsize 46, out_qsize 0\n",
            "2022-05-22 23:29:47,204 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 31 more threads\n",
            "2022-05-22 23:29:47,269 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 30 more threads\n",
            "2022-05-22 23:29:47,293 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 29 more threads\n",
            "2022-05-22 23:29:47,306 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 28 more threads\n",
            "2022-05-22 23:29:47,330 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 27 more threads\n",
            "2022-05-22 23:29:47,334 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 26 more threads\n",
            "2022-05-22 23:29:47,378 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 25 more threads\n",
            "2022-05-22 23:29:47,447 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 24 more threads\n",
            "2022-05-22 23:29:47,558 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 23 more threads\n",
            "2022-05-22 23:29:47,594 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 22 more threads\n",
            "2022-05-22 23:29:47,604 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 21 more threads\n",
            "2022-05-22 23:29:47,641 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 20 more threads\n",
            "2022-05-22 23:29:47,644 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 19 more threads\n",
            "2022-05-22 23:29:47,648 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 18 more threads\n",
            "2022-05-22 23:29:47,651 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 17 more threads\n",
            "2022-05-22 23:29:47,677 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 16 more threads\n",
            "2022-05-22 23:29:47,697 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 15 more threads\n",
            "2022-05-22 23:29:47,701 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 14 more threads\n",
            "2022-05-22 23:29:47,790 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 13 more threads\n",
            "2022-05-22 23:29:47,796 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 12 more threads\n",
            "2022-05-22 23:29:47,801 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 11 more threads\n",
            "2022-05-22 23:29:47,807 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 10 more threads\n",
            "2022-05-22 23:29:47,829 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 9 more threads\n",
            "2022-05-22 23:29:47,837 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 8 more threads\n",
            "2022-05-22 23:29:47,848 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 7 more threads\n",
            "2022-05-22 23:29:47,856 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 6 more threads\n",
            "2022-05-22 23:29:47,858 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 5 more threads\n",
            "2022-05-22 23:29:47,864 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 4 more threads\n",
            "2022-05-22 23:29:47,866 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 3 more threads\n",
            "2022-05-22 23:29:47,871 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 2 more threads\n",
            "2022-05-22 23:29:47,872 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 1 more threads\n",
            "2022-05-22 23:29:47,873 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 0 more threads\n",
            "2022-05-22 23:29:47,875 | INFO | base_any2vec.py:1346 | _log_epoch_end | EPOCH - 1 : training on 1673757 raw words (741391 effective words) took 5.3s, 139180 effective words/s\n",
            "2022-05-22 23:29:48,992 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 2 - PROGRESS: at 4.88% examples, 33919 words/s, in_qsize 33, out_qsize 1\n",
            "2022-05-22 23:29:50,163 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 2 - PROGRESS: at 25.30% examples, 84116 words/s, in_qsize 62, out_qsize 9\n",
            "2022-05-22 23:29:51,178 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 2 - PROGRESS: at 49.92% examples, 113605 words/s, in_qsize 55, out_qsize 8\n",
            "2022-05-22 23:29:52,256 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 2 - PROGRESS: at 64.62% examples, 110961 words/s, in_qsize 47, out_qsize 13\n",
            "2022-05-22 23:29:52,837 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 31 more threads\n",
            "2022-05-22 23:29:52,853 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 30 more threads\n",
            "2022-05-22 23:29:52,926 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 29 more threads\n",
            "2022-05-22 23:29:52,975 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 28 more threads\n",
            "2022-05-22 23:29:53,052 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 27 more threads\n",
            "2022-05-22 23:29:53,062 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 26 more threads\n",
            "2022-05-22 23:29:53,114 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 25 more threads\n",
            "2022-05-22 23:29:53,117 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 24 more threads\n",
            "2022-05-22 23:29:53,127 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 23 more threads\n",
            "2022-05-22 23:29:53,130 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 22 more threads\n",
            "2022-05-22 23:29:53,139 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 21 more threads\n",
            "2022-05-22 23:29:53,158 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 20 more threads\n",
            "2022-05-22 23:29:53,162 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 19 more threads\n",
            "2022-05-22 23:29:53,166 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 18 more threads\n",
            "2022-05-22 23:29:53,170 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 17 more threads\n",
            "2022-05-22 23:29:53,171 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 16 more threads\n",
            "2022-05-22 23:29:53,196 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 15 more threads\n",
            "2022-05-22 23:29:53,214 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 14 more threads\n",
            "2022-05-22 23:29:53,221 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 13 more threads\n",
            "2022-05-22 23:29:53,226 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 12 more threads\n",
            "2022-05-22 23:29:53,232 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 11 more threads\n",
            "2022-05-22 23:29:53,234 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 10 more threads\n",
            "2022-05-22 23:29:53,246 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 9 more threads\n",
            "2022-05-22 23:29:53,251 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 8 more threads\n",
            "2022-05-22 23:29:53,266 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 2 - PROGRESS: at 95.80% examples, 133858 words/s, in_qsize 2, out_qsize 11\n",
            "2022-05-22 23:29:53,273 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 7 more threads\n",
            "2022-05-22 23:29:53,274 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 6 more threads\n",
            "2022-05-22 23:29:53,275 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 5 more threads\n",
            "2022-05-22 23:29:53,277 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 4 more threads\n",
            "2022-05-22 23:29:53,279 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 3 more threads\n",
            "2022-05-22 23:29:53,281 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 2 more threads\n",
            "2022-05-22 23:29:53,285 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 1 more threads\n",
            "2022-05-22 23:29:53,286 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 0 more threads\n",
            "2022-05-22 23:29:53,287 | INFO | base_any2vec.py:1346 | _log_epoch_end | EPOCH - 2 : training on 1673757 raw words (741329 effective words) took 5.3s, 139202 effective words/s\n",
            "2022-05-22 23:29:53,288 | INFO | base_any2vec.py:1382 | _log_train_end | training on a 3347514 raw words (1482720 effective words) took 10.8s, 137281 effective words/s\n"
          ]
        }
      ],
      "source": [
        "modelFastTextSkipGram = FastText(tokenized_tag, \n",
        "                     size=50, # desired no. of features/independent variables\n",
        "                     window=2,  # context window size\n",
        "                     min_count=2, # Ignores all words with total frequency lower than 2.  \n",
        "                     workers=32, # no.of cores\n",
        "                     hs = 0,\n",
        "                     negative = 10, # for negative sampling\n",
        "                     sg=1  # 1 for Skipgram model\n",
        "                     )\n",
        "\n",
        "modelFastTextSkipGram.build_vocab(tokenized_tag, update=True)\n",
        "modelFastTextSkipGram.train(tokenized_tag, total_examples= len(tokenized_tag), epochs=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "hboM6vAaoXmy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9bcfd3e1-02da-4acd-a3e1-a6004b07fbd1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-22 23:29:53,564 | INFO | keyedvectors.py:1360 | init_sims | precomputing L2-norms of word weight vectors\n",
            "2022-05-22 23:29:53,567 | INFO | keyedvectors.py:2011 | init_sims | precomputing L2-norms of ngram weight vectors\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('phalaenopsis', 0.875116765499115),\n",
              " ('analgesic', 0.8542455434799194),\n",
              " ('tagliatelle', 0.8494495749473572),\n",
              " ('bandage', 0.8434736132621765),\n",
              " ('salchicha3n', 0.8409441709518433),\n",
              " ('alps', 0.8372900485992432),\n",
              " ('baarnaise', 0.8331668972969055),\n",
              " ('gazpacho', 0.8266377449035645),\n",
              " ('cdj', 0.8259006142616272),\n",
              " ('vinyl', 0.8249576091766357)]"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ],
      "source": [
        "modelFastTextSkipGram.wv.most_similar(\"Gastroenteritis\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "fn-_Wh2ajey1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c346ba0-14f3-417d-a404-3c6aae84e6eb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('flatbread', 0.8586891293525696),\n",
              " ('italian', 0.8420588374137878),\n",
              " ('sicilian', 0.8088645339012146),\n",
              " ('california', 0.80636066198349),\n",
              " ('pepperoni', 0.7982450127601624),\n",
              " ('style', 0.7957154512405396),\n",
              " ('cheese', 0.7772330641746521),\n",
              " ('manakish', 0.7543833255767822),\n",
              " ('cheddar', 0.7449068427085876),\n",
              " ('cheesemaking', 0.7388368844985962)]"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ],
      "source": [
        "modelFastTextSkipGram.wv.most_similar(\"pizza\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "i3HC0ovJoXmz"
      },
      "outputs": [],
      "source": [
        "def word_vector(tokens, size,model):\n",
        "    vec = np.zeros(size).reshape((1, size))\n",
        "    count = 0\n",
        "    for word in tokens:\n",
        "        try:\n",
        "            vec += model[word].reshape((1, size))\n",
        "            count += 1.\n",
        "        except KeyError:\n",
        "            continue\n",
        "    if count != 0:\n",
        "        vec /= count\n",
        "    return vec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "rCuZeP_Xvg-Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1838bbde-393c-4600-b2a3-39b0db43fcf6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(88514, 50)"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ],
      "source": [
        "fastText_arrays = np.zeros((len(tokenized_tag), 50)) \n",
        "for i in range(len(tokenized_tag)):\n",
        "    fastText_arrays[i,:] = word_vector(tokenized_tag[i], 50,modelFastTextSkipGram)\n",
        "fastText_df = pd.DataFrame(fastText_arrays)\n",
        "fastText_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "7DysAHcMoXm0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cbff637f-9195-4867-9d6a-eb8ff749ef60"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pandas.core.frame.DataFrame"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ],
      "source": [
        "type(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### caption"
      ],
      "metadata": {
        "id": "ioLFneTluQ7K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_caption = data['caption'].apply(lambda x: str(x).split()) # tokenizing\n",
        "modelFastTextSkipGramCaption = FastText(tokenized_caption, \n",
        "                     size=50, # desired no. of features/independent variables\n",
        "                     window=2,  # context window size\n",
        "                     min_count=2, # Ignores all words with total frequency lower than 2.  \n",
        "                     workers=32, # no.of cores\n",
        "                     hs = 0,\n",
        "                     negative = 10, # for negative sampling\n",
        "                     sg=1  # 1 for Skipgram model\n",
        "                     )\n",
        "\n",
        "modelFastTextSkipGramCaption.build_vocab(tokenized_caption, update=True)\n",
        "modelFastTextSkipGramCaption.train(tokenized_caption, total_examples= len(tokenized_caption), epochs=20)"
      ],
      "metadata": {
        "id": "lC86O3z-uSYQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4bc6f58-49cf-4a82-b589-0729323e176f"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-22 23:30:14,676 | WARNING | base_any2vec.py:723 | __init__ | consider setting layer size to a multiple of 4 for greater performance\n",
            "2022-05-22 23:30:14,678 | INFO | word2vec.py:1567 | scan_vocab | collecting all words and their counts\n",
            "2022-05-22 23:30:14,685 | INFO | word2vec.py:1552 | _scan_vocab | PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
            "2022-05-22 23:30:14,739 | INFO | word2vec.py:1552 | _scan_vocab | PROGRESS: at sentence #10000, processed 267626 words, keeping 27703 word types\n",
            "2022-05-22 23:30:14,799 | INFO | word2vec.py:1552 | _scan_vocab | PROGRESS: at sentence #20000, processed 532556 words, keeping 43036 word types\n",
            "2022-05-22 23:30:14,869 | INFO | word2vec.py:1552 | _scan_vocab | PROGRESS: at sentence #30000, processed 831440 words, keeping 57740 word types\n",
            "2022-05-22 23:30:14,936 | INFO | word2vec.py:1552 | _scan_vocab | PROGRESS: at sentence #40000, processed 1099425 words, keeping 69288 word types\n",
            "2022-05-22 23:30:15,000 | INFO | word2vec.py:1552 | _scan_vocab | PROGRESS: at sentence #50000, processed 1378504 words, keeping 80011 word types\n",
            "2022-05-22 23:30:15,068 | INFO | word2vec.py:1552 | _scan_vocab | PROGRESS: at sentence #60000, processed 1644746 words, keeping 90126 word types\n",
            "2022-05-22 23:30:15,133 | INFO | word2vec.py:1552 | _scan_vocab | PROGRESS: at sentence #70000, processed 1929775 words, keeping 100059 word types\n",
            "2022-05-22 23:30:15,197 | INFO | word2vec.py:1552 | _scan_vocab | PROGRESS: at sentence #80000, processed 2195704 words, keeping 109756 word types\n",
            "2022-05-22 23:30:15,255 | INFO | word2vec.py:1575 | scan_vocab | collected 119185 word types from a corpus of 2450591 raw words and 88514 sentences\n",
            "2022-05-22 23:30:15,256 | INFO | word2vec.py:1626 | prepare_vocab | Loading a fresh vocabulary\n",
            "2022-05-22 23:30:15,361 | INFO | word2vec.py:1650 | prepare_vocab | effective_min_count=2 retains 43592 unique words (36% of original 119185, drops 75593)\n",
            "2022-05-22 23:30:15,362 | INFO | word2vec.py:1656 | prepare_vocab | effective_min_count=2 leaves 2374998 word corpus (96% of original 2450591, drops 75593)\n",
            "2022-05-22 23:30:15,475 | INFO | word2vec.py:1715 | prepare_vocab | deleting the raw counts dictionary of 119185 items\n",
            "2022-05-22 23:30:15,478 | INFO | word2vec.py:1718 | prepare_vocab | sample=0.001 downsamples 23 most-common words\n",
            "2022-05-22 23:30:15,480 | INFO | word2vec.py:1721 | prepare_vocab | downsampling leaves estimated 2317029 word corpus (97.6% of prior 2374998)\n",
            "2022-05-22 23:30:16,063 | INFO | fasttext.py:551 | estimate_memory | estimated required memory for 43592 words, 240750 buckets and 50 dimensions: 98045600 bytes\n",
            "2022-05-22 23:30:16,071 | INFO | word2vec.py:1834 | reset_weights | resetting layer weights\n",
            "2022-05-22 23:30:23,936 | INFO | fasttext.py:1011 | init_ngrams_weights | Total number of ngrams is 240750\n",
            "2022-05-22 23:30:25,320 | INFO | base_any2vec.py:1210 | _check_training_sanity | training model with 32 workers on 43592 vocabulary and 50 features, using sg=1 hs=0 sample=0.001 negative=10 window=2\n",
            "2022-05-22 23:30:26,744 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 1 - PROGRESS: at 0.98% examples, 13341 words/s, in_qsize 63, out_qsize 0\n",
            "2022-05-22 23:30:28,006 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 1 - PROGRESS: at 1.22% examples, 10543 words/s, in_qsize 53, out_qsize 10\n",
            "2022-05-22 23:30:29,752 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 1 - PROGRESS: at 14.76% examples, 74660 words/s, in_qsize 63, out_qsize 0\n",
            "2022-05-22 23:30:32,008 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 1 - PROGRESS: at 27.86% examples, 94626 words/s, in_qsize 62, out_qsize 1\n",
            "2022-05-22 23:30:33,412 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 1 - PROGRESS: at 30.70% examples, 87513 words/s, in_qsize 51, out_qsize 19\n",
            "2022-05-22 23:30:34,423 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 1 - PROGRESS: at 41.27% examples, 104843 words/s, in_qsize 62, out_qsize 1\n",
            "2022-05-22 23:30:35,671 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 1 - PROGRESS: at 43.75% examples, 97631 words/s, in_qsize 63, out_qsize 0\n",
            "2022-05-22 23:30:37,011 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 1 - PROGRESS: at 55.50% examples, 109870 words/s, in_qsize 63, out_qsize 0\n",
            "2022-05-22 23:30:38,388 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 1 - PROGRESS: at 57.56% examples, 101876 words/s, in_qsize 63, out_qsize 0\n",
            "2022-05-22 23:30:39,497 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 1 - PROGRESS: at 69.66% examples, 113239 words/s, in_qsize 63, out_qsize 0\n",
            "2022-05-22 23:30:40,640 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 1 - PROGRESS: at 70.94% examples, 106624 words/s, in_qsize 63, out_qsize 0\n",
            "2022-05-22 23:30:41,683 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 1 - PROGRESS: at 83.28% examples, 117093 words/s, in_qsize 43, out_qsize 0\n",
            "2022-05-22 23:30:42,733 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 1 - PROGRESS: at 84.58% examples, 111655 words/s, in_qsize 40, out_qsize 0\n",
            "2022-05-22 23:30:43,752 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 1 - PROGRESS: at 85.53% examples, 106498 words/s, in_qsize 37, out_qsize 1\n",
            "2022-05-22 23:30:44,144 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 31 more threads\n",
            "2022-05-22 23:30:44,148 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 30 more threads\n",
            "2022-05-22 23:30:44,151 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 29 more threads\n",
            "2022-05-22 23:30:44,152 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 28 more threads\n",
            "2022-05-22 23:30:44,153 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 27 more threads\n",
            "2022-05-22 23:30:44,161 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 26 more threads\n",
            "2022-05-22 23:30:44,162 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 25 more threads\n",
            "2022-05-22 23:30:44,180 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 24 more threads\n",
            "2022-05-22 23:30:44,187 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 23 more threads\n",
            "2022-05-22 23:30:44,193 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 22 more threads\n",
            "2022-05-22 23:30:44,203 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 21 more threads\n",
            "2022-05-22 23:30:44,209 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 20 more threads\n",
            "2022-05-22 23:30:44,218 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 19 more threads\n",
            "2022-05-22 23:30:44,226 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 18 more threads\n",
            "2022-05-22 23:30:44,229 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 17 more threads\n",
            "2022-05-22 23:30:44,238 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 16 more threads\n",
            "2022-05-22 23:30:44,257 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 15 more threads\n",
            "2022-05-22 23:30:44,262 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 14 more threads\n",
            "2022-05-22 23:30:44,264 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 13 more threads\n",
            "2022-05-22 23:30:44,271 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 12 more threads\n",
            "2022-05-22 23:30:44,274 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 11 more threads\n",
            "2022-05-22 23:30:44,279 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 10 more threads\n",
            "2022-05-22 23:30:44,473 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 9 more threads\n",
            "2022-05-22 23:30:44,513 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 8 more threads\n",
            "2022-05-22 23:30:44,574 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 7 more threads\n",
            "2022-05-22 23:30:44,710 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 6 more threads\n",
            "2022-05-22 23:30:44,714 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 5 more threads\n",
            "2022-05-22 23:30:44,747 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 4 more threads\n",
            "2022-05-22 23:30:44,764 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 1 - PROGRESS: at 99.03% examples, 117797 words/s, in_qsize 3, out_qsize 1\n",
            "2022-05-22 23:30:44,765 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 3 more threads\n",
            "2022-05-22 23:30:44,776 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 2 more threads\n",
            "2022-05-22 23:30:44,781 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 1 more threads\n",
            "2022-05-22 23:30:44,784 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 0 more threads\n",
            "2022-05-22 23:30:44,785 | INFO | base_any2vec.py:1346 | _log_epoch_end | EPOCH - 1 : training on 2450591 raw words (2316887 effective words) took 19.4s, 119124 effective words/s\n",
            "2022-05-22 23:30:45,953 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 2 - PROGRESS: at 0.24% examples, 8175 words/s, in_qsize 63, out_qsize 0\n",
            "2022-05-22 23:30:47,253 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 2 - PROGRESS: at 1.61% examples, 15297 words/s, in_qsize 64, out_qsize 1\n",
            "2022-05-22 23:30:48,588 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 2 - PROGRESS: at 14.80% examples, 87175 words/s, in_qsize 63, out_qsize 0\n",
            "2022-05-22 23:30:49,654 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 2 - PROGRESS: at 16.90% examples, 77734 words/s, in_qsize 64, out_qsize 0\n",
            "2022-05-22 23:30:50,665 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 2 - PROGRESS: at 27.86% examples, 107762 words/s, in_qsize 64, out_qsize 0\n",
            "2022-05-22 23:30:51,831 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 2 - PROGRESS: at 30.16% examples, 97922 words/s, in_qsize 63, out_qsize 0\n",
            "2022-05-22 23:30:52,930 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 2 - PROGRESS: at 31.11% examples, 88192 words/s, in_qsize 62, out_qsize 1\n",
            "2022-05-22 23:30:54,738 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 2 - PROGRESS: at 43.81% examples, 103199 words/s, in_qsize 63, out_qsize 1\n",
            "2022-05-22 23:30:55,603 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 2 - PROGRESS: at 45.78% examples, 97807 words/s, in_qsize 61, out_qsize 2\n",
            "2022-05-22 23:30:56,884 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 2 - PROGRESS: at 56.77% examples, 108544 words/s, in_qsize 63, out_qsize 0\n",
            "2022-05-22 23:30:58,117 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 2 - PROGRESS: at 59.59% examples, 103732 words/s, in_qsize 63, out_qsize 1\n",
            "2022-05-22 23:30:59,188 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 2 - PROGRESS: at 70.10% examples, 112138 words/s, in_qsize 64, out_qsize 1\n",
            "2022-05-22 23:31:00,364 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 2 - PROGRESS: at 72.60% examples, 107303 words/s, in_qsize 62, out_qsize 1\n",
            "2022-05-22 23:31:01,392 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 2 - PROGRESS: at 82.81% examples, 114831 words/s, in_qsize 43, out_qsize 1\n",
            "2022-05-22 23:31:02,706 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 2 - PROGRESS: at 85.71% examples, 110081 words/s, in_qsize 37, out_qsize 0\n",
            "2022-05-22 23:31:03,077 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 31 more threads\n",
            "2022-05-22 23:31:03,091 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 30 more threads\n",
            "2022-05-22 23:31:03,124 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 29 more threads\n",
            "2022-05-22 23:31:03,489 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 28 more threads\n",
            "2022-05-22 23:31:03,531 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 27 more threads\n",
            "2022-05-22 23:31:03,596 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 26 more threads\n",
            "2022-05-22 23:31:03,646 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 25 more threads\n",
            "2022-05-22 23:31:03,658 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 24 more threads\n",
            "2022-05-22 23:31:03,688 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 23 more threads\n",
            "2022-05-22 23:31:03,694 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 22 more threads\n",
            "2022-05-22 23:31:03,707 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 2 - PROGRESS: at 92.31% examples, 112233 words/s, in_qsize 21, out_qsize 1\n",
            "2022-05-22 23:31:03,708 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 21 more threads\n",
            "2022-05-22 23:31:03,726 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 20 more threads\n",
            "2022-05-22 23:31:03,750 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 19 more threads\n",
            "2022-05-22 23:31:03,765 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 18 more threads\n",
            "2022-05-22 23:31:03,784 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 17 more threads\n",
            "2022-05-22 23:31:03,803 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 16 more threads\n",
            "2022-05-22 23:31:03,808 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 15 more threads\n",
            "2022-05-22 23:31:03,813 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 14 more threads\n",
            "2022-05-22 23:31:03,835 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 13 more threads\n",
            "2022-05-22 23:31:03,850 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 12 more threads\n",
            "2022-05-22 23:31:03,868 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 11 more threads\n",
            "2022-05-22 23:31:03,875 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 10 more threads\n",
            "2022-05-22 23:31:04,078 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 9 more threads\n",
            "2022-05-22 23:31:04,094 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 8 more threads\n",
            "2022-05-22 23:31:04,101 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 7 more threads\n",
            "2022-05-22 23:31:04,113 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 6 more threads\n",
            "2022-05-22 23:31:04,142 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 5 more threads\n",
            "2022-05-22 23:31:04,174 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 4 more threads\n",
            "2022-05-22 23:31:04,198 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 3 more threads\n",
            "2022-05-22 23:31:04,203 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 2 more threads\n",
            "2022-05-22 23:31:04,208 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 1 more threads\n",
            "2022-05-22 23:31:04,216 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 0 more threads\n",
            "2022-05-22 23:31:04,217 | INFO | base_any2vec.py:1346 | _log_epoch_end | EPOCH - 2 : training on 2450591 raw words (2316875 effective words) took 19.4s, 119354 effective words/s\n",
            "2022-05-22 23:31:05,933 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 3 - PROGRESS: at 0.39% examples, 5637 words/s, in_qsize 64, out_qsize 0\n",
            "2022-05-22 23:31:07,039 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 3 - PROGRESS: at 1.55% examples, 13416 words/s, in_qsize 63, out_qsize 2\n",
            "2022-05-22 23:31:08,422 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 3 - PROGRESS: at 14.38% examples, 76490 words/s, in_qsize 63, out_qsize 0\n",
            "2022-05-22 23:31:09,473 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 3 - PROGRESS: at 16.72% examples, 71931 words/s, in_qsize 63, out_qsize 0\n",
            "2022-05-22 23:31:10,975 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 3 - PROGRESS: at 27.86% examples, 93656 words/s, in_qsize 63, out_qsize 0\n",
            "2022-05-22 23:31:12,402 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 3 - PROGRESS: at 31.37% examples, 87703 words/s, in_qsize 63, out_qsize 0\n",
            "2022-05-22 23:31:13,690 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 3 - PROGRESS: at 42.23% examples, 103720 words/s, in_qsize 63, out_qsize 0\n",
            "2022-05-22 23:31:15,178 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 3 - PROGRESS: at 44.63% examples, 93908 words/s, in_qsize 63, out_qsize 0\n",
            "2022-05-22 23:31:16,184 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 3 - PROGRESS: at 56.80% examples, 109711 words/s, in_qsize 64, out_qsize 0\n",
            "2022-05-22 23:31:17,423 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 3 - PROGRESS: at 57.43% examples, 100825 words/s, in_qsize 63, out_qsize 0\n",
            "2022-05-22 23:31:18,510 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 3 - PROGRESS: at 57.74% examples, 93818 words/s, in_qsize 63, out_qsize 0\n",
            "2022-05-22 23:31:20,586 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 3 - PROGRESS: at 71.34% examples, 100368 words/s, in_qsize 62, out_qsize 1\n",
            "2022-05-22 23:31:21,720 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 3 - PROGRESS: at 73.34% examples, 96560 words/s, in_qsize 54, out_qsize 9\n",
            "2022-05-22 23:31:23,571 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 3 - PROGRESS: at 86.60% examples, 102884 words/s, in_qsize 35, out_qsize 0\n",
            "2022-05-22 23:31:24,359 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 31 more threads\n",
            "2022-05-22 23:31:24,380 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 30 more threads\n",
            "2022-05-22 23:31:24,398 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 29 more threads\n",
            "2022-05-22 23:31:24,399 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 28 more threads\n",
            "2022-05-22 23:31:24,403 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 27 more threads\n",
            "2022-05-22 23:31:24,413 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 26 more threads\n",
            "2022-05-22 23:31:24,416 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 25 more threads\n",
            "2022-05-22 23:31:24,420 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 24 more threads\n",
            "2022-05-22 23:31:24,428 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 23 more threads\n",
            "2022-05-22 23:31:24,436 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 22 more threads\n",
            "2022-05-22 23:31:24,452 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 21 more threads\n",
            "2022-05-22 23:31:24,456 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 20 more threads\n",
            "2022-05-22 23:31:24,459 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 19 more threads\n",
            "2022-05-22 23:31:24,494 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 18 more threads\n",
            "2022-05-22 23:31:24,499 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 17 more threads\n",
            "2022-05-22 23:31:24,506 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 16 more threads\n",
            "2022-05-22 23:31:24,509 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 15 more threads\n",
            "2022-05-22 23:31:24,520 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 14 more threads\n",
            "2022-05-22 23:31:24,523 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 13 more threads\n",
            "2022-05-22 23:31:24,530 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 12 more threads\n",
            "2022-05-22 23:31:24,539 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 11 more threads\n",
            "2022-05-22 23:31:24,542 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 10 more threads\n",
            "2022-05-22 23:31:24,550 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 9 more threads\n",
            "2022-05-22 23:31:24,556 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 8 more threads\n",
            "2022-05-22 23:31:24,560 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 7 more threads\n",
            "2022-05-22 23:31:24,566 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 6 more threads\n",
            "2022-05-22 23:31:24,569 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 5 more threads\n",
            "2022-05-22 23:31:24,608 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 3 - PROGRESS: at 98.78% examples, 111992 words/s, in_qsize 4, out_qsize 1\n",
            "2022-05-22 23:31:24,609 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 4 more threads\n",
            "2022-05-22 23:31:24,698 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 3 more threads\n",
            "2022-05-22 23:31:24,744 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 2 more threads\n",
            "2022-05-22 23:31:24,761 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 1 more threads\n",
            "2022-05-22 23:31:24,775 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 0 more threads\n",
            "2022-05-22 23:31:24,776 | INFO | base_any2vec.py:1346 | _log_epoch_end | EPOCH - 3 : training on 2450591 raw words (2317052 effective words) took 20.5s, 112789 effective words/s\n",
            "2022-05-22 23:31:25,964 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 4 - PROGRESS: at 0.24% examples, 8018 words/s, in_qsize 64, out_qsize 0\n",
            "2022-05-22 23:31:27,111 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 4 - PROGRESS: at 2.72% examples, 28437 words/s, in_qsize 63, out_qsize 0\n",
            "2022-05-22 23:31:28,736 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 4 - PROGRESS: at 14.39% examples, 81250 words/s, in_qsize 63, out_qsize 0\n",
            "2022-05-22 23:31:30,157 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 4 - PROGRESS: at 18.06% examples, 75537 words/s, in_qsize 61, out_qsize 2\n",
            "2022-05-22 23:31:31,185 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 4 - PROGRESS: at 28.90% examples, 103241 words/s, in_qsize 63, out_qsize 0\n",
            "2022-05-22 23:31:32,583 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 4 - PROGRESS: at 30.92% examples, 90773 words/s, in_qsize 64, out_qsize 2\n",
            "2022-05-22 23:31:33,751 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 4 - PROGRESS: at 42.83% examples, 110571 words/s, in_qsize 62, out_qsize 1\n",
            "2022-05-22 23:31:35,422 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 4 - PROGRESS: at 45.06% examples, 97632 words/s, in_qsize 62, out_qsize 5\n",
            "2022-05-22 23:31:36,557 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 4 - PROGRESS: at 56.77% examples, 111486 words/s, in_qsize 63, out_qsize 0\n",
            "2022-05-22 23:31:37,766 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 4 - PROGRESS: at 59.19% examples, 105450 words/s, in_qsize 63, out_qsize 0\n",
            "2022-05-22 23:31:39,234 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 4 - PROGRESS: at 70.94% examples, 113024 words/s, in_qsize 63, out_qsize 0\n",
            "2022-05-22 23:31:40,475 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 4 - PROGRESS: at 73.44% examples, 107695 words/s, in_qsize 64, out_qsize 0\n",
            "2022-05-22 23:31:41,638 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 4 - PROGRESS: at 84.17% examples, 114781 words/s, in_qsize 41, out_qsize 0\n",
            "2022-05-22 23:31:43,060 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 4 - PROGRESS: at 86.65% examples, 108936 words/s, in_qsize 33, out_qsize 2\n",
            "2022-05-22 23:31:43,141 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 31 more threads\n",
            "2022-05-22 23:31:43,143 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 30 more threads\n",
            "2022-05-22 23:31:43,165 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 29 more threads\n",
            "2022-05-22 23:31:43,187 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 28 more threads\n",
            "2022-05-22 23:31:43,252 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 27 more threads\n",
            "2022-05-22 23:31:43,301 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 26 more threads\n",
            "2022-05-22 23:31:43,331 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 25 more threads\n",
            "2022-05-22 23:31:43,407 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 24 more threads\n",
            "2022-05-22 23:31:43,442 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 23 more threads\n",
            "2022-05-22 23:31:43,483 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 22 more threads\n",
            "2022-05-22 23:31:43,489 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 21 more threads\n",
            "2022-05-22 23:31:43,535 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 20 more threads\n",
            "2022-05-22 23:31:43,547 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 19 more threads\n",
            "2022-05-22 23:31:43,560 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 18 more threads\n",
            "2022-05-22 23:31:43,561 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 17 more threads\n",
            "2022-05-22 23:31:43,566 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 16 more threads\n",
            "2022-05-22 23:31:43,590 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 15 more threads\n",
            "2022-05-22 23:31:43,610 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 14 more threads\n",
            "2022-05-22 23:31:43,640 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 13 more threads\n",
            "2022-05-22 23:31:43,659 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 12 more threads\n",
            "2022-05-22 23:31:43,665 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 11 more threads\n",
            "2022-05-22 23:31:43,673 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 10 more threads\n",
            "2022-05-22 23:31:43,899 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 9 more threads\n",
            "2022-05-22 23:31:43,993 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 8 more threads\n",
            "2022-05-22 23:31:44,034 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 7 more threads\n",
            "2022-05-22 23:31:44,072 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 4 - PROGRESS: at 98.06% examples, 117393 words/s, in_qsize 6, out_qsize 1\n",
            "2022-05-22 23:31:44,073 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 6 more threads\n",
            "2022-05-22 23:31:44,136 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 5 more threads\n",
            "2022-05-22 23:31:44,139 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 4 more threads\n",
            "2022-05-22 23:31:44,153 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 3 more threads\n",
            "2022-05-22 23:31:44,257 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 2 more threads\n",
            "2022-05-22 23:31:44,265 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 1 more threads\n",
            "2022-05-22 23:31:44,275 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 0 more threads\n",
            "2022-05-22 23:31:44,276 | INFO | base_any2vec.py:1346 | _log_epoch_end | EPOCH - 4 : training on 2450591 raw words (2317316 effective words) took 19.5s, 118951 effective words/s\n",
            "2022-05-22 23:31:45,677 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 5 - PROGRESS: at 1.17% examples, 20360 words/s, in_qsize 64, out_qsize 0\n",
            "2022-05-22 23:31:46,945 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 5 - PROGRESS: at 1.55% examples, 14130 words/s, in_qsize 64, out_qsize 2\n",
            "2022-05-22 23:31:48,062 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 5 - PROGRESS: at 15.27% examples, 90135 words/s, in_qsize 64, out_qsize 0\n",
            "2022-05-22 23:31:49,322 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 5 - PROGRESS: at 16.38% examples, 73155 words/s, in_qsize 62, out_qsize 1\n",
            "2022-05-22 23:31:50,322 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 5 - PROGRESS: at 28.20% examples, 106385 words/s, in_qsize 63, out_qsize 0\n",
            "2022-05-22 23:31:51,447 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 5 - PROGRESS: at 29.35% examples, 93585 words/s, in_qsize 63, out_qsize 0\n",
            "2022-05-22 23:31:52,570 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 5 - PROGRESS: at 32.39% examples, 90032 words/s, in_qsize 62, out_qsize 9\n",
            "2022-05-22 23:31:53,585 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 5 - PROGRESS: at 41.77% examples, 104610 words/s, in_qsize 64, out_qsize 1\n",
            "2022-05-22 23:31:55,243 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 5 - PROGRESS: at 45.52% examples, 95657 words/s, in_qsize 61, out_qsize 2\n",
            "2022-05-22 23:31:56,612 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 5 - PROGRESS: at 57.83% examples, 108767 words/s, in_qsize 63, out_qsize 0\n",
            "2022-05-22 23:31:58,156 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 5 - PROGRESS: at 58.74% examples, 98009 words/s, in_qsize 64, out_qsize 26\n",
            "2022-05-22 23:31:59,682 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 5 - PROGRESS: at 72.12% examples, 107926 words/s, in_qsize 63, out_qsize 0\n",
            "2022-05-22 23:32:00,683 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 5 - PROGRESS: at 73.91% examples, 104227 words/s, in_qsize 48, out_qsize 15\n",
            "2022-05-22 23:32:01,797 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 5 - PROGRESS: at 85.95% examples, 112630 words/s, in_qsize 37, out_qsize 0\n",
            "2022-05-22 23:32:02,841 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 5 - PROGRESS: at 87.48% examples, 108322 words/s, in_qsize 33, out_qsize 0\n",
            "2022-05-22 23:32:02,860 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 31 more threads\n",
            "2022-05-22 23:32:02,870 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 30 more threads\n",
            "2022-05-22 23:32:02,875 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 29 more threads\n",
            "2022-05-22 23:32:02,888 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 28 more threads\n",
            "2022-05-22 23:32:03,113 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 27 more threads\n",
            "2022-05-22 23:32:03,122 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 26 more threads\n",
            "2022-05-22 23:32:03,228 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 25 more threads\n",
            "2022-05-22 23:32:03,240 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 24 more threads\n",
            "2022-05-22 23:32:03,286 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 23 more threads\n",
            "2022-05-22 23:32:03,292 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 22 more threads\n",
            "2022-05-22 23:32:03,297 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 21 more threads\n",
            "2022-05-22 23:32:03,299 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 20 more threads\n",
            "2022-05-22 23:32:03,302 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 19 more threads\n",
            "2022-05-22 23:32:03,304 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 18 more threads\n",
            "2022-05-22 23:32:03,308 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 17 more threads\n",
            "2022-05-22 23:32:03,309 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 16 more threads\n",
            "2022-05-22 23:32:03,315 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 15 more threads\n",
            "2022-05-22 23:32:03,316 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 14 more threads\n",
            "2022-05-22 23:32:03,326 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 13 more threads\n",
            "2022-05-22 23:32:03,352 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 12 more threads\n",
            "2022-05-22 23:32:03,363 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 11 more threads\n",
            "2022-05-22 23:32:03,365 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 10 more threads\n",
            "2022-05-22 23:32:03,370 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 9 more threads\n",
            "2022-05-22 23:32:03,373 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 8 more threads\n",
            "2022-05-22 23:32:03,386 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 7 more threads\n",
            "2022-05-22 23:32:03,389 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 6 more threads\n",
            "2022-05-22 23:32:03,450 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 5 more threads\n",
            "2022-05-22 23:32:03,510 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 4 more threads\n",
            "2022-05-22 23:32:03,520 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 3 more threads\n",
            "2022-05-22 23:32:03,555 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 2 more threads\n",
            "2022-05-22 23:32:03,610 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 1 more threads\n",
            "2022-05-22 23:32:03,614 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 0 more threads\n",
            "2022-05-22 23:32:03,615 | INFO | base_any2vec.py:1346 | _log_epoch_end | EPOCH - 5 : training on 2450591 raw words (2317247 effective words) took 19.3s, 119959 effective words/s\n",
            "2022-05-22 23:32:03,619 | INFO | base_any2vec.py:1382 | _log_train_end | training on a 12252955 raw words (11585377 effective words) took 98.3s, 117861 effective words/s\n",
            "2022-05-22 23:32:05,517 | INFO | word2vec.py:1567 | scan_vocab | collecting all words and their counts\n",
            "2022-05-22 23:32:05,518 | INFO | word2vec.py:1552 | _scan_vocab | PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
            "2022-05-22 23:32:05,574 | INFO | word2vec.py:1552 | _scan_vocab | PROGRESS: at sentence #10000, processed 267626 words, keeping 27703 word types\n",
            "2022-05-22 23:32:05,625 | INFO | word2vec.py:1552 | _scan_vocab | PROGRESS: at sentence #20000, processed 532556 words, keeping 43036 word types\n",
            "2022-05-22 23:32:05,682 | INFO | word2vec.py:1552 | _scan_vocab | PROGRESS: at sentence #30000, processed 831440 words, keeping 57740 word types\n",
            "2022-05-22 23:32:05,741 | INFO | word2vec.py:1552 | _scan_vocab | PROGRESS: at sentence #40000, processed 1099425 words, keeping 69288 word types\n",
            "2022-05-22 23:32:05,796 | INFO | word2vec.py:1552 | _scan_vocab | PROGRESS: at sentence #50000, processed 1378504 words, keeping 80011 word types\n",
            "2022-05-22 23:32:05,849 | INFO | word2vec.py:1552 | _scan_vocab | PROGRESS: at sentence #60000, processed 1644746 words, keeping 90126 word types\n",
            "2022-05-22 23:32:05,902 | INFO | word2vec.py:1552 | _scan_vocab | PROGRESS: at sentence #70000, processed 1929775 words, keeping 100059 word types\n",
            "2022-05-22 23:32:05,957 | INFO | word2vec.py:1552 | _scan_vocab | PROGRESS: at sentence #80000, processed 2195704 words, keeping 109756 word types\n",
            "2022-05-22 23:32:06,014 | INFO | word2vec.py:1575 | scan_vocab | collected 119185 word types from a corpus of 2450591 raw words and 88514 sentences\n",
            "2022-05-22 23:32:06,015 | INFO | word2vec.py:1659 | prepare_vocab | Updating model with new vocabulary\n",
            "2022-05-22 23:32:06,084 | INFO | word2vec.py:1685 | prepare_vocab | New added 43592 unique words (26% of original 162777) and increased the count of 43592 pre-existing words (26% of original 162777)\n",
            "2022-05-22 23:32:06,292 | INFO | word2vec.py:1715 | prepare_vocab | deleting the raw counts dictionary of 119185 items\n",
            "2022-05-22 23:32:06,295 | INFO | word2vec.py:1718 | prepare_vocab | sample=0.001 downsamples 46 most-common words\n",
            "2022-05-22 23:32:06,297 | INFO | word2vec.py:1721 | prepare_vocab | downsampling leaves estimated 4634058 word corpus (195.1% of prior 2374998)\n",
            "2022-05-22 23:32:06,844 | INFO | fasttext.py:551 | estimate_memory | estimated required memory for 43592 words, 240750 buckets and 50 dimensions: 98045600 bytes\n",
            "2022-05-22 23:32:06,853 | INFO | word2vec.py:1850 | update_weights | updating layer weights\n",
            "2022-05-22 23:32:07,633 | INFO | fasttext.py:1030 | init_ngrams_weights | Number of new ngrams is 0\n",
            "2022-05-22 23:32:07,669 | WARNING | base_any2vec.py:1182 | _check_training_sanity | Effective 'alpha' higher than previous training cycles\n",
            "2022-05-22 23:32:07,670 | INFO | base_any2vec.py:1210 | _check_training_sanity | training model with 32 workers on 43592 vocabulary and 50 features, using sg=1 hs=0 sample=0.001 negative=10 window=2\n",
            "2022-05-22 23:32:08,747 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 1 - PROGRESS: at 0.92% examples, 17610 words/s, in_qsize 64, out_qsize 0\n",
            "2022-05-22 23:32:09,864 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 1 - PROGRESS: at 1.59% examples, 17241 words/s, in_qsize 63, out_qsize 0\n",
            "2022-05-22 23:32:10,981 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 1 - PROGRESS: at 15.23% examples, 102904 words/s, in_qsize 64, out_qsize 0\n",
            "2022-05-22 23:32:12,064 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 1 - PROGRESS: at 15.69% examples, 79606 words/s, in_qsize 63, out_qsize 0\n",
            "2022-05-22 23:32:13,165 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 1 - PROGRESS: at 16.97% examples, 68784 words/s, in_qsize 48, out_qsize 23\n",
            "2022-05-22 23:32:14,178 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 1 - PROGRESS: at 28.99% examples, 101662 words/s, in_qsize 64, out_qsize 0\n",
            "2022-05-22 23:32:15,352 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 1 - PROGRESS: at 29.76% examples, 88536 words/s, in_qsize 63, out_qsize 0\n",
            "2022-05-22 23:32:16,395 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 1 - PROGRESS: at 41.91% examples, 111559 words/s, in_qsize 63, out_qsize 0\n",
            "2022-05-22 23:32:17,498 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 1 - PROGRESS: at 42.23% examples, 99958 words/s, in_qsize 63, out_qsize 0\n",
            "2022-05-22 23:32:18,629 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 1 - PROGRESS: at 46.29% examples, 97384 words/s, in_qsize 49, out_qsize 14\n",
            "2022-05-22 23:32:19,737 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 1 - PROGRESS: at 55.60% examples, 106450 words/s, in_qsize 62, out_qsize 1\n",
            "2022-05-22 23:32:20,885 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 1 - PROGRESS: at 59.17% examples, 103616 words/s, in_qsize 62, out_qsize 1\n",
            "2022-05-22 23:32:21,911 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 1 - PROGRESS: at 68.95% examples, 111403 words/s, in_qsize 63, out_qsize 1\n",
            "2022-05-22 23:32:23,189 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 1 - PROGRESS: at 72.67% examples, 107691 words/s, in_qsize 63, out_qsize 0\n",
            "2022-05-22 23:32:24,244 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 1 - PROGRESS: at 77.12% examples, 107074 words/s, in_qsize 52, out_qsize 3\n",
            "2022-05-22 23:32:25,626 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 1 - PROGRESS: at 85.71% examples, 109854 words/s, in_qsize 36, out_qsize 1\n",
            "2022-05-22 23:32:26,620 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 31 more threads\n",
            "2022-05-22 23:32:26,626 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 1 - PROGRESS: at 88.67% examples, 107533 words/s, in_qsize 28, out_qsize 5\n",
            "2022-05-22 23:32:26,628 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 30 more threads\n",
            "2022-05-22 23:32:26,632 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 29 more threads\n",
            "2022-05-22 23:32:26,635 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 28 more threads\n",
            "2022-05-22 23:32:26,649 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 27 more threads\n",
            "2022-05-22 23:32:26,668 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 26 more threads\n",
            "2022-05-22 23:32:26,692 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 25 more threads\n",
            "2022-05-22 23:32:26,695 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 24 more threads\n",
            "2022-05-22 23:32:26,729 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 23 more threads\n",
            "2022-05-22 23:32:26,732 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 22 more threads\n",
            "2022-05-22 23:32:26,752 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 21 more threads\n",
            "2022-05-22 23:32:26,762 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 20 more threads\n",
            "2022-05-22 23:32:26,763 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 19 more threads\n",
            "2022-05-22 23:32:26,780 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 18 more threads\n",
            "2022-05-22 23:32:26,796 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 17 more threads\n",
            "2022-05-22 23:32:26,806 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 16 more threads\n",
            "2022-05-22 23:32:26,854 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 15 more threads\n",
            "2022-05-22 23:32:26,860 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 14 more threads\n",
            "2022-05-22 23:32:26,869 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 13 more threads\n",
            "2022-05-22 23:32:26,921 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 12 more threads\n",
            "2022-05-22 23:32:26,926 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 11 more threads\n",
            "2022-05-22 23:32:26,928 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 10 more threads\n",
            "2022-05-22 23:32:26,962 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 9 more threads\n",
            "2022-05-22 23:32:26,965 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 8 more threads\n",
            "2022-05-22 23:32:26,988 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 7 more threads\n",
            "2022-05-22 23:32:27,052 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 6 more threads\n",
            "2022-05-22 23:32:27,133 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 5 more threads\n",
            "2022-05-22 23:32:27,148 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 4 more threads\n",
            "2022-05-22 23:32:27,171 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 3 more threads\n",
            "2022-05-22 23:32:27,199 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 2 more threads\n",
            "2022-05-22 23:32:27,206 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 1 more threads\n",
            "2022-05-22 23:32:27,230 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 0 more threads\n",
            "2022-05-22 23:32:27,231 | INFO | base_any2vec.py:1346 | _log_epoch_end | EPOCH - 1 : training on 2450591 raw words (2316959 effective words) took 19.5s, 118551 effective words/s\n",
            "2022-05-22 23:32:28,887 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 2 - PROGRESS: at 1.05% examples, 17147 words/s, in_qsize 63, out_qsize 0\n",
            "2022-05-22 23:32:29,912 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 2 - PROGRESS: at 2.08% examples, 17563 words/s, in_qsize 61, out_qsize 2\n",
            "2022-05-22 23:32:31,087 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 2 - PROGRESS: at 15.23% examples, 88284 words/s, in_qsize 63, out_qsize 0\n",
            "2022-05-22 23:32:32,184 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 2 - PROGRESS: at 16.08% examples, 72488 words/s, in_qsize 63, out_qsize 0\n",
            "2022-05-22 23:32:33,383 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 2 - PROGRESS: at 28.90% examples, 107479 words/s, in_qsize 63, out_qsize 0\n",
            "2022-05-22 23:32:34,919 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 2 - PROGRESS: at 30.21% examples, 89654 words/s, in_qsize 63, out_qsize 0\n",
            "2022-05-22 23:32:36,966 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 2 - PROGRESS: at 42.76% examples, 101867 words/s, in_qsize 62, out_qsize 1\n",
            "2022-05-22 23:32:38,023 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 2 - PROGRESS: at 50.74% examples, 108498 words/s, in_qsize 64, out_qsize 4\n",
            "2022-05-22 23:32:39,217 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 2 - PROGRESS: at 56.80% examples, 109523 words/s, in_qsize 62, out_qsize 1\n",
            "2022-05-22 23:32:40,242 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 2 - PROGRESS: at 58.39% examples, 103773 words/s, in_qsize 63, out_qsize 0\n",
            "2022-05-22 23:32:41,389 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 2 - PROGRESS: at 70.59% examples, 114708 words/s, in_qsize 63, out_qsize 0\n",
            "2022-05-22 23:32:42,477 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 2 - PROGRESS: at 72.21% examples, 108994 words/s, in_qsize 63, out_qsize 0\n",
            "2022-05-22 23:32:43,491 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 2 - PROGRESS: at 82.18% examples, 116083 words/s, in_qsize 45, out_qsize 1\n",
            "2022-05-22 23:32:44,641 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 2 - PROGRESS: at 84.58% examples, 111672 words/s, in_qsize 40, out_qsize 0\n",
            "2022-05-22 23:32:45,658 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 2 - PROGRESS: at 86.77% examples, 108568 words/s, in_qsize 28, out_qsize 10\n",
            "2022-05-22 23:32:45,675 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 31 more threads\n",
            "2022-05-22 23:32:45,676 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 30 more threads\n",
            "2022-05-22 23:32:45,681 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 29 more threads\n",
            "2022-05-22 23:32:45,687 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 28 more threads\n",
            "2022-05-22 23:32:45,691 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 27 more threads\n",
            "2022-05-22 23:32:45,727 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 26 more threads\n",
            "2022-05-22 23:32:45,749 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 25 more threads\n",
            "2022-05-22 23:32:45,867 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 24 more threads\n",
            "2022-05-22 23:32:45,889 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 23 more threads\n",
            "2022-05-22 23:32:45,901 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 22 more threads\n",
            "2022-05-22 23:32:45,912 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 21 more threads\n",
            "2022-05-22 23:32:45,939 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 20 more threads\n",
            "2022-05-22 23:32:45,969 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 19 more threads\n",
            "2022-05-22 23:32:45,994 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 18 more threads\n",
            "2022-05-22 23:32:46,010 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 17 more threads\n",
            "2022-05-22 23:32:46,037 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 16 more threads\n",
            "2022-05-22 23:32:46,069 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 15 more threads\n",
            "2022-05-22 23:32:46,090 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 14 more threads\n",
            "2022-05-22 23:32:46,097 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 13 more threads\n",
            "2022-05-22 23:32:46,156 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 12 more threads\n",
            "2022-05-22 23:32:46,157 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 11 more threads\n",
            "2022-05-22 23:32:46,164 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 10 more threads\n",
            "2022-05-22 23:32:46,298 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 9 more threads\n",
            "2022-05-22 23:32:46,303 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 8 more threads\n",
            "2022-05-22 23:32:46,413 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 7 more threads\n",
            "2022-05-22 23:32:46,451 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 6 more threads\n",
            "2022-05-22 23:32:46,479 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 5 more threads\n",
            "2022-05-22 23:32:46,535 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 4 more threads\n",
            "2022-05-22 23:32:46,548 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 3 more threads\n",
            "2022-05-22 23:32:46,554 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 2 more threads\n",
            "2022-05-22 23:32:46,567 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 1 more threads\n",
            "2022-05-22 23:32:46,574 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 0 more threads\n",
            "2022-05-22 23:32:46,575 | INFO | base_any2vec.py:1346 | _log_epoch_end | EPOCH - 2 : training on 2450591 raw words (2316901 effective words) took 19.3s, 119866 effective words/s\n",
            "2022-05-22 23:32:48,303 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 3 - PROGRESS: at 0.92% examples, 10928 words/s, in_qsize 63, out_qsize 0\n",
            "2022-05-22 23:32:49,336 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 3 - PROGRESS: at 2.87% examples, 23848 words/s, in_qsize 61, out_qsize 2\n",
            "2022-05-22 23:32:50,418 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 3 - PROGRESS: at 15.23% examples, 88607 words/s, in_qsize 63, out_qsize 0\n",
            "2022-05-22 23:32:51,582 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 3 - PROGRESS: at 16.04% examples, 71711 words/s, in_qsize 64, out_qsize 2\n",
            "2022-05-22 23:32:52,844 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 3 - PROGRESS: at 28.59% examples, 104027 words/s, in_qsize 64, out_qsize 0\n",
            "2022-05-22 23:32:53,977 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 3 - PROGRESS: at 30.55% examples, 94451 words/s, in_qsize 63, out_qsize 0\n",
            "2022-05-22 23:32:55,013 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 3 - PROGRESS: at 41.25% examples, 113142 words/s, in_qsize 63, out_qsize 0\n",
            "2022-05-22 23:32:56,268 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 3 - PROGRESS: at 43.36% examples, 103309 words/s, in_qsize 64, out_qsize 0\n",
            "2022-05-22 23:32:57,300 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 3 - PROGRESS: at 46.73% examples, 100394 words/s, in_qsize 64, out_qsize 0\n",
            "2022-05-22 23:32:58,493 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 3 - PROGRESS: at 56.40% examples, 109379 words/s, in_qsize 63, out_qsize 0\n",
            "2022-05-22 23:32:59,563 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 3 - PROGRESS: at 59.17% examples, 105446 words/s, in_qsize 62, out_qsize 1\n",
            "2022-05-22 23:33:00,696 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 3 - PROGRESS: at 68.95% examples, 112372 words/s, in_qsize 64, out_qsize 0\n",
            "2022-05-22 23:33:01,910 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 3 - PROGRESS: at 72.60% examples, 109014 words/s, in_qsize 63, out_qsize 0\n",
            "2022-05-22 23:33:02,925 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 3 - PROGRESS: at 79.01% examples, 111473 words/s, in_qsize 52, out_qsize 1\n",
            "2022-05-22 23:33:04,022 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 3 - PROGRESS: at 84.23% examples, 110924 words/s, in_qsize 38, out_qsize 3\n",
            "2022-05-22 23:33:05,033 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 3 - PROGRESS: at 87.75% examples, 109438 words/s, in_qsize 31, out_qsize 2\n",
            "2022-05-22 23:33:05,039 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 31 more threads\n",
            "2022-05-22 23:33:05,083 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 30 more threads\n",
            "2022-05-22 23:33:05,119 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 29 more threads\n",
            "2022-05-22 23:33:05,136 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 28 more threads\n",
            "2022-05-22 23:33:05,192 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 27 more threads\n",
            "2022-05-22 23:33:05,300 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 26 more threads\n",
            "2022-05-22 23:33:05,357 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 25 more threads\n",
            "2022-05-22 23:33:05,368 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 24 more threads\n",
            "2022-05-22 23:33:05,390 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 23 more threads\n",
            "2022-05-22 23:33:05,418 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 22 more threads\n",
            "2022-05-22 23:33:05,441 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 21 more threads\n",
            "2022-05-22 23:33:05,448 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 20 more threads\n",
            "2022-05-22 23:33:05,461 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 19 more threads\n",
            "2022-05-22 23:33:05,483 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 18 more threads\n",
            "2022-05-22 23:33:05,501 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 17 more threads\n",
            "2022-05-22 23:33:05,508 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 16 more threads\n",
            "2022-05-22 23:33:05,512 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 15 more threads\n",
            "2022-05-22 23:33:05,550 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 14 more threads\n",
            "2022-05-22 23:33:05,588 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 13 more threads\n",
            "2022-05-22 23:33:05,654 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 12 more threads\n",
            "2022-05-22 23:33:05,712 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 11 more threads\n",
            "2022-05-22 23:33:05,829 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 10 more threads\n",
            "2022-05-22 23:33:05,833 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 9 more threads\n",
            "2022-05-22 23:33:05,847 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 8 more threads\n",
            "2022-05-22 23:33:05,856 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 7 more threads\n",
            "2022-05-22 23:33:05,865 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 6 more threads\n",
            "2022-05-22 23:33:05,916 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 5 more threads\n",
            "2022-05-22 23:33:05,925 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 4 more threads\n",
            "2022-05-22 23:33:05,950 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 3 more threads\n",
            "2022-05-22 23:33:05,958 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 2 more threads\n",
            "2022-05-22 23:33:05,970 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 1 more threads\n",
            "2022-05-22 23:33:05,973 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 0 more threads\n",
            "2022-05-22 23:33:05,975 | INFO | base_any2vec.py:1346 | _log_epoch_end | EPOCH - 3 : training on 2450591 raw words (2317560 effective words) took 19.4s, 119558 effective words/s\n",
            "2022-05-22 23:33:08,613 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 4 - PROGRESS: at 0.78% examples, 7141 words/s, in_qsize 34, out_qsize 29\n",
            "2022-05-22 23:33:10,043 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 4 - PROGRESS: at 14.40% examples, 79076 words/s, in_qsize 63, out_qsize 0\n",
            "2022-05-22 23:33:11,370 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 4 - PROGRESS: at 16.96% examples, 70065 words/s, in_qsize 54, out_qsize 9\n",
            "2022-05-22 23:33:12,485 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 4 - PROGRESS: at 28.20% examples, 98682 words/s, in_qsize 63, out_qsize 0\n",
            "2022-05-22 23:33:13,840 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 4 - PROGRESS: at 29.76% examples, 86478 words/s, in_qsize 64, out_qsize 4\n",
            "2022-05-22 23:33:14,889 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 4 - PROGRESS: at 41.25% examples, 107080 words/s, in_qsize 62, out_qsize 1\n",
            "2022-05-22 23:33:16,068 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 4 - PROGRESS: at 42.36% examples, 97367 words/s, in_qsize 62, out_qsize 1\n",
            "2022-05-22 23:33:17,360 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 4 - PROGRESS: at 55.16% examples, 112026 words/s, in_qsize 63, out_qsize 0\n",
            "2022-05-22 23:33:18,393 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 4 - PROGRESS: at 55.93% examples, 104205 words/s, in_qsize 62, out_qsize 1\n",
            "2022-05-22 23:33:19,666 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 4 - PROGRESS: at 61.82% examples, 104154 words/s, in_qsize 50, out_qsize 13\n",
            "2022-05-22 23:33:20,717 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 4 - PROGRESS: at 69.38% examples, 108269 words/s, in_qsize 63, out_qsize 0\n",
            "2022-05-22 23:33:21,924 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 4 - PROGRESS: at 74.92% examples, 108363 words/s, in_qsize 63, out_qsize 0\n",
            "2022-05-22 23:33:23,059 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 4 - PROGRESS: at 82.28% examples, 111063 words/s, in_qsize 45, out_qsize 0\n",
            "2022-05-22 23:33:24,420 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 4 - PROGRESS: at 88.19% examples, 110013 words/s, in_qsize 31, out_qsize 1\n",
            "2022-05-22 23:33:24,422 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 31 more threads\n",
            "2022-05-22 23:33:24,456 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 30 more threads\n",
            "2022-05-22 23:33:24,654 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 29 more threads\n",
            "2022-05-22 23:33:24,694 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 28 more threads\n",
            "2022-05-22 23:33:24,719 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 27 more threads\n",
            "2022-05-22 23:33:24,737 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 26 more threads\n",
            "2022-05-22 23:33:24,746 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 25 more threads\n",
            "2022-05-22 23:33:24,775 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 24 more threads\n",
            "2022-05-22 23:33:24,783 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 23 more threads\n",
            "2022-05-22 23:33:24,786 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 22 more threads\n",
            "2022-05-22 23:33:24,788 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 21 more threads\n",
            "2022-05-22 23:33:24,798 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 20 more threads\n",
            "2022-05-22 23:33:24,818 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 19 more threads\n",
            "2022-05-22 23:33:24,830 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 18 more threads\n",
            "2022-05-22 23:33:24,865 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 17 more threads\n",
            "2022-05-22 23:33:24,868 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 16 more threads\n",
            "2022-05-22 23:33:24,923 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 15 more threads\n",
            "2022-05-22 23:33:25,029 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 14 more threads\n",
            "2022-05-22 23:33:25,138 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 13 more threads\n",
            "2022-05-22 23:33:25,239 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 12 more threads\n",
            "2022-05-22 23:33:25,328 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 11 more threads\n",
            "2022-05-22 23:33:25,345 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 10 more threads\n",
            "2022-05-22 23:33:25,354 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 9 more threads\n",
            "2022-05-22 23:33:25,366 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 8 more threads\n",
            "2022-05-22 23:33:25,372 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 7 more threads\n",
            "2022-05-22 23:33:25,382 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 6 more threads\n",
            "2022-05-22 23:33:25,396 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 5 more threads\n",
            "2022-05-22 23:33:25,402 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 4 more threads\n",
            "2022-05-22 23:33:25,450 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 4 - PROGRESS: at 99.06% examples, 117643 words/s, in_qsize 3, out_qsize 0\n",
            "2022-05-22 23:33:25,456 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 3 more threads\n",
            "2022-05-22 23:33:25,457 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 2 more threads\n",
            "2022-05-22 23:33:25,459 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 1 more threads\n",
            "2022-05-22 23:33:25,468 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 0 more threads\n",
            "2022-05-22 23:33:25,469 | INFO | base_any2vec.py:1346 | _log_epoch_end | EPOCH - 4 : training on 2450591 raw words (2317025 effective words) took 19.5s, 118967 effective words/s\n",
            "2022-05-22 23:33:26,741 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 5 - PROGRESS: at 1.10% examples, 14996 words/s, in_qsize 64, out_qsize 0\n",
            "2022-05-22 23:33:27,767 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 5 - PROGRESS: at 1.54% examples, 12399 words/s, in_qsize 64, out_qsize 1\n",
            "2022-05-22 23:33:29,708 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 5 - PROGRESS: at 14.80% examples, 78091 words/s, in_qsize 61, out_qsize 2\n",
            "2022-05-22 23:33:30,769 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 5 - PROGRESS: at 17.19% examples, 73129 words/s, in_qsize 62, out_qsize 1\n",
            "2022-05-22 23:33:31,956 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 5 - PROGRESS: at 28.59% examples, 100534 words/s, in_qsize 63, out_qsize 0\n",
            "2022-05-22 23:33:33,351 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 5 - PROGRESS: at 30.12% examples, 87479 words/s, in_qsize 63, out_qsize 0\n",
            "2022-05-22 23:33:34,711 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 5 - PROGRESS: at 41.45% examples, 104319 words/s, in_qsize 63, out_qsize 0\n",
            "2022-05-22 23:33:36,046 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 5 - PROGRESS: at 43.81% examples, 95574 words/s, in_qsize 64, out_qsize 0\n",
            "2022-05-22 23:33:37,328 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 5 - PROGRESS: at 55.93% examples, 109145 words/s, in_qsize 63, out_qsize 1\n",
            "2022-05-22 23:33:38,378 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 5 - PROGRESS: at 57.43% examples, 103164 words/s, in_qsize 64, out_qsize 0\n",
            "2022-05-22 23:33:39,426 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 5 - PROGRESS: at 69.18% examples, 114366 words/s, in_qsize 64, out_qsize 0\n",
            "2022-05-22 23:33:40,544 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 5 - PROGRESS: at 70.10% examples, 107122 words/s, in_qsize 64, out_qsize 1\n",
            "2022-05-22 23:33:41,559 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 5 - PROGRESS: at 74.67% examples, 106812 words/s, in_qsize 61, out_qsize 2\n",
            "2022-05-22 23:33:42,792 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 5 - PROGRESS: at 83.66% examples, 111157 words/s, in_qsize 42, out_qsize 0\n",
            "2022-05-22 23:33:44,117 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 5 - PROGRESS: at 86.45% examples, 106785 words/s, in_qsize 33, out_qsize 2\n",
            "2022-05-22 23:33:44,175 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 31 more threads\n",
            "2022-05-22 23:33:44,289 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 30 more threads\n",
            "2022-05-22 23:33:44,308 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 29 more threads\n",
            "2022-05-22 23:33:44,314 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 28 more threads\n",
            "2022-05-22 23:33:44,366 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 27 more threads\n",
            "2022-05-22 23:33:44,393 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 26 more threads\n",
            "2022-05-22 23:33:44,405 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 25 more threads\n",
            "2022-05-22 23:33:44,413 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 24 more threads\n",
            "2022-05-22 23:33:44,454 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 23 more threads\n",
            "2022-05-22 23:33:44,458 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 22 more threads\n",
            "2022-05-22 23:33:44,465 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 21 more threads\n",
            "2022-05-22 23:33:44,482 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 20 more threads\n",
            "2022-05-22 23:33:44,499 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 19 more threads\n",
            "2022-05-22 23:33:44,513 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 18 more threads\n",
            "2022-05-22 23:33:44,527 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 17 more threads\n",
            "2022-05-22 23:33:44,529 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 16 more threads\n",
            "2022-05-22 23:33:44,542 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 15 more threads\n",
            "2022-05-22 23:33:44,557 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 14 more threads\n",
            "2022-05-22 23:33:44,601 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 13 more threads\n",
            "2022-05-22 23:33:44,601 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 12 more threads\n",
            "2022-05-22 23:33:44,717 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 11 more threads\n",
            "2022-05-22 23:33:44,804 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 10 more threads\n",
            "2022-05-22 23:33:44,903 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 9 more threads\n",
            "2022-05-22 23:33:44,913 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 8 more threads\n",
            "2022-05-22 23:33:44,914 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 7 more threads\n",
            "2022-05-22 23:33:45,013 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 6 more threads\n",
            "2022-05-22 23:33:45,023 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 5 more threads\n",
            "2022-05-22 23:33:45,051 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 4 more threads\n",
            "2022-05-22 23:33:45,060 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 3 more threads\n",
            "2022-05-22 23:33:45,073 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 2 more threads\n",
            "2022-05-22 23:33:45,083 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 1 more threads\n",
            "2022-05-22 23:33:45,100 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 0 more threads\n",
            "2022-05-22 23:33:45,101 | INFO | base_any2vec.py:1346 | _log_epoch_end | EPOCH - 5 : training on 2450591 raw words (2317056 effective words) took 19.6s, 118127 effective words/s\n",
            "2022-05-22 23:33:47,191 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 6 - PROGRESS: at 0.96% examples, 9084 words/s, in_qsize 64, out_qsize 0\n",
            "2022-05-22 23:33:48,940 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 6 - PROGRESS: at 14.38% examples, 83836 words/s, in_qsize 64, out_qsize 0\n",
            "2022-05-22 23:33:50,038 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 6 - PROGRESS: at 16.47% examples, 74699 words/s, in_qsize 62, out_qsize 2\n",
            "2022-05-22 23:33:51,289 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 6 - PROGRESS: at 27.54% examples, 100799 words/s, in_qsize 63, out_qsize 0\n",
            "2022-05-22 23:33:52,474 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 6 - PROGRESS: at 29.35% examples, 90963 words/s, in_qsize 63, out_qsize 3\n",
            "2022-05-22 23:33:53,614 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 6 - PROGRESS: at 33.84% examples, 92126 words/s, in_qsize 55, out_qsize 8\n",
            "2022-05-22 23:33:54,734 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 6 - PROGRESS: at 41.45% examples, 100083 words/s, in_qsize 63, out_qsize 0\n",
            "2022-05-22 23:33:55,869 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 6 - PROGRESS: at 46.25% examples, 99133 words/s, in_qsize 63, out_qsize 0\n",
            "2022-05-22 23:33:57,105 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 6 - PROGRESS: at 54.82% examples, 105467 words/s, in_qsize 64, out_qsize 0\n",
            "2022-05-22 23:33:58,146 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 6 - PROGRESS: at 57.64% examples, 102102 words/s, in_qsize 62, out_qsize 3\n",
            "2022-05-22 23:33:59,172 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 6 - PROGRESS: at 67.81% examples, 110757 words/s, in_qsize 63, out_qsize 0\n",
            "2022-05-22 23:34:00,587 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 6 - PROGRESS: at 70.10% examples, 104283 words/s, in_qsize 63, out_qsize 3\n",
            "2022-05-22 23:34:01,637 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 6 - PROGRESS: at 76.61% examples, 106795 words/s, in_qsize 59, out_qsize 0\n",
            "2022-05-22 23:34:02,959 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 6 - PROGRESS: at 83.28% examples, 107310 words/s, in_qsize 38, out_qsize 5\n",
            "2022-05-22 23:34:03,667 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 31 more threads\n",
            "2022-05-22 23:34:03,866 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 30 more threads\n",
            "2022-05-22 23:34:03,878 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 29 more threads\n",
            "2022-05-22 23:34:03,934 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 28 more threads\n",
            "2022-05-22 23:34:03,988 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 6 - PROGRESS: at 89.92% examples, 109454 words/s, in_qsize 27, out_qsize 1\n",
            "2022-05-22 23:34:03,991 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 27 more threads\n",
            "2022-05-22 23:34:04,050 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 26 more threads\n",
            "2022-05-22 23:34:04,063 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 25 more threads\n",
            "2022-05-22 23:34:04,075 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 24 more threads\n",
            "2022-05-22 23:34:04,077 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 23 more threads\n",
            "2022-05-22 23:34:04,099 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 22 more threads\n",
            "2022-05-22 23:34:04,202 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 21 more threads\n",
            "2022-05-22 23:34:04,217 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 20 more threads\n",
            "2022-05-22 23:34:04,223 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 19 more threads\n",
            "2022-05-22 23:34:04,252 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 18 more threads\n",
            "2022-05-22 23:34:04,255 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 17 more threads\n",
            "2022-05-22 23:34:04,323 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 16 more threads\n",
            "2022-05-22 23:34:04,333 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 15 more threads\n",
            "2022-05-22 23:34:04,351 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 14 more threads\n",
            "2022-05-22 23:34:04,363 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 13 more threads\n",
            "2022-05-22 23:34:04,448 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 12 more threads\n",
            "2022-05-22 23:34:04,666 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 11 more threads\n",
            "2022-05-22 23:34:04,683 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 10 more threads\n",
            "2022-05-22 23:34:04,686 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 9 more threads\n",
            "2022-05-22 23:34:04,716 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 8 more threads\n",
            "2022-05-22 23:34:04,732 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 7 more threads\n",
            "2022-05-22 23:34:04,740 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 6 more threads\n",
            "2022-05-22 23:34:04,747 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 5 more threads\n",
            "2022-05-22 23:34:04,762 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 4 more threads\n",
            "2022-05-22 23:34:04,766 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 3 more threads\n",
            "2022-05-22 23:34:04,787 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 2 more threads\n",
            "2022-05-22 23:34:04,798 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 1 more threads\n",
            "2022-05-22 23:34:04,808 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 0 more threads\n",
            "2022-05-22 23:34:04,809 | INFO | base_any2vec.py:1346 | _log_epoch_end | EPOCH - 6 : training on 2450591 raw words (2317162 effective words) took 19.7s, 117694 effective words/s\n",
            "2022-05-22 23:34:06,108 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 7 - PROGRESS: at 0.41% examples, 7309 words/s, in_qsize 64, out_qsize 0\n",
            "2022-05-22 23:34:07,175 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 7 - PROGRESS: at 2.29% examples, 23996 words/s, in_qsize 63, out_qsize 0\n",
            "2022-05-22 23:34:08,286 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 7 - PROGRESS: at 13.97% examples, 89827 words/s, in_qsize 63, out_qsize 0\n",
            "2022-05-22 23:34:09,309 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 7 - PROGRESS: at 16.00% examples, 79844 words/s, in_qsize 63, out_qsize 0\n",
            "2022-05-22 23:34:10,322 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 7 - PROGRESS: at 20.98% examples, 85690 words/s, in_qsize 61, out_qsize 2\n",
            "2022-05-22 23:34:11,427 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 7 - PROGRESS: at 28.59% examples, 98526 words/s, in_qsize 64, out_qsize 0\n",
            "2022-05-22 23:34:12,468 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 7 - PROGRESS: at 30.90% examples, 92496 words/s, in_qsize 63, out_qsize 0\n",
            "2022-05-22 23:34:13,993 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 7 - PROGRESS: at 41.01% examples, 103943 words/s, in_qsize 61, out_qsize 2\n",
            "2022-05-22 23:34:15,201 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 7 - PROGRESS: at 44.59% examples, 99090 words/s, in_qsize 63, out_qsize 0\n",
            "2022-05-22 23:34:16,316 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 7 - PROGRESS: at 54.38% examples, 109198 words/s, in_qsize 63, out_qsize 2\n",
            "2022-05-22 23:34:17,352 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 7 - PROGRESS: at 56.80% examples, 104680 words/s, in_qsize 62, out_qsize 1\n",
            "2022-05-22 23:34:18,394 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 7 - PROGRESS: at 66.52% examples, 112621 words/s, in_qsize 64, out_qsize 2\n",
            "2022-05-22 23:34:19,679 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 7 - PROGRESS: at 70.59% examples, 109231 words/s, in_qsize 64, out_qsize 0\n",
            "2022-05-22 23:34:20,849 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 7 - PROGRESS: at 75.88% examples, 108914 words/s, in_qsize 58, out_qsize 3\n",
            "2022-05-22 23:34:22,133 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 7 - PROGRESS: at 83.79% examples, 111155 words/s, in_qsize 42, out_qsize 0\n",
            "2022-05-22 23:34:23,146 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 7 - PROGRESS: at 86.27% examples, 108089 words/s, in_qsize 33, out_qsize 3\n",
            "2022-05-22 23:34:23,197 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 31 more threads\n",
            "2022-05-22 23:34:23,243 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 30 more threads\n",
            "2022-05-22 23:34:23,375 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 29 more threads\n",
            "2022-05-22 23:34:23,487 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 28 more threads\n",
            "2022-05-22 23:34:23,534 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 27 more threads\n",
            "2022-05-22 23:34:23,556 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 26 more threads\n",
            "2022-05-22 23:34:23,644 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 25 more threads\n",
            "2022-05-22 23:34:23,701 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 24 more threads\n",
            "2022-05-22 23:34:23,708 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 23 more threads\n",
            "2022-05-22 23:34:23,711 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 22 more threads\n",
            "2022-05-22 23:34:23,718 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 21 more threads\n",
            "2022-05-22 23:34:23,721 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 20 more threads\n",
            "2022-05-22 23:34:23,773 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 19 more threads\n",
            "2022-05-22 23:34:23,774 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 18 more threads\n",
            "2022-05-22 23:34:23,777 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 17 more threads\n",
            "2022-05-22 23:34:23,781 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 16 more threads\n",
            "2022-05-22 23:34:23,787 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 15 more threads\n",
            "2022-05-22 23:34:23,846 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 14 more threads\n",
            "2022-05-22 23:34:23,889 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 13 more threads\n",
            "2022-05-22 23:34:24,086 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 12 more threads\n",
            "2022-05-22 23:34:24,102 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 11 more threads\n",
            "2022-05-22 23:34:24,209 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 7 - PROGRESS: at 96.62% examples, 114815 words/s, in_qsize 10, out_qsize 1\n",
            "2022-05-22 23:34:24,210 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 10 more threads\n",
            "2022-05-22 23:34:24,275 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 9 more threads\n",
            "2022-05-22 23:34:24,329 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 8 more threads\n",
            "2022-05-22 23:34:24,353 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 7 more threads\n",
            "2022-05-22 23:34:24,374 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 6 more threads\n",
            "2022-05-22 23:34:24,383 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 5 more threads\n",
            "2022-05-22 23:34:24,417 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 4 more threads\n",
            "2022-05-22 23:34:24,425 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 3 more threads\n",
            "2022-05-22 23:34:24,449 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 2 more threads\n",
            "2022-05-22 23:34:24,461 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 1 more threads\n",
            "2022-05-22 23:34:24,466 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 0 more threads\n",
            "2022-05-22 23:34:24,467 | INFO | base_any2vec.py:1346 | _log_epoch_end | EPOCH - 7 : training on 2450591 raw words (2317285 effective words) took 19.6s, 117971 effective words/s\n",
            "2022-05-22 23:34:26,061 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 8 - PROGRESS: at 0.94% examples, 11875 words/s, in_qsize 61, out_qsize 2\n",
            "2022-05-22 23:34:27,243 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 8 - PROGRESS: at 2.63% examples, 20459 words/s, in_qsize 49, out_qsize 14\n",
            "2022-05-22 23:34:28,371 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 8 - PROGRESS: at 15.61% examples, 89621 words/s, in_qsize 64, out_qsize 0\n",
            "2022-05-22 23:34:29,482 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 8 - PROGRESS: at 16.40% examples, 73447 words/s, in_qsize 63, out_qsize 0\n",
            "2022-05-22 23:34:31,028 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 8 - PROGRESS: at 28.90% examples, 100774 words/s, in_qsize 64, out_qsize 0\n",
            "2022-05-22 23:34:32,213 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 8 - PROGRESS: at 31.73% examples, 93883 words/s, in_qsize 63, out_qsize 0\n",
            "2022-05-22 23:34:33,284 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 8 - PROGRESS: at 41.45% examples, 109316 words/s, in_qsize 64, out_qsize 0\n",
            "2022-05-22 23:34:34,394 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 8 - PROGRESS: at 44.20% examples, 102753 words/s, in_qsize 64, out_qsize 0\n",
            "2022-05-22 23:34:35,646 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 8 - PROGRESS: at 46.71% examples, 96288 words/s, in_qsize 52, out_qsize 11\n",
            "2022-05-22 23:34:36,849 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 8 - PROGRESS: at 57.43% examples, 107536 words/s, in_qsize 63, out_qsize 0\n",
            "2022-05-22 23:34:38,115 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 8 - PROGRESS: at 60.08% examples, 101701 words/s, in_qsize 57, out_qsize 6\n",
            "2022-05-22 23:34:39,139 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 8 - PROGRESS: at 70.59% examples, 110686 words/s, in_qsize 63, out_qsize 0\n",
            "2022-05-22 23:34:40,489 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 8 - PROGRESS: at 73.47% examples, 105478 words/s, in_qsize 64, out_qsize 2\n",
            "2022-05-22 23:34:41,830 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 8 - PROGRESS: at 85.44% examples, 113048 words/s, in_qsize 38, out_qsize 0\n",
            "2022-05-22 23:34:42,964 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 8 - PROGRESS: at 87.03% examples, 108152 words/s, in_qsize 34, out_qsize 0\n",
            "2022-05-22 23:34:43,223 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 31 more threads\n",
            "2022-05-22 23:34:43,234 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 30 more threads\n",
            "2022-05-22 23:34:43,243 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 29 more threads\n",
            "2022-05-22 23:34:43,248 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 28 more threads\n",
            "2022-05-22 23:34:43,283 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 27 more threads\n",
            "2022-05-22 23:34:43,304 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 26 more threads\n",
            "2022-05-22 23:34:43,426 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 25 more threads\n",
            "2022-05-22 23:34:43,437 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 24 more threads\n",
            "2022-05-22 23:34:43,452 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 23 more threads\n",
            "2022-05-22 23:34:43,470 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 22 more threads\n",
            "2022-05-22 23:34:43,478 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 21 more threads\n",
            "2022-05-22 23:34:43,498 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 20 more threads\n",
            "2022-05-22 23:34:43,507 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 19 more threads\n",
            "2022-05-22 23:34:43,514 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 18 more threads\n",
            "2022-05-22 23:34:43,554 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 17 more threads\n",
            "2022-05-22 23:34:43,582 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 16 more threads\n",
            "2022-05-22 23:34:43,609 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 15 more threads\n",
            "2022-05-22 23:34:43,617 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 14 more threads\n",
            "2022-05-22 23:34:43,636 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 13 more threads\n",
            "2022-05-22 23:34:43,652 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 12 more threads\n",
            "2022-05-22 23:34:43,658 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 11 more threads\n",
            "2022-05-22 23:34:43,660 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 10 more threads\n",
            "2022-05-22 23:34:43,666 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 9 more threads\n",
            "2022-05-22 23:34:43,676 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 8 more threads\n",
            "2022-05-22 23:34:43,686 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 7 more threads\n",
            "2022-05-22 23:34:43,787 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 6 more threads\n",
            "2022-05-22 23:34:43,819 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 5 more threads\n",
            "2022-05-22 23:34:43,822 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 4 more threads\n",
            "2022-05-22 23:34:43,886 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 3 more threads\n",
            "2022-05-22 23:34:43,897 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 2 more threads\n",
            "2022-05-22 23:34:43,928 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 1 more threads\n",
            "2022-05-22 23:34:43,938 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 0 more threads\n",
            "2022-05-22 23:34:43,939 | INFO | base_any2vec.py:1346 | _log_epoch_end | EPOCH - 8 : training on 2450591 raw words (2316627 effective words) took 19.5s, 119070 effective words/s\n",
            "2022-05-22 23:34:45,373 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 9 - PROGRESS: at 1.19% examples, 19842 words/s, in_qsize 63, out_qsize 0\n",
            "2022-05-22 23:34:46,866 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 9 - PROGRESS: at 2.38% examples, 19356 words/s, in_qsize 50, out_qsize 13\n",
            "2022-05-22 23:34:48,704 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 9 - PROGRESS: at 16.08% examples, 75375 words/s, in_qsize 61, out_qsize 2\n",
            "2022-05-22 23:34:49,766 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 9 - PROGRESS: at 28.59% examples, 111934 words/s, in_qsize 63, out_qsize 0\n",
            "2022-05-22 23:34:50,994 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 9 - PROGRESS: at 30.55% examples, 99093 words/s, in_qsize 63, out_qsize 0\n",
            "2022-05-22 23:34:52,462 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 9 - PROGRESS: at 32.49% examples, 88650 words/s, in_qsize 44, out_qsize 19\n",
            "2022-05-22 23:34:53,647 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 9 - PROGRESS: at 43.81% examples, 104126 words/s, in_qsize 64, out_qsize 0\n",
            "2022-05-22 23:34:54,898 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 9 - PROGRESS: at 45.97% examples, 96523 words/s, in_qsize 62, out_qsize 1\n",
            "2022-05-22 23:34:56,201 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 9 - PROGRESS: at 56.80% examples, 107063 words/s, in_qsize 63, out_qsize 0\n",
            "2022-05-22 23:34:57,326 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 9 - PROGRESS: at 58.71% examples, 101567 words/s, in_qsize 63, out_qsize 0\n",
            "2022-05-22 23:34:58,538 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 9 - PROGRESS: at 70.10% examples, 110601 words/s, in_qsize 64, out_qsize 0\n",
            "2022-05-22 23:34:59,954 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 9 - PROGRESS: at 72.21% examples, 103764 words/s, in_qsize 58, out_qsize 5\n",
            "2022-05-22 23:35:01,244 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 9 - PROGRESS: at 83.79% examples, 111264 words/s, in_qsize 42, out_qsize 0\n",
            "2022-05-22 23:35:02,376 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 9 - PROGRESS: at 85.44% examples, 106470 words/s, in_qsize 37, out_qsize 1\n",
            "2022-05-22 23:35:02,567 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 31 more threads\n",
            "2022-05-22 23:35:02,578 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 30 more threads\n",
            "2022-05-22 23:35:02,674 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 29 more threads\n",
            "2022-05-22 23:35:02,697 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 28 more threads\n",
            "2022-05-22 23:35:02,725 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 27 more threads\n",
            "2022-05-22 23:35:02,805 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 26 more threads\n",
            "2022-05-22 23:35:02,814 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 25 more threads\n",
            "2022-05-22 23:35:02,823 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 24 more threads\n",
            "2022-05-22 23:35:02,874 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 23 more threads\n",
            "2022-05-22 23:35:02,889 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 22 more threads\n",
            "2022-05-22 23:35:02,915 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 21 more threads\n",
            "2022-05-22 23:35:02,951 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 20 more threads\n",
            "2022-05-22 23:35:02,957 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 19 more threads\n",
            "2022-05-22 23:35:02,962 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 18 more threads\n",
            "2022-05-22 23:35:02,995 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 17 more threads\n",
            "2022-05-22 23:35:02,997 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 16 more threads\n",
            "2022-05-22 23:35:03,005 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 15 more threads\n",
            "2022-05-22 23:35:03,020 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 14 more threads\n",
            "2022-05-22 23:35:03,050 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 13 more threads\n",
            "2022-05-22 23:35:03,076 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 12 more threads\n",
            "2022-05-22 23:35:03,132 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 11 more threads\n",
            "2022-05-22 23:35:03,265 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 10 more threads\n",
            "2022-05-22 23:35:03,338 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 9 more threads\n",
            "2022-05-22 23:35:03,345 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 8 more threads\n",
            "2022-05-22 23:35:03,355 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 7 more threads\n",
            "2022-05-22 23:35:03,483 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 9 - PROGRESS: at 98.00% examples, 115749 words/s, in_qsize 6, out_qsize 1\n",
            "2022-05-22 23:35:03,490 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 6 more threads\n",
            "2022-05-22 23:35:03,553 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 5 more threads\n",
            "2022-05-22 23:35:03,559 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 4 more threads\n",
            "2022-05-22 23:35:03,570 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 3 more threads\n",
            "2022-05-22 23:35:03,578 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 2 more threads\n",
            "2022-05-22 23:35:03,579 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 1 more threads\n",
            "2022-05-22 23:35:03,583 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 0 more threads\n",
            "2022-05-22 23:35:03,584 | INFO | base_any2vec.py:1346 | _log_epoch_end | EPOCH - 9 : training on 2450591 raw words (2316775 effective words) took 19.6s, 118033 effective words/s\n",
            "2022-05-22 23:35:05,119 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 10 - PROGRESS: at 1.23% examples, 18600 words/s, in_qsize 64, out_qsize 0\n",
            "2022-05-22 23:35:06,321 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 10 - PROGRESS: at 1.71% examples, 13784 words/s, in_qsize 61, out_qsize 2\n",
            "2022-05-22 23:35:08,289 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 10 - PROGRESS: at 15.62% examples, 74437 words/s, in_qsize 63, out_qsize 0\n",
            "2022-05-22 23:35:09,335 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 10 - PROGRESS: at 28.20% examples, 111843 words/s, in_qsize 64, out_qsize 0\n",
            "2022-05-22 23:35:10,492 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 10 - PROGRESS: at 28.51% examples, 94402 words/s, in_qsize 62, out_qsize 1\n",
            "2022-05-22 23:35:11,736 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 10 - PROGRESS: at 32.20% examples, 90444 words/s, in_qsize 59, out_qsize 4\n",
            "2022-05-22 23:35:12,744 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 10 - PROGRESS: at 43.16% examples, 108367 words/s, in_qsize 63, out_qsize 0\n",
            "2022-05-22 23:35:13,841 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 10 - PROGRESS: at 44.59% examples, 100450 words/s, in_qsize 63, out_qsize 0\n",
            "2022-05-22 23:35:14,859 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 10 - PROGRESS: at 55.50% examples, 114010 words/s, in_qsize 62, out_qsize 1\n",
            "2022-05-22 23:35:16,825 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 10 - PROGRESS: at 57.56% examples, 100603 words/s, in_qsize 61, out_qsize 2\n",
            "2022-05-22 23:35:18,409 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 10 - PROGRESS: at 70.94% examples, 110221 words/s, in_qsize 64, out_qsize 0\n",
            "2022-05-22 23:35:19,554 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 10 - PROGRESS: at 73.03% examples, 105264 words/s, in_qsize 64, out_qsize 1\n",
            "2022-05-22 23:35:20,601 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 10 - PROGRESS: at 84.58% examples, 114303 words/s, in_qsize 40, out_qsize 0\n",
            "2022-05-22 23:35:22,022 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 10 - PROGRESS: at 87.03% examples, 108558 words/s, in_qsize 34, out_qsize 0\n",
            "2022-05-22 23:35:22,250 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 31 more threads\n",
            "2022-05-22 23:35:22,258 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 30 more threads\n",
            "2022-05-22 23:35:22,262 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 29 more threads\n",
            "2022-05-22 23:35:22,265 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 28 more threads\n",
            "2022-05-22 23:35:22,272 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 27 more threads\n",
            "2022-05-22 23:35:22,308 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 26 more threads\n",
            "2022-05-22 23:35:22,425 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 25 more threads\n",
            "2022-05-22 23:35:22,447 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 24 more threads\n",
            "2022-05-22 23:35:22,467 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 23 more threads\n",
            "2022-05-22 23:35:22,482 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 22 more threads\n",
            "2022-05-22 23:35:22,511 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 21 more threads\n",
            "2022-05-22 23:35:22,520 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 20 more threads\n",
            "2022-05-22 23:35:22,562 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 19 more threads\n",
            "2022-05-22 23:35:22,571 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 18 more threads\n",
            "2022-05-22 23:35:22,579 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 17 more threads\n",
            "2022-05-22 23:35:22,586 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 16 more threads\n",
            "2022-05-22 23:35:22,593 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 15 more threads\n",
            "2022-05-22 23:35:22,594 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 14 more threads\n",
            "2022-05-22 23:35:22,614 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 13 more threads\n",
            "2022-05-22 23:35:22,640 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 12 more threads\n",
            "2022-05-22 23:35:22,642 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 11 more threads\n",
            "2022-05-22 23:35:22,652 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 10 more threads\n",
            "2022-05-22 23:35:22,663 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 9 more threads\n",
            "2022-05-22 23:35:22,780 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 8 more threads\n",
            "2022-05-22 23:35:22,836 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 7 more threads\n",
            "2022-05-22 23:35:22,901 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 6 more threads\n",
            "2022-05-22 23:35:22,913 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 5 more threads\n",
            "2022-05-22 23:35:22,923 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 4 more threads\n",
            "2022-05-22 23:35:22,938 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 3 more threads\n",
            "2022-05-22 23:35:22,945 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 2 more threads\n",
            "2022-05-22 23:35:22,982 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 1 more threads\n",
            "2022-05-22 23:35:22,992 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 0 more threads\n",
            "2022-05-22 23:35:22,993 | INFO | base_any2vec.py:1346 | _log_epoch_end | EPOCH - 10 : training on 2450591 raw words (2316916 effective words) took 19.4s, 119511 effective words/s\n",
            "2022-05-22 23:35:24,460 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 11 - PROGRESS: at 0.24% examples, 6467 words/s, in_qsize 63, out_qsize 0\n",
            "2022-05-22 23:35:25,979 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 11 - PROGRESS: at 3.25% examples, 25388 words/s, in_qsize 53, out_qsize 22\n",
            "2022-05-22 23:35:27,252 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 11 - PROGRESS: at 14.80% examples, 77745 words/s, in_qsize 60, out_qsize 3\n",
            "2022-05-22 23:35:28,314 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 11 - PROGRESS: at 18.12% examples, 76416 words/s, in_qsize 62, out_qsize 1\n",
            "2022-05-22 23:35:29,316 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 11 - PROGRESS: at 28.91% examples, 104596 words/s, in_qsize 63, out_qsize 0\n",
            "2022-05-22 23:35:30,409 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 11 - PROGRESS: at 30.04% examples, 92978 words/s, in_qsize 63, out_qsize 0\n",
            "2022-05-22 23:35:31,449 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 11 - PROGRESS: at 32.06% examples, 87114 words/s, in_qsize 64, out_qsize 22\n",
            "2022-05-22 23:35:32,926 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 11 - PROGRESS: at 43.81% examples, 101777 words/s, in_qsize 62, out_qsize 1\n",
            "2022-05-22 23:35:33,975 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 11 - PROGRESS: at 48.20% examples, 101504 words/s, in_qsize 57, out_qsize 6\n",
            "2022-05-22 23:35:35,022 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 11 - PROGRESS: at 56.80% examples, 109168 words/s, in_qsize 63, out_qsize 0\n",
            "2022-05-22 23:35:36,058 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 11 - PROGRESS: at 58.76% examples, 104099 words/s, in_qsize 63, out_qsize 0\n",
            "2022-05-22 23:35:37,224 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 11 - PROGRESS: at 70.15% examples, 113491 words/s, in_qsize 63, out_qsize 0\n",
            "2022-05-22 23:35:38,403 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 11 - PROGRESS: at 72.12% examples, 107870 words/s, in_qsize 62, out_qsize 1\n",
            "2022-05-22 23:35:39,427 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 11 - PROGRESS: at 83.79% examples, 117182 words/s, in_qsize 42, out_qsize 0\n",
            "2022-05-22 23:35:40,488 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 11 - PROGRESS: at 84.59% examples, 111148 words/s, in_qsize 40, out_qsize 0\n",
            "2022-05-22 23:35:40,888 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 31 more threads\n",
            "2022-05-22 23:35:40,901 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 30 more threads\n",
            "2022-05-22 23:35:41,458 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 29 more threads\n",
            "2022-05-22 23:35:41,624 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 11 - PROGRESS: at 89.44% examples, 110438 words/s, in_qsize 28, out_qsize 1\n",
            "2022-05-22 23:35:41,631 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 28 more threads\n",
            "2022-05-22 23:35:41,641 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 27 more threads\n",
            "2022-05-22 23:35:41,654 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 26 more threads\n",
            "2022-05-22 23:35:41,662 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 25 more threads\n",
            "2022-05-22 23:35:41,684 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 24 more threads\n",
            "2022-05-22 23:35:41,698 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 23 more threads\n",
            "2022-05-22 23:35:41,712 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 22 more threads\n",
            "2022-05-22 23:35:41,727 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 21 more threads\n",
            "2022-05-22 23:35:41,747 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 20 more threads\n",
            "2022-05-22 23:35:41,787 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 19 more threads\n",
            "2022-05-22 23:35:41,788 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 18 more threads\n",
            "2022-05-22 23:35:41,795 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 17 more threads\n",
            "2022-05-22 23:35:41,841 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 16 more threads\n",
            "2022-05-22 23:35:41,854 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 15 more threads\n",
            "2022-05-22 23:35:41,858 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 14 more threads\n",
            "2022-05-22 23:35:41,898 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 13 more threads\n",
            "2022-05-22 23:35:41,904 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 12 more threads\n",
            "2022-05-22 23:35:41,949 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 11 more threads\n",
            "2022-05-22 23:35:41,980 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 10 more threads\n",
            "2022-05-22 23:35:42,121 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 9 more threads\n",
            "2022-05-22 23:35:42,164 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 8 more threads\n",
            "2022-05-22 23:35:42,178 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 7 more threads\n",
            "2022-05-22 23:35:42,243 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 6 more threads\n",
            "2022-05-22 23:35:42,246 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 5 more threads\n",
            "2022-05-22 23:35:42,248 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 4 more threads\n",
            "2022-05-22 23:35:42,253 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 3 more threads\n",
            "2022-05-22 23:35:42,269 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 2 more threads\n",
            "2022-05-22 23:35:42,272 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 1 more threads\n",
            "2022-05-22 23:35:42,278 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 0 more threads\n",
            "2022-05-22 23:35:42,280 | INFO | base_any2vec.py:1346 | _log_epoch_end | EPOCH - 11 : training on 2450591 raw words (2317082 effective words) took 19.3s, 120247 effective words/s\n",
            "2022-05-22 23:35:44,563 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 12 - PROGRESS: at 1.42% examples, 12432 words/s, in_qsize 64, out_qsize 0\n",
            "2022-05-22 23:35:45,617 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 12 - PROGRESS: at 15.23% examples, 102158 words/s, in_qsize 64, out_qsize 0\n",
            "2022-05-22 23:35:46,889 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 12 - PROGRESS: at 15.69% examples, 75899 words/s, in_qsize 62, out_qsize 1\n",
            "2022-05-22 23:35:47,964 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 12 - PROGRESS: at 18.63% examples, 73166 words/s, in_qsize 64, out_qsize 23\n",
            "2022-05-22 23:35:48,969 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 12 - PROGRESS: at 29.30% examples, 100310 words/s, in_qsize 63, out_qsize 0\n",
            "2022-05-22 23:35:50,087 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 12 - PROGRESS: at 31.01% examples, 90772 words/s, in_qsize 63, out_qsize 0\n",
            "2022-05-22 23:35:51,388 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 12 - PROGRESS: at 41.91% examples, 106898 words/s, in_qsize 63, out_qsize 2\n",
            "2022-05-22 23:35:52,399 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 12 - PROGRESS: at 44.66% examples, 101773 words/s, in_qsize 63, out_qsize 0\n",
            "2022-05-22 23:35:53,989 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 12 - PROGRESS: at 56.80% examples, 112155 words/s, in_qsize 64, out_qsize 0\n",
            "2022-05-22 23:35:55,097 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 12 - PROGRESS: at 58.28% examples, 105378 words/s, in_qsize 63, out_qsize 0\n",
            "2022-05-22 23:35:56,159 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 12 - PROGRESS: at 62.68% examples, 104105 words/s, in_qsize 64, out_qsize 12\n",
            "2022-05-22 23:35:57,628 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 12 - PROGRESS: at 71.73% examples, 107684 words/s, in_qsize 63, out_qsize 0\n",
            "2022-05-22 23:35:58,677 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 12 - PROGRESS: at 75.87% examples, 106549 words/s, in_qsize 60, out_qsize 1\n",
            "2022-05-22 23:36:00,023 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 12 - PROGRESS: at 85.02% examples, 110129 words/s, in_qsize 37, out_qsize 2\n",
            "2022-05-22 23:36:00,605 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 31 more threads\n",
            "2022-05-22 23:36:00,619 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 30 more threads\n",
            "2022-05-22 23:36:00,914 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 29 more threads\n",
            "2022-05-22 23:36:01,097 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 12 - PROGRESS: at 89.53% examples, 109347 words/s, in_qsize 28, out_qsize 1\n",
            "2022-05-22 23:36:01,099 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 28 more threads\n",
            "2022-05-22 23:36:01,102 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 27 more threads\n",
            "2022-05-22 23:36:01,110 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 26 more threads\n",
            "2022-05-22 23:36:01,187 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 25 more threads\n",
            "2022-05-22 23:36:01,202 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 24 more threads\n",
            "2022-05-22 23:36:01,229 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 23 more threads\n",
            "2022-05-22 23:36:01,288 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 22 more threads\n",
            "2022-05-22 23:36:01,289 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 21 more threads\n",
            "2022-05-22 23:36:01,299 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 20 more threads\n",
            "2022-05-22 23:36:01,312 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 19 more threads\n",
            "2022-05-22 23:36:01,313 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 18 more threads\n",
            "2022-05-22 23:36:01,323 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 17 more threads\n",
            "2022-05-22 23:36:01,355 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 16 more threads\n",
            "2022-05-22 23:36:01,373 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 15 more threads\n",
            "2022-05-22 23:36:01,391 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 14 more threads\n",
            "2022-05-22 23:36:01,398 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 13 more threads\n",
            "2022-05-22 23:36:01,408 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 12 more threads\n",
            "2022-05-22 23:36:01,432 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 11 more threads\n",
            "2022-05-22 23:36:01,437 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 10 more threads\n",
            "2022-05-22 23:36:01,446 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 9 more threads\n",
            "2022-05-22 23:36:01,456 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 8 more threads\n",
            "2022-05-22 23:36:01,672 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 7 more threads\n",
            "2022-05-22 23:36:01,674 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 6 more threads\n",
            "2022-05-22 23:36:01,678 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 5 more threads\n",
            "2022-05-22 23:36:01,698 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 4 more threads\n",
            "2022-05-22 23:36:01,703 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 3 more threads\n",
            "2022-05-22 23:36:01,707 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 2 more threads\n",
            "2022-05-22 23:36:01,731 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 1 more threads\n",
            "2022-05-22 23:36:01,737 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 0 more threads\n",
            "2022-05-22 23:36:01,738 | INFO | base_any2vec.py:1346 | _log_epoch_end | EPOCH - 12 : training on 2450591 raw words (2316933 effective words) took 19.4s, 119193 effective words/s\n",
            "2022-05-22 23:36:03,510 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 13 - PROGRESS: at 0.78% examples, 10654 words/s, in_qsize 63, out_qsize 0\n",
            "2022-05-22 23:36:04,571 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 13 - PROGRESS: at 3.44% examples, 30091 words/s, in_qsize 60, out_qsize 5\n",
            "2022-05-22 23:36:05,690 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 13 - PROGRESS: at 14.38% examples, 81393 words/s, in_qsize 63, out_qsize 2\n",
            "2022-05-22 23:36:06,807 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 13 - PROGRESS: at 17.94% examples, 80193 words/s, in_qsize 63, out_qsize 0\n",
            "2022-05-22 23:36:07,953 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 13 - PROGRESS: at 28.24% examples, 103385 words/s, in_qsize 64, out_qsize 0\n",
            "2022-05-22 23:36:09,170 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 13 - PROGRESS: at 30.90% examples, 95345 words/s, in_qsize 64, out_qsize 0\n",
            "2022-05-22 23:36:10,201 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 13 - PROGRESS: at 40.81% examples, 111729 words/s, in_qsize 63, out_qsize 0\n",
            "2022-05-22 23:36:11,773 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 13 - PROGRESS: at 44.20% examples, 101686 words/s, in_qsize 63, out_qsize 0\n",
            "2022-05-22 23:36:12,907 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 13 - PROGRESS: at 46.69% examples, 96413 words/s, in_qsize 61, out_qsize 15\n",
            "2022-05-22 23:36:13,949 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 13 - PROGRESS: at 57.56% examples, 109063 words/s, in_qsize 64, out_qsize 0\n",
            "2022-05-22 23:36:15,201 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 13 - PROGRESS: at 59.49% examples, 102430 words/s, in_qsize 61, out_qsize 2\n",
            "2022-05-22 23:36:16,390 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 13 - PROGRESS: at 71.73% examples, 112810 words/s, in_qsize 64, out_qsize 0\n",
            "2022-05-22 23:36:17,448 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 13 - PROGRESS: at 73.49% examples, 107611 words/s, in_qsize 62, out_qsize 1\n",
            "2022-05-22 23:36:18,471 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 13 - PROGRESS: at 84.58% examples, 116223 words/s, in_qsize 40, out_qsize 0\n",
            "2022-05-22 23:36:19,759 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 13 - PROGRESS: at 86.22% examples, 109993 words/s, in_qsize 35, out_qsize 1\n",
            "2022-05-22 23:36:20,262 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 31 more threads\n",
            "2022-05-22 23:36:20,273 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 30 more threads\n",
            "2022-05-22 23:36:20,276 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 29 more threads\n",
            "2022-05-22 23:36:20,278 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 28 more threads\n",
            "2022-05-22 23:36:20,281 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 27 more threads\n",
            "2022-05-22 23:36:20,404 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 26 more threads\n",
            "2022-05-22 23:36:20,431 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 25 more threads\n",
            "2022-05-22 23:36:20,455 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 24 more threads\n",
            "2022-05-22 23:36:20,489 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 23 more threads\n",
            "2022-05-22 23:36:20,496 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 22 more threads\n",
            "2022-05-22 23:36:20,598 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 21 more threads\n",
            "2022-05-22 23:36:20,606 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 20 more threads\n",
            "2022-05-22 23:36:20,651 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 19 more threads\n",
            "2022-05-22 23:36:20,688 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 18 more threads\n",
            "2022-05-22 23:36:20,715 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 17 more threads\n",
            "2022-05-22 23:36:20,746 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 16 more threads\n",
            "2022-05-22 23:36:20,751 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 15 more threads\n",
            "2022-05-22 23:36:20,754 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 14 more threads\n",
            "2022-05-22 23:36:20,771 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 13 - PROGRESS: at 95.36% examples, 115531 words/s, in_qsize 13, out_qsize 1\n",
            "2022-05-22 23:36:20,772 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 13 more threads\n",
            "2022-05-22 23:36:20,783 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 12 more threads\n",
            "2022-05-22 23:36:20,787 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 11 more threads\n",
            "2022-05-22 23:36:20,793 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 10 more threads\n",
            "2022-05-22 23:36:20,834 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 9 more threads\n",
            "2022-05-22 23:36:20,871 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 8 more threads\n",
            "2022-05-22 23:36:20,885 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 7 more threads\n",
            "2022-05-22 23:36:20,927 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 6 more threads\n",
            "2022-05-22 23:36:21,034 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 5 more threads\n",
            "2022-05-22 23:36:21,058 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 4 more threads\n",
            "2022-05-22 23:36:21,059 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 3 more threads\n",
            "2022-05-22 23:36:21,074 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 2 more threads\n",
            "2022-05-22 23:36:21,083 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 1 more threads\n",
            "2022-05-22 23:36:21,090 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 0 more threads\n",
            "2022-05-22 23:36:21,091 | INFO | base_any2vec.py:1346 | _log_epoch_end | EPOCH - 13 : training on 2450591 raw words (2317229 effective words) took 19.3s, 119845 effective words/s\n",
            "2022-05-22 23:36:22,226 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 14 - PROGRESS: at 0.41% examples, 8430 words/s, in_qsize 63, out_qsize 0\n",
            "2022-05-22 23:36:23,473 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 14 - PROGRESS: at 1.34% examples, 15857 words/s, in_qsize 63, out_qsize 0\n",
            "2022-05-22 23:36:24,880 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 14 - PROGRESS: at 14.80% examples, 87416 words/s, in_qsize 64, out_qsize 1\n",
            "2022-05-22 23:36:26,221 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 14 - PROGRESS: at 17.21% examples, 75536 words/s, in_qsize 63, out_qsize 0\n",
            "2022-05-22 23:36:27,817 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 14 - PROGRESS: at 28.51% examples, 96917 words/s, in_qsize 61, out_qsize 2\n",
            "2022-05-22 23:36:29,049 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 14 - PROGRESS: at 31.26% examples, 90218 words/s, in_qsize 63, out_qsize 0\n",
            "2022-05-22 23:36:30,067 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 14 - PROGRESS: at 41.25% examples, 106361 words/s, in_qsize 64, out_qsize 1\n",
            "2022-05-22 23:36:31,295 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 14 - PROGRESS: at 44.20% examples, 99996 words/s, in_qsize 63, out_qsize 0\n",
            "2022-05-22 23:36:32,310 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 14 - PROGRESS: at 54.38% examples, 112009 words/s, in_qsize 63, out_qsize 0\n",
            "2022-05-22 23:36:33,399 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 14 - PROGRESS: at 56.80% examples, 106693 words/s, in_qsize 63, out_qsize 0\n",
            "2022-05-22 23:36:34,459 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 14 - PROGRESS: at 61.19% examples, 105992 words/s, in_qsize 64, out_qsize 0\n",
            "2022-05-22 23:36:35,537 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 14 - PROGRESS: at 69.66% examples, 111157 words/s, in_qsize 64, out_qsize 0\n",
            "2022-05-22 23:36:36,566 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 14 - PROGRESS: at 71.72% examples, 106808 words/s, in_qsize 64, out_qsize 1\n",
            "2022-05-22 23:36:37,994 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 14 - PROGRESS: at 82.79% examples, 112812 words/s, in_qsize 42, out_qsize 2\n",
            "2022-05-22 23:36:39,508 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 14 - PROGRESS: at 88.18% examples, 110164 words/s, in_qsize 31, out_qsize 1\n",
            "2022-05-22 23:36:39,513 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 31 more threads\n",
            "2022-05-22 23:36:39,530 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 30 more threads\n",
            "2022-05-22 23:36:39,565 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 29 more threads\n",
            "2022-05-22 23:36:39,711 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 28 more threads\n",
            "2022-05-22 23:36:39,720 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 27 more threads\n",
            "2022-05-22 23:36:39,758 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 26 more threads\n",
            "2022-05-22 23:36:39,821 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 25 more threads\n",
            "2022-05-22 23:36:39,827 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 24 more threads\n",
            "2022-05-22 23:36:39,835 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 23 more threads\n",
            "2022-05-22 23:36:39,837 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 22 more threads\n",
            "2022-05-22 23:36:39,843 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 21 more threads\n",
            "2022-05-22 23:36:39,850 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 20 more threads\n",
            "2022-05-22 23:36:39,851 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 19 more threads\n",
            "2022-05-22 23:36:39,876 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 18 more threads\n",
            "2022-05-22 23:36:39,877 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 17 more threads\n",
            "2022-05-22 23:36:39,922 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 16 more threads\n",
            "2022-05-22 23:36:39,939 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 15 more threads\n",
            "2022-05-22 23:36:39,961 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 14 more threads\n",
            "2022-05-22 23:36:39,992 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 13 more threads\n",
            "2022-05-22 23:36:40,121 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 12 more threads\n",
            "2022-05-22 23:36:40,142 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 11 more threads\n",
            "2022-05-22 23:36:40,145 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 10 more threads\n",
            "2022-05-22 23:36:40,154 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 9 more threads\n",
            "2022-05-22 23:36:40,191 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 8 more threads\n",
            "2022-05-22 23:36:40,298 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 7 more threads\n",
            "2022-05-22 23:36:40,389 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 6 more threads\n",
            "2022-05-22 23:36:40,407 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 5 more threads\n",
            "2022-05-22 23:36:40,409 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 4 more threads\n",
            "2022-05-22 23:36:40,410 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 3 more threads\n",
            "2022-05-22 23:36:40,416 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 2 more threads\n",
            "2022-05-22 23:36:40,418 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 1 more threads\n",
            "2022-05-22 23:36:40,419 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 0 more threads\n",
            "2022-05-22 23:36:40,420 | INFO | base_any2vec.py:1346 | _log_epoch_end | EPOCH - 14 : training on 2450591 raw words (2316895 effective words) took 19.3s, 119978 effective words/s\n",
            "2022-05-22 23:36:41,505 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 15 - PROGRESS: at 0.54% examples, 8750 words/s, in_qsize 63, out_qsize 0\n",
            "2022-05-22 23:36:42,570 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 15 - PROGRESS: at 2.29% examples, 26424 words/s, in_qsize 64, out_qsize 0\n",
            "2022-05-22 23:36:43,792 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 15 - PROGRESS: at 13.97% examples, 92718 words/s, in_qsize 63, out_qsize 0\n",
            "2022-05-22 23:36:44,973 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 15 - PROGRESS: at 16.04% examples, 78929 words/s, in_qsize 62, out_qsize 1\n",
            "2022-05-22 23:36:45,995 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 15 - PROGRESS: at 27.15% examples, 110224 words/s, in_qsize 63, out_qsize 0\n",
            "2022-05-22 23:36:47,228 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 15 - PROGRESS: at 29.30% examples, 98547 words/s, in_qsize 63, out_qsize 0\n",
            "2022-05-22 23:36:48,279 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 15 - PROGRESS: at 31.56% examples, 92562 words/s, in_qsize 63, out_qsize 0\n",
            "2022-05-22 23:36:49,423 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 15 - PROGRESS: at 41.25% examples, 106042 words/s, in_qsize 61, out_qsize 2\n",
            "2022-05-22 23:36:50,573 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 15 - PROGRESS: at 44.20% examples, 100492 words/s, in_qsize 62, out_qsize 1\n",
            "2022-05-22 23:36:51,663 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 15 - PROGRESS: at 54.90% examples, 112604 words/s, in_qsize 64, out_qsize 0\n",
            "2022-05-22 23:36:52,775 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 15 - PROGRESS: at 56.80% examples, 106280 words/s, in_qsize 64, out_qsize 2\n",
            "2022-05-22 23:36:54,025 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 15 - PROGRESS: at 60.41% examples, 102734 words/s, in_qsize 55, out_qsize 8\n",
            "2022-05-22 23:36:55,078 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 15 - PROGRESS: at 70.97% examples, 111449 words/s, in_qsize 64, out_qsize 1\n",
            "2022-05-22 23:36:56,126 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 15 - PROGRESS: at 73.03% examples, 107022 words/s, in_qsize 60, out_qsize 3\n",
            "2022-05-22 23:36:57,319 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 15 - PROGRESS: at 84.17% examples, 114510 words/s, in_qsize 40, out_qsize 1\n",
            "2022-05-22 23:36:58,412 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 15 - PROGRESS: at 85.71% examples, 109635 words/s, in_qsize 32, out_qsize 5\n",
            "2022-05-22 23:36:58,453 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 31 more threads\n",
            "2022-05-22 23:36:58,689 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 30 more threads\n",
            "2022-05-22 23:36:58,962 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 29 more threads\n",
            "2022-05-22 23:36:58,989 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 28 more threads\n",
            "2022-05-22 23:36:59,015 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 27 more threads\n",
            "2022-05-22 23:36:59,043 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 26 more threads\n",
            "2022-05-22 23:36:59,070 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 25 more threads\n",
            "2022-05-22 23:36:59,081 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 24 more threads\n",
            "2022-05-22 23:36:59,105 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 23 more threads\n",
            "2022-05-22 23:36:59,123 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 22 more threads\n",
            "2022-05-22 23:36:59,139 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 21 more threads\n",
            "2022-05-22 23:36:59,152 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 20 more threads\n",
            "2022-05-22 23:36:59,166 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 19 more threads\n",
            "2022-05-22 23:36:59,205 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 18 more threads\n",
            "2022-05-22 23:36:59,244 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 17 more threads\n",
            "2022-05-22 23:36:59,250 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 16 more threads\n",
            "2022-05-22 23:36:59,256 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 15 more threads\n",
            "2022-05-22 23:36:59,262 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 14 more threads\n",
            "2022-05-22 23:36:59,264 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 13 more threads\n",
            "2022-05-22 23:36:59,278 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 12 more threads\n",
            "2022-05-22 23:36:59,279 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 11 more threads\n",
            "2022-05-22 23:36:59,280 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 10 more threads\n",
            "2022-05-22 23:36:59,343 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 9 more threads\n",
            "2022-05-22 23:36:59,390 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 8 more threads\n",
            "2022-05-22 23:36:59,401 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 7 more threads\n",
            "2022-05-22 23:36:59,490 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 15 - PROGRESS: at 98.00% examples, 118643 words/s, in_qsize 6, out_qsize 0\n",
            "2022-05-22 23:36:59,492 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 6 more threads\n",
            "2022-05-22 23:36:59,577 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 5 more threads\n",
            "2022-05-22 23:36:59,579 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 4 more threads\n",
            "2022-05-22 23:36:59,600 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 3 more threads\n",
            "2022-05-22 23:36:59,613 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 2 more threads\n",
            "2022-05-22 23:36:59,628 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 1 more threads\n",
            "2022-05-22 23:36:59,635 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 0 more threads\n",
            "2022-05-22 23:36:59,638 | INFO | base_any2vec.py:1346 | _log_epoch_end | EPOCH - 15 : training on 2450591 raw words (2316931 effective words) took 19.2s, 120683 effective words/s\n",
            "2022-05-22 23:37:01,915 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 16 - PROGRESS: at 0.65% examples, 8297 words/s, in_qsize 60, out_qsize 3\n",
            "2022-05-22 23:37:03,607 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 16 - PROGRESS: at 14.38% examples, 81035 words/s, in_qsize 63, out_qsize 0\n",
            "2022-05-22 23:37:04,856 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 16 - PROGRESS: at 18.09% examples, 77870 words/s, in_qsize 62, out_qsize 1\n",
            "2022-05-22 23:37:06,014 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 16 - PROGRESS: at 28.59% examples, 102253 words/s, in_qsize 63, out_qsize 0\n",
            "2022-05-22 23:37:07,184 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 16 - PROGRESS: at 31.19% examples, 95127 words/s, in_qsize 63, out_qsize 0\n",
            "2022-05-22 23:37:08,199 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 16 - PROGRESS: at 41.45% examples, 112598 words/s, in_qsize 63, out_qsize 0\n",
            "2022-05-22 23:37:09,394 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 16 - PROGRESS: at 44.20% examples, 104572 words/s, in_qsize 63, out_qsize 0\n",
            "2022-05-22 23:37:10,404 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 16 - PROGRESS: at 47.54% examples, 101760 words/s, in_qsize 61, out_qsize 2\n",
            "2022-05-22 23:37:11,406 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 16 - PROGRESS: at 56.80% examples, 111569 words/s, in_qsize 63, out_qsize 0\n",
            "2022-05-22 23:37:12,588 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 16 - PROGRESS: at 58.74% examples, 104997 words/s, in_qsize 63, out_qsize 0\n",
            "2022-05-22 23:37:13,904 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 16 - PROGRESS: at 70.59% examples, 113845 words/s, in_qsize 63, out_qsize 0\n",
            "2022-05-22 23:37:15,034 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 16 - PROGRESS: at 72.60% examples, 108552 words/s, in_qsize 61, out_qsize 2\n",
            "2022-05-22 23:37:16,058 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 16 - PROGRESS: at 83.79% examples, 117271 words/s, in_qsize 42, out_qsize 0\n",
            "2022-05-22 23:37:17,263 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 16 - PROGRESS: at 85.80% examples, 111914 words/s, in_qsize 36, out_qsize 1\n",
            "2022-05-22 23:37:17,834 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 31 more threads\n",
            "2022-05-22 23:37:17,846 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 30 more threads\n",
            "2022-05-22 23:37:17,943 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 29 more threads\n",
            "2022-05-22 23:37:18,027 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 28 more threads\n",
            "2022-05-22 23:37:18,092 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 27 more threads\n",
            "2022-05-22 23:37:18,172 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 26 more threads\n",
            "2022-05-22 23:37:18,181 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 25 more threads\n",
            "2022-05-22 23:37:18,200 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 24 more threads\n",
            "2022-05-22 23:37:18,246 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 23 more threads\n",
            "2022-05-22 23:37:18,254 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 22 more threads\n",
            "2022-05-22 23:37:18,295 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 16 - PROGRESS: at 92.42% examples, 113803 words/s, in_qsize 21, out_qsize 1\n",
            "2022-05-22 23:37:18,296 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 21 more threads\n",
            "2022-05-22 23:37:18,308 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 20 more threads\n",
            "2022-05-22 23:37:18,321 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 19 more threads\n",
            "2022-05-22 23:37:18,329 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 18 more threads\n",
            "2022-05-22 23:37:18,346 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 17 more threads\n",
            "2022-05-22 23:37:18,347 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 16 more threads\n",
            "2022-05-22 23:37:18,348 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 15 more threads\n",
            "2022-05-22 23:37:18,382 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 14 more threads\n",
            "2022-05-22 23:37:18,427 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 13 more threads\n",
            "2022-05-22 23:37:18,437 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 12 more threads\n",
            "2022-05-22 23:37:18,439 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 11 more threads\n",
            "2022-05-22 23:37:18,477 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 10 more threads\n",
            "2022-05-22 23:37:18,655 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 9 more threads\n",
            "2022-05-22 23:37:18,705 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 8 more threads\n",
            "2022-05-22 23:37:18,712 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 7 more threads\n",
            "2022-05-22 23:37:18,741 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 6 more threads\n",
            "2022-05-22 23:37:18,777 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 5 more threads\n",
            "2022-05-22 23:37:18,779 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 4 more threads\n",
            "2022-05-22 23:37:18,791 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 3 more threads\n",
            "2022-05-22 23:37:18,796 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 2 more threads\n",
            "2022-05-22 23:37:18,804 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 1 more threads\n",
            "2022-05-22 23:37:18,804 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 0 more threads\n",
            "2022-05-22 23:37:18,807 | INFO | base_any2vec.py:1346 | _log_epoch_end | EPOCH - 16 : training on 2450591 raw words (2316708 effective words) took 19.2s, 120968 effective words/s\n",
            "2022-05-22 23:37:20,480 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 17 - PROGRESS: at 0.92% examples, 11414 words/s, in_qsize 64, out_qsize 2\n",
            "2022-05-22 23:37:21,627 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 17 - PROGRESS: at 2.51% examples, 20149 words/s, in_qsize 64, out_qsize 25\n",
            "2022-05-22 23:37:23,233 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 17 - PROGRESS: at 15.62% examples, 79089 words/s, in_qsize 63, out_qsize 0\n",
            "2022-05-22 23:37:24,353 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 17 - PROGRESS: at 19.76% examples, 80138 words/s, in_qsize 59, out_qsize 10\n",
            "2022-05-22 23:37:25,709 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 17 - PROGRESS: at 29.30% examples, 97209 words/s, in_qsize 62, out_qsize 1\n",
            "2022-05-22 23:37:27,010 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 17 - PROGRESS: at 31.64% examples, 88701 words/s, in_qsize 59, out_qsize 5\n",
            "2022-05-22 23:37:28,162 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 17 - PROGRESS: at 43.36% examples, 107058 words/s, in_qsize 63, out_qsize 0\n",
            "2022-05-22 23:37:29,233 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 17 - PROGRESS: at 45.55% examples, 100587 words/s, in_qsize 63, out_qsize 0\n",
            "2022-05-22 23:37:30,829 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 17 - PROGRESS: at 56.80% examples, 109430 words/s, in_qsize 63, out_qsize 1\n",
            "2022-05-22 23:37:31,941 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 17 - PROGRESS: at 59.14% examples, 104260 words/s, in_qsize 63, out_qsize 0\n",
            "2022-05-22 23:37:33,330 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 17 - PROGRESS: at 70.97% examples, 112487 words/s, in_qsize 62, out_qsize 1\n",
            "2022-05-22 23:37:34,413 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 17 - PROGRESS: at 73.49% examples, 108314 words/s, in_qsize 63, out_qsize 0\n",
            "2022-05-22 23:37:36,089 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 17 - PROGRESS: at 85.44% examples, 113603 words/s, in_qsize 38, out_qsize 0\n",
            "2022-05-22 23:37:37,316 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 17 - PROGRESS: at 87.28% examples, 108610 words/s, in_qsize 29, out_qsize 7\n",
            "2022-05-22 23:37:37,324 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 31 more threads\n",
            "2022-05-22 23:37:37,330 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 30 more threads\n",
            "2022-05-22 23:37:37,339 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 29 more threads\n",
            "2022-05-22 23:37:37,363 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 28 more threads\n",
            "2022-05-22 23:37:37,480 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 27 more threads\n",
            "2022-05-22 23:37:37,482 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 26 more threads\n",
            "2022-05-22 23:37:37,483 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 25 more threads\n",
            "2022-05-22 23:37:37,484 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 24 more threads\n",
            "2022-05-22 23:37:37,495 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 23 more threads\n",
            "2022-05-22 23:37:37,584 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 22 more threads\n",
            "2022-05-22 23:37:37,655 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 21 more threads\n",
            "2022-05-22 23:37:37,657 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 20 more threads\n",
            "2022-05-22 23:37:37,680 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 19 more threads\n",
            "2022-05-22 23:37:37,688 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 18 more threads\n",
            "2022-05-22 23:37:37,739 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 17 more threads\n",
            "2022-05-22 23:37:37,745 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 16 more threads\n",
            "2022-05-22 23:37:37,767 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 15 more threads\n",
            "2022-05-22 23:37:37,774 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 14 more threads\n",
            "2022-05-22 23:37:37,795 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 13 more threads\n",
            "2022-05-22 23:37:37,800 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 12 more threads\n",
            "2022-05-22 23:37:37,827 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 11 more threads\n",
            "2022-05-22 23:37:37,844 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 10 more threads\n",
            "2022-05-22 23:37:37,845 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 9 more threads\n",
            "2022-05-22 23:37:37,850 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 8 more threads\n",
            "2022-05-22 23:37:37,864 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 7 more threads\n",
            "2022-05-22 23:37:37,962 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 6 more threads\n",
            "2022-05-22 23:37:38,000 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 5 more threads\n",
            "2022-05-22 23:37:38,019 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 4 more threads\n",
            "2022-05-22 23:37:38,069 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 3 more threads\n",
            "2022-05-22 23:37:38,093 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 2 more threads\n",
            "2022-05-22 23:37:38,100 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 1 more threads\n",
            "2022-05-22 23:37:38,108 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 0 more threads\n",
            "2022-05-22 23:37:38,109 | INFO | base_any2vec.py:1346 | _log_epoch_end | EPOCH - 17 : training on 2450591 raw words (2316832 effective words) took 19.3s, 120151 effective words/s\n",
            "2022-05-22 23:37:39,287 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 18 - PROGRESS: at 0.94% examples, 16170 words/s, in_qsize 64, out_qsize 0\n",
            "2022-05-22 23:37:40,363 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 18 - PROGRESS: at 1.75% examples, 16812 words/s, in_qsize 63, out_qsize 0\n",
            "2022-05-22 23:37:42,045 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 18 - PROGRESS: at 14.80% examples, 84174 words/s, in_qsize 64, out_qsize 0\n",
            "2022-05-22 23:37:43,482 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 18 - PROGRESS: at 17.17% examples, 72148 words/s, in_qsize 59, out_qsize 4\n",
            "2022-05-22 23:37:44,557 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 18 - PROGRESS: at 28.20% examples, 99683 words/s, in_qsize 63, out_qsize 0\n",
            "2022-05-22 23:37:45,692 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 18 - PROGRESS: at 30.16% examples, 90958 words/s, in_qsize 63, out_qsize 0\n",
            "2022-05-22 23:37:46,848 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 18 - PROGRESS: at 40.76% examples, 108188 words/s, in_qsize 63, out_qsize 0\n",
            "2022-05-22 23:37:48,063 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 18 - PROGRESS: at 43.81% examples, 101572 words/s, in_qsize 63, out_qsize 0\n",
            "2022-05-22 23:37:49,296 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 18 - PROGRESS: at 46.25% examples, 95416 words/s, in_qsize 61, out_qsize 22\n",
            "2022-05-22 23:37:50,405 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 18 - PROGRESS: at 57.43% examples, 108343 words/s, in_qsize 64, out_qsize 1\n",
            "2022-05-22 23:37:51,511 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 18 - PROGRESS: at 59.08% examples, 102203 words/s, in_qsize 62, out_qsize 1\n",
            "2022-05-22 23:37:52,737 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 18 - PROGRESS: at 72.21% examples, 113647 words/s, in_qsize 63, out_qsize 0\n",
            "2022-05-22 23:37:53,858 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 18 - PROGRESS: at 73.38% examples, 107349 words/s, in_qsize 63, out_qsize 0\n",
            "2022-05-22 23:37:54,906 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 18 - PROGRESS: at 78.12% examples, 107386 words/s, in_qsize 38, out_qsize 17\n",
            "2022-05-22 23:37:55,934 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 18 - PROGRESS: at 87.28% examples, 112815 words/s, in_qsize 33, out_qsize 0\n",
            "2022-05-22 23:37:56,220 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 31 more threads\n",
            "2022-05-22 23:37:56,276 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 30 more threads\n",
            "2022-05-22 23:37:56,800 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 29 more threads\n",
            "2022-05-22 23:37:57,045 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 18 - PROGRESS: at 89.32% examples, 108682 words/s, in_qsize 28, out_qsize 1\n",
            "2022-05-22 23:37:57,047 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 28 more threads\n",
            "2022-05-22 23:37:57,062 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 27 more threads\n",
            "2022-05-22 23:37:57,125 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 26 more threads\n",
            "2022-05-22 23:37:57,177 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 25 more threads\n",
            "2022-05-22 23:37:57,196 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 24 more threads\n",
            "2022-05-22 23:37:57,247 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 23 more threads\n",
            "2022-05-22 23:37:57,281 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 22 more threads\n",
            "2022-05-22 23:37:57,311 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 21 more threads\n",
            "2022-05-22 23:37:57,314 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 20 more threads\n",
            "2022-05-22 23:37:57,337 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 19 more threads\n",
            "2022-05-22 23:37:57,370 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 18 more threads\n",
            "2022-05-22 23:37:57,372 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 17 more threads\n",
            "2022-05-22 23:37:57,382 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 16 more threads\n",
            "2022-05-22 23:37:57,385 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 15 more threads\n",
            "2022-05-22 23:37:57,390 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 14 more threads\n",
            "2022-05-22 23:37:57,393 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 13 more threads\n",
            "2022-05-22 23:37:57,394 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 12 more threads\n",
            "2022-05-22 23:37:57,428 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 11 more threads\n",
            "2022-05-22 23:37:57,440 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 10 more threads\n",
            "2022-05-22 23:37:57,444 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 9 more threads\n",
            "2022-05-22 23:37:57,452 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 8 more threads\n",
            "2022-05-22 23:37:57,453 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 7 more threads\n",
            "2022-05-22 23:37:57,479 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 6 more threads\n",
            "2022-05-22 23:37:57,558 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 5 more threads\n",
            "2022-05-22 23:37:57,575 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 4 more threads\n",
            "2022-05-22 23:37:57,583 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 3 more threads\n",
            "2022-05-22 23:37:57,593 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 2 more threads\n",
            "2022-05-22 23:37:57,603 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 1 more threads\n",
            "2022-05-22 23:37:57,614 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 0 more threads\n",
            "2022-05-22 23:37:57,615 | INFO | base_any2vec.py:1346 | _log_epoch_end | EPOCH - 18 : training on 2450591 raw words (2317269 effective words) took 19.5s, 118919 effective words/s\n",
            "2022-05-22 23:37:58,950 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 19 - PROGRESS: at 1.23% examples, 21837 words/s, in_qsize 63, out_qsize 0\n",
            "2022-05-22 23:38:00,426 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 19 - PROGRESS: at 1.71% examples, 13602 words/s, in_qsize 61, out_qsize 2\n",
            "2022-05-22 23:38:01,774 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 19 - PROGRESS: at 15.23% examples, 82327 words/s, in_qsize 62, out_qsize 1\n",
            "2022-05-22 23:38:02,786 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 19 - PROGRESS: at 16.50% examples, 71629 words/s, in_qsize 64, out_qsize 0\n",
            "2022-05-22 23:38:04,864 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 19 - PROGRESS: at 29.30% examples, 92829 words/s, in_qsize 62, out_qsize 1\n",
            "2022-05-22 23:38:05,925 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 19 - PROGRESS: at 32.44% examples, 90060 words/s, in_qsize 55, out_qsize 8\n",
            "2022-05-22 23:38:07,211 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 19 - PROGRESS: at 42.83% examples, 103636 words/s, in_qsize 62, out_qsize 1\n",
            "2022-05-22 23:38:08,263 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 19 - PROGRESS: at 44.29% examples, 96017 words/s, in_qsize 61, out_qsize 2\n",
            "2022-05-22 23:38:09,501 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 19 - PROGRESS: at 56.80% examples, 110683 words/s, in_qsize 63, out_qsize 0\n",
            "2022-05-22 23:38:10,601 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 19 - PROGRESS: at 58.74% examples, 104907 words/s, in_qsize 63, out_qsize 0\n",
            "2022-05-22 23:38:12,247 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 19 - PROGRESS: at 70.59% examples, 111184 words/s, in_qsize 62, out_qsize 1\n",
            "2022-05-22 23:38:13,346 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 19 - PROGRESS: at 73.42% examples, 107622 words/s, in_qsize 64, out_qsize 0\n",
            "2022-05-22 23:38:14,638 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 19 - PROGRESS: at 83.79% examples, 113280 words/s, in_qsize 40, out_qsize 2\n",
            "2022-05-22 23:38:15,688 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 19 - PROGRESS: at 86.92% examples, 110860 words/s, in_qsize 34, out_qsize 0\n",
            "2022-05-22 23:38:16,072 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 31 more threads\n",
            "2022-05-22 23:38:16,234 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 30 more threads\n",
            "2022-05-22 23:38:16,248 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 29 more threads\n",
            "2022-05-22 23:38:16,293 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 28 more threads\n",
            "2022-05-22 23:38:16,314 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 27 more threads\n",
            "2022-05-22 23:38:16,318 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 26 more threads\n",
            "2022-05-22 23:38:16,330 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 25 more threads\n",
            "2022-05-22 23:38:16,352 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 24 more threads\n",
            "2022-05-22 23:38:16,361 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 23 more threads\n",
            "2022-05-22 23:38:16,364 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 22 more threads\n",
            "2022-05-22 23:38:16,391 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 21 more threads\n",
            "2022-05-22 23:38:16,432 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 20 more threads\n",
            "2022-05-22 23:38:16,435 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 19 more threads\n",
            "2022-05-22 23:38:16,440 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 18 more threads\n",
            "2022-05-22 23:38:16,441 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 17 more threads\n",
            "2022-05-22 23:38:16,451 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 16 more threads\n",
            "2022-05-22 23:38:16,483 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 15 more threads\n",
            "2022-05-22 23:38:16,517 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 14 more threads\n",
            "2022-05-22 23:38:16,524 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 13 more threads\n",
            "2022-05-22 23:38:16,577 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 12 more threads\n",
            "2022-05-22 23:38:16,602 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 11 more threads\n",
            "2022-05-22 23:38:16,722 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 19 - PROGRESS: at 96.62% examples, 116715 words/s, in_qsize 10, out_qsize 0\n",
            "2022-05-22 23:38:16,724 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 10 more threads\n",
            "2022-05-22 23:38:16,726 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 9 more threads\n",
            "2022-05-22 23:38:16,728 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 8 more threads\n",
            "2022-05-22 23:38:16,744 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 7 more threads\n",
            "2022-05-22 23:38:16,774 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 6 more threads\n",
            "2022-05-22 23:38:16,833 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 5 more threads\n",
            "2022-05-22 23:38:16,872 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 4 more threads\n",
            "2022-05-22 23:38:16,883 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 3 more threads\n",
            "2022-05-22 23:38:16,888 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 2 more threads\n",
            "2022-05-22 23:38:16,910 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 1 more threads\n",
            "2022-05-22 23:38:16,932 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 0 more threads\n",
            "2022-05-22 23:38:16,933 | INFO | base_any2vec.py:1346 | _log_epoch_end | EPOCH - 19 : training on 2450591 raw words (2317040 effective words) took 19.3s, 120197 effective words/s\n",
            "2022-05-22 23:38:18,020 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 20 - PROGRESS: at 0.79% examples, 17726 words/s, in_qsize 63, out_qsize 0\n",
            "2022-05-22 23:38:19,510 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 20 - PROGRESS: at 1.79% examples, 14715 words/s, in_qsize 63, out_qsize 0\n",
            "2022-05-22 23:38:21,100 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 20 - PROGRESS: at 15.57% examples, 83952 words/s, in_qsize 64, out_qsize 0\n",
            "2022-05-22 23:38:22,101 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 20 - PROGRESS: at 18.89% examples, 82310 words/s, in_qsize 61, out_qsize 2\n",
            "2022-05-22 23:38:23,436 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 20 - PROGRESS: at 28.59% examples, 100254 words/s, in_qsize 63, out_qsize 0\n",
            "2022-05-22 23:38:24,518 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 20 - PROGRESS: at 29.71% examples, 89623 words/s, in_qsize 62, out_qsize 1\n",
            "2022-05-22 23:38:25,725 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 20 - PROGRESS: at 41.25% examples, 108551 words/s, in_qsize 63, out_qsize 0\n",
            "2022-05-22 23:38:26,840 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 20 - PROGRESS: at 41.71% examples, 97272 words/s, in_qsize 61, out_qsize 2\n",
            "2022-05-22 23:38:28,082 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 20 - PROGRESS: at 54.38% examples, 112678 words/s, in_qsize 63, out_qsize 0\n",
            "2022-05-22 23:38:29,373 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 20 - PROGRESS: at 54.82% examples, 101727 words/s, in_qsize 62, out_qsize 1\n",
            "2022-05-22 23:38:32,059 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 20 - PROGRESS: at 68.13% examples, 103622 words/s, in_qsize 56, out_qsize 7\n",
            "2022-05-22 23:38:34,465 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 20 - PROGRESS: at 80.96% examples, 106609 words/s, in_qsize 39, out_qsize 9\n",
            "2022-05-22 23:38:35,246 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 31 more threads\n",
            "2022-05-22 23:38:35,253 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 30 more threads\n",
            "2022-05-22 23:38:35,259 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 29 more threads\n",
            "2022-05-22 23:38:35,267 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 28 more threads\n",
            "2022-05-22 23:38:35,268 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 27 more threads\n",
            "2022-05-22 23:38:35,283 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 26 more threads\n",
            "2022-05-22 23:38:35,291 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 25 more threads\n",
            "2022-05-22 23:38:35,293 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 24 more threads\n",
            "2022-05-22 23:38:35,315 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 23 more threads\n",
            "2022-05-22 23:38:35,316 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 22 more threads\n",
            "2022-05-22 23:38:35,333 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 21 more threads\n",
            "2022-05-22 23:38:35,368 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 20 more threads\n",
            "2022-05-22 23:38:35,375 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 19 more threads\n",
            "2022-05-22 23:38:35,376 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 18 more threads\n",
            "2022-05-22 23:38:35,395 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 17 more threads\n",
            "2022-05-22 23:38:36,037 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 20 - PROGRESS: at 94.33% examples, 113604 words/s, in_qsize 16, out_qsize 1\n",
            "2022-05-22 23:38:36,040 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 16 more threads\n",
            "2022-05-22 23:38:36,085 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 15 more threads\n",
            "2022-05-22 23:38:36,092 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 14 more threads\n",
            "2022-05-22 23:38:36,137 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 13 more threads\n",
            "2022-05-22 23:38:36,154 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 12 more threads\n",
            "2022-05-22 23:38:36,191 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 11 more threads\n",
            "2022-05-22 23:38:36,194 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 10 more threads\n",
            "2022-05-22 23:38:36,196 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 9 more threads\n",
            "2022-05-22 23:38:36,197 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 8 more threads\n",
            "2022-05-22 23:38:36,198 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 7 more threads\n",
            "2022-05-22 23:38:36,211 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 6 more threads\n",
            "2022-05-22 23:38:36,215 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 5 more threads\n",
            "2022-05-22 23:38:36,225 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 4 more threads\n",
            "2022-05-22 23:38:36,238 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 3 more threads\n",
            "2022-05-22 23:38:36,260 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 2 more threads\n",
            "2022-05-22 23:38:36,296 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 1 more threads\n",
            "2022-05-22 23:38:36,299 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 0 more threads\n",
            "2022-05-22 23:38:36,302 | INFO | base_any2vec.py:1346 | _log_epoch_end | EPOCH - 20 : training on 2450591 raw words (2316868 effective words) took 19.4s, 119719 effective words/s\n",
            "2022-05-22 23:38:36,308 | INFO | base_any2vec.py:1382 | _log_train_end | training on a 49011820 raw words (46340053 effective words) took 388.6s, 119238 effective words/s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wordvec_arrays = np.zeros((len(tokenized_caption), 50)) \n",
        "for i in range(len(tokenized_caption)):\n",
        "    wordvec_arrays[i,:] = word_vector(tokenized_caption[i], 50,modelFastTextSkipGramCaption)\n",
        "wordvec_caption = pd.DataFrame(wordvec_arrays)\n",
        "wordvec_caption.shape"
      ],
      "metadata": {
        "id": "oW6GgPkHubI0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88e482ef-df58-4871-f774-918c0d110c84"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(88514, 50)"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### hashtags"
      ],
      "metadata": {
        "id": "ViWDzgKwuxWd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_hastags = df['hashtags'].apply(lambda x: str(x).split()) # tokenizing\n",
        "modelFastTextSkipGramHastags = FastText(tokenized_hastags, \n",
        "                     size=50, # desired no. of features/independent variables\n",
        "                     window=2,  # context window size\n",
        "                     min_count=2, # Ignores all words with total frequency lower than 2.  \n",
        "                     workers=32, # no.of cores\n",
        "                     hs = 0,\n",
        "                     negative = 10, # for negative sampling\n",
        "                     sg=0  # 0 for CBOW model\n",
        "                     )\n",
        "\n",
        "modelFastTextSkipGramHastags.build_vocab(tokenized_hastags, update=True)\n",
        "modelFastTextSkipGramHastags.train(tokenized_hastags, total_examples= len(tokenized_hastags), epochs=20)"
      ],
      "metadata": {
        "id": "yePPpywMu2vJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c4f7b8d-45fb-435a-e3ce-357813743134"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-22 23:39:01,783 | WARNING | base_any2vec.py:723 | __init__ | consider setting layer size to a multiple of 4 for greater performance\n",
            "2022-05-22 23:39:01,785 | INFO | word2vec.py:1567 | scan_vocab | collecting all words and their counts\n",
            "2022-05-22 23:39:01,786 | INFO | word2vec.py:1552 | _scan_vocab | PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
            "2022-05-22 23:39:01,805 | INFO | word2vec.py:1552 | _scan_vocab | PROGRESS: at sentence #10000, processed 50969 words, keeping 10996 word types\n",
            "2022-05-22 23:39:01,825 | INFO | word2vec.py:1552 | _scan_vocab | PROGRESS: at sentence #20000, processed 113744 words, keeping 21000 word types\n",
            "2022-05-22 23:39:01,842 | INFO | word2vec.py:1552 | _scan_vocab | PROGRESS: at sentence #30000, processed 171307 words, keeping 28787 word types\n",
            "2022-05-22 23:39:01,868 | INFO | word2vec.py:1552 | _scan_vocab | PROGRESS: at sentence #40000, processed 238519 words, keeping 35303 word types\n",
            "2022-05-22 23:39:01,891 | INFO | word2vec.py:1552 | _scan_vocab | PROGRESS: at sentence #50000, processed 303169 words, keeping 41748 word types\n",
            "2022-05-22 23:39:01,907 | INFO | word2vec.py:1552 | _scan_vocab | PROGRESS: at sentence #60000, processed 356785 words, keeping 47292 word types\n",
            "2022-05-22 23:39:01,923 | INFO | word2vec.py:1552 | _scan_vocab | PROGRESS: at sentence #70000, processed 409232 words, keeping 52041 word types\n",
            "2022-05-22 23:39:01,938 | INFO | word2vec.py:1552 | _scan_vocab | PROGRESS: at sentence #80000, processed 460207 words, keeping 57823 word types\n",
            "2022-05-22 23:39:01,954 | INFO | word2vec.py:1575 | scan_vocab | collected 62269 word types from a corpus of 497185 raw words and 88514 sentences\n",
            "2022-05-22 23:39:01,955 | INFO | word2vec.py:1626 | prepare_vocab | Loading a fresh vocabulary\n",
            "2022-05-22 23:39:02,014 | INFO | word2vec.py:1650 | prepare_vocab | effective_min_count=2 retains 25970 unique words (41% of original 62269, drops 36299)\n",
            "2022-05-22 23:39:02,015 | INFO | word2vec.py:1656 | prepare_vocab | effective_min_count=2 leaves 460886 word corpus (92% of original 497185, drops 36299)\n",
            "2022-05-22 23:39:02,080 | INFO | word2vec.py:1715 | prepare_vocab | deleting the raw counts dictionary of 62269 items\n",
            "2022-05-22 23:39:02,084 | INFO | word2vec.py:1718 | prepare_vocab | sample=0.001 downsamples 17 most-common words\n",
            "2022-05-22 23:39:02,086 | INFO | word2vec.py:1721 | prepare_vocab | downsampling leaves estimated 447565 word corpus (97.1% of prior 460886)\n",
            "2022-05-22 23:39:02,707 | INFO | fasttext.py:551 | estimate_memory | estimated required memory for 25970 words, 203322 buckets and 50 dimensions: 77024440 bytes\n",
            "2022-05-22 23:39:02,709 | INFO | word2vec.py:1834 | reset_weights | resetting layer weights\n",
            "2022-05-22 23:39:07,875 | INFO | fasttext.py:1011 | init_ngrams_weights | Total number of ngrams is 203322\n",
            "2022-05-22 23:39:08,964 | INFO | base_any2vec.py:1210 | _check_training_sanity | training model with 32 workers on 25970 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=10 window=2\n",
            "2022-05-22 23:39:11,035 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 1 - PROGRESS: at 9.05% examples, 17319 words/s, in_qsize 46, out_qsize 0\n",
            "2022-05-22 23:39:12,247 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 1 - PROGRESS: at 18.41% examples, 24686 words/s, in_qsize 40, out_qsize 1\n",
            "2022-05-22 23:39:12,507 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 31 more threads\n",
            "2022-05-22 23:39:12,522 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 30 more threads\n",
            "2022-05-22 23:39:12,575 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 29 more threads\n",
            "2022-05-22 23:39:12,621 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 28 more threads\n",
            "2022-05-22 23:39:12,624 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 27 more threads\n",
            "2022-05-22 23:39:12,626 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 26 more threads\n",
            "2022-05-22 23:39:12,632 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 25 more threads\n",
            "2022-05-22 23:39:12,634 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 24 more threads\n",
            "2022-05-22 23:39:12,637 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 23 more threads\n",
            "2022-05-22 23:39:12,638 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 22 more threads\n",
            "2022-05-22 23:39:12,661 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 21 more threads\n",
            "2022-05-22 23:39:12,664 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 20 more threads\n",
            "2022-05-22 23:39:12,666 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 19 more threads\n",
            "2022-05-22 23:39:12,688 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 18 more threads\n",
            "2022-05-22 23:39:12,692 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 17 more threads\n",
            "2022-05-22 23:39:12,700 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 16 more threads\n",
            "2022-05-22 23:39:12,705 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 15 more threads\n",
            "2022-05-22 23:39:13,280 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 1 - PROGRESS: at 68.38% examples, 75565 words/s, in_qsize 14, out_qsize 1\n",
            "2022-05-22 23:39:13,284 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 14 more threads\n",
            "2022-05-22 23:39:13,387 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 13 more threads\n",
            "2022-05-22 23:39:13,488 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 12 more threads\n",
            "2022-05-22 23:39:13,606 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 11 more threads\n",
            "2022-05-22 23:39:13,608 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 10 more threads\n",
            "2022-05-22 23:39:13,644 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 9 more threads\n",
            "2022-05-22 23:39:13,655 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 8 more threads\n",
            "2022-05-22 23:39:13,683 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 7 more threads\n",
            "2022-05-22 23:39:13,716 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 6 more threads\n",
            "2022-05-22 23:39:13,744 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 5 more threads\n",
            "2022-05-22 23:39:13,748 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 4 more threads\n",
            "2022-05-22 23:39:13,752 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 3 more threads\n",
            "2022-05-22 23:39:13,756 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 2 more threads\n",
            "2022-05-22 23:39:13,761 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 1 more threads\n",
            "2022-05-22 23:39:13,766 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 0 more threads\n",
            "2022-05-22 23:39:13,766 | INFO | base_any2vec.py:1346 | _log_epoch_end | EPOCH - 1 : training on 497185 raw words (447592 effective words) took 4.8s, 93516 effective words/s\n",
            "2022-05-22 23:39:15,321 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 2 - PROGRESS: at 4.71% examples, 11347 words/s, in_qsize 48, out_qsize 0\n",
            "2022-05-22 23:39:16,745 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 2 - PROGRESS: at 10.83% examples, 14966 words/s, in_qsize 45, out_qsize 0\n",
            "2022-05-22 23:39:17,208 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 31 more threads\n",
            "2022-05-22 23:39:17,232 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 30 more threads\n",
            "2022-05-22 23:39:17,238 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 29 more threads\n",
            "2022-05-22 23:39:17,239 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 28 more threads\n",
            "2022-05-22 23:39:17,242 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 27 more threads\n",
            "2022-05-22 23:39:17,262 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 26 more threads\n",
            "2022-05-22 23:39:17,263 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 25 more threads\n",
            "2022-05-22 23:39:17,264 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 24 more threads\n",
            "2022-05-22 23:39:17,269 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 23 more threads\n",
            "2022-05-22 23:39:17,304 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 22 more threads\n",
            "2022-05-22 23:39:17,305 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 21 more threads\n",
            "2022-05-22 23:39:17,306 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 20 more threads\n",
            "2022-05-22 23:39:17,312 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 19 more threads\n",
            "2022-05-22 23:39:17,348 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 18 more threads\n",
            "2022-05-22 23:39:17,349 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 17 more threads\n",
            "2022-05-22 23:39:17,424 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 16 more threads\n",
            "2022-05-22 23:39:17,632 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 15 more threads\n",
            "2022-05-22 23:39:17,988 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 2 - PROGRESS: at 68.38% examples, 77261 words/s, in_qsize 14, out_qsize 1\n",
            "2022-05-22 23:39:17,990 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 14 more threads\n",
            "2022-05-22 23:39:18,264 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 13 more threads\n",
            "2022-05-22 23:39:18,266 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 12 more threads\n",
            "2022-05-22 23:39:18,344 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 11 more threads\n",
            "2022-05-22 23:39:18,349 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 10 more threads\n",
            "2022-05-22 23:39:18,416 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 9 more threads\n",
            "2022-05-22 23:39:18,421 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 8 more threads\n",
            "2022-05-22 23:39:18,446 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 7 more threads\n",
            "2022-05-22 23:39:18,448 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 6 more threads\n",
            "2022-05-22 23:39:18,449 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 5 more threads\n",
            "2022-05-22 23:39:18,456 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 4 more threads\n",
            "2022-05-22 23:39:18,460 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 3 more threads\n",
            "2022-05-22 23:39:18,476 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 2 more threads\n",
            "2022-05-22 23:39:18,478 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 1 more threads\n",
            "2022-05-22 23:39:18,485 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 0 more threads\n",
            "2022-05-22 23:39:18,485 | INFO | base_any2vec.py:1346 | _log_epoch_end | EPOCH - 2 : training on 497185 raw words (447573 effective words) took 4.7s, 95158 effective words/s\n",
            "2022-05-22 23:39:20,407 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 3 - PROGRESS: at 4.71% examples, 9166 words/s, in_qsize 48, out_qsize 0\n",
            "2022-05-22 23:39:21,557 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 3 - PROGRESS: at 17.13% examples, 23373 words/s, in_qsize 37, out_qsize 5\n",
            "2022-05-22 23:39:21,748 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 31 more threads\n",
            "2022-05-22 23:39:21,749 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 30 more threads\n",
            "2022-05-22 23:39:21,751 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 29 more threads\n",
            "2022-05-22 23:39:21,809 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 28 more threads\n",
            "2022-05-22 23:39:21,835 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 27 more threads\n",
            "2022-05-22 23:39:21,860 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 26 more threads\n",
            "2022-05-22 23:39:21,865 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 25 more threads\n",
            "2022-05-22 23:39:21,926 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 24 more threads\n",
            "2022-05-22 23:39:21,930 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 23 more threads\n",
            "2022-05-22 23:39:22,060 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 22 more threads\n",
            "2022-05-22 23:39:22,065 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 21 more threads\n",
            "2022-05-22 23:39:22,094 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 20 more threads\n",
            "2022-05-22 23:39:22,099 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 19 more threads\n",
            "2022-05-22 23:39:22,138 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 18 more threads\n",
            "2022-05-22 23:39:22,167 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 17 more threads\n",
            "2022-05-22 23:39:22,670 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 3 - PROGRESS: at 64.33% examples, 73532 words/s, in_qsize 16, out_qsize 1\n",
            "2022-05-22 23:39:22,677 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 16 more threads\n",
            "2022-05-22 23:39:22,866 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 15 more threads\n",
            "2022-05-22 23:39:22,968 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 14 more threads\n",
            "2022-05-22 23:39:23,012 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 13 more threads\n",
            "2022-05-22 23:39:23,100 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 12 more threads\n",
            "2022-05-22 23:39:23,105 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 11 more threads\n",
            "2022-05-22 23:39:23,138 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 10 more threads\n",
            "2022-05-22 23:39:23,143 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 9 more threads\n",
            "2022-05-22 23:39:23,153 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 8 more threads\n",
            "2022-05-22 23:39:23,158 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 7 more threads\n",
            "2022-05-22 23:39:23,185 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 6 more threads\n",
            "2022-05-22 23:39:23,190 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 5 more threads\n",
            "2022-05-22 23:39:23,200 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 4 more threads\n",
            "2022-05-22 23:39:23,207 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 3 more threads\n",
            "2022-05-22 23:39:23,213 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 2 more threads\n",
            "2022-05-22 23:39:23,224 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 1 more threads\n",
            "2022-05-22 23:39:23,231 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 0 more threads\n",
            "2022-05-22 23:39:23,232 | INFO | base_any2vec.py:1346 | _log_epoch_end | EPOCH - 3 : training on 497185 raw words (447516 effective words) took 4.7s, 94576 effective words/s\n",
            "2022-05-22 23:39:24,565 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 4 - PROGRESS: at 2.08% examples, 6781 words/s, in_qsize 10, out_qsize 0\n",
            "2022-05-22 23:39:25,677 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 4 - PROGRESS: at 11.06% examples, 18357 words/s, in_qsize 44, out_qsize 1\n",
            "2022-05-22 23:39:26,638 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 31 more threads\n",
            "2022-05-22 23:39:26,675 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 30 more threads\n",
            "2022-05-22 23:39:26,680 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 4 - PROGRESS: at 40.60% examples, 55019 words/s, in_qsize 28, out_qsize 3\n",
            "2022-05-22 23:39:26,683 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 29 more threads\n",
            "2022-05-22 23:39:26,687 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 28 more threads\n",
            "2022-05-22 23:39:26,696 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 27 more threads\n",
            "2022-05-22 23:39:26,802 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 26 more threads\n",
            "2022-05-22 23:39:26,853 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 25 more threads\n",
            "2022-05-22 23:39:26,907 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 24 more threads\n",
            "2022-05-22 23:39:26,914 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 23 more threads\n",
            "2022-05-22 23:39:26,943 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 22 more threads\n",
            "2022-05-22 23:39:26,949 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 21 more threads\n",
            "2022-05-22 23:39:27,011 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 20 more threads\n",
            "2022-05-22 23:39:27,030 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 19 more threads\n",
            "2022-05-22 23:39:27,042 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 18 more threads\n",
            "2022-05-22 23:39:27,193 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 17 more threads\n",
            "2022-05-22 23:39:27,446 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 16 more threads\n",
            "2022-05-22 23:39:27,524 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 15 more threads\n",
            "2022-05-22 23:39:27,767 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 4 - PROGRESS: at 68.38% examples, 71877 words/s, in_qsize 14, out_qsize 1\n",
            "2022-05-22 23:39:27,769 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 14 more threads\n",
            "2022-05-22 23:39:27,805 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 13 more threads\n",
            "2022-05-22 23:39:27,816 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 12 more threads\n",
            "2022-05-22 23:39:27,833 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 11 more threads\n",
            "2022-05-22 23:39:27,855 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 10 more threads\n",
            "2022-05-22 23:39:27,871 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 9 more threads\n",
            "2022-05-22 23:39:27,985 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 8 more threads\n",
            "2022-05-22 23:39:27,990 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 7 more threads\n",
            "2022-05-22 23:39:27,996 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 6 more threads\n",
            "2022-05-22 23:39:28,005 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 5 more threads\n",
            "2022-05-22 23:39:28,012 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 4 more threads\n",
            "2022-05-22 23:39:28,024 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 3 more threads\n",
            "2022-05-22 23:39:28,026 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 2 more threads\n",
            "2022-05-22 23:39:28,033 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 1 more threads\n",
            "2022-05-22 23:39:28,040 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 0 more threads\n",
            "2022-05-22 23:39:28,041 | INFO | base_any2vec.py:1346 | _log_epoch_end | EPOCH - 4 : training on 497185 raw words (447460 effective words) took 4.8s, 93375 effective words/s\n",
            "2022-05-22 23:39:29,413 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 5 - PROGRESS: at 2.08% examples, 6557 words/s, in_qsize 8, out_qsize 0\n",
            "2022-05-22 23:39:30,649 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 5 - PROGRESS: at 9.05% examples, 13724 words/s, in_qsize 46, out_qsize 0\n",
            "2022-05-22 23:39:31,446 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 31 more threads\n",
            "2022-05-22 23:39:31,450 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 30 more threads\n",
            "2022-05-22 23:39:31,470 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 29 more threads\n",
            "2022-05-22 23:39:31,483 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 28 more threads\n",
            "2022-05-22 23:39:31,503 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 27 more threads\n",
            "2022-05-22 23:39:31,504 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 26 more threads\n",
            "2022-05-22 23:39:31,521 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 25 more threads\n",
            "2022-05-22 23:39:31,618 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 24 more threads\n",
            "2022-05-22 23:39:31,622 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 23 more threads\n",
            "2022-05-22 23:39:31,625 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 22 more threads\n",
            "2022-05-22 23:39:31,635 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 21 more threads\n",
            "2022-05-22 23:39:31,660 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 5 - PROGRESS: at 56.59% examples, 74872 words/s, in_qsize 19, out_qsize 3\n",
            "2022-05-22 23:39:31,661 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 20 more threads\n",
            "2022-05-22 23:39:31,669 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 19 more threads\n",
            "2022-05-22 23:39:31,698 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 18 more threads\n",
            "2022-05-22 23:39:32,000 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 17 more threads\n",
            "2022-05-22 23:39:32,323 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 16 more threads\n",
            "2022-05-22 23:39:32,385 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 15 more threads\n",
            "2022-05-22 23:39:32,599 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 14 more threads\n",
            "2022-05-22 23:39:32,646 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 13 more threads\n",
            "2022-05-22 23:39:32,670 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 5 - PROGRESS: at 73.08% examples, 73796 words/s, in_qsize 12, out_qsize 1\n",
            "2022-05-22 23:39:32,674 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 12 more threads\n",
            "2022-05-22 23:39:32,690 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 11 more threads\n",
            "2022-05-22 23:39:32,702 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 10 more threads\n",
            "2022-05-22 23:39:32,726 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 9 more threads\n",
            "2022-05-22 23:39:32,733 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 8 more threads\n",
            "2022-05-22 23:39:32,741 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 7 more threads\n",
            "2022-05-22 23:39:32,745 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 6 more threads\n",
            "2022-05-22 23:39:32,760 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 5 more threads\n",
            "2022-05-22 23:39:32,776 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 4 more threads\n",
            "2022-05-22 23:39:32,784 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 3 more threads\n",
            "2022-05-22 23:39:32,790 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 2 more threads\n",
            "2022-05-22 23:39:32,792 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 1 more threads\n",
            "2022-05-22 23:39:32,794 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 0 more threads\n",
            "2022-05-22 23:39:32,795 | INFO | base_any2vec.py:1346 | _log_epoch_end | EPOCH - 5 : training on 497185 raw words (447653 effective words) took 4.7s, 94442 effective words/s\n",
            "2022-05-22 23:39:32,796 | INFO | base_any2vec.py:1382 | _log_train_end | training on a 2485925 raw words (2237794 effective words) took 23.8s, 93904 effective words/s\n",
            "2022-05-22 23:39:32,798 | WARNING | base_any2vec.py:1386 | _log_train_end | under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
            "2022-05-22 23:39:35,591 | INFO | word2vec.py:1567 | scan_vocab | collecting all words and their counts\n",
            "2022-05-22 23:39:35,592 | INFO | word2vec.py:1552 | _scan_vocab | PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
            "2022-05-22 23:39:35,611 | INFO | word2vec.py:1552 | _scan_vocab | PROGRESS: at sentence #10000, processed 50969 words, keeping 10996 word types\n",
            "2022-05-22 23:39:35,628 | INFO | word2vec.py:1552 | _scan_vocab | PROGRESS: at sentence #20000, processed 113744 words, keeping 21000 word types\n",
            "2022-05-22 23:39:35,645 | INFO | word2vec.py:1552 | _scan_vocab | PROGRESS: at sentence #30000, processed 171307 words, keeping 28787 word types\n",
            "2022-05-22 23:39:35,661 | INFO | word2vec.py:1552 | _scan_vocab | PROGRESS: at sentence #40000, processed 238519 words, keeping 35303 word types\n",
            "2022-05-22 23:39:35,679 | INFO | word2vec.py:1552 | _scan_vocab | PROGRESS: at sentence #50000, processed 303169 words, keeping 41748 word types\n",
            "2022-05-22 23:39:35,698 | INFO | word2vec.py:1552 | _scan_vocab | PROGRESS: at sentence #60000, processed 356785 words, keeping 47292 word types\n",
            "2022-05-22 23:39:35,714 | INFO | word2vec.py:1552 | _scan_vocab | PROGRESS: at sentence #70000, processed 409232 words, keeping 52041 word types\n",
            "2022-05-22 23:39:35,730 | INFO | word2vec.py:1552 | _scan_vocab | PROGRESS: at sentence #80000, processed 460207 words, keeping 57823 word types\n",
            "2022-05-22 23:39:35,741 | INFO | word2vec.py:1575 | scan_vocab | collected 62269 word types from a corpus of 497185 raw words and 88514 sentences\n",
            "2022-05-22 23:39:35,744 | INFO | word2vec.py:1659 | prepare_vocab | Updating model with new vocabulary\n",
            "2022-05-22 23:39:35,781 | INFO | word2vec.py:1685 | prepare_vocab | New added 25970 unique words (29% of original 88239) and increased the count of 25970 pre-existing words (29% of original 88239)\n",
            "2022-05-22 23:39:35,907 | INFO | word2vec.py:1715 | prepare_vocab | deleting the raw counts dictionary of 62269 items\n",
            "2022-05-22 23:39:35,910 | INFO | word2vec.py:1718 | prepare_vocab | sample=0.001 downsamples 34 most-common words\n",
            "2022-05-22 23:39:35,913 | INFO | word2vec.py:1721 | prepare_vocab | downsampling leaves estimated 895130 word corpus (194.2% of prior 460886)\n",
            "2022-05-22 23:39:36,532 | INFO | fasttext.py:551 | estimate_memory | estimated required memory for 25970 words, 203322 buckets and 50 dimensions: 77024440 bytes\n",
            "2022-05-22 23:39:36,539 | INFO | word2vec.py:1850 | update_weights | updating layer weights\n",
            "2022-05-22 23:39:37,433 | INFO | fasttext.py:1030 | init_ngrams_weights | Number of new ngrams is 0\n",
            "2022-05-22 23:39:37,462 | WARNING | base_any2vec.py:1182 | _check_training_sanity | Effective 'alpha' higher than previous training cycles\n",
            "2022-05-22 23:39:37,463 | INFO | base_any2vec.py:1210 | _check_training_sanity | training model with 32 workers on 25970 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=10 window=2\n",
            "2022-05-22 23:39:39,787 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 1 - PROGRESS: at 4.12% examples, 7735 words/s, in_qsize 48, out_qsize 0\n",
            "2022-05-22 23:39:40,761 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 31 more threads\n",
            "2022-05-22 23:39:40,789 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 1 - PROGRESS: at 37.11% examples, 54383 words/s, in_qsize 17, out_qsize 27\n",
            "2022-05-22 23:39:40,792 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 30 more threads\n",
            "2022-05-22 23:39:40,804 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 29 more threads\n",
            "2022-05-22 23:39:40,805 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 28 more threads\n",
            "2022-05-22 23:39:40,811 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 27 more threads\n",
            "2022-05-22 23:39:40,820 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 26 more threads\n",
            "2022-05-22 23:39:40,830 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 25 more threads\n",
            "2022-05-22 23:39:40,845 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 24 more threads\n",
            "2022-05-22 23:39:40,856 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 23 more threads\n",
            "2022-05-22 23:39:40,858 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 22 more threads\n",
            "2022-05-22 23:39:40,874 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 21 more threads\n",
            "2022-05-22 23:39:40,887 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 20 more threads\n",
            "2022-05-22 23:39:40,894 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 19 more threads\n",
            "2022-05-22 23:39:40,895 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 18 more threads\n",
            "2022-05-22 23:39:40,916 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 17 more threads\n",
            "2022-05-22 23:39:41,624 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 16 more threads\n",
            "2022-05-22 23:39:41,633 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 15 more threads\n",
            "2022-05-22 23:39:41,806 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 1 - PROGRESS: at 68.39% examples, 75017 words/s, in_qsize 14, out_qsize 1\n",
            "2022-05-22 23:39:41,810 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 14 more threads\n",
            "2022-05-22 23:39:41,848 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 13 more threads\n",
            "2022-05-22 23:39:41,855 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 12 more threads\n",
            "2022-05-22 23:39:41,934 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 11 more threads\n",
            "2022-05-22 23:39:41,952 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 10 more threads\n",
            "2022-05-22 23:39:42,022 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 9 more threads\n",
            "2022-05-22 23:39:42,050 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 8 more threads\n",
            "2022-05-22 23:39:42,058 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 7 more threads\n",
            "2022-05-22 23:39:42,060 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 6 more threads\n",
            "2022-05-22 23:39:42,078 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 5 more threads\n",
            "2022-05-22 23:39:42,081 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 4 more threads\n",
            "2022-05-22 23:39:42,089 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 3 more threads\n",
            "2022-05-22 23:39:42,097 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 2 more threads\n",
            "2022-05-22 23:39:42,100 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 1 more threads\n",
            "2022-05-22 23:39:42,102 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 0 more threads\n",
            "2022-05-22 23:39:42,105 | INFO | base_any2vec.py:1346 | _log_epoch_end | EPOCH - 1 : training on 497185 raw words (447574 effective words) took 4.6s, 96758 effective words/s\n",
            "2022-05-22 23:39:44,306 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 2 - PROGRESS: at 4.30% examples, 8075 words/s, in_qsize 48, out_qsize 0\n",
            "2022-05-22 23:39:45,458 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 2 - PROGRESS: at 11.65% examples, 15889 words/s, in_qsize 36, out_qsize 8\n",
            "2022-05-22 23:39:45,510 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 31 more threads\n",
            "2022-05-22 23:39:45,526 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 30 more threads\n",
            "2022-05-22 23:39:45,540 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 29 more threads\n",
            "2022-05-22 23:39:45,546 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 28 more threads\n",
            "2022-05-22 23:39:45,555 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 27 more threads\n",
            "2022-05-22 23:39:45,557 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 26 more threads\n",
            "2022-05-22 23:39:45,571 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 25 more threads\n",
            "2022-05-22 23:39:45,575 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 24 more threads\n",
            "2022-05-22 23:39:45,580 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 23 more threads\n",
            "2022-05-22 23:39:45,603 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 22 more threads\n",
            "2022-05-22 23:39:45,604 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 21 more threads\n",
            "2022-05-22 23:39:45,609 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 20 more threads\n",
            "2022-05-22 23:39:45,619 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 19 more threads\n",
            "2022-05-22 23:39:45,620 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 18 more threads\n",
            "2022-05-22 23:39:45,628 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 17 more threads\n",
            "2022-05-22 23:39:46,202 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 16 more threads\n",
            "2022-05-22 23:39:46,242 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 15 more threads\n",
            "2022-05-22 23:39:46,484 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 2 - PROGRESS: at 68.39% examples, 74420 words/s, in_qsize 14, out_qsize 1\n",
            "2022-05-22 23:39:46,486 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 14 more threads\n",
            "2022-05-22 23:39:46,512 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 13 more threads\n",
            "2022-05-22 23:39:46,623 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 12 more threads\n",
            "2022-05-22 23:39:46,750 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 11 more threads\n",
            "2022-05-22 23:39:46,782 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 10 more threads\n",
            "2022-05-22 23:39:46,830 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 9 more threads\n",
            "2022-05-22 23:39:46,848 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 8 more threads\n",
            "2022-05-22 23:39:46,854 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 7 more threads\n",
            "2022-05-22 23:39:46,864 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 6 more threads\n",
            "2022-05-22 23:39:46,870 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 5 more threads\n",
            "2022-05-22 23:39:46,876 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 4 more threads\n",
            "2022-05-22 23:39:46,882 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 3 more threads\n",
            "2022-05-22 23:39:46,886 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 2 more threads\n",
            "2022-05-22 23:39:46,894 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 1 more threads\n",
            "2022-05-22 23:39:46,903 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 0 more threads\n",
            "2022-05-22 23:39:46,904 | INFO | base_any2vec.py:1346 | _log_epoch_end | EPOCH - 2 : training on 497185 raw words (447628 effective words) took 4.8s, 93582 effective words/s\n",
            "2022-05-22 23:39:48,488 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 3 - PROGRESS: at 6.29% examples, 16949 words/s, in_qsize 47, out_qsize 0\n",
            "2022-05-22 23:39:49,747 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 3 - PROGRESS: at 9.89% examples, 15662 words/s, in_qsize 45, out_qsize 0\n",
            "2022-05-22 23:39:50,214 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 31 more threads\n",
            "2022-05-22 23:39:50,232 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 30 more threads\n",
            "2022-05-22 23:39:50,307 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 29 more threads\n",
            "2022-05-22 23:39:50,357 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 28 more threads\n",
            "2022-05-22 23:39:50,361 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 27 more threads\n",
            "2022-05-22 23:39:50,373 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 26 more threads\n",
            "2022-05-22 23:39:50,378 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 25 more threads\n",
            "2022-05-22 23:39:50,390 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 24 more threads\n",
            "2022-05-22 23:39:50,394 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 23 more threads\n",
            "2022-05-22 23:39:50,398 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 22 more threads\n",
            "2022-05-22 23:39:50,412 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 21 more threads\n",
            "2022-05-22 23:39:50,420 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 20 more threads\n",
            "2022-05-22 23:39:50,426 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 19 more threads\n",
            "2022-05-22 23:39:50,444 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 18 more threads\n",
            "2022-05-22 23:39:50,452 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 17 more threads\n",
            "2022-05-22 23:39:50,470 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 16 more threads\n",
            "2022-05-22 23:39:50,810 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 3 - PROGRESS: at 66.08% examples, 81153 words/s, in_qsize 15, out_qsize 1\n",
            "2022-05-22 23:39:50,812 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 15 more threads\n",
            "2022-05-22 23:39:51,254 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 14 more threads\n",
            "2022-05-22 23:39:51,258 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 13 more threads\n",
            "2022-05-22 23:39:51,421 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 12 more threads\n",
            "2022-05-22 23:39:51,479 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 11 more threads\n",
            "2022-05-22 23:39:51,481 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 10 more threads\n",
            "2022-05-22 23:39:51,510 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 9 more threads\n",
            "2022-05-22 23:39:51,514 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 8 more threads\n",
            "2022-05-22 23:39:51,551 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 7 more threads\n",
            "2022-05-22 23:39:51,552 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 6 more threads\n",
            "2022-05-22 23:39:51,584 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 5 more threads\n",
            "2022-05-22 23:39:51,589 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 4 more threads\n",
            "2022-05-22 23:39:51,596 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 3 more threads\n",
            "2022-05-22 23:39:51,597 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 2 more threads\n",
            "2022-05-22 23:39:51,599 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 1 more threads\n",
            "2022-05-22 23:39:51,607 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 0 more threads\n",
            "2022-05-22 23:39:51,608 | INFO | base_any2vec.py:1346 | _log_epoch_end | EPOCH - 3 : training on 497185 raw words (447517 effective words) took 4.7s, 95440 effective words/s\n",
            "2022-05-22 23:39:53,927 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 4 - PROGRESS: at 6.68% examples, 11543 words/s, in_qsize 46, out_qsize 1\n",
            "2022-05-22 23:39:55,023 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 4 - PROGRESS: at 15.04% examples, 18319 words/s, in_qsize 32, out_qsize 11\n",
            "2022-05-22 23:39:55,058 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 31 more threads\n",
            "2022-05-22 23:39:55,060 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 30 more threads\n",
            "2022-05-22 23:39:55,065 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 29 more threads\n",
            "2022-05-22 23:39:55,105 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 28 more threads\n",
            "2022-05-22 23:39:55,110 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 27 more threads\n",
            "2022-05-22 23:39:55,113 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 26 more threads\n",
            "2022-05-22 23:39:55,118 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 25 more threads\n",
            "2022-05-22 23:39:55,120 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 24 more threads\n",
            "2022-05-22 23:39:55,135 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 23 more threads\n",
            "2022-05-22 23:39:55,153 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 22 more threads\n",
            "2022-05-22 23:39:55,155 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 21 more threads\n",
            "2022-05-22 23:39:55,183 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 20 more threads\n",
            "2022-05-22 23:39:55,186 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 19 more threads\n",
            "2022-05-22 23:39:55,189 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 18 more threads\n",
            "2022-05-22 23:39:55,200 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 17 more threads\n",
            "2022-05-22 23:39:55,203 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 16 more threads\n",
            "2022-05-22 23:39:55,567 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 15 more threads\n",
            "2022-05-22 23:39:55,662 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 14 more threads\n",
            "2022-05-22 23:39:55,856 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 13 more threads\n",
            "2022-05-22 23:39:55,894 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 12 more threads\n",
            "2022-05-22 23:39:56,089 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 4 - PROGRESS: at 73.89% examples, 78334 words/s, in_qsize 11, out_qsize 0\n",
            "2022-05-22 23:39:56,093 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 11 more threads\n",
            "2022-05-22 23:39:56,216 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 10 more threads\n",
            "2022-05-22 23:39:56,276 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 9 more threads\n",
            "2022-05-22 23:39:56,280 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 8 more threads\n",
            "2022-05-22 23:39:56,285 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 7 more threads\n",
            "2022-05-22 23:39:56,286 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 6 more threads\n",
            "2022-05-22 23:39:56,297 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 5 more threads\n",
            "2022-05-22 23:39:56,304 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 4 more threads\n",
            "2022-05-22 23:39:56,308 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 3 more threads\n",
            "2022-05-22 23:39:56,318 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 2 more threads\n",
            "2022-05-22 23:39:56,321 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 1 more threads\n",
            "2022-05-22 23:39:56,325 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 0 more threads\n",
            "2022-05-22 23:39:56,327 | INFO | base_any2vec.py:1346 | _log_epoch_end | EPOCH - 4 : training on 497185 raw words (447590 effective words) took 4.7s, 95171 effective words/s\n",
            "2022-05-22 23:39:57,590 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 5 - PROGRESS: at 4.71% examples, 13984 words/s, in_qsize 9, out_qsize 0\n",
            "2022-05-22 23:39:59,287 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 5 - PROGRESS: at 8.85% examples, 11931 words/s, in_qsize 43, out_qsize 3\n",
            "2022-05-22 23:39:59,676 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 31 more threads\n",
            "2022-05-22 23:39:59,695 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 30 more threads\n",
            "2022-05-22 23:39:59,717 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 29 more threads\n",
            "2022-05-22 23:39:59,750 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 28 more threads\n",
            "2022-05-22 23:39:59,755 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 27 more threads\n",
            "2022-05-22 23:39:59,783 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 26 more threads\n",
            "2022-05-22 23:39:59,788 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 25 more threads\n",
            "2022-05-22 23:39:59,797 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 24 more threads\n",
            "2022-05-22 23:39:59,804 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 23 more threads\n",
            "2022-05-22 23:39:59,826 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 22 more threads\n",
            "2022-05-22 23:39:59,832 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 21 more threads\n",
            "2022-05-22 23:39:59,839 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 20 more threads\n",
            "2022-05-22 23:39:59,866 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 19 more threads\n",
            "2022-05-22 23:39:59,871 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 18 more threads\n",
            "2022-05-22 23:39:59,879 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 17 more threads\n",
            "2022-05-22 23:39:59,894 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 16 more threads\n",
            "2022-05-22 23:40:00,342 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 5 - PROGRESS: at 66.08% examples, 78897 words/s, in_qsize 15, out_qsize 1\n",
            "2022-05-22 23:40:00,348 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 15 more threads\n",
            "2022-05-22 23:40:00,818 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 14 more threads\n",
            "2022-05-22 23:40:00,840 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 13 more threads\n",
            "2022-05-22 23:40:00,890 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 12 more threads\n",
            "2022-05-22 23:40:00,952 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 11 more threads\n",
            "2022-05-22 23:40:00,972 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 10 more threads\n",
            "2022-05-22 23:40:00,984 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 9 more threads\n",
            "2022-05-22 23:40:01,022 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 8 more threads\n",
            "2022-05-22 23:40:01,025 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 7 more threads\n",
            "2022-05-22 23:40:01,042 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 6 more threads\n",
            "2022-05-22 23:40:01,072 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 5 more threads\n",
            "2022-05-22 23:40:01,078 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 4 more threads\n",
            "2022-05-22 23:40:01,099 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 3 more threads\n",
            "2022-05-22 23:40:01,101 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 2 more threads\n",
            "2022-05-22 23:40:01,115 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 1 more threads\n",
            "2022-05-22 23:40:01,126 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 0 more threads\n",
            "2022-05-22 23:40:01,127 | INFO | base_any2vec.py:1346 | _log_epoch_end | EPOCH - 5 : training on 497185 raw words (447401 effective words) took 4.8s, 93467 effective words/s\n",
            "2022-05-22 23:40:02,745 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 6 - PROGRESS: at 2.08% examples, 5569 words/s, in_qsize 15, out_qsize 0\n",
            "2022-05-22 23:40:03,891 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 6 - PROGRESS: at 11.40% examples, 16033 words/s, in_qsize 44, out_qsize 1\n",
            "2022-05-22 23:40:04,348 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 31 more threads\n",
            "2022-05-22 23:40:04,386 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 30 more threads\n",
            "2022-05-22 23:40:04,391 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 29 more threads\n",
            "2022-05-22 23:40:04,398 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 28 more threads\n",
            "2022-05-22 23:40:04,452 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 27 more threads\n",
            "2022-05-22 23:40:04,456 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 26 more threads\n",
            "2022-05-22 23:40:04,543 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 25 more threads\n",
            "2022-05-22 23:40:04,573 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 24 more threads\n",
            "2022-05-22 23:40:04,690 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 23 more threads\n",
            "2022-05-22 23:40:04,794 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 22 more threads\n",
            "2022-05-22 23:40:04,803 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 21 more threads\n",
            "2022-05-22 23:40:04,807 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 20 more threads\n",
            "2022-05-22 23:40:04,858 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 19 more threads\n",
            "2022-05-22 23:40:04,875 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 18 more threads\n",
            "2022-05-22 23:40:05,261 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 6 - PROGRESS: at 62.61% examples, 72278 words/s, in_qsize 17, out_qsize 1\n",
            "2022-05-22 23:40:05,263 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 17 more threads\n",
            "2022-05-22 23:40:05,578 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 16 more threads\n",
            "2022-05-22 23:40:05,617 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 15 more threads\n",
            "2022-05-22 23:40:05,657 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 14 more threads\n",
            "2022-05-22 23:40:05,773 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 13 more threads\n",
            "2022-05-22 23:40:05,781 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 12 more threads\n",
            "2022-05-22 23:40:05,826 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 11 more threads\n",
            "2022-05-22 23:40:05,844 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 10 more threads\n",
            "2022-05-22 23:40:05,872 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 9 more threads\n",
            "2022-05-22 23:40:05,884 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 8 more threads\n",
            "2022-05-22 23:40:05,885 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 7 more threads\n",
            "2022-05-22 23:40:05,895 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 6 more threads\n",
            "2022-05-22 23:40:05,896 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 5 more threads\n",
            "2022-05-22 23:40:05,916 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 4 more threads\n",
            "2022-05-22 23:40:05,918 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 3 more threads\n",
            "2022-05-22 23:40:05,920 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 2 more threads\n",
            "2022-05-22 23:40:05,922 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 1 more threads\n",
            "2022-05-22 23:40:05,925 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 0 more threads\n",
            "2022-05-22 23:40:05,928 | INFO | base_any2vec.py:1346 | _log_epoch_end | EPOCH - 6 : training on 497185 raw words (447651 effective words) took 4.8s, 93586 effective words/s\n",
            "2022-05-22 23:40:08,149 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 7 - PROGRESS: at 4.71% examples, 7936 words/s, in_qsize 47, out_qsize 1\n",
            "2022-05-22 23:40:09,149 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 7 - PROGRESS: at 21.51% examples, 30896 words/s, in_qsize 38, out_qsize 1\n",
            "2022-05-22 23:40:09,395 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 31 more threads\n",
            "2022-05-22 23:40:09,405 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 30 more threads\n",
            "2022-05-22 23:40:09,422 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 29 more threads\n",
            "2022-05-22 23:40:09,423 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 28 more threads\n",
            "2022-05-22 23:40:09,429 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 27 more threads\n",
            "2022-05-22 23:40:09,432 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 26 more threads\n",
            "2022-05-22 23:40:09,455 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 25 more threads\n",
            "2022-05-22 23:40:09,465 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 24 more threads\n",
            "2022-05-22 23:40:09,471 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 23 more threads\n",
            "2022-05-22 23:40:09,521 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 22 more threads\n",
            "2022-05-22 23:40:09,537 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 21 more threads\n",
            "2022-05-22 23:40:09,574 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 20 more threads\n",
            "2022-05-22 23:40:09,577 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 19 more threads\n",
            "2022-05-22 23:40:09,651 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 18 more threads\n",
            "2022-05-22 23:40:09,686 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 17 more threads\n",
            "2022-05-22 23:40:10,247 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 7 - PROGRESS: at 64.33% examples, 71278 words/s, in_qsize 16, out_qsize 1\n",
            "2022-05-22 23:40:10,252 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 16 more threads\n",
            "2022-05-22 23:40:10,353 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 15 more threads\n",
            "2022-05-22 23:40:10,544 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 14 more threads\n",
            "2022-05-22 23:40:10,597 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 13 more threads\n",
            "2022-05-22 23:40:10,618 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 12 more threads\n",
            "2022-05-22 23:40:10,623 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 11 more threads\n",
            "2022-05-22 23:40:10,693 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 10 more threads\n",
            "2022-05-22 23:40:10,704 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 9 more threads\n",
            "2022-05-22 23:40:10,706 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 8 more threads\n",
            "2022-05-22 23:40:10,728 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 7 more threads\n",
            "2022-05-22 23:40:10,738 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 6 more threads\n",
            "2022-05-22 23:40:10,744 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 5 more threads\n",
            "2022-05-22 23:40:10,745 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 4 more threads\n",
            "2022-05-22 23:40:10,783 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 3 more threads\n",
            "2022-05-22 23:40:10,788 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 2 more threads\n",
            "2022-05-22 23:40:10,793 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 1 more threads\n",
            "2022-05-22 23:40:10,801 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 0 more threads\n",
            "2022-05-22 23:40:10,802 | INFO | base_any2vec.py:1346 | _log_epoch_end | EPOCH - 7 : training on 497185 raw words (447477 effective words) took 4.9s, 92148 effective words/s\n",
            "2022-05-22 23:40:11,818 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 8 - PROGRESS: at 2.08% examples, 8899 words/s, in_qsize 7, out_qsize 0\n",
            "2022-05-22 23:40:13,051 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 8 - PROGRESS: at 3.65% examples, 8063 words/s, in_qsize 48, out_qsize 0\n",
            "2022-05-22 23:40:14,161 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 8 - PROGRESS: at 24.37% examples, 32179 words/s, in_qsize 26, out_qsize 18\n",
            "2022-05-22 23:40:14,182 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 31 more threads\n",
            "2022-05-22 23:40:14,184 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 30 more threads\n",
            "2022-05-22 23:40:14,191 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 29 more threads\n",
            "2022-05-22 23:40:14,194 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 28 more threads\n",
            "2022-05-22 23:40:14,195 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 27 more threads\n",
            "2022-05-22 23:40:14,198 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 26 more threads\n",
            "2022-05-22 23:40:14,212 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 25 more threads\n",
            "2022-05-22 23:40:14,229 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 24 more threads\n",
            "2022-05-22 23:40:14,235 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 23 more threads\n",
            "2022-05-22 23:40:14,253 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 22 more threads\n",
            "2022-05-22 23:40:14,269 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 21 more threads\n",
            "2022-05-22 23:40:14,277 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 20 more threads\n",
            "2022-05-22 23:40:14,285 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 19 more threads\n",
            "2022-05-22 23:40:14,291 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 18 more threads\n",
            "2022-05-22 23:40:14,410 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 17 more threads\n",
            "2022-05-22 23:40:14,985 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 16 more threads\n",
            "2022-05-22 23:40:14,992 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 15 more threads\n",
            "2022-05-22 23:40:15,135 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 14 more threads\n",
            "2022-05-22 23:40:15,167 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 8 - PROGRESS: at 70.69% examples, 76735 words/s, in_qsize 13, out_qsize 1\n",
            "2022-05-22 23:40:15,171 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 13 more threads\n",
            "2022-05-22 23:40:15,236 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 12 more threads\n",
            "2022-05-22 23:40:15,304 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 11 more threads\n",
            "2022-05-22 23:40:15,320 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 10 more threads\n",
            "2022-05-22 23:40:15,391 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 9 more threads\n",
            "2022-05-22 23:40:15,442 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 8 more threads\n",
            "2022-05-22 23:40:15,444 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 7 more threads\n",
            "2022-05-22 23:40:15,448 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 6 more threads\n",
            "2022-05-22 23:40:15,451 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 5 more threads\n",
            "2022-05-22 23:40:15,452 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 4 more threads\n",
            "2022-05-22 23:40:15,468 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 3 more threads\n",
            "2022-05-22 23:40:15,480 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 2 more threads\n",
            "2022-05-22 23:40:15,481 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 1 more threads\n",
            "2022-05-22 23:40:15,491 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 0 more threads\n",
            "2022-05-22 23:40:15,492 | INFO | base_any2vec.py:1346 | _log_epoch_end | EPOCH - 8 : training on 497185 raw words (447513 effective words) took 4.7s, 95732 effective words/s\n",
            "2022-05-22 23:40:16,541 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 9 - PROGRESS: at 4.71% examples, 16912 words/s, in_qsize 48, out_qsize 0\n",
            "2022-05-22 23:40:17,655 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 9 - PROGRESS: at 6.29% examples, 12382 words/s, in_qsize 47, out_qsize 0\n",
            "2022-05-22 23:40:18,928 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 9 - PROGRESS: at 24.84% examples, 34218 words/s, in_qsize 26, out_qsize 17\n",
            "2022-05-22 23:40:18,947 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 31 more threads\n",
            "2022-05-22 23:40:18,951 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 30 more threads\n",
            "2022-05-22 23:40:18,953 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 29 more threads\n",
            "2022-05-22 23:40:18,957 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 28 more threads\n",
            "2022-05-22 23:40:18,960 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 27 more threads\n",
            "2022-05-22 23:40:18,968 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 26 more threads\n",
            "2022-05-22 23:40:18,982 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 25 more threads\n",
            "2022-05-22 23:40:18,989 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 24 more threads\n",
            "2022-05-22 23:40:18,999 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 23 more threads\n",
            "2022-05-22 23:40:19,004 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 22 more threads\n",
            "2022-05-22 23:40:19,014 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 21 more threads\n",
            "2022-05-22 23:40:19,027 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 20 more threads\n",
            "2022-05-22 23:40:19,032 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 19 more threads\n",
            "2022-05-22 23:40:19,036 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 18 more threads\n",
            "2022-05-22 23:40:19,052 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 17 more threads\n",
            "2022-05-22 23:40:19,072 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 16 more threads\n",
            "2022-05-22 23:40:19,692 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 15 more threads\n",
            "2022-05-22 23:40:19,798 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 14 more threads\n",
            "2022-05-22 23:40:19,944 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 9 - PROGRESS: at 70.21% examples, 74769 words/s, in_qsize 13, out_qsize 1\n",
            "2022-05-22 23:40:19,945 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 13 more threads\n",
            "2022-05-22 23:40:20,010 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 12 more threads\n",
            "2022-05-22 23:40:20,034 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 11 more threads\n",
            "2022-05-22 23:40:20,051 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 10 more threads\n",
            "2022-05-22 23:40:20,053 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 9 more threads\n",
            "2022-05-22 23:40:20,075 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 8 more threads\n",
            "2022-05-22 23:40:20,122 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 7 more threads\n",
            "2022-05-22 23:40:20,168 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 6 more threads\n",
            "2022-05-22 23:40:20,176 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 5 more threads\n",
            "2022-05-22 23:40:20,182 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 4 more threads\n",
            "2022-05-22 23:40:20,187 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 3 more threads\n",
            "2022-05-22 23:40:20,192 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 2 more threads\n",
            "2022-05-22 23:40:20,194 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 1 more threads\n",
            "2022-05-22 23:40:20,207 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 0 more threads\n",
            "2022-05-22 23:40:20,208 | INFO | base_any2vec.py:1346 | _log_epoch_end | EPOCH - 9 : training on 497185 raw words (447584 effective words) took 4.7s, 95230 effective words/s\n",
            "2022-05-22 23:40:22,374 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 10 - PROGRESS: at 3.78% examples, 8430 words/s, in_qsize 48, out_qsize 0\n",
            "2022-05-22 23:40:23,315 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 31 more threads\n",
            "2022-05-22 23:40:23,370 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 30 more threads\n",
            "2022-05-22 23:40:23,414 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 10 - PROGRESS: at 40.87% examples, 59010 words/s, in_qsize 24, out_qsize 11\n",
            "2022-05-22 23:40:23,465 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 29 more threads\n",
            "2022-05-22 23:40:23,476 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 28 more threads\n",
            "2022-05-22 23:40:23,484 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 27 more threads\n",
            "2022-05-22 23:40:23,487 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 26 more threads\n",
            "2022-05-22 23:40:23,490 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 25 more threads\n",
            "2022-05-22 23:40:23,509 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 24 more threads\n",
            "2022-05-22 23:40:23,530 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 23 more threads\n",
            "2022-05-22 23:40:23,533 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 22 more threads\n",
            "2022-05-22 23:40:23,555 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 21 more threads\n",
            "2022-05-22 23:40:23,557 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 20 more threads\n",
            "2022-05-22 23:40:23,571 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 19 more threads\n",
            "2022-05-22 23:40:23,586 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 18 more threads\n",
            "2022-05-22 23:40:23,592 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 17 more threads\n",
            "2022-05-22 23:40:24,340 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 16 more threads\n",
            "2022-05-22 23:40:24,394 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 15 more threads\n",
            "2022-05-22 23:40:24,539 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 10 - PROGRESS: at 68.38% examples, 75316 words/s, in_qsize 14, out_qsize 1\n",
            "2022-05-22 23:40:24,541 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 14 more threads\n",
            "2022-05-22 23:40:24,552 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 13 more threads\n",
            "2022-05-22 23:40:24,611 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 12 more threads\n",
            "2022-05-22 23:40:24,701 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 11 more threads\n",
            "2022-05-22 23:40:24,704 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 10 more threads\n",
            "2022-05-22 23:40:24,717 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 9 more threads\n",
            "2022-05-22 23:40:24,731 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 8 more threads\n",
            "2022-05-22 23:40:24,732 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 7 more threads\n",
            "2022-05-22 23:40:24,761 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 6 more threads\n",
            "2022-05-22 23:40:24,776 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 5 more threads\n",
            "2022-05-22 23:40:24,784 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 4 more threads\n",
            "2022-05-22 23:40:24,796 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 3 more threads\n",
            "2022-05-22 23:40:24,806 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 2 more threads\n",
            "2022-05-22 23:40:24,812 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 1 more threads\n",
            "2022-05-22 23:40:24,820 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 0 more threads\n",
            "2022-05-22 23:40:24,821 | INFO | base_any2vec.py:1346 | _log_epoch_end | EPOCH - 10 : training on 497185 raw words (447558 effective words) took 4.6s, 97375 effective words/s\n",
            "2022-05-22 23:40:26,649 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 11 - PROGRESS: at 4.30% examples, 9710 words/s, in_qsize 48, out_qsize 0\n",
            "2022-05-22 23:40:28,055 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 11 - PROGRESS: at 7.92% examples, 11084 words/s, in_qsize 25, out_qsize 28\n",
            "2022-05-22 23:40:28,093 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 31 more threads\n",
            "2022-05-22 23:40:28,137 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 30 more threads\n",
            "2022-05-22 23:40:28,138 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 29 more threads\n",
            "2022-05-22 23:40:28,143 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 28 more threads\n",
            "2022-05-22 23:40:28,165 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 27 more threads\n",
            "2022-05-22 23:40:28,169 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 26 more threads\n",
            "2022-05-22 23:40:28,173 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 25 more threads\n",
            "2022-05-22 23:40:28,176 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 24 more threads\n",
            "2022-05-22 23:40:28,178 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 23 more threads\n",
            "2022-05-22 23:40:28,183 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 22 more threads\n",
            "2022-05-22 23:40:28,195 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 21 more threads\n",
            "2022-05-22 23:40:28,207 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 20 more threads\n",
            "2022-05-22 23:40:28,213 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 19 more threads\n",
            "2022-05-22 23:40:28,216 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 18 more threads\n",
            "2022-05-22 23:40:28,218 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 17 more threads\n",
            "2022-05-22 23:40:28,697 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 16 more threads\n",
            "2022-05-22 23:40:29,177 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 11 - PROGRESS: at 67.02% examples, 72742 words/s, in_qsize 15, out_qsize 1\n",
            "2022-05-22 23:40:29,182 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 15 more threads\n",
            "2022-05-22 23:40:29,226 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 14 more threads\n",
            "2022-05-22 23:40:29,291 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 13 more threads\n",
            "2022-05-22 23:40:29,417 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 12 more threads\n",
            "2022-05-22 23:40:29,438 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 11 more threads\n",
            "2022-05-22 23:40:29,448 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 10 more threads\n",
            "2022-05-22 23:40:29,470 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 9 more threads\n",
            "2022-05-22 23:40:29,474 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 8 more threads\n",
            "2022-05-22 23:40:29,482 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 7 more threads\n",
            "2022-05-22 23:40:29,495 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 6 more threads\n",
            "2022-05-22 23:40:29,499 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 5 more threads\n",
            "2022-05-22 23:40:29,508 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 4 more threads\n",
            "2022-05-22 23:40:29,524 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 3 more threads\n",
            "2022-05-22 23:40:29,530 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 2 more threads\n",
            "2022-05-22 23:40:29,531 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 1 more threads\n",
            "2022-05-22 23:40:29,539 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 0 more threads\n",
            "2022-05-22 23:40:29,542 | INFO | base_any2vec.py:1346 | _log_epoch_end | EPOCH - 11 : training on 497185 raw words (447470 effective words) took 4.7s, 95172 effective words/s\n",
            "2022-05-22 23:40:30,955 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 12 - PROGRESS: at 4.71% examples, 12494 words/s, in_qsize 9, out_qsize 0\n",
            "2022-05-22 23:40:32,075 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 12 - PROGRESS: at 11.10% examples, 17660 words/s, in_qsize 45, out_qsize 0\n",
            "2022-05-22 23:40:33,080 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 12 - PROGRESS: at 25.92% examples, 33042 words/s, in_qsize 32, out_qsize 5\n",
            "2022-05-22 23:40:33,100 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 31 more threads\n",
            "2022-05-22 23:40:33,106 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 30 more threads\n",
            "2022-05-22 23:40:33,116 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 29 more threads\n",
            "2022-05-22 23:40:33,119 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 28 more threads\n",
            "2022-05-22 23:40:33,124 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 27 more threads\n",
            "2022-05-22 23:40:33,152 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 26 more threads\n",
            "2022-05-22 23:40:33,154 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 25 more threads\n",
            "2022-05-22 23:40:33,159 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 24 more threads\n",
            "2022-05-22 23:40:33,167 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 23 more threads\n",
            "2022-05-22 23:40:33,204 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 22 more threads\n",
            "2022-05-22 23:40:33,224 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 21 more threads\n",
            "2022-05-22 23:40:33,273 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 20 more threads\n",
            "2022-05-22 23:40:33,276 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 19 more threads\n",
            "2022-05-22 23:40:33,281 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 18 more threads\n",
            "2022-05-22 23:40:33,295 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 17 more threads\n",
            "2022-05-22 23:40:33,459 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 16 more threads\n",
            "2022-05-22 23:40:33,831 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 15 more threads\n",
            "2022-05-22 23:40:33,891 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 14 more threads\n",
            "2022-05-22 23:40:34,052 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 13 more threads\n",
            "2022-05-22 23:40:34,054 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 12 more threads\n",
            "2022-05-22 23:40:34,077 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 11 more threads\n",
            "2022-05-22 23:40:34,078 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 10 more threads\n",
            "2022-05-22 23:40:34,084 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 12 - PROGRESS: at 80.33% examples, 81586 words/s, in_qsize 9, out_qsize 1\n",
            "2022-05-22 23:40:34,086 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 9 more threads\n",
            "2022-05-22 23:40:34,115 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 8 more threads\n",
            "2022-05-22 23:40:34,130 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 7 more threads\n",
            "2022-05-22 23:40:34,162 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 6 more threads\n",
            "2022-05-22 23:40:34,184 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 5 more threads\n",
            "2022-05-22 23:40:34,233 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 4 more threads\n",
            "2022-05-22 23:40:34,240 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 3 more threads\n",
            "2022-05-22 23:40:34,247 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 2 more threads\n",
            "2022-05-22 23:40:34,249 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 1 more threads\n",
            "2022-05-22 23:40:34,258 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 0 more threads\n",
            "2022-05-22 23:40:34,259 | INFO | base_any2vec.py:1346 | _log_epoch_end | EPOCH - 12 : training on 497185 raw words (447659 effective words) took 4.7s, 95186 effective words/s\n",
            "2022-05-22 23:40:35,913 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 13 - PROGRESS: at 2.08% examples, 5446 words/s, in_qsize 49, out_qsize 0\n",
            "2022-05-22 23:40:37,084 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 13 - PROGRESS: at 14.89% examples, 22198 words/s, in_qsize 40, out_qsize 3\n",
            "2022-05-22 23:40:37,524 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 31 more threads\n",
            "2022-05-22 23:40:37,543 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 30 more threads\n",
            "2022-05-22 23:40:37,632 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 29 more threads\n",
            "2022-05-22 23:40:37,657 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 28 more threads\n",
            "2022-05-22 23:40:37,663 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 27 more threads\n",
            "2022-05-22 23:40:37,670 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 26 more threads\n",
            "2022-05-22 23:40:37,710 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 25 more threads\n",
            "2022-05-22 23:40:37,781 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 24 more threads\n",
            "2022-05-22 23:40:37,783 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 23 more threads\n",
            "2022-05-22 23:40:37,799 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 22 more threads\n",
            "2022-05-22 23:40:37,874 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 21 more threads\n",
            "2022-05-22 23:40:37,883 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 20 more threads\n",
            "2022-05-22 23:40:37,913 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 19 more threads\n",
            "2022-05-22 23:40:37,957 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 18 more threads\n",
            "2022-05-22 23:40:38,316 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 13 - PROGRESS: at 62.61% examples, 73605 words/s, in_qsize 17, out_qsize 1\n",
            "2022-05-22 23:40:38,318 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 17 more threads\n",
            "2022-05-22 23:40:38,556 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 16 more threads\n",
            "2022-05-22 23:40:38,624 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 15 more threads\n",
            "2022-05-22 23:40:38,725 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 14 more threads\n",
            "2022-05-22 23:40:38,729 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 13 more threads\n",
            "2022-05-22 23:40:38,778 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 12 more threads\n",
            "2022-05-22 23:40:38,853 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 11 more threads\n",
            "2022-05-22 23:40:38,865 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 10 more threads\n",
            "2022-05-22 23:40:38,878 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 9 more threads\n",
            "2022-05-22 23:40:38,895 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 8 more threads\n",
            "2022-05-22 23:40:38,932 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 7 more threads\n",
            "2022-05-22 23:40:38,942 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 6 more threads\n",
            "2022-05-22 23:40:38,949 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 5 more threads\n",
            "2022-05-22 23:40:38,959 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 4 more threads\n",
            "2022-05-22 23:40:38,967 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 3 more threads\n",
            "2022-05-22 23:40:38,980 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 2 more threads\n",
            "2022-05-22 23:40:38,987 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 1 more threads\n",
            "2022-05-22 23:40:38,989 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 0 more threads\n",
            "2022-05-22 23:40:38,993 | INFO | base_any2vec.py:1346 | _log_epoch_end | EPOCH - 13 : training on 497185 raw words (447496 effective words) took 4.7s, 94830 effective words/s\n",
            "2022-05-22 23:40:41,288 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 14 - PROGRESS: at 3.78% examples, 7950 words/s, in_qsize 48, out_qsize 0\n",
            "2022-05-22 23:40:42,333 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 14 - PROGRESS: at 24.72% examples, 32277 words/s, in_qsize 35, out_qsize 3\n",
            "2022-05-22 23:40:42,439 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 31 more threads\n",
            "2022-05-22 23:40:42,442 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 30 more threads\n",
            "2022-05-22 23:40:42,446 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 29 more threads\n",
            "2022-05-22 23:40:42,447 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 28 more threads\n",
            "2022-05-22 23:40:42,448 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 27 more threads\n",
            "2022-05-22 23:40:42,464 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 26 more threads\n",
            "2022-05-22 23:40:42,492 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 25 more threads\n",
            "2022-05-22 23:40:42,501 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 24 more threads\n",
            "2022-05-22 23:40:42,521 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 23 more threads\n",
            "2022-05-22 23:40:42,528 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 22 more threads\n",
            "2022-05-22 23:40:42,534 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 21 more threads\n",
            "2022-05-22 23:40:42,550 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 20 more threads\n",
            "2022-05-22 23:40:42,562 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 19 more threads\n",
            "2022-05-22 23:40:42,576 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 18 more threads\n",
            "2022-05-22 23:40:42,583 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 17 more threads\n",
            "2022-05-22 23:40:43,315 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 16 more threads\n",
            "2022-05-22 23:40:43,457 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 14 - PROGRESS: at 66.08% examples, 70995 words/s, in_qsize 15, out_qsize 1\n",
            "2022-05-22 23:40:43,459 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 15 more threads\n",
            "2022-05-22 23:40:43,507 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 14 more threads\n",
            "2022-05-22 23:40:43,518 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 13 more threads\n",
            "2022-05-22 23:40:43,565 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 12 more threads\n",
            "2022-05-22 23:40:43,574 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 11 more threads\n",
            "2022-05-22 23:40:43,598 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 10 more threads\n",
            "2022-05-22 23:40:43,605 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 9 more threads\n",
            "2022-05-22 23:40:43,634 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 8 more threads\n",
            "2022-05-22 23:40:43,674 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 7 more threads\n",
            "2022-05-22 23:40:43,690 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 6 more threads\n",
            "2022-05-22 23:40:43,692 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 5 more threads\n",
            "2022-05-22 23:40:43,708 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 4 more threads\n",
            "2022-05-22 23:40:43,732 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 3 more threads\n",
            "2022-05-22 23:40:43,734 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 2 more threads\n",
            "2022-05-22 23:40:43,738 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 1 more threads\n",
            "2022-05-22 23:40:43,750 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 0 more threads\n",
            "2022-05-22 23:40:43,751 | INFO | base_any2vec.py:1346 | _log_epoch_end | EPOCH - 14 : training on 497185 raw words (447582 effective words) took 4.7s, 94378 effective words/s\n",
            "2022-05-22 23:40:45,084 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 15 - PROGRESS: at 2.08% examples, 6758 words/s, in_qsize 11, out_qsize 0\n",
            "2022-05-22 23:40:46,251 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 15 - PROGRESS: at 8.72% examples, 14260 words/s, in_qsize 46, out_qsize 0\n",
            "2022-05-22 23:40:47,285 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 15 - PROGRESS: at 29.69% examples, 38193 words/s, in_qsize 26, out_qsize 15\n",
            "2022-05-22 23:40:47,299 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 31 more threads\n",
            "2022-05-22 23:40:47,311 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 30 more threads\n",
            "2022-05-22 23:40:47,320 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 29 more threads\n",
            "2022-05-22 23:40:47,326 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 28 more threads\n",
            "2022-05-22 23:40:47,335 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 27 more threads\n",
            "2022-05-22 23:40:47,340 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 26 more threads\n",
            "2022-05-22 23:40:47,358 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 25 more threads\n",
            "2022-05-22 23:40:47,368 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 24 more threads\n",
            "2022-05-22 23:40:47,393 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 23 more threads\n",
            "2022-05-22 23:40:47,398 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 22 more threads\n",
            "2022-05-22 23:40:47,403 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 21 more threads\n",
            "2022-05-22 23:40:47,418 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 20 more threads\n",
            "2022-05-22 23:40:47,429 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 19 more threads\n",
            "2022-05-22 23:40:47,439 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 18 more threads\n",
            "2022-05-22 23:40:47,690 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 17 more threads\n",
            "2022-05-22 23:40:47,792 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 16 more threads\n",
            "2022-05-22 23:40:47,955 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 15 more threads\n",
            "2022-05-22 23:40:48,176 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 14 more threads\n",
            "2022-05-22 23:40:48,276 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 13 more threads\n",
            "2022-05-22 23:40:48,330 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 15 - PROGRESS: at 72.84% examples, 75052 words/s, in_qsize 12, out_qsize 1\n",
            "2022-05-22 23:40:48,334 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 12 more threads\n",
            "2022-05-22 23:40:48,335 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 11 more threads\n",
            "2022-05-22 23:40:48,338 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 10 more threads\n",
            "2022-05-22 23:40:48,342 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 9 more threads\n",
            "2022-05-22 23:40:48,362 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 8 more threads\n",
            "2022-05-22 23:40:48,373 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 7 more threads\n",
            "2022-05-22 23:40:48,444 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 6 more threads\n",
            "2022-05-22 23:40:48,474 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 5 more threads\n",
            "2022-05-22 23:40:48,487 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 4 more threads\n",
            "2022-05-22 23:40:48,488 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 3 more threads\n",
            "2022-05-22 23:40:48,504 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 2 more threads\n",
            "2022-05-22 23:40:48,510 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 1 more threads\n",
            "2022-05-22 23:40:48,513 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 0 more threads\n",
            "2022-05-22 23:40:48,515 | INFO | base_any2vec.py:1346 | _log_epoch_end | EPOCH - 15 : training on 497185 raw words (447547 effective words) took 4.7s, 94251 effective words/s\n",
            "2022-05-22 23:40:50,504 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 16 - PROGRESS: at 6.71% examples, 13454 words/s, in_qsize 47, out_qsize 0\n",
            "2022-05-22 23:40:51,584 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 16 - PROGRESS: at 17.76% examples, 26383 words/s, in_qsize 41, out_qsize 0\n",
            "2022-05-22 23:40:51,872 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 31 more threads\n",
            "2022-05-22 23:40:51,881 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 30 more threads\n",
            "2022-05-22 23:40:51,883 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 29 more threads\n",
            "2022-05-22 23:40:51,969 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 28 more threads\n",
            "2022-05-22 23:40:52,005 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 27 more threads\n",
            "2022-05-22 23:40:52,015 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 26 more threads\n",
            "2022-05-22 23:40:52,016 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 25 more threads\n",
            "2022-05-22 23:40:52,040 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 24 more threads\n",
            "2022-05-22 23:40:52,043 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 23 more threads\n",
            "2022-05-22 23:40:52,059 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 22 more threads\n",
            "2022-05-22 23:40:52,061 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 21 more threads\n",
            "2022-05-22 23:40:52,104 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 20 more threads\n",
            "2022-05-22 23:40:52,143 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 19 more threads\n",
            "2022-05-22 23:40:52,146 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 18 more threads\n",
            "2022-05-22 23:40:52,167 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 17 more threads\n",
            "2022-05-22 23:40:52,209 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 16 more threads\n",
            "2022-05-22 23:40:52,725 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 16 - PROGRESS: at 66.08% examples, 75287 words/s, in_qsize 15, out_qsize 1\n",
            "2022-05-22 23:40:52,732 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 15 more threads\n",
            "2022-05-22 23:40:52,809 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 14 more threads\n",
            "2022-05-22 23:40:53,048 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 13 more threads\n",
            "2022-05-22 23:40:53,119 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 12 more threads\n",
            "2022-05-22 23:40:53,128 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 11 more threads\n",
            "2022-05-22 23:40:53,157 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 10 more threads\n",
            "2022-05-22 23:40:53,169 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 9 more threads\n",
            "2022-05-22 23:40:53,176 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 8 more threads\n",
            "2022-05-22 23:40:53,184 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 7 more threads\n",
            "2022-05-22 23:40:53,185 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 6 more threads\n",
            "2022-05-22 23:40:53,197 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 5 more threads\n",
            "2022-05-22 23:40:53,214 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 4 more threads\n",
            "2022-05-22 23:40:53,225 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 3 more threads\n",
            "2022-05-22 23:40:53,232 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 2 more threads\n",
            "2022-05-22 23:40:53,242 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 1 more threads\n",
            "2022-05-22 23:40:53,246 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 0 more threads\n",
            "2022-05-22 23:40:53,247 | INFO | base_any2vec.py:1346 | _log_epoch_end | EPOCH - 16 : training on 497185 raw words (447525 effective words) took 4.7s, 94908 effective words/s\n",
            "2022-05-22 23:40:54,570 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 17 - PROGRESS: at 2.08% examples, 6828 words/s, in_qsize 6, out_qsize 0\n",
            "2022-05-22 23:40:55,666 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 17 - PROGRESS: at 7.14% examples, 10966 words/s, in_qsize 47, out_qsize 0\n",
            "2022-05-22 23:40:56,410 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 31 more threads\n",
            "2022-05-22 23:40:56,413 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 30 more threads\n",
            "2022-05-22 23:40:56,415 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 29 more threads\n",
            "2022-05-22 23:40:56,418 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 28 more threads\n",
            "2022-05-22 23:40:56,452 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 27 more threads\n",
            "2022-05-22 23:40:56,469 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 26 more threads\n",
            "2022-05-22 23:40:56,477 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 25 more threads\n",
            "2022-05-22 23:40:56,494 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 24 more threads\n",
            "2022-05-22 23:40:56,540 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 23 more threads\n",
            "2022-05-22 23:40:56,571 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 22 more threads\n",
            "2022-05-22 23:40:56,576 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 21 more threads\n",
            "2022-05-22 23:40:56,581 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 20 more threads\n",
            "2022-05-22 23:40:56,585 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 19 more threads\n",
            "2022-05-22 23:40:56,624 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 18 more threads\n",
            "2022-05-22 23:40:56,872 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 17 - PROGRESS: at 62.61% examples, 82409 words/s, in_qsize 17, out_qsize 1\n",
            "2022-05-22 23:40:56,878 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 17 more threads\n",
            "2022-05-22 23:40:57,316 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 16 more threads\n",
            "2022-05-22 23:40:57,424 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 15 more threads\n",
            "2022-05-22 23:40:57,608 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 14 more threads\n",
            "2022-05-22 23:40:57,749 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 13 more threads\n",
            "2022-05-22 23:40:57,806 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 12 more threads\n",
            "2022-05-22 23:40:57,811 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 11 more threads\n",
            "2022-05-22 23:40:57,833 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 10 more threads\n",
            "2022-05-22 23:40:57,857 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 9 more threads\n",
            "2022-05-22 23:40:57,859 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 8 more threads\n",
            "2022-05-22 23:40:57,863 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 7 more threads\n",
            "2022-05-22 23:40:57,868 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 6 more threads\n",
            "2022-05-22 23:40:57,869 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 5 more threads\n",
            "2022-05-22 23:40:57,881 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 17 - PROGRESS: at 91.36% examples, 89079 words/s, in_qsize 3, out_qsize 3\n",
            "2022-05-22 23:40:57,885 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 4 more threads\n",
            "2022-05-22 23:40:57,888 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 3 more threads\n",
            "2022-05-22 23:40:57,889 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 2 more threads\n",
            "2022-05-22 23:40:57,895 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 1 more threads\n",
            "2022-05-22 23:40:57,908 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 0 more threads\n",
            "2022-05-22 23:40:57,909 | INFO | base_any2vec.py:1346 | _log_epoch_end | EPOCH - 17 : training on 497185 raw words (447391 effective words) took 4.6s, 96311 effective words/s\n",
            "2022-05-22 23:40:59,594 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 18 - PROGRESS: at 2.08% examples, 5335 words/s, in_qsize 14, out_qsize 0\n",
            "2022-05-22 23:41:00,595 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 18 - PROGRESS: at 15.07% examples, 23493 words/s, in_qsize 43, out_qsize 0\n",
            "2022-05-22 23:41:01,195 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 31 more threads\n",
            "2022-05-22 23:41:01,197 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 30 more threads\n",
            "2022-05-22 23:41:01,198 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 29 more threads\n",
            "2022-05-22 23:41:01,227 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 28 more threads\n",
            "2022-05-22 23:41:01,228 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 27 more threads\n",
            "2022-05-22 23:41:01,232 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 26 more threads\n",
            "2022-05-22 23:41:01,234 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 25 more threads\n",
            "2022-05-22 23:41:01,242 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 24 more threads\n",
            "2022-05-22 23:41:01,243 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 23 more threads\n",
            "2022-05-22 23:41:01,311 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 22 more threads\n",
            "2022-05-22 23:41:01,349 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 21 more threads\n",
            "2022-05-22 23:41:01,371 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 20 more threads\n",
            "2022-05-22 23:41:01,382 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 19 more threads\n",
            "2022-05-22 23:41:01,455 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 18 more threads\n",
            "2022-05-22 23:41:01,869 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 18 - PROGRESS: at 62.61% examples, 75483 words/s, in_qsize 17, out_qsize 1\n",
            "2022-05-22 23:41:01,870 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 17 more threads\n",
            "2022-05-22 23:41:02,042 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 16 more threads\n",
            "2022-05-22 23:41:02,053 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 15 more threads\n",
            "2022-05-22 23:41:02,210 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 14 more threads\n",
            "2022-05-22 23:41:02,315 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 13 more threads\n",
            "2022-05-22 23:41:02,355 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 12 more threads\n",
            "2022-05-22 23:41:02,359 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 11 more threads\n",
            "2022-05-22 23:41:02,393 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 10 more threads\n",
            "2022-05-22 23:41:02,395 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 9 more threads\n",
            "2022-05-22 23:41:02,455 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 8 more threads\n",
            "2022-05-22 23:41:02,474 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 7 more threads\n",
            "2022-05-22 23:41:02,477 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 6 more threads\n",
            "2022-05-22 23:41:02,496 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 5 more threads\n",
            "2022-05-22 23:41:02,513 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 4 more threads\n",
            "2022-05-22 23:41:02,531 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 3 more threads\n",
            "2022-05-22 23:41:02,537 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 2 more threads\n",
            "2022-05-22 23:41:02,540 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 1 more threads\n",
            "2022-05-22 23:41:02,547 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 0 more threads\n",
            "2022-05-22 23:41:02,548 | INFO | base_any2vec.py:1346 | _log_epoch_end | EPOCH - 18 : training on 497185 raw words (447649 effective words) took 4.6s, 96891 effective words/s\n",
            "2022-05-22 23:41:04,007 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 19 - PROGRESS: at 3.65% examples, 12516 words/s, in_qsize 48, out_qsize 0\n",
            "2022-05-22 23:41:05,321 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 19 - PROGRESS: at 7.99% examples, 13001 words/s, in_qsize 46, out_qsize 0\n",
            "2022-05-22 23:41:05,761 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 31 more threads\n",
            "2022-05-22 23:41:05,798 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 30 more threads\n",
            "2022-05-22 23:41:05,839 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 29 more threads\n",
            "2022-05-22 23:41:05,848 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 28 more threads\n",
            "2022-05-22 23:41:05,853 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 27 more threads\n",
            "2022-05-22 23:41:05,871 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 26 more threads\n",
            "2022-05-22 23:41:05,937 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 25 more threads\n",
            "2022-05-22 23:41:05,944 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 24 more threads\n",
            "2022-05-22 23:41:05,946 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 23 more threads\n",
            "2022-05-22 23:41:05,947 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 22 more threads\n",
            "2022-05-22 23:41:05,951 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 21 more threads\n",
            "2022-05-22 23:41:05,957 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 20 more threads\n",
            "2022-05-22 23:41:05,984 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 19 more threads\n",
            "2022-05-22 23:41:05,989 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 18 more threads\n",
            "2022-05-22 23:41:06,022 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 17 more threads\n",
            "2022-05-22 23:41:06,228 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 16 more threads\n",
            "2022-05-22 23:41:06,450 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 19 - PROGRESS: at 66.08% examples, 81338 words/s, in_qsize 15, out_qsize 1\n",
            "2022-05-22 23:41:06,451 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 15 more threads\n",
            "2022-05-22 23:41:06,928 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 14 more threads\n",
            "2022-05-22 23:41:06,936 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 13 more threads\n",
            "2022-05-22 23:41:07,040 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 12 more threads\n",
            "2022-05-22 23:41:07,117 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 11 more threads\n",
            "2022-05-22 23:41:07,146 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 10 more threads\n",
            "2022-05-22 23:41:07,148 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 9 more threads\n",
            "2022-05-22 23:41:07,154 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 8 more threads\n",
            "2022-05-22 23:41:07,166 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 7 more threads\n",
            "2022-05-22 23:41:07,168 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 6 more threads\n",
            "2022-05-22 23:41:07,170 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 5 more threads\n",
            "2022-05-22 23:41:07,175 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 4 more threads\n",
            "2022-05-22 23:41:07,181 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 3 more threads\n",
            "2022-05-22 23:41:07,190 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 2 more threads\n",
            "2022-05-22 23:41:07,207 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 1 more threads\n",
            "2022-05-22 23:41:07,218 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 0 more threads\n",
            "2022-05-22 23:41:07,219 | INFO | base_any2vec.py:1346 | _log_epoch_end | EPOCH - 19 : training on 497185 raw words (447537 effective words) took 4.7s, 96211 effective words/s\n",
            "2022-05-22 23:41:08,988 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 20 - PROGRESS: at 2.08% examples, 5075 words/s, in_qsize 7, out_qsize 2\n",
            "2022-05-22 23:41:10,096 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 20 - PROGRESS: at 16.66% examples, 25006 words/s, in_qsize 42, out_qsize 0\n",
            "2022-05-22 23:41:10,393 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 31 more threads\n",
            "2022-05-22 23:41:10,467 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 30 more threads\n",
            "2022-05-22 23:41:10,519 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 29 more threads\n",
            "2022-05-22 23:41:10,525 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 28 more threads\n",
            "2022-05-22 23:41:10,532 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 27 more threads\n",
            "2022-05-22 23:41:10,544 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 26 more threads\n",
            "2022-05-22 23:41:10,582 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 25 more threads\n",
            "2022-05-22 23:41:10,738 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 24 more threads\n",
            "2022-05-22 23:41:10,747 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 23 more threads\n",
            "2022-05-22 23:41:10,772 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 22 more threads\n",
            "2022-05-22 23:41:10,821 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 21 more threads\n",
            "2022-05-22 23:41:10,865 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 20 more threads\n",
            "2022-05-22 23:41:10,892 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 19 more threads\n",
            "2022-05-22 23:41:10,912 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 18 more threads\n",
            "2022-05-22 23:41:11,207 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 20 - PROGRESS: at 62.70% examples, 74783 words/s, in_qsize 17, out_qsize 1\n",
            "2022-05-22 23:41:11,208 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 17 more threads\n",
            "2022-05-22 23:41:11,292 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 16 more threads\n",
            "2022-05-22 23:41:11,334 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 15 more threads\n",
            "2022-05-22 23:41:11,484 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 14 more threads\n",
            "2022-05-22 23:41:11,680 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 13 more threads\n",
            "2022-05-22 23:41:11,709 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 12 more threads\n",
            "2022-05-22 23:41:11,745 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 11 more threads\n",
            "2022-05-22 23:41:11,787 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 10 more threads\n",
            "2022-05-22 23:41:11,809 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 9 more threads\n",
            "2022-05-22 23:41:11,818 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 8 more threads\n",
            "2022-05-22 23:41:11,858 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 7 more threads\n",
            "2022-05-22 23:41:11,884 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 6 more threads\n",
            "2022-05-22 23:41:11,885 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 5 more threads\n",
            "2022-05-22 23:41:11,891 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 4 more threads\n",
            "2022-05-22 23:41:11,893 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 3 more threads\n",
            "2022-05-22 23:41:11,898 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 2 more threads\n",
            "2022-05-22 23:41:11,904 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 1 more threads\n",
            "2022-05-22 23:41:11,912 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 0 more threads\n",
            "2022-05-22 23:41:11,913 | INFO | base_any2vec.py:1346 | _log_epoch_end | EPOCH - 20 : training on 497185 raw words (447534 effective words) took 4.7s, 95613 effective words/s\n",
            "2022-05-22 23:41:11,916 | INFO | base_any2vec.py:1382 | _log_train_end | training on a 9943700 raw words (8950883 effective words) took 94.5s, 94766 effective words/s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wordvec_arrays = np.zeros((len(tokenized_hastags), 50)) \n",
        "for i in range(len(tokenized_hastags)):\n",
        "    wordvec_arrays[i,:] = word_vector(tokenized_hastags[i], 50,modelFastTextSkipGramHastags)\n",
        "wordvec_Hashtag = pd.DataFrame(wordvec_arrays)\n",
        "wordvec_Hashtag.shape"
      ],
      "metadata": {
        "id": "It6lLkX_vIoq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae8a5d87-eabd-4e4b-bf74-ec78df685bb3"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(88514, 50)"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### emojiText"
      ],
      "metadata": {
        "id": "nLgoSAybvTMC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_emojiText = df['hashtags'].apply(lambda x: str(x).split()) # tokenizing\n",
        "modelFastTextSkipGramEmojiText = FastText(tokenized_emojiText, \n",
        "                     size=50, # desired no. of features/independent variables\n",
        "                     window=2,  # context window size\n",
        "                     min_count=2, # Ignores all words with total frequency lower than 2.  \n",
        "                     workers=32, # no.of cores\n",
        "                     hs = 0,\n",
        "                     negative = 10, # for negative sampling\n",
        "                     sg=1  # 1 for Skipgram model\n",
        "                     )\n",
        "\n",
        "modelFastTextSkipGramEmojiText.build_vocab(tokenized_emojiText, update=True)\n",
        "modelFastTextSkipGramEmojiText.train(tokenized_emojiText, total_examples= len(tokenized_emojiText), epochs=20)"
      ],
      "metadata": {
        "id": "LgVqlHrnvVqw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67731b75-bb6a-4439-fa4a-476911bbe1dd"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-22 23:41:22,653 | WARNING | base_any2vec.py:723 | __init__ | consider setting layer size to a multiple of 4 for greater performance\n",
            "2022-05-22 23:41:22,655 | INFO | word2vec.py:1567 | scan_vocab | collecting all words and their counts\n",
            "2022-05-22 23:41:22,656 | INFO | word2vec.py:1552 | _scan_vocab | PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
            "2022-05-22 23:41:22,677 | INFO | word2vec.py:1552 | _scan_vocab | PROGRESS: at sentence #10000, processed 50969 words, keeping 10996 word types\n",
            "2022-05-22 23:41:22,694 | INFO | word2vec.py:1552 | _scan_vocab | PROGRESS: at sentence #20000, processed 113744 words, keeping 21000 word types\n",
            "2022-05-22 23:41:22,714 | INFO | word2vec.py:1552 | _scan_vocab | PROGRESS: at sentence #30000, processed 171307 words, keeping 28787 word types\n",
            "2022-05-22 23:41:22,732 | INFO | word2vec.py:1552 | _scan_vocab | PROGRESS: at sentence #40000, processed 238519 words, keeping 35303 word types\n",
            "2022-05-22 23:41:22,753 | INFO | word2vec.py:1552 | _scan_vocab | PROGRESS: at sentence #50000, processed 303169 words, keeping 41748 word types\n",
            "2022-05-22 23:41:22,771 | INFO | word2vec.py:1552 | _scan_vocab | PROGRESS: at sentence #60000, processed 356785 words, keeping 47292 word types\n",
            "2022-05-22 23:41:22,789 | INFO | word2vec.py:1552 | _scan_vocab | PROGRESS: at sentence #70000, processed 409232 words, keeping 52041 word types\n",
            "2022-05-22 23:41:22,808 | INFO | word2vec.py:1552 | _scan_vocab | PROGRESS: at sentence #80000, processed 460207 words, keeping 57823 word types\n",
            "2022-05-22 23:41:22,819 | INFO | word2vec.py:1575 | scan_vocab | collected 62269 word types from a corpus of 497185 raw words and 88514 sentences\n",
            "2022-05-22 23:41:22,823 | INFO | word2vec.py:1626 | prepare_vocab | Loading a fresh vocabulary\n",
            "2022-05-22 23:41:22,880 | INFO | word2vec.py:1650 | prepare_vocab | effective_min_count=2 retains 25970 unique words (41% of original 62269, drops 36299)\n",
            "2022-05-22 23:41:22,881 | INFO | word2vec.py:1656 | prepare_vocab | effective_min_count=2 leaves 460886 word corpus (92% of original 497185, drops 36299)\n",
            "2022-05-22 23:41:22,944 | INFO | word2vec.py:1715 | prepare_vocab | deleting the raw counts dictionary of 62269 items\n",
            "2022-05-22 23:41:22,947 | INFO | word2vec.py:1718 | prepare_vocab | sample=0.001 downsamples 17 most-common words\n",
            "2022-05-22 23:41:22,948 | INFO | word2vec.py:1721 | prepare_vocab | downsampling leaves estimated 447565 word corpus (97.1% of prior 460886)\n",
            "2022-05-22 23:41:23,572 | INFO | fasttext.py:551 | estimate_memory | estimated required memory for 25970 words, 203322 buckets and 50 dimensions: 77024440 bytes\n",
            "2022-05-22 23:41:23,580 | INFO | word2vec.py:1834 | reset_weights | resetting layer weights\n",
            "2022-05-22 23:41:28,706 | INFO | fasttext.py:1011 | init_ngrams_weights | Total number of ngrams is 203322\n",
            "2022-05-22 23:41:29,808 | INFO | base_any2vec.py:1210 | _check_training_sanity | training model with 32 workers on 25970 vocabulary and 50 features, using sg=1 hs=0 sample=0.001 negative=10 window=2\n",
            "2022-05-22 23:41:32,173 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 1 - PROGRESS: at 2.08% examples, 3800 words/s, in_qsize 49, out_qsize 0\n",
            "2022-05-22 23:41:33,193 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 1 - PROGRESS: at 14.80% examples, 18652 words/s, in_qsize 43, out_qsize 0\n",
            "2022-05-22 23:41:33,886 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 31 more threads\n",
            "2022-05-22 23:41:33,896 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 30 more threads\n",
            "2022-05-22 23:41:33,902 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 29 more threads\n",
            "2022-05-22 23:41:33,910 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 28 more threads\n",
            "2022-05-22 23:41:33,915 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 27 more threads\n",
            "2022-05-22 23:41:33,917 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 26 more threads\n",
            "2022-05-22 23:41:33,921 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 25 more threads\n",
            "2022-05-22 23:41:33,927 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 24 more threads\n",
            "2022-05-22 23:41:33,960 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 23 more threads\n",
            "2022-05-22 23:41:33,962 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 22 more threads\n",
            "2022-05-22 23:41:33,970 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 21 more threads\n",
            "2022-05-22 23:41:33,980 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 20 more threads\n",
            "2022-05-22 23:41:33,985 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 19 more threads\n",
            "2022-05-22 23:41:33,996 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 18 more threads\n",
            "2022-05-22 23:41:34,792 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 1 - PROGRESS: at 62.61% examples, 59880 words/s, in_qsize 17, out_qsize 1\n",
            "2022-05-22 23:41:34,795 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 17 more threads\n",
            "2022-05-22 23:41:34,950 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 16 more threads\n",
            "2022-05-22 23:41:35,081 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 15 more threads\n",
            "2022-05-22 23:41:35,112 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 14 more threads\n",
            "2022-05-22 23:41:35,170 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 13 more threads\n",
            "2022-05-22 23:41:35,246 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 12 more threads\n",
            "2022-05-22 23:41:35,269 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 11 more threads\n",
            "2022-05-22 23:41:35,378 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 10 more threads\n",
            "2022-05-22 23:41:35,453 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 9 more threads\n",
            "2022-05-22 23:41:35,457 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 8 more threads\n",
            "2022-05-22 23:41:35,462 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 7 more threads\n",
            "2022-05-22 23:41:35,463 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 6 more threads\n",
            "2022-05-22 23:41:35,472 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 5 more threads\n",
            "2022-05-22 23:41:35,474 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 4 more threads\n",
            "2022-05-22 23:41:35,483 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 3 more threads\n",
            "2022-05-22 23:41:35,490 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 2 more threads\n",
            "2022-05-22 23:41:35,497 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 1 more threads\n",
            "2022-05-22 23:41:35,504 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 0 more threads\n",
            "2022-05-22 23:41:35,505 | INFO | base_any2vec.py:1346 | _log_epoch_end | EPOCH - 1 : training on 497185 raw words (447537 effective words) took 5.7s, 78772 effective words/s\n",
            "2022-05-22 23:41:37,031 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 2 - PROGRESS: at 2.08% examples, 5890 words/s, in_qsize 16, out_qsize 0\n",
            "2022-05-22 23:41:38,358 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 2 - PROGRESS: at 4.71% examples, 6158 words/s, in_qsize 48, out_qsize 0\n",
            "2022-05-22 23:41:39,381 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 2 - PROGRESS: at 16.97% examples, 18466 words/s, in_qsize 34, out_qsize 8\n",
            "2022-05-22 23:41:39,512 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 31 more threads\n",
            "2022-05-22 23:41:39,558 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 30 more threads\n",
            "2022-05-22 23:41:39,570 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 29 more threads\n",
            "2022-05-22 23:41:39,577 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 28 more threads\n",
            "2022-05-22 23:41:39,578 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 27 more threads\n",
            "2022-05-22 23:41:39,579 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 26 more threads\n",
            "2022-05-22 23:41:39,580 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 25 more threads\n",
            "2022-05-22 23:41:39,586 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 24 more threads\n",
            "2022-05-22 23:41:39,625 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 23 more threads\n",
            "2022-05-22 23:41:39,627 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 22 more threads\n",
            "2022-05-22 23:41:39,680 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 21 more threads\n",
            "2022-05-22 23:41:39,683 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 20 more threads\n",
            "2022-05-22 23:41:39,701 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 19 more threads\n",
            "2022-05-22 23:41:39,763 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 18 more threads\n",
            "2022-05-22 23:41:40,129 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 17 more threads\n",
            "2022-05-22 23:41:40,814 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 2 - PROGRESS: at 64.33% examples, 57919 words/s, in_qsize 16, out_qsize 1\n",
            "2022-05-22 23:41:40,816 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 16 more threads\n",
            "2022-05-22 23:41:40,841 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 15 more threads\n",
            "2022-05-22 23:41:40,939 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 14 more threads\n",
            "2022-05-22 23:41:41,048 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 13 more threads\n",
            "2022-05-22 23:41:41,100 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 12 more threads\n",
            "2022-05-22 23:41:41,176 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 11 more threads\n",
            "2022-05-22 23:41:41,193 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 10 more threads\n",
            "2022-05-22 23:41:41,203 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 9 more threads\n",
            "2022-05-22 23:41:41,218 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 8 more threads\n",
            "2022-05-22 23:41:41,226 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 7 more threads\n",
            "2022-05-22 23:41:41,236 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 6 more threads\n",
            "2022-05-22 23:41:41,242 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 5 more threads\n",
            "2022-05-22 23:41:41,248 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 4 more threads\n",
            "2022-05-22 23:41:41,253 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 3 more threads\n",
            "2022-05-22 23:41:41,275 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 2 more threads\n",
            "2022-05-22 23:41:41,277 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 1 more threads\n",
            "2022-05-22 23:41:41,282 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 0 more threads\n",
            "2022-05-22 23:41:41,283 | INFO | base_any2vec.py:1346 | _log_epoch_end | EPOCH - 2 : training on 497185 raw words (447628 effective words) took 5.8s, 77683 effective words/s\n",
            "2022-05-22 23:41:42,708 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 3 - PROGRESS: at 2.08% examples, 6321 words/s, in_qsize 49, out_qsize 0\n",
            "2022-05-22 23:41:43,833 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 3 - PROGRESS: at 4.71% examples, 6893 words/s, in_qsize 48, out_qsize 0\n",
            "2022-05-22 23:41:45,410 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 3 - PROGRESS: at 12.73% examples, 12987 words/s, in_qsize 32, out_qsize 12\n",
            "2022-05-22 23:41:45,422 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 31 more threads\n",
            "2022-05-22 23:41:45,449 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 30 more threads\n",
            "2022-05-22 23:41:45,453 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 29 more threads\n",
            "2022-05-22 23:41:45,458 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 28 more threads\n",
            "2022-05-22 23:41:45,461 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 27 more threads\n",
            "2022-05-22 23:41:45,467 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 26 more threads\n",
            "2022-05-22 23:41:45,471 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 25 more threads\n",
            "2022-05-22 23:41:45,478 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 24 more threads\n",
            "2022-05-22 23:41:45,493 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 23 more threads\n",
            "2022-05-22 23:41:45,502 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 22 more threads\n",
            "2022-05-22 23:41:45,535 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 21 more threads\n",
            "2022-05-22 23:41:45,538 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 20 more threads\n",
            "2022-05-22 23:41:45,541 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 19 more threads\n",
            "2022-05-22 23:41:45,550 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 18 more threads\n",
            "2022-05-22 23:41:45,829 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 17 more threads\n",
            "2022-05-22 23:41:46,306 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 16 more threads\n",
            "2022-05-22 23:41:46,467 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 3 - PROGRESS: at 66.08% examples, 61113 words/s, in_qsize 15, out_qsize 1\n",
            "2022-05-22 23:41:46,468 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 15 more threads\n",
            "2022-05-22 23:41:46,608 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 14 more threads\n",
            "2022-05-22 23:41:46,840 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 13 more threads\n",
            "2022-05-22 23:41:46,880 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 12 more threads\n",
            "2022-05-22 23:41:47,000 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 11 more threads\n",
            "2022-05-22 23:41:47,008 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 10 more threads\n",
            "2022-05-22 23:41:47,057 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 9 more threads\n",
            "2022-05-22 23:41:47,061 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 8 more threads\n",
            "2022-05-22 23:41:47,076 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 7 more threads\n",
            "2022-05-22 23:41:47,089 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 6 more threads\n",
            "2022-05-22 23:41:47,097 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 5 more threads\n",
            "2022-05-22 23:41:47,125 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 4 more threads\n",
            "2022-05-22 23:41:47,131 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 3 more threads\n",
            "2022-05-22 23:41:47,133 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 2 more threads\n",
            "2022-05-22 23:41:47,138 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 1 more threads\n",
            "2022-05-22 23:41:47,139 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 0 more threads\n",
            "2022-05-22 23:41:47,143 | INFO | base_any2vec.py:1346 | _log_epoch_end | EPOCH - 3 : training on 497185 raw words (447590 effective words) took 5.8s, 76574 effective words/s\n",
            "2022-05-22 23:41:48,717 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 4 - PROGRESS: at 2.08% examples, 5718 words/s, in_qsize 8, out_qsize 0\n",
            "2022-05-22 23:41:50,340 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 4 - PROGRESS: at 6.41% examples, 8394 words/s, in_qsize 47, out_qsize 0\n",
            "2022-05-22 23:41:50,961 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 31 more threads\n",
            "2022-05-22 23:41:51,049 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 30 more threads\n",
            "2022-05-22 23:41:51,074 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 29 more threads\n",
            "2022-05-22 23:41:51,118 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 28 more threads\n",
            "2022-05-22 23:41:51,128 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 27 more threads\n",
            "2022-05-22 23:41:51,164 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 26 more threads\n",
            "2022-05-22 23:41:51,210 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 25 more threads\n",
            "2022-05-22 23:41:51,211 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 24 more threads\n",
            "2022-05-22 23:41:51,326 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 23 more threads\n",
            "2022-05-22 23:41:51,358 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 4 - PROGRESS: at 53.60% examples, 59911 words/s, in_qsize 22, out_qsize 1\n",
            "2022-05-22 23:41:51,359 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 22 more threads\n",
            "2022-05-22 23:41:51,384 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 21 more threads\n",
            "2022-05-22 23:41:51,446 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 20 more threads\n",
            "2022-05-22 23:41:51,508 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 19 more threads\n",
            "2022-05-22 23:41:51,518 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 18 more threads\n",
            "2022-05-22 23:41:51,816 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 17 more threads\n",
            "2022-05-22 23:41:52,287 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 16 more threads\n",
            "2022-05-22 23:41:52,520 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 4 - PROGRESS: at 66.16% examples, 58407 words/s, in_qsize 15, out_qsize 1\n",
            "2022-05-22 23:41:52,522 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 15 more threads\n",
            "2022-05-22 23:41:52,615 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 14 more threads\n",
            "2022-05-22 23:41:52,734 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 13 more threads\n",
            "2022-05-22 23:41:52,747 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 12 more threads\n",
            "2022-05-22 23:41:52,766 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 11 more threads\n",
            "2022-05-22 23:41:52,783 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 10 more threads\n",
            "2022-05-22 23:41:52,803 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 9 more threads\n",
            "2022-05-22 23:41:52,808 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 8 more threads\n",
            "2022-05-22 23:41:52,834 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 7 more threads\n",
            "2022-05-22 23:41:52,838 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 6 more threads\n",
            "2022-05-22 23:41:52,843 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 5 more threads\n",
            "2022-05-22 23:41:52,862 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 4 more threads\n",
            "2022-05-22 23:41:52,870 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 3 more threads\n",
            "2022-05-22 23:41:52,877 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 2 more threads\n",
            "2022-05-22 23:41:52,882 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 1 more threads\n",
            "2022-05-22 23:41:52,889 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 0 more threads\n",
            "2022-05-22 23:41:52,890 | INFO | base_any2vec.py:1346 | _log_epoch_end | EPOCH - 4 : training on 497185 raw words (447476 effective words) took 5.7s, 78058 effective words/s\n",
            "2022-05-22 23:41:53,947 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 5 - PROGRESS: at 2.08% examples, 8565 words/s, in_qsize 14, out_qsize 0\n",
            "2022-05-22 23:41:55,695 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 5 - PROGRESS: at 4.08% examples, 6448 words/s, in_qsize 48, out_qsize 0\n",
            "2022-05-22 23:41:56,720 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 5 - PROGRESS: at 23.18% examples, 25865 words/s, in_qsize 39, out_qsize 0\n",
            "2022-05-22 23:41:57,134 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 31 more threads\n",
            "2022-05-22 23:41:57,146 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 30 more threads\n",
            "2022-05-22 23:41:57,154 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 29 more threads\n",
            "2022-05-22 23:41:57,157 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 28 more threads\n",
            "2022-05-22 23:41:57,166 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 27 more threads\n",
            "2022-05-22 23:41:57,176 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 26 more threads\n",
            "2022-05-22 23:41:57,180 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 25 more threads\n",
            "2022-05-22 23:41:57,184 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 24 more threads\n",
            "2022-05-22 23:41:57,216 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 23 more threads\n",
            "2022-05-22 23:41:57,220 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 22 more threads\n",
            "2022-05-22 23:41:57,227 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 21 more threads\n",
            "2022-05-22 23:41:57,234 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 20 more threads\n",
            "2022-05-22 23:41:57,246 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 19 more threads\n",
            "2022-05-22 23:41:57,252 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 18 more threads\n",
            "2022-05-22 23:41:57,321 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 17 more threads\n",
            "2022-05-22 23:41:58,130 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 5 - PROGRESS: at 64.33% examples, 58674 words/s, in_qsize 16, out_qsize 1\n",
            "2022-05-22 23:41:58,132 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 16 more threads\n",
            "2022-05-22 23:41:58,162 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 15 more threads\n",
            "2022-05-22 23:41:58,348 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 14 more threads\n",
            "2022-05-22 23:41:58,413 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 13 more threads\n",
            "2022-05-22 23:41:58,457 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 12 more threads\n",
            "2022-05-22 23:41:58,478 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 11 more threads\n",
            "2022-05-22 23:41:58,482 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 10 more threads\n",
            "2022-05-22 23:41:58,488 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 9 more threads\n",
            "2022-05-22 23:41:58,517 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 8 more threads\n",
            "2022-05-22 23:41:58,522 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 7 more threads\n",
            "2022-05-22 23:41:58,530 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 6 more threads\n",
            "2022-05-22 23:41:58,604 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 5 more threads\n",
            "2022-05-22 23:41:58,611 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 4 more threads\n",
            "2022-05-22 23:41:58,636 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 3 more threads\n",
            "2022-05-22 23:41:58,648 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 2 more threads\n",
            "2022-05-22 23:41:58,659 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 1 more threads\n",
            "2022-05-22 23:41:58,669 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 0 more threads\n",
            "2022-05-22 23:41:58,670 | INFO | base_any2vec.py:1346 | _log_epoch_end | EPOCH - 5 : training on 497185 raw words (447553 effective words) took 5.8s, 77642 effective words/s\n",
            "2022-05-22 23:41:58,674 | INFO | base_any2vec.py:1382 | _log_train_end | training on a 2485925 raw words (2237784 effective words) took 28.9s, 77527 effective words/s\n",
            "2022-05-22 23:41:58,675 | WARNING | base_any2vec.py:1386 | _log_train_end | under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
            "2022-05-22 23:42:01,387 | INFO | word2vec.py:1567 | scan_vocab | collecting all words and their counts\n",
            "2022-05-22 23:42:01,388 | INFO | word2vec.py:1552 | _scan_vocab | PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
            "2022-05-22 23:42:01,407 | INFO | word2vec.py:1552 | _scan_vocab | PROGRESS: at sentence #10000, processed 50969 words, keeping 10996 word types\n",
            "2022-05-22 23:42:01,421 | INFO | word2vec.py:1552 | _scan_vocab | PROGRESS: at sentence #20000, processed 113744 words, keeping 21000 word types\n",
            "2022-05-22 23:42:01,447 | INFO | word2vec.py:1552 | _scan_vocab | PROGRESS: at sentence #30000, processed 171307 words, keeping 28787 word types\n",
            "2022-05-22 23:42:01,465 | INFO | word2vec.py:1552 | _scan_vocab | PROGRESS: at sentence #40000, processed 238519 words, keeping 35303 word types\n",
            "2022-05-22 23:42:01,481 | INFO | word2vec.py:1552 | _scan_vocab | PROGRESS: at sentence #50000, processed 303169 words, keeping 41748 word types\n",
            "2022-05-22 23:42:01,500 | INFO | word2vec.py:1552 | _scan_vocab | PROGRESS: at sentence #60000, processed 356785 words, keeping 47292 word types\n",
            "2022-05-22 23:42:01,513 | INFO | word2vec.py:1552 | _scan_vocab | PROGRESS: at sentence #70000, processed 409232 words, keeping 52041 word types\n",
            "2022-05-22 23:42:01,531 | INFO | word2vec.py:1552 | _scan_vocab | PROGRESS: at sentence #80000, processed 460207 words, keeping 57823 word types\n",
            "2022-05-22 23:42:01,545 | INFO | word2vec.py:1575 | scan_vocab | collected 62269 word types from a corpus of 497185 raw words and 88514 sentences\n",
            "2022-05-22 23:42:01,548 | INFO | word2vec.py:1659 | prepare_vocab | Updating model with new vocabulary\n",
            "2022-05-22 23:42:01,589 | INFO | word2vec.py:1685 | prepare_vocab | New added 25970 unique words (29% of original 88239) and increased the count of 25970 pre-existing words (29% of original 88239)\n",
            "2022-05-22 23:42:01,707 | INFO | word2vec.py:1715 | prepare_vocab | deleting the raw counts dictionary of 62269 items\n",
            "2022-05-22 23:42:01,709 | INFO | word2vec.py:1718 | prepare_vocab | sample=0.001 downsamples 34 most-common words\n",
            "2022-05-22 23:42:01,711 | INFO | word2vec.py:1721 | prepare_vocab | downsampling leaves estimated 895130 word corpus (194.2% of prior 460886)\n",
            "2022-05-22 23:42:02,323 | INFO | fasttext.py:551 | estimate_memory | estimated required memory for 25970 words, 203322 buckets and 50 dimensions: 77024440 bytes\n",
            "2022-05-22 23:42:02,324 | INFO | word2vec.py:1850 | update_weights | updating layer weights\n",
            "2022-05-22 23:42:03,229 | INFO | fasttext.py:1030 | init_ngrams_weights | Number of new ngrams is 0\n",
            "2022-05-22 23:42:03,265 | WARNING | base_any2vec.py:1182 | _check_training_sanity | Effective 'alpha' higher than previous training cycles\n",
            "2022-05-22 23:42:03,266 | INFO | base_any2vec.py:1210 | _check_training_sanity | training model with 32 workers on 25970 vocabulary and 50 features, using sg=1 hs=0 sample=0.001 negative=10 window=2\n",
            "2022-05-22 23:42:04,921 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 1 - PROGRESS: at 2.08% examples, 5418 words/s, in_qsize 49, out_qsize 0\n",
            "2022-05-22 23:42:05,977 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 1 - PROGRESS: at 9.18% examples, 13086 words/s, in_qsize 46, out_qsize 0\n",
            "2022-05-22 23:42:07,236 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 1 - PROGRESS: at 18.94% examples, 22712 words/s, in_qsize 23, out_qsize 26\n",
            "2022-05-22 23:42:07,244 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 31 more threads\n",
            "2022-05-22 23:42:07,268 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 30 more threads\n",
            "2022-05-22 23:42:07,278 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 29 more threads\n",
            "2022-05-22 23:42:07,281 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 28 more threads\n",
            "2022-05-22 23:42:07,284 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 27 more threads\n",
            "2022-05-22 23:42:07,286 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 26 more threads\n",
            "2022-05-22 23:42:07,299 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 25 more threads\n",
            "2022-05-22 23:42:07,305 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 24 more threads\n",
            "2022-05-22 23:42:07,319 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 23 more threads\n",
            "2022-05-22 23:42:07,329 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 22 more threads\n",
            "2022-05-22 23:42:07,343 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 21 more threads\n",
            "2022-05-22 23:42:07,351 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 20 more threads\n",
            "2022-05-22 23:42:07,363 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 19 more threads\n",
            "2022-05-22 23:42:07,373 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 18 more threads\n",
            "2022-05-22 23:42:07,820 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 17 more threads\n",
            "2022-05-22 23:42:08,049 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 16 more threads\n",
            "2022-05-22 23:42:08,303 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 1 - PROGRESS: at 66.08% examples, 62885 words/s, in_qsize 15, out_qsize 1\n",
            "2022-05-22 23:42:08,305 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 15 more threads\n",
            "2022-05-22 23:42:08,375 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 14 more threads\n",
            "2022-05-22 23:42:08,604 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 13 more threads\n",
            "2022-05-22 23:42:08,661 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 12 more threads\n",
            "2022-05-22 23:42:08,666 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 11 more threads\n",
            "2022-05-22 23:42:08,749 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 10 more threads\n",
            "2022-05-22 23:42:08,796 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 9 more threads\n",
            "2022-05-22 23:42:08,807 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 8 more threads\n",
            "2022-05-22 23:42:08,814 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 7 more threads\n",
            "2022-05-22 23:42:08,825 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 6 more threads\n",
            "2022-05-22 23:42:08,830 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 5 more threads\n",
            "2022-05-22 23:42:08,852 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 4 more threads\n",
            "2022-05-22 23:42:08,857 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 3 more threads\n",
            "2022-05-22 23:42:08,867 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 2 more threads\n",
            "2022-05-22 23:42:08,869 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 1 more threads\n",
            "2022-05-22 23:42:08,877 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 0 more threads\n",
            "2022-05-22 23:42:08,877 | INFO | base_any2vec.py:1346 | _log_epoch_end | EPOCH - 1 : training on 497185 raw words (447608 effective words) took 5.6s, 79992 effective words/s\n",
            "2022-05-22 23:42:10,624 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 2 - PROGRESS: at 4.71% examples, 10090 words/s, in_qsize 48, out_qsize 0\n",
            "2022-05-22 23:42:12,728 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 2 - PROGRESS: at 12.39% examples, 14010 words/s, in_qsize 37, out_qsize 7\n",
            "2022-05-22 23:42:12,781 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 31 more threads\n",
            "2022-05-22 23:42:12,804 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 30 more threads\n",
            "2022-05-22 23:42:12,858 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 29 more threads\n",
            "2022-05-22 23:42:12,872 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 28 more threads\n",
            "2022-05-22 23:42:12,915 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 27 more threads\n",
            "2022-05-22 23:42:12,921 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 26 more threads\n",
            "2022-05-22 23:42:12,954 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 25 more threads\n",
            "2022-05-22 23:42:12,965 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 24 more threads\n",
            "2022-05-22 23:42:12,966 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 23 more threads\n",
            "2022-05-22 23:42:12,971 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 22 more threads\n",
            "2022-05-22 23:42:12,972 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 21 more threads\n",
            "2022-05-22 23:42:12,973 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 20 more threads\n",
            "2022-05-22 23:42:12,997 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 19 more threads\n",
            "2022-05-22 23:42:12,998 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 18 more threads\n",
            "2022-05-22 23:42:12,999 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 17 more threads\n",
            "2022-05-22 23:42:13,294 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 16 more threads\n",
            "2022-05-22 23:42:13,303 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 15 more threads\n",
            "2022-05-22 23:42:13,820 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 2 - PROGRESS: at 68.38% examples, 65947 words/s, in_qsize 13, out_qsize 3\n",
            "2022-05-22 23:42:13,822 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 14 more threads\n",
            "2022-05-22 23:42:13,824 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 13 more threads\n",
            "2022-05-22 23:42:14,144 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 12 more threads\n",
            "2022-05-22 23:42:14,226 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 11 more threads\n",
            "2022-05-22 23:42:14,299 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 10 more threads\n",
            "2022-05-22 23:42:14,325 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 9 more threads\n",
            "2022-05-22 23:42:14,326 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 8 more threads\n",
            "2022-05-22 23:42:14,362 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 7 more threads\n",
            "2022-05-22 23:42:14,364 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 6 more threads\n",
            "2022-05-22 23:42:14,370 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 5 more threads\n",
            "2022-05-22 23:42:14,380 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 4 more threads\n",
            "2022-05-22 23:42:14,392 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 3 more threads\n",
            "2022-05-22 23:42:14,399 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 2 more threads\n",
            "2022-05-22 23:42:14,404 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 1 more threads\n",
            "2022-05-22 23:42:14,413 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 0 more threads\n",
            "2022-05-22 23:42:14,413 | INFO | base_any2vec.py:1346 | _log_epoch_end | EPOCH - 2 : training on 497185 raw words (447624 effective words) took 5.5s, 81080 effective words/s\n",
            "2022-05-22 23:42:15,868 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 3 - PROGRESS: at 2.08% examples, 6196 words/s, in_qsize 13, out_qsize 0\n",
            "2022-05-22 23:42:16,897 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 3 - PROGRESS: at 7.14% examples, 10665 words/s, in_qsize 47, out_qsize 0\n",
            "2022-05-22 23:42:18,121 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 3 - PROGRESS: at 14.74% examples, 17013 words/s, in_qsize 38, out_qsize 5\n",
            "2022-05-22 23:42:18,131 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 31 more threads\n",
            "2022-05-22 23:42:18,148 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 30 more threads\n",
            "2022-05-22 23:42:18,202 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 29 more threads\n",
            "2022-05-22 23:42:18,277 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 28 more threads\n",
            "2022-05-22 23:42:18,305 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 27 more threads\n",
            "2022-05-22 23:42:18,307 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 26 more threads\n",
            "2022-05-22 23:42:18,311 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 25 more threads\n",
            "2022-05-22 23:42:18,321 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 24 more threads\n",
            "2022-05-22 23:42:18,402 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 23 more threads\n",
            "2022-05-22 23:42:18,422 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 22 more threads\n",
            "2022-05-22 23:42:18,427 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 21 more threads\n",
            "2022-05-22 23:42:18,485 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 20 more threads\n",
            "2022-05-22 23:42:18,509 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 19 more threads\n",
            "2022-05-22 23:42:18,533 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 18 more threads\n",
            "2022-05-22 23:42:18,836 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 17 more threads\n",
            "2022-05-22 23:42:19,164 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 3 - PROGRESS: at 64.33% examples, 64737 words/s, in_qsize 16, out_qsize 1\n",
            "2022-05-22 23:42:19,165 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 16 more threads\n",
            "2022-05-22 23:42:19,409 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 15 more threads\n",
            "2022-05-22 23:42:19,618 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 14 more threads\n",
            "2022-05-22 23:42:19,654 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 13 more threads\n",
            "2022-05-22 23:42:19,657 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 12 more threads\n",
            "2022-05-22 23:42:19,813 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 11 more threads\n",
            "2022-05-22 23:42:19,834 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 10 more threads\n",
            "2022-05-22 23:42:19,850 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 9 more threads\n",
            "2022-05-22 23:42:19,874 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 8 more threads\n",
            "2022-05-22 23:42:19,877 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 7 more threads\n",
            "2022-05-22 23:42:19,878 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 6 more threads\n",
            "2022-05-22 23:42:19,901 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 5 more threads\n",
            "2022-05-22 23:42:19,907 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 4 more threads\n",
            "2022-05-22 23:42:19,924 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 3 more threads\n",
            "2022-05-22 23:42:19,925 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 2 more threads\n",
            "2022-05-22 23:42:19,932 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 1 more threads\n",
            "2022-05-22 23:42:19,941 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 0 more threads\n",
            "2022-05-22 23:42:19,942 | INFO | base_any2vec.py:1346 | _log_epoch_end | EPOCH - 3 : training on 497185 raw words (447506 effective words) took 5.5s, 81174 effective words/s\n",
            "2022-05-22 23:42:21,100 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 4 - PROGRESS: at 2.63% examples, 7475 words/s, in_qsize 14, out_qsize 0\n",
            "2022-05-22 23:42:22,375 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 4 - PROGRESS: at 6.62% examples, 11030 words/s, in_qsize 47, out_qsize 0\n",
            "2022-05-22 23:42:23,840 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 4 - PROGRESS: at 17.56% examples, 20822 words/s, in_qsize 27, out_qsize 19\n",
            "2022-05-22 23:42:23,846 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 31 more threads\n",
            "2022-05-22 23:42:23,876 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 30 more threads\n",
            "2022-05-22 23:42:23,878 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 29 more threads\n",
            "2022-05-22 23:42:23,899 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 28 more threads\n",
            "2022-05-22 23:42:23,906 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 27 more threads\n",
            "2022-05-22 23:42:23,912 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 26 more threads\n",
            "2022-05-22 23:42:23,921 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 25 more threads\n",
            "2022-05-22 23:42:23,925 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 24 more threads\n",
            "2022-05-22 23:42:23,928 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 23 more threads\n",
            "2022-05-22 23:42:23,929 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 22 more threads\n",
            "2022-05-22 23:42:23,966 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 21 more threads\n",
            "2022-05-22 23:42:23,967 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 20 more threads\n",
            "2022-05-22 23:42:23,968 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 19 more threads\n",
            "2022-05-22 23:42:23,973 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 18 more threads\n",
            "2022-05-22 23:42:24,150 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 17 more threads\n",
            "2022-05-22 23:42:24,280 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 16 more threads\n",
            "2022-05-22 23:42:24,745 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 15 more threads\n",
            "2022-05-22 23:42:25,157 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 4 - PROGRESS: at 67.91% examples, 62022 words/s, in_qsize 14, out_qsize 1\n",
            "2022-05-22 23:42:25,159 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 14 more threads\n",
            "2022-05-22 23:42:25,223 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 13 more threads\n",
            "2022-05-22 23:42:25,244 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 12 more threads\n",
            "2022-05-22 23:42:25,259 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 11 more threads\n",
            "2022-05-22 23:42:25,260 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 10 more threads\n",
            "2022-05-22 23:42:25,335 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 9 more threads\n",
            "2022-05-22 23:42:25,360 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 8 more threads\n",
            "2022-05-22 23:42:25,378 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 7 more threads\n",
            "2022-05-22 23:42:25,386 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 6 more threads\n",
            "2022-05-22 23:42:25,428 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 5 more threads\n",
            "2022-05-22 23:42:25,433 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 4 more threads\n",
            "2022-05-22 23:42:25,439 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 3 more threads\n",
            "2022-05-22 23:42:25,446 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 2 more threads\n",
            "2022-05-22 23:42:25,449 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 1 more threads\n",
            "2022-05-22 23:42:25,454 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 0 more threads\n",
            "2022-05-22 23:42:25,455 | INFO | base_any2vec.py:1346 | _log_epoch_end | EPOCH - 4 : training on 497185 raw words (447550 effective words) took 5.5s, 81410 effective words/s\n",
            "2022-05-22 23:42:26,826 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 5 - PROGRESS: at 3.99% examples, 13417 words/s, in_qsize 48, out_qsize 0\n",
            "2022-05-22 23:42:28,616 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 5 - PROGRESS: at 6.42% examples, 8587 words/s, in_qsize 46, out_qsize 1\n",
            "2022-05-22 23:42:29,474 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 31 more threads\n",
            "2022-05-22 23:42:29,487 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 30 more threads\n",
            "2022-05-22 23:42:29,492 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 29 more threads\n",
            "2022-05-22 23:42:29,492 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 28 more threads\n",
            "2022-05-22 23:42:29,504 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 27 more threads\n",
            "2022-05-22 23:42:29,527 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 26 more threads\n",
            "2022-05-22 23:42:29,532 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 25 more threads\n",
            "2022-05-22 23:42:29,564 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 24 more threads\n",
            "2022-05-22 23:42:29,568 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 23 more threads\n",
            "2022-05-22 23:42:29,572 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 22 more threads\n",
            "2022-05-22 23:42:29,579 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 21 more threads\n",
            "2022-05-22 23:42:29,587 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 20 more threads\n",
            "2022-05-22 23:42:29,623 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 5 - PROGRESS: at 59.13% examples, 67262 words/s, in_qsize 16, out_qsize 7\n",
            "2022-05-22 23:42:29,624 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 19 more threads\n",
            "2022-05-22 23:42:29,627 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 18 more threads\n",
            "2022-05-22 23:42:29,639 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 17 more threads\n",
            "2022-05-22 23:42:29,645 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 16 more threads\n",
            "2022-05-22 23:42:30,474 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 15 more threads\n",
            "2022-05-22 23:42:30,569 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 14 more threads\n",
            "2022-05-22 23:42:30,757 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 5 - PROGRESS: at 70.21% examples, 62777 words/s, in_qsize 13, out_qsize 1\n",
            "2022-05-22 23:42:30,759 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 13 more threads\n",
            "2022-05-22 23:42:30,832 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 12 more threads\n",
            "2022-05-22 23:42:30,834 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 11 more threads\n",
            "2022-05-22 23:42:30,891 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 10 more threads\n",
            "2022-05-22 23:42:30,903 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 9 more threads\n",
            "2022-05-22 23:42:30,914 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 8 more threads\n",
            "2022-05-22 23:42:30,948 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 7 more threads\n",
            "2022-05-22 23:42:30,956 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 6 more threads\n",
            "2022-05-22 23:42:30,970 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 5 more threads\n",
            "2022-05-22 23:42:30,980 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 4 more threads\n",
            "2022-05-22 23:42:30,998 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 3 more threads\n",
            "2022-05-22 23:42:31,011 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 2 more threads\n",
            "2022-05-22 23:42:31,018 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 1 more threads\n",
            "2022-05-22 23:42:31,022 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 0 more threads\n",
            "2022-05-22 23:42:31,023 | INFO | base_any2vec.py:1346 | _log_epoch_end | EPOCH - 5 : training on 497185 raw words (447577 effective words) took 5.5s, 80684 effective words/s\n",
            "2022-05-22 23:42:33,686 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 6 - PROGRESS: at 3.99% examples, 6848 words/s, in_qsize 48, out_qsize 0\n",
            "2022-05-22 23:42:34,788 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 6 - PROGRESS: at 33.61% examples, 40449 words/s, in_qsize 31, out_qsize 3\n",
            "2022-05-22 23:42:34,825 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 31 more threads\n",
            "2022-05-22 23:42:34,830 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 30 more threads\n",
            "2022-05-22 23:42:34,860 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 29 more threads\n",
            "2022-05-22 23:42:34,889 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 28 more threads\n",
            "2022-05-22 23:42:34,891 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 27 more threads\n",
            "2022-05-22 23:42:34,892 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 26 more threads\n",
            "2022-05-22 23:42:34,893 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 25 more threads\n",
            "2022-05-22 23:42:34,894 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 24 more threads\n",
            "2022-05-22 23:42:34,895 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 23 more threads\n",
            "2022-05-22 23:42:34,896 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 22 more threads\n",
            "2022-05-22 23:42:34,904 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 21 more threads\n",
            "2022-05-22 23:42:34,923 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 20 more threads\n",
            "2022-05-22 23:42:34,924 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 19 more threads\n",
            "2022-05-22 23:42:34,924 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 18 more threads\n",
            "2022-05-22 23:42:34,980 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 17 more threads\n",
            "2022-05-22 23:42:36,058 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 6 - PROGRESS: at 64.33% examples, 61048 words/s, in_qsize 16, out_qsize 1\n",
            "2022-05-22 23:42:36,060 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 16 more threads\n",
            "2022-05-22 23:42:36,144 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 15 more threads\n",
            "2022-05-22 23:42:36,355 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 14 more threads\n",
            "2022-05-22 23:42:36,417 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 13 more threads\n",
            "2022-05-22 23:42:36,441 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 12 more threads\n",
            "2022-05-22 23:42:36,460 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 11 more threads\n",
            "2022-05-22 23:42:36,461 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 10 more threads\n",
            "2022-05-22 23:42:36,478 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 9 more threads\n",
            "2022-05-22 23:42:36,497 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 8 more threads\n",
            "2022-05-22 23:42:36,516 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 7 more threads\n",
            "2022-05-22 23:42:36,522 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 6 more threads\n",
            "2022-05-22 23:42:36,529 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 5 more threads\n",
            "2022-05-22 23:42:36,530 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 4 more threads\n",
            "2022-05-22 23:42:36,533 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 3 more threads\n",
            "2022-05-22 23:42:36,538 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 2 more threads\n",
            "2022-05-22 23:42:36,547 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 1 more threads\n",
            "2022-05-22 23:42:36,558 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 0 more threads\n",
            "2022-05-22 23:42:36,558 | INFO | base_any2vec.py:1346 | _log_epoch_end | EPOCH - 6 : training on 497185 raw words (447474 effective words) took 5.5s, 81059 effective words/s\n",
            "2022-05-22 23:42:38,103 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 7 - PROGRESS: at 4.71% examples, 11456 words/s, in_qsize 48, out_qsize 0\n",
            "2022-05-22 23:42:39,751 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 7 - PROGRESS: at 8.70% examples, 11191 words/s, in_qsize 46, out_qsize 0\n",
            "2022-05-22 23:42:40,577 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 31 more threads\n",
            "2022-05-22 23:42:40,595 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 30 more threads\n",
            "2022-05-22 23:42:40,612 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 29 more threads\n",
            "2022-05-22 23:42:40,621 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 28 more threads\n",
            "2022-05-22 23:42:40,622 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 27 more threads\n",
            "2022-05-22 23:42:40,632 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 26 more threads\n",
            "2022-05-22 23:42:40,636 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 25 more threads\n",
            "2022-05-22 23:42:40,638 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 24 more threads\n",
            "2022-05-22 23:42:40,656 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 23 more threads\n",
            "2022-05-22 23:42:40,662 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 22 more threads\n",
            "2022-05-22 23:42:40,663 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 21 more threads\n",
            "2022-05-22 23:42:40,665 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 20 more threads\n",
            "2022-05-22 23:42:40,695 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 19 more threads\n",
            "2022-05-22 23:42:40,705 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 18 more threads\n",
            "2022-05-22 23:42:40,707 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 17 more threads\n",
            "2022-05-22 23:42:40,776 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 7 - PROGRESS: at 64.33% examples, 72999 words/s, in_qsize 16, out_qsize 1\n",
            "2022-05-22 23:42:40,778 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 16 more threads\n",
            "2022-05-22 23:42:41,373 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 15 more threads\n",
            "2022-05-22 23:42:41,790 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 7 - PROGRESS: at 68.39% examples, 62266 words/s, in_qsize 14, out_qsize 1\n",
            "2022-05-22 23:42:41,796 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 14 more threads\n",
            "2022-05-22 23:42:41,804 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 13 more threads\n",
            "2022-05-22 23:42:41,862 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 12 more threads\n",
            "2022-05-22 23:42:41,874 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 11 more threads\n",
            "2022-05-22 23:42:42,047 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 10 more threads\n",
            "2022-05-22 23:42:42,092 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 9 more threads\n",
            "2022-05-22 23:42:42,098 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 8 more threads\n",
            "2022-05-22 23:42:42,105 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 7 more threads\n",
            "2022-05-22 23:42:42,108 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 6 more threads\n",
            "2022-05-22 23:42:42,110 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 5 more threads\n",
            "2022-05-22 23:42:42,113 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 4 more threads\n",
            "2022-05-22 23:42:42,130 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 3 more threads\n",
            "2022-05-22 23:42:42,148 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 2 more threads\n",
            "2022-05-22 23:42:42,150 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 1 more threads\n",
            "2022-05-22 23:42:42,160 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 0 more threads\n",
            "2022-05-22 23:42:42,161 | INFO | base_any2vec.py:1346 | _log_epoch_end | EPOCH - 7 : training on 497185 raw words (447528 effective words) took 5.6s, 80127 effective words/s\n",
            "2022-05-22 23:42:44,302 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 8 - PROGRESS: at 2.08% examples, 4190 words/s, in_qsize 49, out_qsize 0\n",
            "2022-05-22 23:42:45,374 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 8 - PROGRESS: at 11.06% examples, 13952 words/s, in_qsize 43, out_qsize 2\n",
            "2022-05-22 23:42:45,960 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 31 more threads\n",
            "2022-05-22 23:42:45,971 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 30 more threads\n",
            "2022-05-22 23:42:45,980 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 29 more threads\n",
            "2022-05-22 23:42:45,991 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 28 more threads\n",
            "2022-05-22 23:42:46,004 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 27 more threads\n",
            "2022-05-22 23:42:46,008 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 26 more threads\n",
            "2022-05-22 23:42:46,010 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 25 more threads\n",
            "2022-05-22 23:42:46,014 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 24 more threads\n",
            "2022-05-22 23:42:46,077 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 23 more threads\n",
            "2022-05-22 23:42:46,078 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 22 more threads\n",
            "2022-05-22 23:42:46,120 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 21 more threads\n",
            "2022-05-22 23:42:46,122 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 20 more threads\n",
            "2022-05-22 23:42:46,166 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 19 more threads\n",
            "2022-05-22 23:42:46,231 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 18 more threads\n",
            "2022-05-22 23:42:46,932 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 8 - PROGRESS: at 62.61% examples, 62559 words/s, in_qsize 17, out_qsize 1\n",
            "2022-05-22 23:42:46,933 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 17 more threads\n",
            "2022-05-22 23:42:47,167 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 16 more threads\n",
            "2022-05-22 23:42:47,335 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 15 more threads\n",
            "2022-05-22 23:42:47,362 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 14 more threads\n",
            "2022-05-22 23:42:47,433 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 13 more threads\n",
            "2022-05-22 23:42:47,453 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 12 more threads\n",
            "2022-05-22 23:42:47,479 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 11 more threads\n",
            "2022-05-22 23:42:47,500 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 10 more threads\n",
            "2022-05-22 23:42:47,507 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 9 more threads\n",
            "2022-05-22 23:42:47,512 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 8 more threads\n",
            "2022-05-22 23:42:47,525 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 7 more threads\n",
            "2022-05-22 23:42:47,580 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 6 more threads\n",
            "2022-05-22 23:42:47,585 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 5 more threads\n",
            "2022-05-22 23:42:47,600 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 4 more threads\n",
            "2022-05-22 23:42:47,613 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 3 more threads\n",
            "2022-05-22 23:42:47,629 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 2 more threads\n",
            "2022-05-22 23:42:47,639 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 1 more threads\n",
            "2022-05-22 23:42:47,640 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 0 more threads\n",
            "2022-05-22 23:42:47,646 | INFO | base_any2vec.py:1346 | _log_epoch_end | EPOCH - 8 : training on 497185 raw words (447491 effective words) took 5.5s, 81825 effective words/s\n",
            "2022-05-22 23:42:50,127 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 9 - PROGRESS: at 4.71% examples, 7074 words/s, in_qsize 48, out_qsize 0\n",
            "2022-05-22 23:42:51,167 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 9 - PROGRESS: at 10.37% examples, 12794 words/s, in_qsize 43, out_qsize 2\n",
            "2022-05-22 23:42:51,327 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 31 more threads\n",
            "2022-05-22 23:42:51,346 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 30 more threads\n",
            "2022-05-22 23:42:51,394 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 29 more threads\n",
            "2022-05-22 23:42:51,437 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 28 more threads\n",
            "2022-05-22 23:42:51,439 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 27 more threads\n",
            "2022-05-22 23:42:51,446 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 26 more threads\n",
            "2022-05-22 23:42:51,447 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 25 more threads\n",
            "2022-05-22 23:42:51,458 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 24 more threads\n",
            "2022-05-22 23:42:51,480 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 23 more threads\n",
            "2022-05-22 23:42:51,502 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 22 more threads\n",
            "2022-05-22 23:42:51,503 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 21 more threads\n",
            "2022-05-22 23:42:51,509 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 20 more threads\n",
            "2022-05-22 23:42:51,516 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 19 more threads\n",
            "2022-05-22 23:42:51,559 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 18 more threads\n",
            "2022-05-22 23:42:51,570 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 17 more threads\n",
            "2022-05-22 23:42:52,370 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 9 - PROGRESS: at 64.33% examples, 65089 words/s, in_qsize 16, out_qsize 1\n",
            "2022-05-22 23:42:52,371 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 16 more threads\n",
            "2022-05-22 23:42:52,656 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 15 more threads\n",
            "2022-05-22 23:42:52,713 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 14 more threads\n",
            "2022-05-22 23:42:52,887 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 13 more threads\n",
            "2022-05-22 23:42:52,914 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 12 more threads\n",
            "2022-05-22 23:42:52,917 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 11 more threads\n",
            "2022-05-22 23:42:52,975 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 10 more threads\n",
            "2022-05-22 23:42:52,981 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 9 more threads\n",
            "2022-05-22 23:42:52,983 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 8 more threads\n",
            "2022-05-22 23:42:53,003 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 7 more threads\n",
            "2022-05-22 23:42:53,012 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 6 more threads\n",
            "2022-05-22 23:42:53,014 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 5 more threads\n",
            "2022-05-22 23:42:53,024 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 4 more threads\n",
            "2022-05-22 23:42:53,033 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 3 more threads\n",
            "2022-05-22 23:42:53,035 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 2 more threads\n",
            "2022-05-22 23:42:53,047 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 1 more threads\n",
            "2022-05-22 23:42:53,051 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 0 more threads\n",
            "2022-05-22 23:42:53,052 | INFO | base_any2vec.py:1346 | _log_epoch_end | EPOCH - 9 : training on 497185 raw words (447544 effective words) took 5.4s, 82983 effective words/s\n",
            "2022-05-22 23:42:54,939 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 10 - PROGRESS: at 2.08% examples, 4761 words/s, in_qsize 48, out_qsize 1\n",
            "2022-05-22 23:42:56,210 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 10 - PROGRESS: at 9.11% examples, 11266 words/s, in_qsize 44, out_qsize 2\n",
            "2022-05-22 23:42:56,859 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 31 more threads\n",
            "2022-05-22 23:42:56,909 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 30 more threads\n",
            "2022-05-22 23:42:56,963 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 29 more threads\n",
            "2022-05-22 23:42:56,992 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 28 more threads\n",
            "2022-05-22 23:42:57,026 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 27 more threads\n",
            "2022-05-22 23:42:57,064 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 26 more threads\n",
            "2022-05-22 23:42:57,070 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 25 more threads\n",
            "2022-05-22 23:42:57,079 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 24 more threads\n",
            "2022-05-22 23:42:57,092 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 23 more threads\n",
            "2022-05-22 23:42:57,121 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 22 more threads\n",
            "2022-05-22 23:42:57,123 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 21 more threads\n",
            "2022-05-22 23:42:57,159 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 20 more threads\n",
            "2022-05-22 23:42:57,214 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 10 - PROGRESS: at 59.19% examples, 67302 words/s, in_qsize 18, out_qsize 3\n",
            "2022-05-22 23:42:57,215 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 19 more threads\n",
            "2022-05-22 23:42:57,220 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 18 more threads\n",
            "2022-05-22 23:42:57,742 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 17 more threads\n",
            "2022-05-22 23:42:57,774 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 16 more threads\n",
            "2022-05-22 23:42:58,147 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 15 more threads\n",
            "2022-05-22 23:42:58,324 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 10 - PROGRESS: at 67.91% examples, 61361 words/s, in_qsize 14, out_qsize 1\n",
            "2022-05-22 23:42:58,326 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 14 more threads\n",
            "2022-05-22 23:42:58,371 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 13 more threads\n",
            "2022-05-22 23:42:58,402 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 12 more threads\n",
            "2022-05-22 23:42:58,441 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 11 more threads\n",
            "2022-05-22 23:42:58,480 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 10 more threads\n",
            "2022-05-22 23:42:58,482 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 9 more threads\n",
            "2022-05-22 23:42:58,484 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 8 more threads\n",
            "2022-05-22 23:42:58,501 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 7 more threads\n",
            "2022-05-22 23:42:58,516 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 6 more threads\n",
            "2022-05-22 23:42:58,518 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 5 more threads\n",
            "2022-05-22 23:42:58,523 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 4 more threads\n",
            "2022-05-22 23:42:58,525 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 3 more threads\n",
            "2022-05-22 23:42:58,535 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 2 more threads\n",
            "2022-05-22 23:42:58,552 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 1 more threads\n",
            "2022-05-22 23:42:58,556 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 0 more threads\n",
            "2022-05-22 23:42:58,557 | INFO | base_any2vec.py:1346 | _log_epoch_end | EPOCH - 10 : training on 497185 raw words (447650 effective words) took 5.5s, 81537 effective words/s\n",
            "2022-05-22 23:42:59,727 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 11 - PROGRESS: at 2.08% examples, 7717 words/s, in_qsize 49, out_qsize 0\n",
            "2022-05-22 23:43:01,318 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 11 - PROGRESS: at 4.51% examples, 6477 words/s, in_qsize 46, out_qsize 2\n",
            "2022-05-22 23:43:02,406 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 11 - PROGRESS: at 29.14% examples, 35064 words/s, in_qsize 34, out_qsize 1\n",
            "2022-05-22 23:43:02,436 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 31 more threads\n",
            "2022-05-22 23:43:02,447 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 30 more threads\n",
            "2022-05-22 23:43:02,452 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 29 more threads\n",
            "2022-05-22 23:43:02,456 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 28 more threads\n",
            "2022-05-22 23:43:02,459 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 27 more threads\n",
            "2022-05-22 23:43:02,472 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 26 more threads\n",
            "2022-05-22 23:43:02,515 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 25 more threads\n",
            "2022-05-22 23:43:02,517 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 24 more threads\n",
            "2022-05-22 23:43:02,560 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 23 more threads\n",
            "2022-05-22 23:43:02,566 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 22 more threads\n",
            "2022-05-22 23:43:02,572 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 21 more threads\n",
            "2022-05-22 23:43:02,588 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 20 more threads\n",
            "2022-05-22 23:43:02,595 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 19 more threads\n",
            "2022-05-22 23:43:02,618 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 18 more threads\n",
            "2022-05-22 23:43:02,819 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 17 more threads\n",
            "2022-05-22 23:43:03,637 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 11 - PROGRESS: at 64.36% examples, 60560 words/s, in_qsize 16, out_qsize 1\n",
            "2022-05-22 23:43:03,644 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 16 more threads\n",
            "2022-05-22 23:43:03,660 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 15 more threads\n",
            "2022-05-22 23:43:03,708 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 14 more threads\n",
            "2022-05-22 23:43:03,718 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 13 more threads\n",
            "2022-05-22 23:43:03,849 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 12 more threads\n",
            "2022-05-22 23:43:03,932 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 11 more threads\n",
            "2022-05-22 23:43:03,960 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 10 more threads\n",
            "2022-05-22 23:43:03,962 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 9 more threads\n",
            "2022-05-22 23:43:03,977 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 8 more threads\n",
            "2022-05-22 23:43:04,000 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 7 more threads\n",
            "2022-05-22 23:43:04,003 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 6 more threads\n",
            "2022-05-22 23:43:04,016 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 5 more threads\n",
            "2022-05-22 23:43:04,022 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 4 more threads\n",
            "2022-05-22 23:43:04,022 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 3 more threads\n",
            "2022-05-22 23:43:04,033 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 2 more threads\n",
            "2022-05-22 23:43:04,037 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 1 more threads\n",
            "2022-05-22 23:43:04,057 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 0 more threads\n",
            "2022-05-22 23:43:04,058 | INFO | base_any2vec.py:1346 | _log_epoch_end | EPOCH - 11 : training on 497185 raw words (447574 effective words) took 5.5s, 81591 effective words/s\n",
            "2022-05-22 23:43:06,233 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 12 - PROGRESS: at 2.63% examples, 3958 words/s, in_qsize 49, out_qsize 0\n",
            "2022-05-22 23:43:07,292 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 12 - PROGRESS: at 17.06% examples, 22249 words/s, in_qsize 42, out_qsize 0\n",
            "2022-05-22 23:43:07,934 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 31 more threads\n",
            "2022-05-22 23:43:07,967 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 30 more threads\n",
            "2022-05-22 23:43:08,006 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 29 more threads\n",
            "2022-05-22 23:43:08,013 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 28 more threads\n",
            "2022-05-22 23:43:08,020 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 27 more threads\n",
            "2022-05-22 23:43:08,024 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 26 more threads\n",
            "2022-05-22 23:43:08,032 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 25 more threads\n",
            "2022-05-22 23:43:08,044 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 24 more threads\n",
            "2022-05-22 23:43:08,060 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 23 more threads\n",
            "2022-05-22 23:43:08,065 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 22 more threads\n",
            "2022-05-22 23:43:08,071 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 21 more threads\n",
            "2022-05-22 23:43:08,087 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 20 more threads\n",
            "2022-05-22 23:43:08,095 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 19 more threads\n",
            "2022-05-22 23:43:08,107 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 18 more threads\n",
            "2022-05-22 23:43:08,917 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 12 - PROGRESS: at 62.61% examples, 61424 words/s, in_qsize 17, out_qsize 1\n",
            "2022-05-22 23:43:08,919 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 17 more threads\n",
            "2022-05-22 23:43:09,086 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 16 more threads\n",
            "2022-05-22 23:43:09,178 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 15 more threads\n",
            "2022-05-22 23:43:09,325 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 14 more threads\n",
            "2022-05-22 23:43:09,342 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 13 more threads\n",
            "2022-05-22 23:43:09,350 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 12 more threads\n",
            "2022-05-22 23:43:09,364 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 11 more threads\n",
            "2022-05-22 23:43:09,401 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 10 more threads\n",
            "2022-05-22 23:43:09,430 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 9 more threads\n",
            "2022-05-22 23:43:09,465 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 8 more threads\n",
            "2022-05-22 23:43:09,476 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 7 more threads\n",
            "2022-05-22 23:43:09,490 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 6 more threads\n",
            "2022-05-22 23:43:09,508 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 5 more threads\n",
            "2022-05-22 23:43:09,529 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 4 more threads\n",
            "2022-05-22 23:43:09,545 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 3 more threads\n",
            "2022-05-22 23:43:09,563 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 2 more threads\n",
            "2022-05-22 23:43:09,578 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 1 more threads\n",
            "2022-05-22 23:43:09,587 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 0 more threads\n",
            "2022-05-22 23:43:09,588 | INFO | base_any2vec.py:1346 | _log_epoch_end | EPOCH - 12 : training on 497185 raw words (447494 effective words) took 5.5s, 81172 effective words/s\n",
            "2022-05-22 23:43:11,332 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 13 - PROGRESS: at 4.51% examples, 10301 words/s, in_qsize 48, out_qsize 0\n",
            "2022-05-22 23:43:12,586 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 13 - PROGRESS: at 8.29% examples, 12072 words/s, in_qsize 46, out_qsize 0\n",
            "2022-05-22 23:43:13,528 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 31 more threads\n",
            "2022-05-22 23:43:13,533 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 30 more threads\n",
            "2022-05-22 23:43:13,543 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 29 more threads\n",
            "2022-05-22 23:43:13,568 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 28 more threads\n",
            "2022-05-22 23:43:13,589 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 13 - PROGRESS: at 43.22% examples, 52081 words/s, in_qsize 17, out_qsize 21\n",
            "2022-05-22 23:43:13,593 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 27 more threads\n",
            "2022-05-22 23:43:13,598 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 26 more threads\n",
            "2022-05-22 23:43:13,610 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 25 more threads\n",
            "2022-05-22 23:43:13,619 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 24 more threads\n",
            "2022-05-22 23:43:13,642 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 23 more threads\n",
            "2022-05-22 23:43:13,658 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 22 more threads\n",
            "2022-05-22 23:43:13,661 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 21 more threads\n",
            "2022-05-22 23:43:13,680 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 20 more threads\n",
            "2022-05-22 23:43:13,683 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 19 more threads\n",
            "2022-05-22 23:43:13,686 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 18 more threads\n",
            "2022-05-22 23:43:13,708 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 17 more threads\n",
            "2022-05-22 23:43:14,082 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 16 more threads\n",
            "2022-05-22 23:43:14,384 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 15 more threads\n",
            "2022-05-22 23:43:14,489 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 14 more threads\n",
            "2022-05-22 23:43:14,701 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 13 - PROGRESS: at 71.07% examples, 65535 words/s, in_qsize 13, out_qsize 1\n",
            "2022-05-22 23:43:14,703 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 13 more threads\n",
            "2022-05-22 23:43:14,723 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 12 more threads\n",
            "2022-05-22 23:43:14,785 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 11 more threads\n",
            "2022-05-22 23:43:14,806 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 10 more threads\n",
            "2022-05-22 23:43:14,872 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 9 more threads\n",
            "2022-05-22 23:43:14,911 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 8 more threads\n",
            "2022-05-22 23:43:14,943 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 7 more threads\n",
            "2022-05-22 23:43:14,980 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 6 more threads\n",
            "2022-05-22 23:43:14,983 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 5 more threads\n",
            "2022-05-22 23:43:15,000 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 4 more threads\n",
            "2022-05-22 23:43:15,018 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 3 more threads\n",
            "2022-05-22 23:43:15,020 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 2 more threads\n",
            "2022-05-22 23:43:15,027 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 1 more threads\n",
            "2022-05-22 23:43:15,030 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 0 more threads\n",
            "2022-05-22 23:43:15,031 | INFO | base_any2vec.py:1346 | _log_epoch_end | EPOCH - 13 : training on 497185 raw words (447606 effective words) took 5.4s, 82501 effective words/s\n",
            "2022-05-22 23:43:17,195 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 14 - PROGRESS: at 2.63% examples, 4017 words/s, in_qsize 49, out_qsize 0\n",
            "2022-05-22 23:43:18,303 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 14 - PROGRESS: at 13.08% examples, 16509 words/s, in_qsize 43, out_qsize 1\n",
            "2022-05-22 23:43:18,940 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 31 more threads\n",
            "2022-05-22 23:43:18,949 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 30 more threads\n",
            "2022-05-22 23:43:18,967 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 29 more threads\n",
            "2022-05-22 23:43:18,970 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 28 more threads\n",
            "2022-05-22 23:43:18,978 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 27 more threads\n",
            "2022-05-22 23:43:18,979 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 26 more threads\n",
            "2022-05-22 23:43:18,984 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 25 more threads\n",
            "2022-05-22 23:43:18,985 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 24 more threads\n",
            "2022-05-22 23:43:19,045 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 23 more threads\n",
            "2022-05-22 23:43:19,046 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 22 more threads\n",
            "2022-05-22 23:43:19,049 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 21 more threads\n",
            "2022-05-22 23:43:19,050 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 20 more threads\n",
            "2022-05-22 23:43:19,106 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 19 more threads\n",
            "2022-05-22 23:43:19,108 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 18 more threads\n",
            "2022-05-22 23:43:19,895 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 14 - PROGRESS: at 62.61% examples, 61549 words/s, in_qsize 17, out_qsize 1\n",
            "2022-05-22 23:43:19,897 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 17 more threads\n",
            "2022-05-22 23:43:19,929 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 16 more threads\n",
            "2022-05-22 23:43:20,276 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 15 more threads\n",
            "2022-05-22 23:43:20,334 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 14 more threads\n",
            "2022-05-22 23:43:20,386 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 13 more threads\n",
            "2022-05-22 23:43:20,395 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 12 more threads\n",
            "2022-05-22 23:43:20,418 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 11 more threads\n",
            "2022-05-22 23:43:20,436 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 10 more threads\n",
            "2022-05-22 23:43:20,458 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 9 more threads\n",
            "2022-05-22 23:43:20,467 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 8 more threads\n",
            "2022-05-22 23:43:20,484 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 7 more threads\n",
            "2022-05-22 23:43:20,520 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 6 more threads\n",
            "2022-05-22 23:43:20,523 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 5 more threads\n",
            "2022-05-22 23:43:20,531 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 4 more threads\n",
            "2022-05-22 23:43:20,538 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 3 more threads\n",
            "2022-05-22 23:43:20,547 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 2 more threads\n",
            "2022-05-22 23:43:20,559 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 1 more threads\n",
            "2022-05-22 23:43:20,564 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 0 more threads\n",
            "2022-05-22 23:43:20,565 | INFO | base_any2vec.py:1346 | _log_epoch_end | EPOCH - 14 : training on 497185 raw words (447567 effective words) took 5.5s, 81312 effective words/s\n",
            "2022-05-22 23:43:21,902 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 15 - PROGRESS: at 2.08% examples, 6757 words/s, in_qsize 49, out_qsize 0\n",
            "2022-05-22 23:43:23,512 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 15 - PROGRESS: at 5.99% examples, 9282 words/s, in_qsize 47, out_qsize 0\n",
            "2022-05-22 23:43:24,511 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 31 more threads\n",
            "2022-05-22 23:43:24,517 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 15 - PROGRESS: at 40.22% examples, 45568 words/s, in_qsize 19, out_qsize 23\n",
            "2022-05-22 23:43:24,524 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 30 more threads\n",
            "2022-05-22 23:43:24,529 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 29 more threads\n",
            "2022-05-22 23:43:24,546 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 28 more threads\n",
            "2022-05-22 23:43:24,556 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 27 more threads\n",
            "2022-05-22 23:43:24,557 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 26 more threads\n",
            "2022-05-22 23:43:24,577 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 25 more threads\n",
            "2022-05-22 23:43:24,587 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 24 more threads\n",
            "2022-05-22 23:43:24,598 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 23 more threads\n",
            "2022-05-22 23:43:24,604 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 22 more threads\n",
            "2022-05-22 23:43:24,616 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 21 more threads\n",
            "2022-05-22 23:43:24,632 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 20 more threads\n",
            "2022-05-22 23:43:24,633 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 19 more threads\n",
            "2022-05-22 23:43:24,655 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 18 more threads\n",
            "2022-05-22 23:43:24,773 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 17 more threads\n",
            "2022-05-22 23:43:24,957 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 16 more threads\n",
            "2022-05-22 23:43:25,783 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 15 - PROGRESS: at 66.08% examples, 60740 words/s, in_qsize 15, out_qsize 1\n",
            "2022-05-22 23:43:25,785 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 15 more threads\n",
            "2022-05-22 23:43:25,850 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 14 more threads\n",
            "2022-05-22 23:43:25,872 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 13 more threads\n",
            "2022-05-22 23:43:25,957 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 12 more threads\n",
            "2022-05-22 23:43:25,995 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 11 more threads\n",
            "2022-05-22 23:43:26,032 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 10 more threads\n",
            "2022-05-22 23:43:26,061 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 9 more threads\n",
            "2022-05-22 23:43:26,067 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 8 more threads\n",
            "2022-05-22 23:43:26,078 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 7 more threads\n",
            "2022-05-22 23:43:26,105 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 6 more threads\n",
            "2022-05-22 23:43:26,112 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 5 more threads\n",
            "2022-05-22 23:43:26,117 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 4 more threads\n",
            "2022-05-22 23:43:26,124 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 3 more threads\n",
            "2022-05-22 23:43:26,126 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 2 more threads\n",
            "2022-05-22 23:43:26,130 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 1 more threads\n",
            "2022-05-22 23:43:26,139 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 0 more threads\n",
            "2022-05-22 23:43:26,140 | INFO | base_any2vec.py:1346 | _log_epoch_end | EPOCH - 15 : training on 497185 raw words (447746 effective words) took 5.6s, 80564 effective words/s\n",
            "2022-05-22 23:43:28,343 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 16 - PROGRESS: at 2.08% examples, 4069 words/s, in_qsize 49, out_qsize 0\n",
            "2022-05-22 23:43:29,580 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 16 - PROGRESS: at 14.67% examples, 18292 words/s, in_qsize 39, out_qsize 4\n",
            "2022-05-22 23:43:30,027 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 31 more threads\n",
            "2022-05-22 23:43:30,029 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 30 more threads\n",
            "2022-05-22 23:43:30,035 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 29 more threads\n",
            "2022-05-22 23:43:30,049 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 28 more threads\n",
            "2022-05-22 23:43:30,063 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 27 more threads\n",
            "2022-05-22 23:43:30,070 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 26 more threads\n",
            "2022-05-22 23:43:30,079 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 25 more threads\n",
            "2022-05-22 23:43:30,080 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 24 more threads\n",
            "2022-05-22 23:43:30,152 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 23 more threads\n",
            "2022-05-22 23:43:30,193 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 22 more threads\n",
            "2022-05-22 23:43:30,225 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 21 more threads\n",
            "2022-05-22 23:43:30,248 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 20 more threads\n",
            "2022-05-22 23:43:30,252 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 19 more threads\n",
            "2022-05-22 23:43:30,312 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 18 more threads\n",
            "2022-05-22 23:43:31,013 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 16 - PROGRESS: at 62.61% examples, 61219 words/s, in_qsize 17, out_qsize 1\n",
            "2022-05-22 23:43:31,015 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 17 more threads\n",
            "2022-05-22 23:43:31,211 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 16 more threads\n",
            "2022-05-22 23:43:31,277 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 15 more threads\n",
            "2022-05-22 23:43:31,355 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 14 more threads\n",
            "2022-05-22 23:43:31,376 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 13 more threads\n",
            "2022-05-22 23:43:31,422 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 12 more threads\n",
            "2022-05-22 23:43:31,505 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 11 more threads\n",
            "2022-05-22 23:43:31,534 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 10 more threads\n",
            "2022-05-22 23:43:31,542 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 9 more threads\n",
            "2022-05-22 23:43:31,548 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 8 more threads\n",
            "2022-05-22 23:43:31,568 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 7 more threads\n",
            "2022-05-22 23:43:31,592 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 6 more threads\n",
            "2022-05-22 23:43:31,600 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 5 more threads\n",
            "2022-05-22 23:43:31,634 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 4 more threads\n",
            "2022-05-22 23:43:31,641 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 3 more threads\n",
            "2022-05-22 23:43:31,645 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 2 more threads\n",
            "2022-05-22 23:43:31,648 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 1 more threads\n",
            "2022-05-22 23:43:31,649 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 0 more threads\n",
            "2022-05-22 23:43:31,650 | INFO | base_any2vec.py:1346 | _log_epoch_end | EPOCH - 16 : training on 497185 raw words (447514 effective words) took 5.5s, 81437 effective words/s\n",
            "2022-05-22 23:43:33,802 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 17 - PROGRESS: at 2.08% examples, 4166 words/s, in_qsize 49, out_qsize 0\n",
            "2022-05-22 23:43:34,870 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 17 - PROGRESS: at 11.10% examples, 13904 words/s, in_qsize 41, out_qsize 4\n",
            "2022-05-22 23:43:35,442 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 31 more threads\n",
            "2022-05-22 23:43:35,454 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 30 more threads\n",
            "2022-05-22 23:43:35,458 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 29 more threads\n",
            "2022-05-22 23:43:35,461 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 28 more threads\n",
            "2022-05-22 23:43:35,468 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 27 more threads\n",
            "2022-05-22 23:43:35,471 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 26 more threads\n",
            "2022-05-22 23:43:35,474 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 25 more threads\n",
            "2022-05-22 23:43:35,492 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 24 more threads\n",
            "2022-05-22 23:43:35,571 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 23 more threads\n",
            "2022-05-22 23:43:35,640 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 22 more threads\n",
            "2022-05-22 23:43:35,695 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 21 more threads\n",
            "2022-05-22 23:43:35,739 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 20 more threads\n",
            "2022-05-22 23:43:35,749 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 19 more threads\n",
            "2022-05-22 23:43:35,754 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 18 more threads\n",
            "2022-05-22 23:43:36,374 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 17 - PROGRESS: at 62.61% examples, 63214 words/s, in_qsize 17, out_qsize 1\n",
            "2022-05-22 23:43:36,375 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 17 more threads\n",
            "2022-05-22 23:43:36,710 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 16 more threads\n",
            "2022-05-22 23:43:36,796 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 15 more threads\n",
            "2022-05-22 23:43:36,877 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 14 more threads\n",
            "2022-05-22 23:43:36,908 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 13 more threads\n",
            "2022-05-22 23:43:36,912 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 12 more threads\n",
            "2022-05-22 23:43:36,927 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 11 more threads\n",
            "2022-05-22 23:43:36,938 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 10 more threads\n",
            "2022-05-22 23:43:36,968 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 9 more threads\n",
            "2022-05-22 23:43:36,974 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 8 more threads\n",
            "2022-05-22 23:43:36,975 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 7 more threads\n",
            "2022-05-22 23:43:37,015 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 6 more threads\n",
            "2022-05-22 23:43:37,020 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 5 more threads\n",
            "2022-05-22 23:43:37,044 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 4 more threads\n",
            "2022-05-22 23:43:37,054 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 3 more threads\n",
            "2022-05-22 23:43:37,070 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 2 more threads\n",
            "2022-05-22 23:43:37,086 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 1 more threads\n",
            "2022-05-22 23:43:37,087 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 0 more threads\n",
            "2022-05-22 23:43:37,091 | INFO | base_any2vec.py:1346 | _log_epoch_end | EPOCH - 17 : training on 497185 raw words (447483 effective words) took 5.4s, 82508 effective words/s\n",
            "2022-05-22 23:43:39,577 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 18 - PROGRESS: at 4.71% examples, 7083 words/s, in_qsize 47, out_qsize 1\n",
            "2022-05-22 23:43:40,955 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 18 - PROGRESS: at 20.75% examples, 23143 words/s, in_qsize 32, out_qsize 8\n",
            "2022-05-22 23:43:40,981 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 31 more threads\n",
            "2022-05-22 23:43:40,988 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 30 more threads\n",
            "2022-05-22 23:43:41,008 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 29 more threads\n",
            "2022-05-22 23:43:41,008 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 28 more threads\n",
            "2022-05-22 23:43:41,013 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 27 more threads\n",
            "2022-05-22 23:43:41,018 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 26 more threads\n",
            "2022-05-22 23:43:41,031 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 25 more threads\n",
            "2022-05-22 23:43:41,039 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 24 more threads\n",
            "2022-05-22 23:43:41,052 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 23 more threads\n",
            "2022-05-22 23:43:41,057 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 22 more threads\n",
            "2022-05-22 23:43:41,070 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 21 more threads\n",
            "2022-05-22 23:43:41,078 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 20 more threads\n",
            "2022-05-22 23:43:41,100 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 19 more threads\n",
            "2022-05-22 23:43:41,118 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 18 more threads\n",
            "2022-05-22 23:43:41,137 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 17 more threads\n",
            "2022-05-22 23:43:41,852 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 16 more threads\n",
            "2022-05-22 23:43:41,939 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 15 more threads\n",
            "2022-05-22 23:43:42,153 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 18 - PROGRESS: at 68.38% examples, 64396 words/s, in_qsize 14, out_qsize 1\n",
            "2022-05-22 23:43:42,161 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 14 more threads\n",
            "2022-05-22 23:43:42,223 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 13 more threads\n",
            "2022-05-22 23:43:42,244 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 12 more threads\n",
            "2022-05-22 23:43:42,267 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 11 more threads\n",
            "2022-05-22 23:43:42,292 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 10 more threads\n",
            "2022-05-22 23:43:42,308 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 9 more threads\n",
            "2022-05-22 23:43:42,416 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 8 more threads\n",
            "2022-05-22 23:43:42,423 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 7 more threads\n",
            "2022-05-22 23:43:42,435 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 6 more threads\n",
            "2022-05-22 23:43:42,449 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 5 more threads\n",
            "2022-05-22 23:43:42,465 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 4 more threads\n",
            "2022-05-22 23:43:42,482 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 3 more threads\n",
            "2022-05-22 23:43:42,490 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 2 more threads\n",
            "2022-05-22 23:43:42,496 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 1 more threads\n",
            "2022-05-22 23:43:42,504 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 0 more threads\n",
            "2022-05-22 23:43:42,505 | INFO | base_any2vec.py:1346 | _log_epoch_end | EPOCH - 18 : training on 497185 raw words (447675 effective words) took 5.4s, 82932 effective words/s\n",
            "2022-05-22 23:43:45,108 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 19 - PROGRESS: at 4.71% examples, 6761 words/s, in_qsize 48, out_qsize 0\n",
            "2022-05-22 23:43:46,343 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 19 - PROGRESS: at 18.24% examples, 21028 words/s, in_qsize 27, out_qsize 19\n",
            "2022-05-22 23:43:46,376 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 31 more threads\n",
            "2022-05-22 23:43:46,430 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 30 more threads\n",
            "2022-05-22 23:43:46,448 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 29 more threads\n",
            "2022-05-22 23:43:46,449 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 28 more threads\n",
            "2022-05-22 23:43:46,457 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 27 more threads\n",
            "2022-05-22 23:43:46,461 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 26 more threads\n",
            "2022-05-22 23:43:46,470 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 25 more threads\n",
            "2022-05-22 23:43:46,482 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 24 more threads\n",
            "2022-05-22 23:43:46,483 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 23 more threads\n",
            "2022-05-22 23:43:46,484 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 22 more threads\n",
            "2022-05-22 23:43:46,493 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 21 more threads\n",
            "2022-05-22 23:43:46,520 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 20 more threads\n",
            "2022-05-22 23:43:46,521 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 19 more threads\n",
            "2022-05-22 23:43:46,566 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 18 more threads\n",
            "2022-05-22 23:43:46,582 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 17 more threads\n",
            "2022-05-22 23:43:47,363 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 19 - PROGRESS: at 64.33% examples, 63339 words/s, in_qsize 16, out_qsize 1\n",
            "2022-05-22 23:43:47,365 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 16 more threads\n",
            "2022-05-22 23:43:47,547 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 15 more threads\n",
            "2022-05-22 23:43:47,556 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 14 more threads\n",
            "2022-05-22 23:43:47,689 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 13 more threads\n",
            "2022-05-22 23:43:47,743 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 12 more threads\n",
            "2022-05-22 23:43:47,745 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 11 more threads\n",
            "2022-05-22 23:43:47,857 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 10 more threads\n",
            "2022-05-22 23:43:47,859 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 9 more threads\n",
            "2022-05-22 23:43:47,894 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 8 more threads\n",
            "2022-05-22 23:43:47,924 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 7 more threads\n",
            "2022-05-22 23:43:47,925 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 6 more threads\n",
            "2022-05-22 23:43:47,962 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 5 more threads\n",
            "2022-05-22 23:43:47,966 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 4 more threads\n",
            "2022-05-22 23:43:47,983 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 3 more threads\n",
            "2022-05-22 23:43:47,989 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 2 more threads\n",
            "2022-05-22 23:43:47,997 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 1 more threads\n",
            "2022-05-22 23:43:48,008 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 0 more threads\n",
            "2022-05-22 23:43:48,010 | INFO | base_any2vec.py:1346 | _log_epoch_end | EPOCH - 19 : training on 497185 raw words (447529 effective words) took 5.5s, 81563 effective words/s\n",
            "2022-05-22 23:43:50,185 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 20 - PROGRESS: at 4.71% examples, 8079 words/s, in_qsize 48, out_qsize 0\n",
            "2022-05-22 23:43:51,257 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 20 - PROGRESS: at 8.20% examples, 11067 words/s, in_qsize 46, out_qsize 0\n",
            "2022-05-22 23:43:51,756 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 31 more threads\n",
            "2022-05-22 23:43:51,770 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 30 more threads\n",
            "2022-05-22 23:43:51,793 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 29 more threads\n",
            "2022-05-22 23:43:51,798 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 28 more threads\n",
            "2022-05-22 23:43:51,841 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 27 more threads\n",
            "2022-05-22 23:43:51,848 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 26 more threads\n",
            "2022-05-22 23:43:51,855 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 25 more threads\n",
            "2022-05-22 23:43:51,887 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 24 more threads\n",
            "2022-05-22 23:43:51,911 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 23 more threads\n",
            "2022-05-22 23:43:51,923 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 22 more threads\n",
            "2022-05-22 23:43:51,932 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 21 more threads\n",
            "2022-05-22 23:43:51,945 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 20 more threads\n",
            "2022-05-22 23:43:51,954 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 19 more threads\n",
            "2022-05-22 23:43:51,964 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 18 more threads\n",
            "2022-05-22 23:43:51,985 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 17 more threads\n",
            "2022-05-22 23:43:52,417 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 20 - PROGRESS: at 64.33% examples, 69785 words/s, in_qsize 16, out_qsize 1\n",
            "2022-05-22 23:43:52,422 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 16 more threads\n",
            "2022-05-22 23:43:52,778 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 15 more threads\n",
            "2022-05-22 23:43:52,941 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 14 more threads\n",
            "2022-05-22 23:43:52,980 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 13 more threads\n",
            "2022-05-22 23:43:53,253 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 12 more threads\n",
            "2022-05-22 23:43:53,366 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 11 more threads\n",
            "2022-05-22 23:43:53,372 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 10 more threads\n",
            "2022-05-22 23:43:53,374 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 9 more threads\n",
            "2022-05-22 23:43:53,376 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 8 more threads\n",
            "2022-05-22 23:43:53,387 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 7 more threads\n",
            "2022-05-22 23:43:53,422 | INFO | base_any2vec.py:1305 | _log_progress | EPOCH 20 - PROGRESS: at 87.15% examples, 72986 words/s, in_qsize 6, out_qsize 1\n",
            "2022-05-22 23:43:53,435 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 6 more threads\n",
            "2022-05-22 23:43:53,437 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 5 more threads\n",
            "2022-05-22 23:43:53,441 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 4 more threads\n",
            "2022-05-22 23:43:53,452 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 3 more threads\n",
            "2022-05-22 23:43:53,452 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 2 more threads\n",
            "2022-05-22 23:43:53,453 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 1 more threads\n",
            "2022-05-22 23:43:53,468 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 0 more threads\n",
            "2022-05-22 23:43:53,470 | INFO | base_any2vec.py:1346 | _log_epoch_end | EPOCH - 20 : training on 497185 raw words (447656 effective words) took 5.4s, 82191 effective words/s\n",
            "2022-05-22 23:43:53,472 | INFO | base_any2vec.py:1382 | _log_train_end | training on a 9943700 raw words (8951396 effective words) took 110.2s, 81228 effective words/s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wordvec_arrays = np.zeros((len(tokenized_emojiText), 50)) \n",
        "for i in range(len(tokenized_emojiText)):\n",
        "    wordvec_arrays[i,:] = word_vector(tokenized_emojiText[i], 50,modelFastTextSkipGramEmojiText)\n",
        "wordvec_emojiText = pd.DataFrame(wordvec_arrays)\n",
        "wordvec_emojiText.shape"
      ],
      "metadata": {
        "id": "yDJWDQfdvXMM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8d1b8d9-f888-447e-8f81-b18073fb604f"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(88514, 50)"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### mentions"
      ],
      "metadata": {
        "id": "HokoSe61vbLZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_mentions = df['mentions'].apply(lambda x: str(x).split()) # tokenizing\n",
        "modelFastTextSkipGramMentions = FastText(tokenized_mentions, \n",
        "                     size=50, # desired no. of features/independent variables\n",
        "                     window=2,  # context window size\n",
        "                     min_count=2, # Ignores all words with total frequency lower than 2.  \n",
        "                     workers=32, # no.of cores\n",
        "                     hs = 0,\n",
        "                     negative = 10, # for negative sampling\n",
        "                     sg=1  # 1 for Skipgram model\n",
        "                     )\n",
        "\n",
        "modelFastTextSkipGramMentions.build_vocab(tokenized_mentions, update=True)\n",
        "modelFastTextSkipGramMentions.train(tokenized_mentions, total_examples= len(tokenized_mentions), epochs=20)"
      ],
      "metadata": {
        "id": "VOW0YsHfvdGO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c84eb196-26e1-47c4-d711-7d49c87e3733"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-05-22 23:44:04,012 | WARNING | base_any2vec.py:723 | __init__ | consider setting layer size to a multiple of 4 for greater performance\n",
            "2022-05-22 23:44:04,014 | INFO | word2vec.py:1567 | scan_vocab | collecting all words and their counts\n",
            "2022-05-22 23:44:04,015 | INFO | word2vec.py:1552 | _scan_vocab | PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
            "2022-05-22 23:44:04,024 | INFO | word2vec.py:1552 | _scan_vocab | PROGRESS: at sentence #10000, processed 4754 words, keeping 2945 word types\n",
            "2022-05-22 23:44:04,032 | INFO | word2vec.py:1552 | _scan_vocab | PROGRESS: at sentence #20000, processed 9509 words, keeping 5724 word types\n",
            "2022-05-22 23:44:04,041 | INFO | word2vec.py:1552 | _scan_vocab | PROGRESS: at sentence #30000, processed 14594 words, keeping 8486 word types\n",
            "2022-05-22 23:44:04,047 | INFO | word2vec.py:1552 | _scan_vocab | PROGRESS: at sentence #40000, processed 19425 words, keeping 10973 word types\n",
            "2022-05-22 23:44:04,055 | INFO | word2vec.py:1552 | _scan_vocab | PROGRESS: at sentence #50000, processed 24270 words, keeping 13455 word types\n",
            "2022-05-22 23:44:04,061 | INFO | word2vec.py:1552 | _scan_vocab | PROGRESS: at sentence #60000, processed 29249 words, keeping 15919 word types\n",
            "2022-05-22 23:44:04,069 | INFO | word2vec.py:1552 | _scan_vocab | PROGRESS: at sentence #70000, processed 34172 words, keeping 18196 word types\n",
            "2022-05-22 23:44:04,082 | INFO | word2vec.py:1552 | _scan_vocab | PROGRESS: at sentence #80000, processed 39536 words, keeping 20626 word types\n",
            "2022-05-22 23:44:04,087 | INFO | word2vec.py:1575 | scan_vocab | collected 22591 word types from a corpus of 44236 raw words and 88514 sentences\n",
            "2022-05-22 23:44:04,090 | INFO | word2vec.py:1626 | prepare_vocab | Loading a fresh vocabulary\n",
            "2022-05-22 23:44:04,109 | INFO | word2vec.py:1650 | prepare_vocab | effective_min_count=2 retains 6721 unique words (29% of original 22591, drops 15870)\n",
            "2022-05-22 23:44:04,112 | INFO | word2vec.py:1656 | prepare_vocab | effective_min_count=2 leaves 28366 word corpus (64% of original 44236, drops 15870)\n",
            "2022-05-22 23:44:04,129 | INFO | word2vec.py:1715 | prepare_vocab | deleting the raw counts dictionary of 22591 items\n",
            "2022-05-22 23:44:04,132 | INFO | word2vec.py:1718 | prepare_vocab | sample=0.001 downsamples 14 most-common words\n",
            "2022-05-22 23:44:04,135 | INFO | word2vec.py:1721 | prepare_vocab | downsampling leaves estimated 27894 word corpus (98.3% of prior 28366)\n",
            "2022-05-22 23:44:04,327 | INFO | fasttext.py:551 | estimate_memory | estimated required memory for 6721 words, 130405 buckets and 50 dimensions: 35680620 bytes\n",
            "2022-05-22 23:44:04,331 | INFO | word2vec.py:1834 | reset_weights | resetting layer weights\n",
            "2022-05-22 23:44:05,795 | INFO | fasttext.py:1011 | init_ngrams_weights | Total number of ngrams is 130405\n",
            "2022-05-22 23:44:06,489 | INFO | base_any2vec.py:1210 | _check_training_sanity | training model with 32 workers on 6721 vocabulary and 50 features, using sg=1 hs=0 sample=0.001 negative=10 window=2\n",
            "2022-05-22 23:44:06,671 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 31 more threads\n",
            "2022-05-22 23:44:06,677 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 30 more threads\n",
            "2022-05-22 23:44:06,681 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 29 more threads\n",
            "2022-05-22 23:44:06,685 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 28 more threads\n",
            "2022-05-22 23:44:06,688 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 27 more threads\n",
            "2022-05-22 23:44:06,690 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 26 more threads\n",
            "2022-05-22 23:44:06,696 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 25 more threads\n",
            "2022-05-22 23:44:06,699 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 24 more threads\n",
            "2022-05-22 23:44:06,704 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 23 more threads\n",
            "2022-05-22 23:44:06,710 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 22 more threads\n",
            "2022-05-22 23:44:06,715 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 21 more threads\n",
            "2022-05-22 23:44:06,719 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 20 more threads\n",
            "2022-05-22 23:44:06,722 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 19 more threads\n",
            "2022-05-22 23:44:06,729 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 18 more threads\n",
            "2022-05-22 23:44:06,733 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 17 more threads\n",
            "2022-05-22 23:44:06,734 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 16 more threads\n",
            "2022-05-22 23:44:06,738 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 15 more threads\n",
            "2022-05-22 23:44:06,743 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 14 more threads\n",
            "2022-05-22 23:44:06,746 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 13 more threads\n",
            "2022-05-22 23:44:06,752 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 12 more threads\n",
            "2022-05-22 23:44:06,755 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 11 more threads\n",
            "2022-05-22 23:44:06,758 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 10 more threads\n",
            "2022-05-22 23:44:06,760 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 9 more threads\n",
            "2022-05-22 23:44:06,761 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 8 more threads\n",
            "2022-05-22 23:44:06,763 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 7 more threads\n",
            "2022-05-22 23:44:06,765 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 6 more threads\n",
            "2022-05-22 23:44:06,767 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 5 more threads\n",
            "2022-05-22 23:44:06,767 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 4 more threads\n",
            "2022-05-22 23:44:06,768 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 3 more threads\n",
            "2022-05-22 23:44:06,769 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 2 more threads\n",
            "2022-05-22 23:44:06,770 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 1 more threads\n",
            "2022-05-22 23:44:06,802 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 0 more threads\n",
            "2022-05-22 23:44:06,803 | INFO | base_any2vec.py:1346 | _log_epoch_end | EPOCH - 1 : training on 44236 raw words (27918 effective words) took 0.3s, 93928 effective words/s\n",
            "2022-05-22 23:44:06,997 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 31 more threads\n",
            "2022-05-22 23:44:07,000 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 30 more threads\n",
            "2022-05-22 23:44:07,003 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 29 more threads\n",
            "2022-05-22 23:44:07,004 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 28 more threads\n",
            "2022-05-22 23:44:07,005 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 27 more threads\n",
            "2022-05-22 23:44:07,006 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 26 more threads\n",
            "2022-05-22 23:44:07,009 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 25 more threads\n",
            "2022-05-22 23:44:07,010 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 24 more threads\n",
            "2022-05-22 23:44:07,011 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 23 more threads\n",
            "2022-05-22 23:44:07,012 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 22 more threads\n",
            "2022-05-22 23:44:07,017 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 21 more threads\n",
            "2022-05-22 23:44:07,018 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 20 more threads\n",
            "2022-05-22 23:44:07,019 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 19 more threads\n",
            "2022-05-22 23:44:07,020 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 18 more threads\n",
            "2022-05-22 23:44:07,021 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 17 more threads\n",
            "2022-05-22 23:44:07,022 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 16 more threads\n",
            "2022-05-22 23:44:07,023 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 15 more threads\n",
            "2022-05-22 23:44:07,024 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 14 more threads\n",
            "2022-05-22 23:44:07,025 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 13 more threads\n",
            "2022-05-22 23:44:07,026 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 12 more threads\n",
            "2022-05-22 23:44:07,027 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 11 more threads\n",
            "2022-05-22 23:44:07,028 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 10 more threads\n",
            "2022-05-22 23:44:07,029 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 9 more threads\n",
            "2022-05-22 23:44:07,030 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 8 more threads\n",
            "2022-05-22 23:44:07,042 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 7 more threads\n",
            "2022-05-22 23:44:07,043 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 6 more threads\n",
            "2022-05-22 23:44:07,044 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 5 more threads\n",
            "2022-05-22 23:44:07,049 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 4 more threads\n",
            "2022-05-22 23:44:07,055 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 3 more threads\n",
            "2022-05-22 23:44:07,056 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 2 more threads\n",
            "2022-05-22 23:44:07,070 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 1 more threads\n",
            "2022-05-22 23:44:07,120 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 0 more threads\n",
            "2022-05-22 23:44:07,121 | INFO | base_any2vec.py:1346 | _log_epoch_end | EPOCH - 2 : training on 44236 raw words (27887 effective words) took 0.3s, 91949 effective words/s\n",
            "2022-05-22 23:44:07,309 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 31 more threads\n",
            "2022-05-22 23:44:07,323 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 30 more threads\n",
            "2022-05-22 23:44:07,327 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 29 more threads\n",
            "2022-05-22 23:44:07,333 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 28 more threads\n",
            "2022-05-22 23:44:07,338 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 27 more threads\n",
            "2022-05-22 23:44:07,343 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 26 more threads\n",
            "2022-05-22 23:44:07,357 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 25 more threads\n",
            "2022-05-22 23:44:07,359 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 24 more threads\n",
            "2022-05-22 23:44:07,367 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 23 more threads\n",
            "2022-05-22 23:44:07,371 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 22 more threads\n",
            "2022-05-22 23:44:07,373 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 21 more threads\n",
            "2022-05-22 23:44:07,375 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 20 more threads\n",
            "2022-05-22 23:44:07,377 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 19 more threads\n",
            "2022-05-22 23:44:07,388 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 18 more threads\n",
            "2022-05-22 23:44:07,389 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 17 more threads\n",
            "2022-05-22 23:44:07,390 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 16 more threads\n",
            "2022-05-22 23:44:07,392 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 15 more threads\n",
            "2022-05-22 23:44:07,394 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 14 more threads\n",
            "2022-05-22 23:44:07,395 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 13 more threads\n",
            "2022-05-22 23:44:07,402 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 12 more threads\n",
            "2022-05-22 23:44:07,404 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 11 more threads\n",
            "2022-05-22 23:44:07,405 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 10 more threads\n",
            "2022-05-22 23:44:07,406 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 9 more threads\n",
            "2022-05-22 23:44:07,409 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 8 more threads\n",
            "2022-05-22 23:44:07,411 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 7 more threads\n",
            "2022-05-22 23:44:07,414 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 6 more threads\n",
            "2022-05-22 23:44:07,417 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 5 more threads\n",
            "2022-05-22 23:44:07,419 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 4 more threads\n",
            "2022-05-22 23:44:07,421 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 3 more threads\n",
            "2022-05-22 23:44:07,424 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 2 more threads\n",
            "2022-05-22 23:44:07,427 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 1 more threads\n",
            "2022-05-22 23:44:07,442 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 0 more threads\n",
            "2022-05-22 23:44:07,443 | INFO | base_any2vec.py:1346 | _log_epoch_end | EPOCH - 3 : training on 44236 raw words (27871 effective words) took 0.3s, 90907 effective words/s\n",
            "2022-05-22 23:44:07,642 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 31 more threads\n",
            "2022-05-22 23:44:07,648 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 30 more threads\n",
            "2022-05-22 23:44:07,652 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 29 more threads\n",
            "2022-05-22 23:44:07,653 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 28 more threads\n",
            "2022-05-22 23:44:07,656 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 27 more threads\n",
            "2022-05-22 23:44:07,659 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 26 more threads\n",
            "2022-05-22 23:44:07,662 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 25 more threads\n",
            "2022-05-22 23:44:07,664 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 24 more threads\n",
            "2022-05-22 23:44:07,671 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 23 more threads\n",
            "2022-05-22 23:44:07,673 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 22 more threads\n",
            "2022-05-22 23:44:07,677 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 21 more threads\n",
            "2022-05-22 23:44:07,680 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 20 more threads\n",
            "2022-05-22 23:44:07,682 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 19 more threads\n",
            "2022-05-22 23:44:07,685 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 18 more threads\n",
            "2022-05-22 23:44:07,688 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 17 more threads\n",
            "2022-05-22 23:44:07,691 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 16 more threads\n",
            "2022-05-22 23:44:07,693 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 15 more threads\n",
            "2022-05-22 23:44:07,696 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 14 more threads\n",
            "2022-05-22 23:44:07,699 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 13 more threads\n",
            "2022-05-22 23:44:07,709 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 12 more threads\n",
            "2022-05-22 23:44:07,711 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 11 more threads\n",
            "2022-05-22 23:44:07,714 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 10 more threads\n",
            "2022-05-22 23:44:07,717 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 9 more threads\n",
            "2022-05-22 23:44:07,720 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 8 more threads\n",
            "2022-05-22 23:44:07,723 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 7 more threads\n",
            "2022-05-22 23:44:07,726 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 6 more threads\n",
            "2022-05-22 23:44:07,728 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 5 more threads\n",
            "2022-05-22 23:44:07,733 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 4 more threads\n",
            "2022-05-22 23:44:07,736 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 3 more threads\n",
            "2022-05-22 23:44:07,738 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 2 more threads\n",
            "2022-05-22 23:44:07,739 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 1 more threads\n",
            "2022-05-22 23:44:07,759 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 0 more threads\n",
            "2022-05-22 23:44:07,759 | INFO | base_any2vec.py:1346 | _log_epoch_end | EPOCH - 4 : training on 44236 raw words (27901 effective words) took 0.3s, 95515 effective words/s\n",
            "2022-05-22 23:44:07,949 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 31 more threads\n",
            "2022-05-22 23:44:07,954 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 30 more threads\n",
            "2022-05-22 23:44:07,960 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 29 more threads\n",
            "2022-05-22 23:44:07,961 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 28 more threads\n",
            "2022-05-22 23:44:07,963 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 27 more threads\n",
            "2022-05-22 23:44:07,965 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 26 more threads\n",
            "2022-05-22 23:44:07,969 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 25 more threads\n",
            "2022-05-22 23:44:07,973 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 24 more threads\n",
            "2022-05-22 23:44:07,976 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 23 more threads\n",
            "2022-05-22 23:44:07,977 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 22 more threads\n",
            "2022-05-22 23:44:07,990 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 21 more threads\n",
            "2022-05-22 23:44:07,992 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 20 more threads\n",
            "2022-05-22 23:44:07,995 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 19 more threads\n",
            "2022-05-22 23:44:07,996 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 18 more threads\n",
            "2022-05-22 23:44:08,002 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 17 more threads\n",
            "2022-05-22 23:44:08,003 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 16 more threads\n",
            "2022-05-22 23:44:08,006 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 15 more threads\n",
            "2022-05-22 23:44:08,007 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 14 more threads\n",
            "2022-05-22 23:44:08,017 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 13 more threads\n",
            "2022-05-22 23:44:08,021 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 12 more threads\n",
            "2022-05-22 23:44:08,022 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 11 more threads\n",
            "2022-05-22 23:44:08,030 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 10 more threads\n",
            "2022-05-22 23:44:08,031 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 9 more threads\n",
            "2022-05-22 23:44:08,032 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 8 more threads\n",
            "2022-05-22 23:44:08,034 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 7 more threads\n",
            "2022-05-22 23:44:08,035 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 6 more threads\n",
            "2022-05-22 23:44:08,036 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 5 more threads\n",
            "2022-05-22 23:44:08,038 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 4 more threads\n",
            "2022-05-22 23:44:08,040 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 3 more threads\n",
            "2022-05-22 23:44:08,043 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 2 more threads\n",
            "2022-05-22 23:44:08,044 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 1 more threads\n",
            "2022-05-22 23:44:08,092 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 0 more threads\n",
            "2022-05-22 23:44:08,093 | INFO | base_any2vec.py:1346 | _log_epoch_end | EPOCH - 5 : training on 44236 raw words (27882 effective words) took 0.3s, 89064 effective words/s\n",
            "2022-05-22 23:44:08,097 | INFO | base_any2vec.py:1382 | _log_train_end | training on a 221180 raw words (139459 effective words) took 1.6s, 86785 effective words/s\n",
            "2022-05-22 23:44:08,102 | WARNING | base_any2vec.py:1386 | _log_train_end | under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
            "2022-05-22 23:44:08,863 | INFO | word2vec.py:1567 | scan_vocab | collecting all words and their counts\n",
            "2022-05-22 23:44:08,867 | INFO | word2vec.py:1552 | _scan_vocab | PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
            "2022-05-22 23:44:08,875 | INFO | word2vec.py:1552 | _scan_vocab | PROGRESS: at sentence #10000, processed 4754 words, keeping 2945 word types\n",
            "2022-05-22 23:44:08,880 | INFO | word2vec.py:1552 | _scan_vocab | PROGRESS: at sentence #20000, processed 9509 words, keeping 5724 word types\n",
            "2022-05-22 23:44:08,890 | INFO | word2vec.py:1552 | _scan_vocab | PROGRESS: at sentence #30000, processed 14594 words, keeping 8486 word types\n",
            "2022-05-22 23:44:08,896 | INFO | word2vec.py:1552 | _scan_vocab | PROGRESS: at sentence #40000, processed 19425 words, keeping 10973 word types\n",
            "2022-05-22 23:44:08,905 | INFO | word2vec.py:1552 | _scan_vocab | PROGRESS: at sentence #50000, processed 24270 words, keeping 13455 word types\n",
            "2022-05-22 23:44:08,913 | INFO | word2vec.py:1552 | _scan_vocab | PROGRESS: at sentence #60000, processed 29249 words, keeping 15919 word types\n",
            "2022-05-22 23:44:08,918 | INFO | word2vec.py:1552 | _scan_vocab | PROGRESS: at sentence #70000, processed 34172 words, keeping 18196 word types\n",
            "2022-05-22 23:44:08,929 | INFO | word2vec.py:1552 | _scan_vocab | PROGRESS: at sentence #80000, processed 39536 words, keeping 20626 word types\n",
            "2022-05-22 23:44:08,934 | INFO | word2vec.py:1575 | scan_vocab | collected 22591 word types from a corpus of 44236 raw words and 88514 sentences\n",
            "2022-05-22 23:44:08,937 | INFO | word2vec.py:1659 | prepare_vocab | Updating model with new vocabulary\n",
            "2022-05-22 23:44:08,952 | INFO | word2vec.py:1685 | prepare_vocab | New added 6721 unique words (22% of original 29312) and increased the count of 6721 pre-existing words (22% of original 29312)\n",
            "2022-05-22 23:44:08,984 | INFO | word2vec.py:1715 | prepare_vocab | deleting the raw counts dictionary of 22591 items\n",
            "2022-05-22 23:44:08,986 | INFO | word2vec.py:1718 | prepare_vocab | sample=0.001 downsamples 28 most-common words\n",
            "2022-05-22 23:44:08,988 | INFO | word2vec.py:1721 | prepare_vocab | downsampling leaves estimated 55789 word corpus (196.7% of prior 28366)\n",
            "2022-05-22 23:44:09,181 | INFO | fasttext.py:551 | estimate_memory | estimated required memory for 6721 words, 130405 buckets and 50 dimensions: 35680620 bytes\n",
            "2022-05-22 23:44:09,187 | INFO | word2vec.py:1850 | update_weights | updating layer weights\n",
            "2022-05-22 23:44:09,469 | INFO | fasttext.py:1030 | init_ngrams_weights | Number of new ngrams is 0\n",
            "2022-05-22 23:44:09,485 | WARNING | base_any2vec.py:1182 | _check_training_sanity | Effective 'alpha' higher than previous training cycles\n",
            "2022-05-22 23:44:09,486 | INFO | base_any2vec.py:1210 | _check_training_sanity | training model with 32 workers on 6721 vocabulary and 50 features, using sg=1 hs=0 sample=0.001 negative=10 window=2\n",
            "2022-05-22 23:44:09,678 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 31 more threads\n",
            "2022-05-22 23:44:09,680 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 30 more threads\n",
            "2022-05-22 23:44:09,685 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 29 more threads\n",
            "2022-05-22 23:44:09,687 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 28 more threads\n",
            "2022-05-22 23:44:09,690 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 27 more threads\n",
            "2022-05-22 23:44:09,693 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 26 more threads\n",
            "2022-05-22 23:44:09,696 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 25 more threads\n",
            "2022-05-22 23:44:09,723 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 24 more threads\n",
            "2022-05-22 23:44:09,726 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 23 more threads\n",
            "2022-05-22 23:44:09,729 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 22 more threads\n",
            "2022-05-22 23:44:09,731 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 21 more threads\n",
            "2022-05-22 23:44:09,735 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 20 more threads\n",
            "2022-05-22 23:44:09,736 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 19 more threads\n",
            "2022-05-22 23:44:09,740 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 18 more threads\n",
            "2022-05-22 23:44:09,744 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 17 more threads\n",
            "2022-05-22 23:44:09,745 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 16 more threads\n",
            "2022-05-22 23:44:09,746 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 15 more threads\n",
            "2022-05-22 23:44:09,747 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 14 more threads\n",
            "2022-05-22 23:44:09,748 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 13 more threads\n",
            "2022-05-22 23:44:09,750 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 12 more threads\n",
            "2022-05-22 23:44:09,751 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 11 more threads\n",
            "2022-05-22 23:44:09,752 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 10 more threads\n",
            "2022-05-22 23:44:09,753 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 9 more threads\n",
            "2022-05-22 23:44:09,754 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 8 more threads\n",
            "2022-05-22 23:44:09,755 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 7 more threads\n",
            "2022-05-22 23:44:09,756 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 6 more threads\n",
            "2022-05-22 23:44:09,761 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 5 more threads\n",
            "2022-05-22 23:44:09,762 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 4 more threads\n",
            "2022-05-22 23:44:09,763 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 3 more threads\n",
            "2022-05-22 23:44:09,764 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 2 more threads\n",
            "2022-05-22 23:44:09,765 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 1 more threads\n",
            "2022-05-22 23:44:09,814 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 0 more threads\n",
            "2022-05-22 23:44:09,816 | INFO | base_any2vec.py:1346 | _log_epoch_end | EPOCH - 1 : training on 44236 raw words (27882 effective words) took 0.3s, 89295 effective words/s\n",
            "2022-05-22 23:44:10,022 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 31 more threads\n",
            "2022-05-22 23:44:10,023 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 30 more threads\n",
            "2022-05-22 23:44:10,029 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 29 more threads\n",
            "2022-05-22 23:44:10,032 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 28 more threads\n",
            "2022-05-22 23:44:10,036 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 27 more threads\n",
            "2022-05-22 23:44:10,040 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 26 more threads\n",
            "2022-05-22 23:44:10,042 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 25 more threads\n",
            "2022-05-22 23:44:10,046 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 24 more threads\n",
            "2022-05-22 23:44:10,049 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 23 more threads\n",
            "2022-05-22 23:44:10,050 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 22 more threads\n",
            "2022-05-22 23:44:10,054 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 21 more threads\n",
            "2022-05-22 23:44:10,059 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 20 more threads\n",
            "2022-05-22 23:44:10,060 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 19 more threads\n",
            "2022-05-22 23:44:10,063 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 18 more threads\n",
            "2022-05-22 23:44:10,080 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 17 more threads\n",
            "2022-05-22 23:44:10,081 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 16 more threads\n",
            "2022-05-22 23:44:10,082 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 15 more threads\n",
            "2022-05-22 23:44:10,083 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 14 more threads\n",
            "2022-05-22 23:44:10,084 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 13 more threads\n",
            "2022-05-22 23:44:10,085 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 12 more threads\n",
            "2022-05-22 23:44:10,094 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 11 more threads\n",
            "2022-05-22 23:44:10,097 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 10 more threads\n",
            "2022-05-22 23:44:10,099 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 9 more threads\n",
            "2022-05-22 23:44:10,100 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 8 more threads\n",
            "2022-05-22 23:44:10,103 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 7 more threads\n",
            "2022-05-22 23:44:10,105 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 6 more threads\n",
            "2022-05-22 23:44:10,106 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 5 more threads\n",
            "2022-05-22 23:44:10,108 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 4 more threads\n",
            "2022-05-22 23:44:10,111 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 3 more threads\n",
            "2022-05-22 23:44:10,112 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 2 more threads\n",
            "2022-05-22 23:44:10,114 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 1 more threads\n",
            "2022-05-22 23:44:10,148 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 0 more threads\n",
            "2022-05-22 23:44:10,150 | INFO | base_any2vec.py:1346 | _log_epoch_end | EPOCH - 2 : training on 44236 raw words (27898 effective words) took 0.3s, 87318 effective words/s\n",
            "2022-05-22 23:44:10,365 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 31 more threads\n",
            "2022-05-22 23:44:10,374 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 30 more threads\n",
            "2022-05-22 23:44:10,375 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 29 more threads\n",
            "2022-05-22 23:44:10,376 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 28 more threads\n",
            "2022-05-22 23:44:10,377 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 27 more threads\n",
            "2022-05-22 23:44:10,378 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 26 more threads\n",
            "2022-05-22 23:44:10,385 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 25 more threads\n",
            "2022-05-22 23:44:10,387 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 24 more threads\n",
            "2022-05-22 23:44:10,389 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 23 more threads\n",
            "2022-05-22 23:44:10,393 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 22 more threads\n",
            "2022-05-22 23:44:10,399 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 21 more threads\n",
            "2022-05-22 23:44:10,400 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 20 more threads\n",
            "2022-05-22 23:44:10,407 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 19 more threads\n",
            "2022-05-22 23:44:10,412 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 18 more threads\n",
            "2022-05-22 23:44:10,414 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 17 more threads\n",
            "2022-05-22 23:44:10,415 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 16 more threads\n",
            "2022-05-22 23:44:10,417 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 15 more threads\n",
            "2022-05-22 23:44:10,421 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 14 more threads\n",
            "2022-05-22 23:44:10,426 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 13 more threads\n",
            "2022-05-22 23:44:10,430 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 12 more threads\n",
            "2022-05-22 23:44:10,431 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 11 more threads\n",
            "2022-05-22 23:44:10,434 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 10 more threads\n",
            "2022-05-22 23:44:10,436 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 9 more threads\n",
            "2022-05-22 23:44:10,442 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 8 more threads\n",
            "2022-05-22 23:44:10,443 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 7 more threads\n",
            "2022-05-22 23:44:10,444 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 6 more threads\n",
            "2022-05-22 23:44:10,447 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 5 more threads\n",
            "2022-05-22 23:44:10,449 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 4 more threads\n",
            "2022-05-22 23:44:10,453 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 3 more threads\n",
            "2022-05-22 23:44:10,471 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 2 more threads\n",
            "2022-05-22 23:44:10,487 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 1 more threads\n",
            "2022-05-22 23:44:10,520 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 0 more threads\n",
            "2022-05-22 23:44:10,521 | INFO | base_any2vec.py:1346 | _log_epoch_end | EPOCH - 3 : training on 44236 raw words (27920 effective words) took 0.4s, 78126 effective words/s\n",
            "2022-05-22 23:44:10,724 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 31 more threads\n",
            "2022-05-22 23:44:10,730 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 30 more threads\n",
            "2022-05-22 23:44:10,734 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 29 more threads\n",
            "2022-05-22 23:44:10,743 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 28 more threads\n",
            "2022-05-22 23:44:10,746 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 27 more threads\n",
            "2022-05-22 23:44:10,753 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 26 more threads\n",
            "2022-05-22 23:44:10,754 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 25 more threads\n",
            "2022-05-22 23:44:10,758 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 24 more threads\n",
            "2022-05-22 23:44:10,759 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 23 more threads\n",
            "2022-05-22 23:44:10,769 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 22 more threads\n",
            "2022-05-22 23:44:10,784 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 21 more threads\n",
            "2022-05-22 23:44:10,785 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 20 more threads\n",
            "2022-05-22 23:44:10,786 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 19 more threads\n",
            "2022-05-22 23:44:10,787 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 18 more threads\n",
            "2022-05-22 23:44:10,795 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 17 more threads\n",
            "2022-05-22 23:44:10,796 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 16 more threads\n",
            "2022-05-22 23:44:10,797 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 15 more threads\n",
            "2022-05-22 23:44:10,798 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 14 more threads\n",
            "2022-05-22 23:44:10,806 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 13 more threads\n",
            "2022-05-22 23:44:10,808 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 12 more threads\n",
            "2022-05-22 23:44:10,809 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 11 more threads\n",
            "2022-05-22 23:44:10,810 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 10 more threads\n",
            "2022-05-22 23:44:10,811 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 9 more threads\n",
            "2022-05-22 23:44:10,812 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 8 more threads\n",
            "2022-05-22 23:44:10,814 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 7 more threads\n",
            "2022-05-22 23:44:10,816 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 6 more threads\n",
            "2022-05-22 23:44:10,817 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 5 more threads\n",
            "2022-05-22 23:44:10,818 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 4 more threads\n",
            "2022-05-22 23:44:10,820 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 3 more threads\n",
            "2022-05-22 23:44:10,821 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 2 more threads\n",
            "2022-05-22 23:44:10,823 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 1 more threads\n",
            "2022-05-22 23:44:10,824 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 0 more threads\n",
            "2022-05-22 23:44:10,826 | INFO | base_any2vec.py:1346 | _log_epoch_end | EPOCH - 4 : training on 44236 raw words (27869 effective words) took 0.3s, 95797 effective words/s\n",
            "2022-05-22 23:44:11,028 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 31 more threads\n",
            "2022-05-22 23:44:11,035 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 30 more threads\n",
            "2022-05-22 23:44:11,036 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 29 more threads\n",
            "2022-05-22 23:44:11,041 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 28 more threads\n",
            "2022-05-22 23:44:11,041 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 27 more threads\n",
            "2022-05-22 23:44:11,056 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 26 more threads\n",
            "2022-05-22 23:44:11,057 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 25 more threads\n",
            "2022-05-22 23:44:11,060 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 24 more threads\n",
            "2022-05-22 23:44:11,066 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 23 more threads\n",
            "2022-05-22 23:44:11,068 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 22 more threads\n",
            "2022-05-22 23:44:11,085 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 21 more threads\n",
            "2022-05-22 23:44:11,090 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 20 more threads\n",
            "2022-05-22 23:44:11,091 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 19 more threads\n",
            "2022-05-22 23:44:11,092 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 18 more threads\n",
            "2022-05-22 23:44:11,095 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 17 more threads\n",
            "2022-05-22 23:44:11,097 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 16 more threads\n",
            "2022-05-22 23:44:11,098 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 15 more threads\n",
            "2022-05-22 23:44:11,099 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 14 more threads\n",
            "2022-05-22 23:44:11,100 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 13 more threads\n",
            "2022-05-22 23:44:11,105 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 12 more threads\n",
            "2022-05-22 23:44:11,106 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 11 more threads\n",
            "2022-05-22 23:44:11,107 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 10 more threads\n",
            "2022-05-22 23:44:11,108 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 9 more threads\n",
            "2022-05-22 23:44:11,109 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 8 more threads\n",
            "2022-05-22 23:44:11,110 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 7 more threads\n",
            "2022-05-22 23:44:11,115 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 6 more threads\n",
            "2022-05-22 23:44:11,116 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 5 more threads\n",
            "2022-05-22 23:44:11,117 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 4 more threads\n",
            "2022-05-22 23:44:11,117 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 3 more threads\n",
            "2022-05-22 23:44:11,119 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 2 more threads\n",
            "2022-05-22 23:44:11,148 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 1 more threads\n",
            "2022-05-22 23:44:11,177 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 0 more threads\n",
            "2022-05-22 23:44:11,178 | INFO | base_any2vec.py:1346 | _log_epoch_end | EPOCH - 5 : training on 44236 raw words (27924 effective words) took 0.3s, 88223 effective words/s\n",
            "2022-05-22 23:44:11,396 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 31 more threads\n",
            "2022-05-22 23:44:11,403 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 30 more threads\n",
            "2022-05-22 23:44:11,406 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 29 more threads\n",
            "2022-05-22 23:44:11,408 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 28 more threads\n",
            "2022-05-22 23:44:11,422 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 27 more threads\n",
            "2022-05-22 23:44:11,426 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 26 more threads\n",
            "2022-05-22 23:44:11,428 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 25 more threads\n",
            "2022-05-22 23:44:11,430 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 24 more threads\n",
            "2022-05-22 23:44:11,433 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 23 more threads\n",
            "2022-05-22 23:44:11,441 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 22 more threads\n",
            "2022-05-22 23:44:11,442 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 21 more threads\n",
            "2022-05-22 23:44:11,444 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 20 more threads\n",
            "2022-05-22 23:44:11,452 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 19 more threads\n",
            "2022-05-22 23:44:11,454 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 18 more threads\n",
            "2022-05-22 23:44:11,459 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 17 more threads\n",
            "2022-05-22 23:44:11,464 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 16 more threads\n",
            "2022-05-22 23:44:11,465 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 15 more threads\n",
            "2022-05-22 23:44:11,466 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 14 more threads\n",
            "2022-05-22 23:44:11,471 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 13 more threads\n",
            "2022-05-22 23:44:11,472 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 12 more threads\n",
            "2022-05-22 23:44:11,477 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 11 more threads\n",
            "2022-05-22 23:44:11,478 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 10 more threads\n",
            "2022-05-22 23:44:11,478 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 9 more threads\n",
            "2022-05-22 23:44:11,484 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 8 more threads\n",
            "2022-05-22 23:44:11,485 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 7 more threads\n",
            "2022-05-22 23:44:11,486 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 6 more threads\n",
            "2022-05-22 23:44:11,488 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 5 more threads\n",
            "2022-05-22 23:44:11,493 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 4 more threads\n",
            "2022-05-22 23:44:11,494 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 3 more threads\n",
            "2022-05-22 23:44:11,496 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 2 more threads\n",
            "2022-05-22 23:44:11,504 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 1 more threads\n",
            "2022-05-22 23:44:11,509 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 0 more threads\n",
            "2022-05-22 23:44:11,510 | INFO | base_any2vec.py:1346 | _log_epoch_end | EPOCH - 6 : training on 44236 raw words (27884 effective words) took 0.3s, 87370 effective words/s\n",
            "2022-05-22 23:44:11,751 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 31 more threads\n",
            "2022-05-22 23:44:11,754 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 30 more threads\n",
            "2022-05-22 23:44:11,755 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 29 more threads\n",
            "2022-05-22 23:44:11,759 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 28 more threads\n",
            "2022-05-22 23:44:11,762 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 27 more threads\n",
            "2022-05-22 23:44:11,763 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 26 more threads\n",
            "2022-05-22 23:44:11,767 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 25 more threads\n",
            "2022-05-22 23:44:11,779 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 24 more threads\n",
            "2022-05-22 23:44:11,780 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 23 more threads\n",
            "2022-05-22 23:44:11,781 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 22 more threads\n",
            "2022-05-22 23:44:11,785 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 21 more threads\n",
            "2022-05-22 23:44:11,794 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 20 more threads\n",
            "2022-05-22 23:44:11,795 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 19 more threads\n",
            "2022-05-22 23:44:11,796 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 18 more threads\n",
            "2022-05-22 23:44:11,800 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 17 more threads\n",
            "2022-05-22 23:44:11,808 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 16 more threads\n",
            "2022-05-22 23:44:11,809 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 15 more threads\n",
            "2022-05-22 23:44:11,810 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 14 more threads\n",
            "2022-05-22 23:44:11,811 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 13 more threads\n",
            "2022-05-22 23:44:11,815 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 12 more threads\n",
            "2022-05-22 23:44:11,816 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 11 more threads\n",
            "2022-05-22 23:44:11,817 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 10 more threads\n",
            "2022-05-22 23:44:11,820 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 9 more threads\n",
            "2022-05-22 23:44:11,821 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 8 more threads\n",
            "2022-05-22 23:44:11,825 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 7 more threads\n",
            "2022-05-22 23:44:11,829 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 6 more threads\n",
            "2022-05-22 23:44:11,830 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 5 more threads\n",
            "2022-05-22 23:44:11,839 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 4 more threads\n",
            "2022-05-22 23:44:11,840 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 3 more threads\n",
            "2022-05-22 23:44:11,841 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 2 more threads\n",
            "2022-05-22 23:44:11,862 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 1 more threads\n",
            "2022-05-22 23:44:11,868 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 0 more threads\n",
            "2022-05-22 23:44:11,869 | INFO | base_any2vec.py:1346 | _log_epoch_end | EPOCH - 7 : training on 44236 raw words (27920 effective words) took 0.3s, 87653 effective words/s\n",
            "2022-05-22 23:44:12,068 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 31 more threads\n",
            "2022-05-22 23:44:12,078 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 30 more threads\n",
            "2022-05-22 23:44:12,079 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 29 more threads\n",
            "2022-05-22 23:44:12,080 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 28 more threads\n",
            "2022-05-22 23:44:12,081 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 27 more threads\n",
            "2022-05-22 23:44:12,082 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 26 more threads\n",
            "2022-05-22 23:44:12,083 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 25 more threads\n",
            "2022-05-22 23:44:12,084 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 24 more threads\n",
            "2022-05-22 23:44:12,087 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 23 more threads\n",
            "2022-05-22 23:44:12,092 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 22 more threads\n",
            "2022-05-22 23:44:12,097 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 21 more threads\n",
            "2022-05-22 23:44:12,099 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 20 more threads\n",
            "2022-05-22 23:44:12,100 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 19 more threads\n",
            "2022-05-22 23:44:12,103 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 18 more threads\n",
            "2022-05-22 23:44:12,104 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 17 more threads\n",
            "2022-05-22 23:44:12,106 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 16 more threads\n",
            "2022-05-22 23:44:12,108 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 15 more threads\n",
            "2022-05-22 23:44:12,111 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 14 more threads\n",
            "2022-05-22 23:44:12,112 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 13 more threads\n",
            "2022-05-22 23:44:12,113 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 12 more threads\n",
            "2022-05-22 23:44:12,115 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 11 more threads\n",
            "2022-05-22 23:44:12,117 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 10 more threads\n",
            "2022-05-22 23:44:12,118 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 9 more threads\n",
            "2022-05-22 23:44:12,123 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 8 more threads\n",
            "2022-05-22 23:44:12,124 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 7 more threads\n",
            "2022-05-22 23:44:12,125 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 6 more threads\n",
            "2022-05-22 23:44:12,132 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 5 more threads\n",
            "2022-05-22 23:44:12,133 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 4 more threads\n",
            "2022-05-22 23:44:12,134 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 3 more threads\n",
            "2022-05-22 23:44:12,135 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 2 more threads\n",
            "2022-05-22 23:44:12,186 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 1 more threads\n",
            "2022-05-22 23:44:12,201 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 0 more threads\n",
            "2022-05-22 23:44:12,203 | INFO | base_any2vec.py:1346 | _log_epoch_end | EPOCH - 8 : training on 44236 raw words (27903 effective words) took 0.3s, 91863 effective words/s\n",
            "2022-05-22 23:44:12,409 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 31 more threads\n",
            "2022-05-22 23:44:12,414 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 30 more threads\n",
            "2022-05-22 23:44:12,417 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 29 more threads\n",
            "2022-05-22 23:44:12,419 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 28 more threads\n",
            "2022-05-22 23:44:12,422 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 27 more threads\n",
            "2022-05-22 23:44:12,425 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 26 more threads\n",
            "2022-05-22 23:44:12,427 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 25 more threads\n",
            "2022-05-22 23:44:12,433 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 24 more threads\n",
            "2022-05-22 23:44:12,439 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 23 more threads\n",
            "2022-05-22 23:44:12,441 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 22 more threads\n",
            "2022-05-22 23:44:12,445 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 21 more threads\n",
            "2022-05-22 23:44:12,448 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 20 more threads\n",
            "2022-05-22 23:44:12,459 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 19 more threads\n",
            "2022-05-22 23:44:12,462 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 18 more threads\n",
            "2022-05-22 23:44:12,465 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 17 more threads\n",
            "2022-05-22 23:44:12,467 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 16 more threads\n",
            "2022-05-22 23:44:12,470 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 15 more threads\n",
            "2022-05-22 23:44:12,473 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 14 more threads\n",
            "2022-05-22 23:44:12,474 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 13 more threads\n",
            "2022-05-22 23:44:12,475 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 12 more threads\n",
            "2022-05-22 23:44:12,479 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 11 more threads\n",
            "2022-05-22 23:44:12,481 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 10 more threads\n",
            "2022-05-22 23:44:12,483 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 9 more threads\n",
            "2022-05-22 23:44:12,490 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 8 more threads\n",
            "2022-05-22 23:44:12,491 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 7 more threads\n",
            "2022-05-22 23:44:12,492 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 6 more threads\n",
            "2022-05-22 23:44:12,493 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 5 more threads\n",
            "2022-05-22 23:44:12,495 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 4 more threads\n",
            "2022-05-22 23:44:12,500 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 3 more threads\n",
            "2022-05-22 23:44:12,501 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 2 more threads\n",
            "2022-05-22 23:44:12,519 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 1 more threads\n",
            "2022-05-22 23:44:12,540 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 0 more threads\n",
            "2022-05-22 23:44:12,541 | INFO | base_any2vec.py:1346 | _log_epoch_end | EPOCH - 9 : training on 44236 raw words (27906 effective words) took 0.3s, 88467 effective words/s\n",
            "2022-05-22 23:44:12,715 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 31 more threads\n",
            "2022-05-22 23:44:12,720 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 30 more threads\n",
            "2022-05-22 23:44:12,725 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 29 more threads\n",
            "2022-05-22 23:44:12,727 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 28 more threads\n",
            "2022-05-22 23:44:12,732 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 27 more threads\n",
            "2022-05-22 23:44:12,737 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 26 more threads\n",
            "2022-05-22 23:44:12,741 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 25 more threads\n",
            "2022-05-22 23:44:12,755 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 24 more threads\n",
            "2022-05-22 23:44:12,758 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 23 more threads\n",
            "2022-05-22 23:44:12,763 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 22 more threads\n",
            "2022-05-22 23:44:12,766 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 21 more threads\n",
            "2022-05-22 23:44:12,769 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 20 more threads\n",
            "2022-05-22 23:44:12,771 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 19 more threads\n",
            "2022-05-22 23:44:12,778 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 18 more threads\n",
            "2022-05-22 23:44:12,783 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 17 more threads\n",
            "2022-05-22 23:44:12,785 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 16 more threads\n",
            "2022-05-22 23:44:12,790 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 15 more threads\n",
            "2022-05-22 23:44:12,796 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 14 more threads\n",
            "2022-05-22 23:44:12,803 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 13 more threads\n",
            "2022-05-22 23:44:12,815 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 12 more threads\n",
            "2022-05-22 23:44:12,818 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 11 more threads\n",
            "2022-05-22 23:44:12,823 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 10 more threads\n",
            "2022-05-22 23:44:12,828 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 9 more threads\n",
            "2022-05-22 23:44:12,828 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 8 more threads\n",
            "2022-05-22 23:44:12,830 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 7 more threads\n",
            "2022-05-22 23:44:12,833 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 6 more threads\n",
            "2022-05-22 23:44:12,841 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 5 more threads\n",
            "2022-05-22 23:44:12,846 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 4 more threads\n",
            "2022-05-22 23:44:12,848 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 3 more threads\n",
            "2022-05-22 23:44:12,850 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 2 more threads\n",
            "2022-05-22 23:44:12,851 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 1 more threads\n",
            "2022-05-22 23:44:12,854 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 0 more threads\n",
            "2022-05-22 23:44:12,856 | INFO | base_any2vec.py:1346 | _log_epoch_end | EPOCH - 10 : training on 44236 raw words (27895 effective words) took 0.3s, 94356 effective words/s\n",
            "2022-05-22 23:44:13,048 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 31 more threads\n",
            "2022-05-22 23:44:13,058 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 30 more threads\n",
            "2022-05-22 23:44:13,062 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 29 more threads\n",
            "2022-05-22 23:44:13,065 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 28 more threads\n",
            "2022-05-22 23:44:13,071 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 27 more threads\n",
            "2022-05-22 23:44:13,078 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 26 more threads\n",
            "2022-05-22 23:44:13,082 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 25 more threads\n",
            "2022-05-22 23:44:13,088 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 24 more threads\n",
            "2022-05-22 23:44:13,089 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 23 more threads\n",
            "2022-05-22 23:44:13,094 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 22 more threads\n",
            "2022-05-22 23:44:13,102 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 21 more threads\n",
            "2022-05-22 23:44:13,103 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 20 more threads\n",
            "2022-05-22 23:44:13,104 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 19 more threads\n",
            "2022-05-22 23:44:13,111 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 18 more threads\n",
            "2022-05-22 23:44:13,112 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 17 more threads\n",
            "2022-05-22 23:44:13,113 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 16 more threads\n",
            "2022-05-22 23:44:13,124 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 15 more threads\n",
            "2022-05-22 23:44:13,126 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 14 more threads\n",
            "2022-05-22 23:44:13,129 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 13 more threads\n",
            "2022-05-22 23:44:13,131 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 12 more threads\n",
            "2022-05-22 23:44:13,132 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 11 more threads\n",
            "2022-05-22 23:44:13,133 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 10 more threads\n",
            "2022-05-22 23:44:13,136 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 9 more threads\n",
            "2022-05-22 23:44:13,138 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 8 more threads\n",
            "2022-05-22 23:44:13,139 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 7 more threads\n",
            "2022-05-22 23:44:13,142 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 6 more threads\n",
            "2022-05-22 23:44:13,144 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 5 more threads\n",
            "2022-05-22 23:44:13,146 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 4 more threads\n",
            "2022-05-22 23:44:13,147 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 3 more threads\n",
            "2022-05-22 23:44:13,149 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 2 more threads\n",
            "2022-05-22 23:44:13,153 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 1 more threads\n",
            "2022-05-22 23:44:13,171 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 0 more threads\n",
            "2022-05-22 23:44:13,173 | INFO | base_any2vec.py:1346 | _log_epoch_end | EPOCH - 11 : training on 44236 raw words (27888 effective words) took 0.3s, 94181 effective words/s\n",
            "2022-05-22 23:44:13,400 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 31 more threads\n",
            "2022-05-22 23:44:13,402 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 30 more threads\n",
            "2022-05-22 23:44:13,403 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 29 more threads\n",
            "2022-05-22 23:44:13,409 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 28 more threads\n",
            "2022-05-22 23:44:13,415 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 27 more threads\n",
            "2022-05-22 23:44:13,423 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 26 more threads\n",
            "2022-05-22 23:44:13,424 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 25 more threads\n",
            "2022-05-22 23:44:13,435 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 24 more threads\n",
            "2022-05-22 23:44:13,436 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 23 more threads\n",
            "2022-05-22 23:44:13,443 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 22 more threads\n",
            "2022-05-22 23:44:13,444 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 21 more threads\n",
            "2022-05-22 23:44:13,445 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 20 more threads\n",
            "2022-05-22 23:44:13,460 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 19 more threads\n",
            "2022-05-22 23:44:13,472 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 18 more threads\n",
            "2022-05-22 23:44:13,475 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 17 more threads\n",
            "2022-05-22 23:44:13,478 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 16 more threads\n",
            "2022-05-22 23:44:13,483 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 15 more threads\n",
            "2022-05-22 23:44:13,484 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 14 more threads\n",
            "2022-05-22 23:44:13,485 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 13 more threads\n",
            "2022-05-22 23:44:13,486 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 12 more threads\n",
            "2022-05-22 23:44:13,493 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 11 more threads\n",
            "2022-05-22 23:44:13,498 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 10 more threads\n",
            "2022-05-22 23:44:13,500 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 9 more threads\n",
            "2022-05-22 23:44:13,503 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 8 more threads\n",
            "2022-05-22 23:44:13,505 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 7 more threads\n",
            "2022-05-22 23:44:13,507 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 6 more threads\n",
            "2022-05-22 23:44:13,509 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 5 more threads\n",
            "2022-05-22 23:44:13,511 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 4 more threads\n",
            "2022-05-22 23:44:13,512 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 3 more threads\n",
            "2022-05-22 23:44:13,513 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 2 more threads\n",
            "2022-05-22 23:44:13,514 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 1 more threads\n",
            "2022-05-22 23:44:13,516 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 0 more threads\n",
            "2022-05-22 23:44:13,517 | INFO | base_any2vec.py:1346 | _log_epoch_end | EPOCH - 12 : training on 44236 raw words (27885 effective words) took 0.3s, 87159 effective words/s\n",
            "2022-05-22 23:44:13,725 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 31 more threads\n",
            "2022-05-22 23:44:13,732 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 30 more threads\n",
            "2022-05-22 23:44:13,737 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 29 more threads\n",
            "2022-05-22 23:44:13,738 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 28 more threads\n",
            "2022-05-22 23:44:13,750 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 27 more threads\n",
            "2022-05-22 23:44:13,751 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 26 more threads\n",
            "2022-05-22 23:44:13,752 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 25 more threads\n",
            "2022-05-22 23:44:13,759 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 24 more threads\n",
            "2022-05-22 23:44:13,760 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 23 more threads\n",
            "2022-05-22 23:44:13,779 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 22 more threads\n",
            "2022-05-22 23:44:13,781 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 21 more threads\n",
            "2022-05-22 23:44:13,783 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 20 more threads\n",
            "2022-05-22 23:44:13,786 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 19 more threads\n",
            "2022-05-22 23:44:13,797 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 18 more threads\n",
            "2022-05-22 23:44:13,798 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 17 more threads\n",
            "2022-05-22 23:44:13,799 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 16 more threads\n",
            "2022-05-22 23:44:13,800 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 15 more threads\n",
            "2022-05-22 23:44:13,801 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 14 more threads\n",
            "2022-05-22 23:44:13,802 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 13 more threads\n",
            "2022-05-22 23:44:13,803 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 12 more threads\n",
            "2022-05-22 23:44:13,806 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 11 more threads\n",
            "2022-05-22 23:44:13,807 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 10 more threads\n",
            "2022-05-22 23:44:13,817 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 9 more threads\n",
            "2022-05-22 23:44:13,821 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 8 more threads\n",
            "2022-05-22 23:44:13,822 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 7 more threads\n",
            "2022-05-22 23:44:13,825 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 6 more threads\n",
            "2022-05-22 23:44:13,827 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 5 more threads\n",
            "2022-05-22 23:44:13,828 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 4 more threads\n",
            "2022-05-22 23:44:13,830 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 3 more threads\n",
            "2022-05-22 23:44:13,831 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 2 more threads\n",
            "2022-05-22 23:44:13,835 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 1 more threads\n",
            "2022-05-22 23:44:13,857 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 0 more threads\n",
            "2022-05-22 23:44:13,857 | INFO | base_any2vec.py:1346 | _log_epoch_end | EPOCH - 13 : training on 44236 raw words (27884 effective words) took 0.3s, 92505 effective words/s\n",
            "2022-05-22 23:44:14,068 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 31 more threads\n",
            "2022-05-22 23:44:14,068 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 30 more threads\n",
            "2022-05-22 23:44:14,074 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 29 more threads\n",
            "2022-05-22 23:44:14,077 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 28 more threads\n",
            "2022-05-22 23:44:14,083 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 27 more threads\n",
            "2022-05-22 23:44:14,088 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 26 more threads\n",
            "2022-05-22 23:44:14,092 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 25 more threads\n",
            "2022-05-22 23:44:14,099 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 24 more threads\n",
            "2022-05-22 23:44:14,102 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 23 more threads\n",
            "2022-05-22 23:44:14,111 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 22 more threads\n",
            "2022-05-22 23:44:14,116 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 21 more threads\n",
            "2022-05-22 23:44:14,119 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 20 more threads\n",
            "2022-05-22 23:44:14,123 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 19 more threads\n",
            "2022-05-22 23:44:14,132 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 18 more threads\n",
            "2022-05-22 23:44:14,133 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 17 more threads\n",
            "2022-05-22 23:44:14,134 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 16 more threads\n",
            "2022-05-22 23:44:14,142 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 15 more threads\n",
            "2022-05-22 23:44:14,145 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 14 more threads\n",
            "2022-05-22 23:44:14,146 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 13 more threads\n",
            "2022-05-22 23:44:14,151 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 12 more threads\n",
            "2022-05-22 23:44:14,152 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 11 more threads\n",
            "2022-05-22 23:44:14,160 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 10 more threads\n",
            "2022-05-22 23:44:14,166 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 9 more threads\n",
            "2022-05-22 23:44:14,168 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 8 more threads\n",
            "2022-05-22 23:44:14,173 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 7 more threads\n",
            "2022-05-22 23:44:14,177 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 6 more threads\n",
            "2022-05-22 23:44:14,178 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 5 more threads\n",
            "2022-05-22 23:44:14,179 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 4 more threads\n",
            "2022-05-22 23:44:14,180 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 3 more threads\n",
            "2022-05-22 23:44:14,181 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 2 more threads\n",
            "2022-05-22 23:44:14,185 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 1 more threads\n",
            "2022-05-22 23:44:14,198 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 0 more threads\n",
            "2022-05-22 23:44:14,199 | INFO | base_any2vec.py:1346 | _log_epoch_end | EPOCH - 14 : training on 44236 raw words (27913 effective words) took 0.3s, 90456 effective words/s\n",
            "2022-05-22 23:44:14,419 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 31 more threads\n",
            "2022-05-22 23:44:14,424 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 30 more threads\n",
            "2022-05-22 23:44:14,427 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 29 more threads\n",
            "2022-05-22 23:44:14,428 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 28 more threads\n",
            "2022-05-22 23:44:14,431 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 27 more threads\n",
            "2022-05-22 23:44:14,434 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 26 more threads\n",
            "2022-05-22 23:44:14,439 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 25 more threads\n",
            "2022-05-22 23:44:14,442 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 24 more threads\n",
            "2022-05-22 23:44:14,445 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 23 more threads\n",
            "2022-05-22 23:44:14,446 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 22 more threads\n",
            "2022-05-22 23:44:14,447 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 21 more threads\n",
            "2022-05-22 23:44:14,453 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 20 more threads\n",
            "2022-05-22 23:44:14,456 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 19 more threads\n",
            "2022-05-22 23:44:14,461 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 18 more threads\n",
            "2022-05-22 23:44:14,464 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 17 more threads\n",
            "2022-05-22 23:44:14,467 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 16 more threads\n",
            "2022-05-22 23:44:14,473 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 15 more threads\n",
            "2022-05-22 23:44:14,476 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 14 more threads\n",
            "2022-05-22 23:44:14,485 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 13 more threads\n",
            "2022-05-22 23:44:14,488 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 12 more threads\n",
            "2022-05-22 23:44:14,490 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 11 more threads\n",
            "2022-05-22 23:44:14,491 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 10 more threads\n",
            "2022-05-22 23:44:14,496 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 9 more threads\n",
            "2022-05-22 23:44:14,501 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 8 more threads\n",
            "2022-05-22 23:44:14,502 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 7 more threads\n",
            "2022-05-22 23:44:14,509 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 6 more threads\n",
            "2022-05-22 23:44:14,510 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 5 more threads\n",
            "2022-05-22 23:44:14,514 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 4 more threads\n",
            "2022-05-22 23:44:14,522 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 3 more threads\n",
            "2022-05-22 23:44:14,523 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 2 more threads\n",
            "2022-05-22 23:44:14,524 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 1 more threads\n",
            "2022-05-22 23:44:14,561 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 0 more threads\n",
            "2022-05-22 23:44:14,562 | INFO | base_any2vec.py:1346 | _log_epoch_end | EPOCH - 15 : training on 44236 raw words (27886 effective words) took 0.3s, 81110 effective words/s\n",
            "2022-05-22 23:44:14,768 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 31 more threads\n",
            "2022-05-22 23:44:14,771 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 30 more threads\n",
            "2022-05-22 23:44:14,772 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 29 more threads\n",
            "2022-05-22 23:44:14,773 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 28 more threads\n",
            "2022-05-22 23:44:14,776 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 27 more threads\n",
            "2022-05-22 23:44:14,778 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 26 more threads\n",
            "2022-05-22 23:44:14,780 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 25 more threads\n",
            "2022-05-22 23:44:14,781 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 24 more threads\n",
            "2022-05-22 23:44:14,784 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 23 more threads\n",
            "2022-05-22 23:44:14,785 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 22 more threads\n",
            "2022-05-22 23:44:14,789 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 21 more threads\n",
            "2022-05-22 23:44:14,790 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 20 more threads\n",
            "2022-05-22 23:44:14,791 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 19 more threads\n",
            "2022-05-22 23:44:14,792 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 18 more threads\n",
            "2022-05-22 23:44:14,795 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 17 more threads\n",
            "2022-05-22 23:44:14,796 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 16 more threads\n",
            "2022-05-22 23:44:14,797 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 15 more threads\n",
            "2022-05-22 23:44:14,799 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 14 more threads\n",
            "2022-05-22 23:44:14,800 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 13 more threads\n",
            "2022-05-22 23:44:14,802 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 12 more threads\n",
            "2022-05-22 23:44:14,804 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 11 more threads\n",
            "2022-05-22 23:44:14,806 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 10 more threads\n",
            "2022-05-22 23:44:14,807 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 9 more threads\n",
            "2022-05-22 23:44:14,809 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 8 more threads\n",
            "2022-05-22 23:44:14,813 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 7 more threads\n",
            "2022-05-22 23:44:14,814 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 6 more threads\n",
            "2022-05-22 23:44:14,815 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 5 more threads\n",
            "2022-05-22 23:44:14,817 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 4 more threads\n",
            "2022-05-22 23:44:14,820 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 3 more threads\n",
            "2022-05-22 23:44:14,821 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 2 more threads\n",
            "2022-05-22 23:44:14,837 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 1 more threads\n",
            "2022-05-22 23:44:14,890 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 0 more threads\n",
            "2022-05-22 23:44:14,892 | INFO | base_any2vec.py:1346 | _log_epoch_end | EPOCH - 16 : training on 44236 raw words (27907 effective words) took 0.3s, 90392 effective words/s\n",
            "2022-05-22 23:44:15,088 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 31 more threads\n",
            "2022-05-22 23:44:15,095 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 30 more threads\n",
            "2022-05-22 23:44:15,097 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 29 more threads\n",
            "2022-05-22 23:44:15,098 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 28 more threads\n",
            "2022-05-22 23:44:15,100 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 27 more threads\n",
            "2022-05-22 23:44:15,101 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 26 more threads\n",
            "2022-05-22 23:44:15,102 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 25 more threads\n",
            "2022-05-22 23:44:15,105 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 24 more threads\n",
            "2022-05-22 23:44:15,106 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 23 more threads\n",
            "2022-05-22 23:44:15,109 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 22 more threads\n",
            "2022-05-22 23:44:15,110 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 21 more threads\n",
            "2022-05-22 23:44:15,111 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 20 more threads\n",
            "2022-05-22 23:44:15,114 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 19 more threads\n",
            "2022-05-22 23:44:15,116 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 18 more threads\n",
            "2022-05-22 23:44:15,117 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 17 more threads\n",
            "2022-05-22 23:44:15,121 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 16 more threads\n",
            "2022-05-22 23:44:15,122 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 15 more threads\n",
            "2022-05-22 23:44:15,122 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 14 more threads\n",
            "2022-05-22 23:44:15,125 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 13 more threads\n",
            "2022-05-22 23:44:15,128 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 12 more threads\n",
            "2022-05-22 23:44:15,135 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 11 more threads\n",
            "2022-05-22 23:44:15,137 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 10 more threads\n",
            "2022-05-22 23:44:15,142 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 9 more threads\n",
            "2022-05-22 23:44:15,143 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 8 more threads\n",
            "2022-05-22 23:44:15,145 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 7 more threads\n",
            "2022-05-22 23:44:15,149 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 6 more threads\n",
            "2022-05-22 23:44:15,151 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 5 more threads\n",
            "2022-05-22 23:44:15,152 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 4 more threads\n",
            "2022-05-22 23:44:15,155 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 3 more threads\n",
            "2022-05-22 23:44:15,198 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 2 more threads\n",
            "2022-05-22 23:44:15,206 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 1 more threads\n",
            "2022-05-22 23:44:15,241 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 0 more threads\n",
            "2022-05-22 23:44:15,248 | INFO | base_any2vec.py:1346 | _log_epoch_end | EPOCH - 17 : training on 44236 raw words (27897 effective words) took 0.3s, 82116 effective words/s\n",
            "2022-05-22 23:44:15,452 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 31 more threads\n",
            "2022-05-22 23:44:15,455 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 30 more threads\n",
            "2022-05-22 23:44:15,456 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 29 more threads\n",
            "2022-05-22 23:44:15,464 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 28 more threads\n",
            "2022-05-22 23:44:15,468 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 27 more threads\n",
            "2022-05-22 23:44:15,468 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 26 more threads\n",
            "2022-05-22 23:44:15,478 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 25 more threads\n",
            "2022-05-22 23:44:15,479 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 24 more threads\n",
            "2022-05-22 23:44:15,486 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 23 more threads\n",
            "2022-05-22 23:44:15,487 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 22 more threads\n",
            "2022-05-22 23:44:15,488 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 21 more threads\n",
            "2022-05-22 23:44:15,492 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 20 more threads\n",
            "2022-05-22 23:44:15,504 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 19 more threads\n",
            "2022-05-22 23:44:15,513 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 18 more threads\n",
            "2022-05-22 23:44:15,517 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 17 more threads\n",
            "2022-05-22 23:44:15,522 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 16 more threads\n",
            "2022-05-22 23:44:15,523 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 15 more threads\n",
            "2022-05-22 23:44:15,527 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 14 more threads\n",
            "2022-05-22 23:44:15,527 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 13 more threads\n",
            "2022-05-22 23:44:15,528 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 12 more threads\n",
            "2022-05-22 23:44:15,531 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 11 more threads\n",
            "2022-05-22 23:44:15,538 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 10 more threads\n",
            "2022-05-22 23:44:15,545 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 9 more threads\n",
            "2022-05-22 23:44:15,546 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 8 more threads\n",
            "2022-05-22 23:44:15,547 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 7 more threads\n",
            "2022-05-22 23:44:15,550 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 6 more threads\n",
            "2022-05-22 23:44:15,551 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 5 more threads\n",
            "2022-05-22 23:44:15,554 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 4 more threads\n",
            "2022-05-22 23:44:15,555 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 3 more threads\n",
            "2022-05-22 23:44:15,558 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 2 more threads\n",
            "2022-05-22 23:44:15,559 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 1 more threads\n",
            "2022-05-22 23:44:15,590 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 0 more threads\n",
            "2022-05-22 23:44:15,593 | INFO | base_any2vec.py:1346 | _log_epoch_end | EPOCH - 18 : training on 44236 raw words (27886 effective words) took 0.3s, 89176 effective words/s\n",
            "2022-05-22 23:44:15,800 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 31 more threads\n",
            "2022-05-22 23:44:15,801 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 30 more threads\n",
            "2022-05-22 23:44:15,803 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 29 more threads\n",
            "2022-05-22 23:44:15,813 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 28 more threads\n",
            "2022-05-22 23:44:15,814 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 27 more threads\n",
            "2022-05-22 23:44:15,816 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 26 more threads\n",
            "2022-05-22 23:44:15,817 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 25 more threads\n",
            "2022-05-22 23:44:15,822 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 24 more threads\n",
            "2022-05-22 23:44:15,829 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 23 more threads\n",
            "2022-05-22 23:44:15,830 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 22 more threads\n",
            "2022-05-22 23:44:15,831 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 21 more threads\n",
            "2022-05-22 23:44:15,839 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 20 more threads\n",
            "2022-05-22 23:44:15,840 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 19 more threads\n",
            "2022-05-22 23:44:15,841 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 18 more threads\n",
            "2022-05-22 23:44:15,843 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 17 more threads\n",
            "2022-05-22 23:44:15,847 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 16 more threads\n",
            "2022-05-22 23:44:15,848 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 15 more threads\n",
            "2022-05-22 23:44:15,858 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 14 more threads\n",
            "2022-05-22 23:44:15,862 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 13 more threads\n",
            "2022-05-22 23:44:15,863 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 12 more threads\n",
            "2022-05-22 23:44:15,869 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 11 more threads\n",
            "2022-05-22 23:44:15,872 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 10 more threads\n",
            "2022-05-22 23:44:15,876 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 9 more threads\n",
            "2022-05-22 23:44:15,882 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 8 more threads\n",
            "2022-05-22 23:44:15,885 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 7 more threads\n",
            "2022-05-22 23:44:15,891 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 6 more threads\n",
            "2022-05-22 23:44:15,901 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 5 more threads\n",
            "2022-05-22 23:44:15,902 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 4 more threads\n",
            "2022-05-22 23:44:15,903 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 3 more threads\n",
            "2022-05-22 23:44:15,903 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 2 more threads\n",
            "2022-05-22 23:44:15,904 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 1 more threads\n",
            "2022-05-22 23:44:15,905 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 0 more threads\n",
            "2022-05-22 23:44:15,906 | INFO | base_any2vec.py:1346 | _log_epoch_end | EPOCH - 19 : training on 44236 raw words (27883 effective words) took 0.3s, 93831 effective words/s\n",
            "2022-05-22 23:44:16,125 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 31 more threads\n",
            "2022-05-22 23:44:16,127 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 30 more threads\n",
            "2022-05-22 23:44:16,132 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 29 more threads\n",
            "2022-05-22 23:44:16,146 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 28 more threads\n",
            "2022-05-22 23:44:16,147 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 27 more threads\n",
            "2022-05-22 23:44:16,154 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 26 more threads\n",
            "2022-05-22 23:44:16,155 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 25 more threads\n",
            "2022-05-22 23:44:16,158 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 24 more threads\n",
            "2022-05-22 23:44:16,159 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 23 more threads\n",
            "2022-05-22 23:44:16,165 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 22 more threads\n",
            "2022-05-22 23:44:16,166 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 21 more threads\n",
            "2022-05-22 23:44:16,169 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 20 more threads\n",
            "2022-05-22 23:44:16,170 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 19 more threads\n",
            "2022-05-22 23:44:16,173 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 18 more threads\n",
            "2022-05-22 23:44:16,174 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 17 more threads\n",
            "2022-05-22 23:44:16,182 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 16 more threads\n",
            "2022-05-22 23:44:16,183 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 15 more threads\n",
            "2022-05-22 23:44:16,184 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 14 more threads\n",
            "2022-05-22 23:44:16,194 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 13 more threads\n",
            "2022-05-22 23:44:16,195 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 12 more threads\n",
            "2022-05-22 23:44:16,196 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 11 more threads\n",
            "2022-05-22 23:44:16,198 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 10 more threads\n",
            "2022-05-22 23:44:16,202 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 9 more threads\n",
            "2022-05-22 23:44:16,208 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 8 more threads\n",
            "2022-05-22 23:44:16,210 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 7 more threads\n",
            "2022-05-22 23:44:16,211 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 6 more threads\n",
            "2022-05-22 23:44:16,213 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 5 more threads\n",
            "2022-05-22 23:44:16,219 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 4 more threads\n",
            "2022-05-22 23:44:16,223 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 3 more threads\n",
            "2022-05-22 23:44:16,230 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 2 more threads\n",
            "2022-05-22 23:44:16,232 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 1 more threads\n",
            "2022-05-22 23:44:16,272 | INFO | base_any2vec.py:349 | _log_epoch_progress | worker thread finished; awaiting finish of 0 more threads\n",
            "2022-05-22 23:44:16,275 | INFO | base_any2vec.py:1346 | _log_epoch_end | EPOCH - 20 : training on 44236 raw words (27888 effective words) took 0.3s, 80290 effective words/s\n",
            "2022-05-22 23:44:16,278 | INFO | base_any2vec.py:1382 | _log_train_end | training on a 884720 raw words (557918 effective words) took 6.8s, 82197 effective words/s\n",
            "2022-05-22 23:44:16,279 | WARNING | base_any2vec.py:1386 | _log_train_end | under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wordvec_arrays = np.zeros((len(tokenized_mentions), 50)) \n",
        "for i in range(len(tokenized_mentions)):\n",
        "    wordvec_arrays[i,:] = word_vector(tokenized_mentions[i], 50,modelFastTextSkipGramMentions)\n",
        "wordvec_Mentions = pd.DataFrame(wordvec_arrays)\n",
        "wordvec_Mentions.shape"
      ],
      "metadata": {
        "id": "Kd2UvgVRNhqx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6e62018-dd03-4a23-efb1-31cf247c298b"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(88514, 50)"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_fastText2 = pd.DataFrame(np.hstack((fastText_df,wordvec_caption,wordvec_Hashtag,wordvec_emojiText,wordvec_Mentions,data)))"
      ],
      "metadata": {
        "id": "d4e5vKdMNisp"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_fastText2[254]"
      ],
      "metadata": {
        "id": "vZeho1Fj19Nm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb24bc1b-88da-4f5c-a4e9-c12b13a70b06"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0         29.0\n",
              "1         44.0\n",
              "2        209.0\n",
              "3         95.0\n",
              "4        101.0\n",
              "         ...  \n",
              "88509     10.0\n",
              "88510     50.0\n",
              "88511      8.0\n",
              "88512      9.0\n",
              "88513     11.0\n",
              "Name: 254, Length: 88514, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(dataset_fastText2.columns))\n",
        "a=len(dataset_fastText2.columns)-45\n",
        "print(a)\n",
        "dataset_fastText2[len(dataset_fastText2.columns)-43]\n",
        "dataset_fastText2.rename(columns = {a:'likes'}, inplace = True)\n",
        "df=removeColumnContainString(dataset_fastText2)"
      ],
      "metadata": {
        "id": "lph_gWTs3pXZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd260de8-6706-49ed-9deb-f8855c6d5123"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "299\n",
            "254\n",
            "Couldn't covert 250 to float\n",
            "Couldn't covert 251 to float\n",
            "Couldn't covert 252 to float\n",
            "Couldn't covert 258 to float\n",
            "Couldn't covert 272 to float\n",
            "Couldn't covert 274 to float\n",
            "Couldn't covert 276 to float\n",
            "Couldn't covert 277 to float\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "id": "P1dOj_IzoXm1"
      },
      "outputs": [],
      "source": [
        "dataset_fastText2 = dataset_fastText2.reset_index()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# dataset_fastText2[254]"
      ],
      "metadata": {
        "id": "Ecgil_3V4HkJ"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dropped = [250,251,252,258,272,274,276,277]\n",
        "dataset_fastText2.drop(dropped,axis=1,inplace=True)\n",
        "dataset_fastText2"
      ],
      "metadata": {
        "id": "djht73DRgpAs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "69737b3f-4f15-48d9-88ae-97ed92066079"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       index         0         1         2         3         4         5  \\\n",
              "0          0  0.276721  0.113139  0.034563  0.134659 -0.546147 -0.182426   \n",
              "1          1  0.048888  0.576153 -0.355953 -0.162595 -0.233754  0.050176   \n",
              "2          2  -0.01117  0.387848 -0.242469  -0.23539 -0.023971  0.032928   \n",
              "3          3  0.038574  0.280561 -0.386209 -0.046993 -0.029427  0.042889   \n",
              "4          4  0.300424  0.106753  0.064463  0.109077 -0.548251 -0.159049   \n",
              "...      ...       ...       ...       ...       ...       ...       ...   \n",
              "88509  88509  0.286842  0.243731 -0.033131 -0.079824 -0.226685 -0.259312   \n",
              "88510  88510  0.381816   0.00839   0.00374 -0.275623 -0.553979 -0.210371   \n",
              "88511  88511 -0.019925  0.451035 -0.110425 -0.269043 -0.002999  0.007781   \n",
              "88512  88512 -0.052274  0.105286 -0.057282  -0.22315 -0.353306 -0.000037   \n",
              "88513  88513   0.11929   0.32367 -0.046375 -0.322923 -0.294204 -0.026113   \n",
              "\n",
              "              6         7         8  ... 289 290 291 292 293 294       295  \\\n",
              "0     -0.160515  -0.59871 -0.025352  ...   0   0   0   0   0   0       1.0   \n",
              "1     -0.115882 -0.507439 -0.257501  ...   0   0   0   0   0   1  0.647059   \n",
              "2     -0.171692 -0.523088 -0.063837  ...   0   0   0   0   0   1  0.647059   \n",
              "3      0.047218 -0.454082  0.008513  ...   0   0   0   0   0   1  0.647059   \n",
              "4      -0.23577 -0.599744 -0.023256  ...   0   0   0   0   0   0       1.0   \n",
              "...         ...       ...       ...  ...  ..  ..  ..  ..  ..  ..       ...   \n",
              "88509  -0.10287 -0.364772  0.205498  ...   0   0   0   0   0   1       1.0   \n",
              "88510 -0.156245 -0.342969   0.01574  ...   0   0   0   0   0   1  0.501961   \n",
              "88511  0.010109 -0.355132  0.236052  ...   0   0   0   0   0   1  0.501961   \n",
              "88512 -0.157015 -0.686578  0.213414  ...   0   0   0   0   0   1       1.0   \n",
              "88513 -0.011695 -0.493446 -0.016739  ...   0   0   0   0   0   1       1.0   \n",
              "\n",
              "            296       297       298  \n",
              "0      0.788235       1.0       1.0  \n",
              "1      0.690196  0.647059       0.0  \n",
              "2      0.658824  0.647059  0.647059  \n",
              "3      0.243137  0.647059  0.647059  \n",
              "4      0.792157       1.0       1.0  \n",
              "...         ...       ...       ...  \n",
              "88509  0.011765       0.0       1.0  \n",
              "88510  0.647059       0.0       1.0  \n",
              "88511  0.658824  0.501961  0.501961  \n",
              "88512  0.015686       1.0       1.0  \n",
              "88513  0.015686       0.0       1.0  \n",
              "\n",
              "[88514 rows x 292 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ccdae4ad-6783-4dc2-967b-8f4db89af8cd\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>...</th>\n",
              "      <th>289</th>\n",
              "      <th>290</th>\n",
              "      <th>291</th>\n",
              "      <th>292</th>\n",
              "      <th>293</th>\n",
              "      <th>294</th>\n",
              "      <th>295</th>\n",
              "      <th>296</th>\n",
              "      <th>297</th>\n",
              "      <th>298</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0.276721</td>\n",
              "      <td>0.113139</td>\n",
              "      <td>0.034563</td>\n",
              "      <td>0.134659</td>\n",
              "      <td>-0.546147</td>\n",
              "      <td>-0.182426</td>\n",
              "      <td>-0.160515</td>\n",
              "      <td>-0.59871</td>\n",
              "      <td>-0.025352</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.788235</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0.048888</td>\n",
              "      <td>0.576153</td>\n",
              "      <td>-0.355953</td>\n",
              "      <td>-0.162595</td>\n",
              "      <td>-0.233754</td>\n",
              "      <td>0.050176</td>\n",
              "      <td>-0.115882</td>\n",
              "      <td>-0.507439</td>\n",
              "      <td>-0.257501</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.647059</td>\n",
              "      <td>0.690196</td>\n",
              "      <td>0.647059</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>-0.01117</td>\n",
              "      <td>0.387848</td>\n",
              "      <td>-0.242469</td>\n",
              "      <td>-0.23539</td>\n",
              "      <td>-0.023971</td>\n",
              "      <td>0.032928</td>\n",
              "      <td>-0.171692</td>\n",
              "      <td>-0.523088</td>\n",
              "      <td>-0.063837</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.647059</td>\n",
              "      <td>0.658824</td>\n",
              "      <td>0.647059</td>\n",
              "      <td>0.647059</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>0.038574</td>\n",
              "      <td>0.280561</td>\n",
              "      <td>-0.386209</td>\n",
              "      <td>-0.046993</td>\n",
              "      <td>-0.029427</td>\n",
              "      <td>0.042889</td>\n",
              "      <td>0.047218</td>\n",
              "      <td>-0.454082</td>\n",
              "      <td>0.008513</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.647059</td>\n",
              "      <td>0.243137</td>\n",
              "      <td>0.647059</td>\n",
              "      <td>0.647059</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>0.300424</td>\n",
              "      <td>0.106753</td>\n",
              "      <td>0.064463</td>\n",
              "      <td>0.109077</td>\n",
              "      <td>-0.548251</td>\n",
              "      <td>-0.159049</td>\n",
              "      <td>-0.23577</td>\n",
              "      <td>-0.599744</td>\n",
              "      <td>-0.023256</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.792157</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88509</th>\n",
              "      <td>88509</td>\n",
              "      <td>0.286842</td>\n",
              "      <td>0.243731</td>\n",
              "      <td>-0.033131</td>\n",
              "      <td>-0.079824</td>\n",
              "      <td>-0.226685</td>\n",
              "      <td>-0.259312</td>\n",
              "      <td>-0.10287</td>\n",
              "      <td>-0.364772</td>\n",
              "      <td>0.205498</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.011765</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88510</th>\n",
              "      <td>88510</td>\n",
              "      <td>0.381816</td>\n",
              "      <td>0.00839</td>\n",
              "      <td>0.00374</td>\n",
              "      <td>-0.275623</td>\n",
              "      <td>-0.553979</td>\n",
              "      <td>-0.210371</td>\n",
              "      <td>-0.156245</td>\n",
              "      <td>-0.342969</td>\n",
              "      <td>0.01574</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.501961</td>\n",
              "      <td>0.647059</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88511</th>\n",
              "      <td>88511</td>\n",
              "      <td>-0.019925</td>\n",
              "      <td>0.451035</td>\n",
              "      <td>-0.110425</td>\n",
              "      <td>-0.269043</td>\n",
              "      <td>-0.002999</td>\n",
              "      <td>0.007781</td>\n",
              "      <td>0.010109</td>\n",
              "      <td>-0.355132</td>\n",
              "      <td>0.236052</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.501961</td>\n",
              "      <td>0.658824</td>\n",
              "      <td>0.501961</td>\n",
              "      <td>0.501961</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88512</th>\n",
              "      <td>88512</td>\n",
              "      <td>-0.052274</td>\n",
              "      <td>0.105286</td>\n",
              "      <td>-0.057282</td>\n",
              "      <td>-0.22315</td>\n",
              "      <td>-0.353306</td>\n",
              "      <td>-0.000037</td>\n",
              "      <td>-0.157015</td>\n",
              "      <td>-0.686578</td>\n",
              "      <td>0.213414</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.015686</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88513</th>\n",
              "      <td>88513</td>\n",
              "      <td>0.11929</td>\n",
              "      <td>0.32367</td>\n",
              "      <td>-0.046375</td>\n",
              "      <td>-0.322923</td>\n",
              "      <td>-0.294204</td>\n",
              "      <td>-0.026113</td>\n",
              "      <td>-0.011695</td>\n",
              "      <td>-0.493446</td>\n",
              "      <td>-0.016739</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.015686</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>88514 rows × 292 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ccdae4ad-6783-4dc2-967b-8f4db89af8cd')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ccdae4ad-6783-4dc2-967b-8f4db89af8cd button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ccdae4ad-6783-4dc2-967b-8f4db89af8cd');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from utils import clean_dataset\n",
        "clean_dataset(dataset_fastText2)"
      ],
      "metadata": {
        "id": "gB9k44k5lwEB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "7b131f65-00c8-4ee5-ead2-cdc3debee274"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         index         0         1         2         3         4         5  \\\n",
              "0          0.0  0.276721  0.113139  0.034563  0.134659 -0.546147 -0.182426   \n",
              "1          1.0  0.048888  0.576153 -0.355953 -0.162595 -0.233754  0.050176   \n",
              "2          2.0 -0.011170  0.387848 -0.242469 -0.235390 -0.023971  0.032928   \n",
              "3          3.0  0.038574  0.280561 -0.386209 -0.046993 -0.029427  0.042889   \n",
              "4          4.0  0.300424  0.106753  0.064463  0.109077 -0.548251 -0.159049   \n",
              "...        ...       ...       ...       ...       ...       ...       ...   \n",
              "88509  88509.0  0.286842  0.243731 -0.033131 -0.079824 -0.226685 -0.259312   \n",
              "88510  88510.0  0.381816  0.008390  0.003740 -0.275623 -0.553979 -0.210371   \n",
              "88511  88511.0 -0.019925  0.451035 -0.110425 -0.269043 -0.002999  0.007781   \n",
              "88512  88512.0 -0.052274  0.105286 -0.057282 -0.223150 -0.353306 -0.000037   \n",
              "88513  88513.0  0.119290  0.323670 -0.046375 -0.322923 -0.294204 -0.026113   \n",
              "\n",
              "              6         7         8  ...  289  290  291  292  293  294  \\\n",
              "0     -0.160515 -0.598710 -0.025352  ...  0.0  0.0  0.0  0.0  0.0  0.0   \n",
              "1     -0.115882 -0.507439 -0.257501  ...  0.0  0.0  0.0  0.0  0.0  1.0   \n",
              "2     -0.171692 -0.523088 -0.063837  ...  0.0  0.0  0.0  0.0  0.0  1.0   \n",
              "3      0.047218 -0.454082  0.008513  ...  0.0  0.0  0.0  0.0  0.0  1.0   \n",
              "4     -0.235770 -0.599744 -0.023256  ...  0.0  0.0  0.0  0.0  0.0  0.0   \n",
              "...         ...       ...       ...  ...  ...  ...  ...  ...  ...  ...   \n",
              "88509 -0.102870 -0.364772  0.205498  ...  0.0  0.0  0.0  0.0  0.0  1.0   \n",
              "88510 -0.156245 -0.342969  0.015740  ...  0.0  0.0  0.0  0.0  0.0  1.0   \n",
              "88511  0.010109 -0.355132  0.236052  ...  0.0  0.0  0.0  0.0  0.0  1.0   \n",
              "88512 -0.157015 -0.686578  0.213414  ...  0.0  0.0  0.0  0.0  0.0  1.0   \n",
              "88513 -0.011695 -0.493446 -0.016739  ...  0.0  0.0  0.0  0.0  0.0  1.0   \n",
              "\n",
              "            295       296       297       298  \n",
              "0      1.000000  0.788235  1.000000  1.000000  \n",
              "1      0.647059  0.690196  0.647059  0.000000  \n",
              "2      0.647059  0.658824  0.647059  0.647059  \n",
              "3      0.647059  0.243137  0.647059  0.647059  \n",
              "4      1.000000  0.792157  1.000000  1.000000  \n",
              "...         ...       ...       ...       ...  \n",
              "88509  1.000000  0.011765  0.000000  1.000000  \n",
              "88510  0.501961  0.647059  0.000000  1.000000  \n",
              "88511  0.501961  0.658824  0.501961  0.501961  \n",
              "88512  1.000000  0.015686  1.000000  1.000000  \n",
              "88513  1.000000  0.015686  0.000000  1.000000  \n",
              "\n",
              "[88511 rows x 292 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7e76bf47-60b2-460d-97a6-0f4d5f90921e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>...</th>\n",
              "      <th>289</th>\n",
              "      <th>290</th>\n",
              "      <th>291</th>\n",
              "      <th>292</th>\n",
              "      <th>293</th>\n",
              "      <th>294</th>\n",
              "      <th>295</th>\n",
              "      <th>296</th>\n",
              "      <th>297</th>\n",
              "      <th>298</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.276721</td>\n",
              "      <td>0.113139</td>\n",
              "      <td>0.034563</td>\n",
              "      <td>0.134659</td>\n",
              "      <td>-0.546147</td>\n",
              "      <td>-0.182426</td>\n",
              "      <td>-0.160515</td>\n",
              "      <td>-0.598710</td>\n",
              "      <td>-0.025352</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.788235</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.048888</td>\n",
              "      <td>0.576153</td>\n",
              "      <td>-0.355953</td>\n",
              "      <td>-0.162595</td>\n",
              "      <td>-0.233754</td>\n",
              "      <td>0.050176</td>\n",
              "      <td>-0.115882</td>\n",
              "      <td>-0.507439</td>\n",
              "      <td>-0.257501</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.647059</td>\n",
              "      <td>0.690196</td>\n",
              "      <td>0.647059</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2.0</td>\n",
              "      <td>-0.011170</td>\n",
              "      <td>0.387848</td>\n",
              "      <td>-0.242469</td>\n",
              "      <td>-0.235390</td>\n",
              "      <td>-0.023971</td>\n",
              "      <td>0.032928</td>\n",
              "      <td>-0.171692</td>\n",
              "      <td>-0.523088</td>\n",
              "      <td>-0.063837</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.647059</td>\n",
              "      <td>0.658824</td>\n",
              "      <td>0.647059</td>\n",
              "      <td>0.647059</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3.0</td>\n",
              "      <td>0.038574</td>\n",
              "      <td>0.280561</td>\n",
              "      <td>-0.386209</td>\n",
              "      <td>-0.046993</td>\n",
              "      <td>-0.029427</td>\n",
              "      <td>0.042889</td>\n",
              "      <td>0.047218</td>\n",
              "      <td>-0.454082</td>\n",
              "      <td>0.008513</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.647059</td>\n",
              "      <td>0.243137</td>\n",
              "      <td>0.647059</td>\n",
              "      <td>0.647059</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4.0</td>\n",
              "      <td>0.300424</td>\n",
              "      <td>0.106753</td>\n",
              "      <td>0.064463</td>\n",
              "      <td>0.109077</td>\n",
              "      <td>-0.548251</td>\n",
              "      <td>-0.159049</td>\n",
              "      <td>-0.235770</td>\n",
              "      <td>-0.599744</td>\n",
              "      <td>-0.023256</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.792157</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88509</th>\n",
              "      <td>88509.0</td>\n",
              "      <td>0.286842</td>\n",
              "      <td>0.243731</td>\n",
              "      <td>-0.033131</td>\n",
              "      <td>-0.079824</td>\n",
              "      <td>-0.226685</td>\n",
              "      <td>-0.259312</td>\n",
              "      <td>-0.102870</td>\n",
              "      <td>-0.364772</td>\n",
              "      <td>0.205498</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.011765</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88510</th>\n",
              "      <td>88510.0</td>\n",
              "      <td>0.381816</td>\n",
              "      <td>0.008390</td>\n",
              "      <td>0.003740</td>\n",
              "      <td>-0.275623</td>\n",
              "      <td>-0.553979</td>\n",
              "      <td>-0.210371</td>\n",
              "      <td>-0.156245</td>\n",
              "      <td>-0.342969</td>\n",
              "      <td>0.015740</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.501961</td>\n",
              "      <td>0.647059</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88511</th>\n",
              "      <td>88511.0</td>\n",
              "      <td>-0.019925</td>\n",
              "      <td>0.451035</td>\n",
              "      <td>-0.110425</td>\n",
              "      <td>-0.269043</td>\n",
              "      <td>-0.002999</td>\n",
              "      <td>0.007781</td>\n",
              "      <td>0.010109</td>\n",
              "      <td>-0.355132</td>\n",
              "      <td>0.236052</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.501961</td>\n",
              "      <td>0.658824</td>\n",
              "      <td>0.501961</td>\n",
              "      <td>0.501961</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88512</th>\n",
              "      <td>88512.0</td>\n",
              "      <td>-0.052274</td>\n",
              "      <td>0.105286</td>\n",
              "      <td>-0.057282</td>\n",
              "      <td>-0.223150</td>\n",
              "      <td>-0.353306</td>\n",
              "      <td>-0.000037</td>\n",
              "      <td>-0.157015</td>\n",
              "      <td>-0.686578</td>\n",
              "      <td>0.213414</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.015686</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88513</th>\n",
              "      <td>88513.0</td>\n",
              "      <td>0.119290</td>\n",
              "      <td>0.323670</td>\n",
              "      <td>-0.046375</td>\n",
              "      <td>-0.322923</td>\n",
              "      <td>-0.294204</td>\n",
              "      <td>-0.026113</td>\n",
              "      <td>-0.011695</td>\n",
              "      <td>-0.493446</td>\n",
              "      <td>-0.016739</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.015686</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>88511 rows × 292 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7e76bf47-60b2-460d-97a6-0f4d5f90921e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7e76bf47-60b2-460d-97a6-0f4d5f90921e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7e76bf47-60b2-460d-97a6-0f4d5f90921e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BPKV1kN2Cxmz"
      },
      "source": [
        "## MinMaxScaling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "id": "WI2tKMsKoXm8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a9dd452-bff2-46e4-ebec-1666218cefa9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:1692: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:1692: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
            "  FutureWarning,\n"
          ]
        }
      ],
      "source": [
        "from sklearn import preprocessing\n",
        "df = pd.DataFrame(dataset_fastText2)\n",
        "dataset_fastText33=df.astype(str)\n",
        "\n",
        "normalizer = preprocessing.MinMaxScaler(feature_range=(0, 1))\n",
        "normalized_df = pd.DataFrame(normalizer.fit_transform(dataset_fastText33),  columns = dataset_fastText33.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "id": "8A7jwzRZFwFt"
      },
      "outputs": [],
      "source": [
        "y=normalized_df['likes']                #Target Variable \n",
        "X = normalized_df.drop('likes', axis=1) #Feature Matrix "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "id": "Ht99jtBGCoJR"
      },
      "outputs": [],
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=2022)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LightLGBM"
      ],
      "metadata": {
        "id": "XY-M4A3oKxZ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from lightgbm import LGBMRegressor\n",
        "model_lgb = LGBMRegressor(colsample_bytree=0.8,learning_rate=0.01, max_depth=8,min_child_weight=1, min_split_gain=0.0222415, n_estimators=35000,num_leaves=966, reg_alpha=0.04, reg_lambda=0.073,subsample=0.6)"
      ],
      "metadata": {
        "id": "MZoZ2cllKzwH"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start = datetime.datetime.now()\n",
        "lgbm = model_lgb.fit(x_train, y_train,eval_set=[(x_train, y_train), (x_test, y_test)],eval_metric ='mae')\n",
        "end = datetime.datetime.now()\n",
        "end-start"
      ],
      "metadata": {
        "id": "2EN5KQxdLX6V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4c48317-e125-46d1-bd38-0d331a5e28c3"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "[30001]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30002]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30003]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30004]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30005]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30006]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30007]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30008]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30009]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30010]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30011]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30012]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30013]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30014]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30015]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30016]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30017]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30018]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30019]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30020]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30021]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30022]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30023]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30024]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30025]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30026]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30027]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30028]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30029]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30030]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30031]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30032]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30033]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30034]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30035]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30036]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30037]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30038]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30039]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30040]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30041]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30042]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30043]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30044]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30045]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30046]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30047]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30048]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30049]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30050]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30051]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30052]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30053]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30054]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30055]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30056]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30057]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30058]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30059]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30060]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30061]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30062]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30063]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30064]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30065]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30066]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30067]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30068]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30069]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30070]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30071]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30072]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30073]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30074]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30075]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30076]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30077]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30078]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30079]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30080]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30081]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30082]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30083]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30084]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30085]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30086]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30087]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30088]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30089]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30090]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30091]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30092]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30093]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30094]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30095]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30096]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30097]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30098]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30099]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30100]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30101]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30102]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30103]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30104]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30105]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30106]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30107]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30108]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30109]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30110]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30111]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30112]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30113]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30114]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30115]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30116]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30117]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30118]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30119]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30120]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30121]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30122]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30123]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30124]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30125]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30126]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30127]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30128]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30129]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30130]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30131]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30132]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30133]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30134]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30135]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30136]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30137]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30138]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30139]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30140]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30141]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30142]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30143]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30144]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30145]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30146]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30147]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30148]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30149]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30150]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30151]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30152]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30153]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30154]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30155]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30156]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30157]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30158]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30159]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30160]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30161]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30162]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30163]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30164]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30165]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30166]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30167]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30168]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30169]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30170]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30171]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30172]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30173]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30174]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30175]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30176]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30177]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30178]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30179]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30180]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30181]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30182]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30183]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30184]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30185]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30186]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30187]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30188]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30189]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30190]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30191]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30192]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30193]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30194]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30195]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30196]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30197]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30198]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30199]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30200]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30201]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30202]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30203]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30204]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30205]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30206]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30207]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30208]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30209]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30210]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30211]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30212]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30213]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30214]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30215]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30216]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30217]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30218]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30219]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30220]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30221]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30222]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30223]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30224]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30225]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30226]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30227]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30228]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30229]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30230]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30231]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30232]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30233]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30234]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30235]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30236]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30237]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30238]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30239]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30240]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30241]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30242]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30243]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30244]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30245]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30246]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30247]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30248]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30249]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30250]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30251]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30252]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30253]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30254]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30255]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30256]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30257]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30258]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30259]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30260]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30261]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30262]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30263]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30264]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30265]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30266]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30267]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30268]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30269]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30270]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30271]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30272]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30273]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30274]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30275]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30276]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30277]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30278]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30279]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30280]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30281]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30282]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30283]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30284]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30285]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30286]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30287]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30288]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30289]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30290]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30291]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30292]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30293]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30294]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30295]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30296]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30297]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30298]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30299]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30300]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30301]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30302]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30303]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30304]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30305]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30306]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30307]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30308]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30309]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30310]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30311]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30312]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30313]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30314]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30315]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30316]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30317]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30318]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30319]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30320]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30321]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30322]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30323]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30324]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30325]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30326]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30327]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30328]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30329]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30330]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30331]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30332]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30333]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30334]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30335]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30336]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30337]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30338]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30339]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30340]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30341]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30342]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30343]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30344]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30345]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30346]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30347]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30348]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30349]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30350]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30351]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30352]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30353]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30354]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30355]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30356]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30357]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30358]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30359]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30360]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30361]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30362]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30363]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30364]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30365]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30366]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30367]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30368]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30369]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30370]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30371]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30372]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30373]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30374]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30375]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30376]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30377]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30378]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30379]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30380]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30381]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30382]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30383]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30384]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30385]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30386]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30387]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30388]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30389]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30390]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30391]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30392]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30393]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30394]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30395]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30396]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30397]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30398]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30399]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30400]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30401]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30402]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30403]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30404]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30405]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30406]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30407]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30408]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30409]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30410]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30411]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30412]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30413]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30414]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30415]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30416]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30417]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30418]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30419]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30420]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30421]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30422]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30423]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30424]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30425]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30426]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30427]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30428]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30429]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30430]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30431]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30432]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30433]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30434]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30435]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30436]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30437]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30438]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30439]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30440]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30441]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30442]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30443]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30444]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30445]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30446]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30447]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30448]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30449]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30450]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30451]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30452]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30453]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30454]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30455]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30456]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30457]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30458]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30459]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30460]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30461]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30462]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30463]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30464]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30465]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30466]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30467]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30468]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30469]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30470]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30471]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30472]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30473]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30474]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30475]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30476]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30477]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30478]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30479]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30480]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30481]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30482]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30483]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30484]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30485]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30486]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30487]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30488]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30489]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30490]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30491]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30492]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30493]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30494]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30495]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30496]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30497]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30498]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30499]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30500]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30501]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30502]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30503]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30504]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30505]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30506]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30507]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30508]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30509]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30510]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30511]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30512]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30513]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30514]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30515]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30516]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30517]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30518]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30519]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30520]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30521]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30522]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30523]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30524]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30525]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30526]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30527]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30528]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30529]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30530]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30531]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30532]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30533]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30534]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30535]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30536]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30537]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30538]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30539]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30540]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30541]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30542]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30543]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30544]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30545]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30546]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30547]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30548]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30549]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30550]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30551]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30552]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30553]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30554]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30555]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30556]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30557]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30558]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30559]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30560]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30561]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30562]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30563]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30564]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30565]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30566]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30567]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30568]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30569]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30570]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30571]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30572]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30573]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30574]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30575]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30576]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30577]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30578]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30579]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30580]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30581]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30582]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30583]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30584]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30585]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30586]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30587]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30588]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30589]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30590]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30591]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30592]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30593]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30594]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30595]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30596]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30597]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30598]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30599]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30600]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30601]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30602]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30603]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30604]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30605]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30606]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30607]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30608]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30609]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30610]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30611]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30612]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30613]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30614]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30615]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30616]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30617]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30618]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30619]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30620]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30621]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30622]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30623]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30624]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30625]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30626]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30627]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30628]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30629]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30630]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30631]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30632]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30633]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30634]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30635]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30636]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30637]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30638]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30639]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30640]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30641]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30642]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30643]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30644]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30645]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30646]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30647]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30648]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30649]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30650]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30651]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30652]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30653]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30654]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30655]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30656]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30657]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30658]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30659]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30660]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30661]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30662]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30663]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30664]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30665]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30666]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30667]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30668]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30669]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30670]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30671]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30672]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30673]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30674]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30675]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30676]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30677]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30678]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30679]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30680]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30681]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30682]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30683]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30684]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30685]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30686]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30687]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30688]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30689]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30690]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30691]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30692]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30693]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30694]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30695]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30696]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30697]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30698]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30699]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30700]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30701]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30702]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30703]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30704]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30705]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30706]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30707]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30708]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30709]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30710]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30711]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30712]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30713]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30714]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30715]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30716]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30717]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30718]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30719]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30720]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30721]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30722]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30723]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30724]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30725]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30726]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30727]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30728]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30729]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30730]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30731]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30732]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30733]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30734]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30735]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30736]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30737]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30738]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30739]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30740]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30741]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30742]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30743]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30744]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30745]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30746]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30747]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30748]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30749]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30750]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30751]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30752]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30753]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30754]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30755]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30756]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30757]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30758]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30759]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30760]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30761]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30762]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30763]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30764]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30765]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30766]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30767]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30768]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30769]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30770]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30771]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30772]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30773]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30774]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30775]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30776]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30777]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30778]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30779]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30780]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30781]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30782]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30783]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30784]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30785]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30786]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30787]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30788]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30789]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30790]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30791]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30792]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30793]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30794]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30795]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30796]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30797]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30798]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30799]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30800]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30801]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30802]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30803]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30804]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30805]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30806]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30807]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30808]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30809]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30810]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30811]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30812]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30813]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30814]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30815]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30816]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30817]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30818]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30819]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30820]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30821]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30822]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30823]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30824]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30825]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30826]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30827]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30828]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30829]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30830]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30831]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30832]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30833]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30834]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30835]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30836]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30837]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30838]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30839]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30840]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30841]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30842]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30843]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30844]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30845]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30846]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30847]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30848]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30849]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30850]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30851]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30852]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30853]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30854]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30855]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30856]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30857]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30858]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30859]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30860]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30861]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30862]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30863]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30864]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30865]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30866]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30867]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30868]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30869]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30870]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30871]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30872]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30873]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30874]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30875]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30876]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30877]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30878]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30879]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30880]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30881]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30882]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30883]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30884]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30885]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30886]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30887]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30888]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30889]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30890]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30891]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30892]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30893]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30894]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30895]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30896]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30897]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30898]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30899]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30900]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30901]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30902]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30903]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30904]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30905]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30906]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30907]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30908]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30909]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30910]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30911]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30912]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30913]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30914]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30915]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30916]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30917]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30918]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30919]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30920]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30921]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30922]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30923]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30924]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30925]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30926]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30927]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30928]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30929]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30930]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30931]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30932]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30933]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30934]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30935]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30936]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30937]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30938]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30939]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30940]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30941]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30942]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30943]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30944]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30945]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30946]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30947]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30948]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30949]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30950]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30951]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30952]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30953]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30954]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30955]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30956]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30957]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30958]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30959]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30960]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30961]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30962]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30963]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30964]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30965]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30966]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30967]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30968]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30969]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30970]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30971]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30972]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30973]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30974]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30975]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30976]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30977]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30978]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30979]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30980]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30981]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30982]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30983]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30984]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30985]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30986]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30987]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30988]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30989]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30990]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30991]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30992]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30993]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30994]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30995]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30996]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30997]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30998]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[30999]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31000]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31001]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31002]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31003]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31004]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31005]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31006]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31007]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31008]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31009]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31010]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31011]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31012]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31013]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31014]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31015]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31016]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31017]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31018]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31019]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31020]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31021]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31022]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31023]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31024]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31025]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31026]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31027]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31028]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31029]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31030]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31031]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31032]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31033]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31034]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31035]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31036]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31037]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31038]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31039]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31040]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31041]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31042]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31043]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31044]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31045]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31046]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31047]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31048]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31049]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31050]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31051]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31052]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31053]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31054]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31055]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31056]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31057]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31058]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31059]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31060]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31061]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31062]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31063]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31064]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31065]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31066]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31067]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31068]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31069]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31070]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31071]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31072]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31073]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31074]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31075]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31076]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31077]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31078]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31079]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31080]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31081]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31082]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31083]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31084]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31085]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31086]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31087]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31088]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31089]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31090]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31091]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31092]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31093]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31094]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31095]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31096]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31097]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31098]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31099]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31100]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31101]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31102]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31103]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31104]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31105]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31106]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31107]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31108]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31109]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31110]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31111]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31112]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31113]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31114]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31115]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31116]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31117]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31118]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31119]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31120]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31121]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31122]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31123]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31124]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31125]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31126]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31127]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31128]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31129]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31130]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31131]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31132]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31133]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31134]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31135]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31136]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31137]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31138]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31139]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31140]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31141]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31142]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31143]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31144]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31145]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31146]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31147]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31148]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31149]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31150]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31151]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31152]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31153]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31154]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31155]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31156]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31157]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31158]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31159]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31160]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31161]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31162]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31163]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31164]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31165]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31166]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31167]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31168]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31169]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31170]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31171]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31172]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31173]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31174]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31175]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31176]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31177]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31178]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31179]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31180]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31181]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31182]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31183]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31184]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31185]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31186]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31187]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31188]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31189]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31190]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31191]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31192]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31193]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31194]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31195]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31196]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31197]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31198]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31199]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31200]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31201]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31202]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31203]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31204]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31205]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31206]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31207]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31208]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31209]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31210]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31211]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31212]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31213]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31214]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31215]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31216]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31217]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31218]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31219]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31220]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31221]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31222]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31223]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31224]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31225]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31226]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31227]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31228]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31229]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31230]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31231]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31232]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31233]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31234]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31235]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31236]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31237]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31238]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31239]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31240]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31241]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31242]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31243]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31244]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31245]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31246]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31247]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31248]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31249]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31250]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31251]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31252]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31253]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31254]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31255]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31256]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31257]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31258]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31259]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31260]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31261]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31262]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31263]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31264]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31265]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31266]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31267]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31268]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31269]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31270]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31271]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31272]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31273]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31274]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31275]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31276]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31277]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31278]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31279]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31280]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31281]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31282]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31283]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31284]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31285]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31286]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31287]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31288]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31289]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31290]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31291]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31292]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31293]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31294]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31295]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31296]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31297]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31298]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31299]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31300]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31301]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31302]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31303]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31304]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31305]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31306]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31307]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31308]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31309]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31310]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31311]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31312]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31313]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31314]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31315]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31316]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31317]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31318]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31319]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31320]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31321]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31322]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31323]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31324]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31325]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31326]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31327]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31328]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31329]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31330]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31331]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31332]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31333]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31334]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31335]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31336]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31337]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31338]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31339]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31340]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31341]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31342]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31343]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31344]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31345]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31346]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31347]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31348]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31349]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31350]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31351]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31352]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31353]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31354]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31355]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31356]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31357]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31358]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31359]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31360]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31361]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31362]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31363]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31364]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31365]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31366]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31367]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31368]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31369]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31370]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31371]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31372]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31373]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31374]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31375]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31376]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31377]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31378]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31379]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31380]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31381]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31382]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31383]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31384]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31385]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31386]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31387]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31388]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31389]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31390]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31391]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31392]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31393]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31394]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31395]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31396]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31397]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31398]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31399]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31400]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31401]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31402]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31403]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31404]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31405]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31406]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31407]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31408]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31409]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31410]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31411]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31412]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31413]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31414]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31415]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31416]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31417]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31418]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31419]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31420]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31421]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31422]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31423]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31424]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31425]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31426]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31427]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31428]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31429]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31430]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31431]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31432]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31433]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31434]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31435]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31436]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31437]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31438]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31439]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31440]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31441]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31442]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31443]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31444]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31445]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31446]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31447]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31448]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31449]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31450]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31451]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31452]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31453]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31454]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31455]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31456]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31457]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31458]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31459]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31460]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31461]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31462]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31463]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31464]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31465]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31466]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31467]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31468]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31469]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31470]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31471]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31472]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31473]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31474]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31475]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31476]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31477]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31478]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31479]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31480]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31481]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31482]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31483]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31484]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31485]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31486]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31487]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31488]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31489]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31490]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31491]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31492]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31493]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31494]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31495]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31496]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31497]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31498]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31499]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31500]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31501]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31502]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31503]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31504]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31505]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31506]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31507]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31508]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31509]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31510]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31511]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31512]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31513]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31514]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31515]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31516]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31517]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31518]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31519]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31520]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31521]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31522]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31523]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31524]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31525]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31526]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31527]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31528]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31529]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31530]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31531]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31532]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31533]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31534]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31535]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31536]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31537]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31538]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31539]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31540]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31541]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31542]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31543]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31544]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31545]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31546]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31547]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31548]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31549]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31550]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31551]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31552]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31553]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31554]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31555]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31556]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31557]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31558]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31559]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31560]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31561]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31562]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31563]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31564]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31565]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31566]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31567]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31568]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31569]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31570]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31571]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31572]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31573]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31574]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31575]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31576]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31577]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31578]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31579]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31580]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31581]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31582]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31583]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31584]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31585]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31586]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31587]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31588]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31589]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31590]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31591]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31592]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31593]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31594]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31595]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31596]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31597]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31598]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31599]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31600]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31601]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31602]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31603]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31604]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31605]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31606]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31607]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31608]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31609]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31610]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31611]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31612]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31613]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31614]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31615]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31616]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31617]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31618]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31619]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31620]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31621]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31622]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31623]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31624]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31625]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31626]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31627]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31628]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31629]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31630]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31631]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31632]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31633]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31634]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31635]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31636]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31637]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31638]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31639]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31640]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31641]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31642]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31643]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31644]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31645]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31646]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31647]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31648]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31649]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31650]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31651]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31652]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31653]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31654]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31655]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31656]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31657]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31658]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31659]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31660]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31661]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31662]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31663]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31664]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31665]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31666]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31667]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31668]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31669]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31670]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31671]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31672]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31673]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31674]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31675]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31676]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31677]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31678]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31679]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31680]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31681]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31682]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31683]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31684]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31685]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31686]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31687]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31688]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31689]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31690]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31691]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31692]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31693]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31694]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31695]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31696]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31697]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31698]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31699]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31700]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31701]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31702]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31703]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31704]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31705]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31706]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31707]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31708]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31709]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31710]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31711]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31712]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31713]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31714]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31715]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31716]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31717]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31718]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31719]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31720]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31721]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31722]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31723]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31724]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31725]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31726]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31727]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31728]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31729]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31730]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31731]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31732]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31733]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31734]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31735]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31736]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31737]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31738]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31739]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31740]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31741]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31742]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31743]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31744]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31745]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31746]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31747]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31748]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31749]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31750]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31751]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31752]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31753]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31754]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31755]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31756]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31757]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31758]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31759]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31760]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31761]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31762]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31763]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31764]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31765]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31766]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31767]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31768]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31769]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31770]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31771]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31772]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31773]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31774]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31775]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31776]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31777]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31778]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31779]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31780]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31781]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31782]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31783]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31784]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31785]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31786]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31787]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31788]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31789]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31790]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31791]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31792]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31793]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31794]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31795]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31796]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31797]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31798]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31799]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31800]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31801]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31802]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31803]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31804]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31805]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31806]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31807]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31808]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31809]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31810]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31811]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31812]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31813]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31814]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31815]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31816]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31817]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31818]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31819]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31820]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31821]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31822]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31823]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31824]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31825]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31826]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31827]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31828]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31829]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31830]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31831]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31832]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31833]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31834]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31835]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31836]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31837]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31838]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31839]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31840]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31841]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31842]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31843]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31844]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31845]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31846]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31847]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31848]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31849]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31850]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31851]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31852]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31853]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31854]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31855]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31856]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31857]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31858]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31859]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31860]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31861]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31862]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31863]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31864]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31865]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31866]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31867]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31868]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31869]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31870]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31871]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31872]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31873]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31874]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31875]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31876]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31877]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31878]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31879]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31880]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31881]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31882]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31883]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31884]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31885]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31886]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31887]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31888]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31889]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31890]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31891]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31892]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31893]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31894]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31895]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31896]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31897]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31898]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31899]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31900]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31901]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31902]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31903]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31904]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31905]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31906]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31907]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31908]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31909]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31910]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31911]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31912]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31913]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31914]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31915]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31916]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31917]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31918]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31919]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31920]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31921]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31922]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31923]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31924]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31925]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31926]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31927]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31928]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31929]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31930]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31931]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31932]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31933]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31934]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31935]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31936]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31937]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31938]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31939]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31940]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31941]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31942]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31943]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31944]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31945]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31946]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31947]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31948]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31949]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31950]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31951]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31952]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31953]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31954]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31955]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31956]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31957]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31958]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31959]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31960]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31961]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31962]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31963]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31964]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31965]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31966]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31967]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31968]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31969]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31970]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31971]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31972]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31973]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31974]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31975]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31976]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31977]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31978]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31979]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31980]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31981]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31982]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31983]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31984]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31985]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31986]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31987]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31988]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31989]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31990]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31991]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31992]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31993]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31994]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31995]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31996]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31997]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31998]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[31999]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32000]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32001]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32002]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32003]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32004]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32005]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32006]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32007]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32008]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32009]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32010]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32011]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32012]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32013]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32014]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32015]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32016]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32017]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32018]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32019]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32020]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32021]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32022]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32023]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32024]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32025]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32026]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32027]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32028]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32029]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32030]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32031]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32032]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32033]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32034]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32035]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32036]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32037]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32038]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32039]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32040]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32041]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32042]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32043]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32044]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32045]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32046]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32047]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32048]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32049]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32050]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32051]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32052]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32053]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32054]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32055]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32056]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32057]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32058]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32059]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32060]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32061]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32062]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32063]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32064]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32065]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32066]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32067]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32068]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32069]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32070]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32071]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32072]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32073]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32074]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32075]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32076]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32077]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32078]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32079]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32080]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32081]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32082]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32083]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32084]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32085]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32086]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32087]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32088]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32089]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32090]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32091]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32092]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32093]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32094]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32095]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32096]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32097]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32098]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32099]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32100]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32101]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32102]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32103]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32104]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32105]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32106]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32107]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32108]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32109]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32110]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32111]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32112]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32113]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32114]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32115]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32116]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32117]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32118]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32119]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32120]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32121]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32122]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32123]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32124]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32125]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32126]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32127]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32128]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32129]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32130]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32131]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32132]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32133]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32134]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32135]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32136]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32137]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32138]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32139]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32140]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32141]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32142]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32143]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32144]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32145]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32146]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32147]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32148]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32149]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32150]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32151]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32152]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32153]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32154]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32155]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32156]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32157]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32158]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32159]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32160]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32161]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32162]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32163]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32164]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32165]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32166]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32167]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32168]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32169]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32170]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32171]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32172]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32173]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32174]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32175]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32176]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32177]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32178]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32179]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32180]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32181]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32182]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32183]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32184]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32185]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32186]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32187]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32188]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32189]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32190]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32191]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32192]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32193]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32194]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32195]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32196]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32197]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32198]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32199]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32200]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32201]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32202]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32203]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32204]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32205]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32206]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32207]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32208]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32209]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32210]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32211]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32212]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32213]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32214]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32215]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32216]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32217]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32218]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32219]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32220]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32221]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32222]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32223]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32224]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32225]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32226]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32227]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32228]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32229]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32230]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32231]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32232]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32233]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32234]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32235]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32236]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32237]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32238]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32239]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32240]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32241]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32242]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32243]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32244]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32245]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32246]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32247]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32248]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32249]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32250]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32251]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32252]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32253]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32254]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32255]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32256]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32257]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32258]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32259]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32260]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32261]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32262]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32263]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32264]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32265]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32266]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32267]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32268]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32269]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32270]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32271]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32272]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32273]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32274]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32275]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32276]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32277]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32278]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32279]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32280]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32281]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32282]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32283]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32284]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32285]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32286]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32287]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32288]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32289]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32290]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32291]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32292]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32293]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32294]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32295]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32296]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32297]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32298]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32299]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32300]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32301]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32302]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32303]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32304]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32305]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32306]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32307]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32308]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32309]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32310]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32311]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32312]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32313]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32314]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32315]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32316]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32317]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32318]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32319]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32320]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32321]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32322]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32323]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32324]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32325]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32326]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32327]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32328]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32329]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32330]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32331]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32332]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32333]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32334]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32335]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32336]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32337]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32338]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32339]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32340]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32341]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32342]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32343]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32344]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32345]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32346]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32347]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32348]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32349]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32350]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32351]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32352]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32353]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32354]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32355]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32356]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32357]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32358]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32359]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32360]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32361]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32362]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32363]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32364]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32365]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32366]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32367]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32368]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32369]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32370]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32371]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32372]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32373]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32374]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32375]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32376]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32377]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32378]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32379]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32380]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32381]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32382]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32383]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32384]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32385]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32386]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32387]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32388]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32389]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32390]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32391]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32392]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32393]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32394]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32395]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32396]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32397]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32398]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32399]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32400]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32401]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32402]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32403]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32404]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32405]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32406]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32407]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32408]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32409]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32410]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32411]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32412]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32413]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32414]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32415]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32416]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32417]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32418]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32419]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32420]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32421]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32422]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32423]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32424]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32425]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32426]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32427]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32428]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32429]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32430]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32431]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32432]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32433]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32434]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32435]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32436]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32437]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32438]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32439]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32440]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32441]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32442]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32443]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32444]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32445]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32446]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32447]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32448]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32449]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32450]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32451]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32452]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32453]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32454]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32455]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32456]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32457]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32458]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32459]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32460]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32461]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32462]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32463]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32464]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32465]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32466]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32467]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32468]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32469]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32470]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32471]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32472]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32473]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32474]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32475]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32476]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32477]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32478]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32479]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32480]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32481]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32482]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32483]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32484]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32485]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32486]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32487]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32488]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32489]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32490]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32491]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32492]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32493]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32494]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32495]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32496]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32497]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32498]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32499]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32500]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32501]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32502]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32503]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32504]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32505]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32506]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32507]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32508]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32509]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32510]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32511]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32512]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32513]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32514]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32515]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32516]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32517]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32518]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32519]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32520]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32521]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32522]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32523]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32524]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32525]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32526]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32527]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32528]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32529]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32530]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32531]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32532]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32533]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32534]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32535]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32536]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32537]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32538]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32539]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32540]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32541]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32542]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32543]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32544]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32545]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32546]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32547]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32548]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32549]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32550]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32551]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32552]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32553]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32554]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32555]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32556]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32557]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32558]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32559]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32560]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32561]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32562]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32563]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32564]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32565]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32566]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32567]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32568]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32569]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32570]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32571]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32572]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32573]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32574]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32575]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32576]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32577]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32578]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32579]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32580]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32581]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32582]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32583]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32584]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32585]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32586]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32587]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32588]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32589]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32590]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32591]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32592]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32593]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32594]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32595]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32596]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32597]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32598]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32599]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32600]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32601]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32602]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32603]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32604]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32605]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32606]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32607]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32608]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32609]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32610]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32611]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32612]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32613]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32614]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32615]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32616]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32617]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32618]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32619]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32620]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32621]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32622]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32623]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32624]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32625]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32626]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32627]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32628]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32629]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32630]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32631]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32632]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32633]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32634]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32635]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32636]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32637]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32638]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32639]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32640]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32641]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32642]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32643]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32644]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32645]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32646]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32647]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32648]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32649]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32650]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32651]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32652]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32653]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32654]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32655]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32656]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32657]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32658]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32659]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32660]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32661]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32662]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32663]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32664]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32665]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32666]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32667]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32668]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32669]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32670]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32671]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32672]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32673]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32674]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32675]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32676]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32677]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32678]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32679]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32680]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32681]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32682]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32683]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32684]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32685]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32686]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32687]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32688]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32689]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32690]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32691]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32692]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32693]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32694]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32695]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32696]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32697]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32698]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32699]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32700]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32701]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32702]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32703]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32704]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32705]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32706]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32707]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32708]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32709]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32710]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32711]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32712]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32713]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32714]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32715]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32716]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32717]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32718]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32719]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32720]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32721]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32722]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32723]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32724]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32725]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32726]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32727]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32728]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32729]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32730]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32731]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32732]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32733]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32734]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32735]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32736]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32737]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32738]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32739]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32740]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32741]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32742]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32743]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32744]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32745]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32746]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32747]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32748]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32749]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32750]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32751]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32752]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32753]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32754]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32755]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32756]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32757]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32758]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32759]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32760]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32761]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32762]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32763]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32764]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32765]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32766]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32767]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32768]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32769]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32770]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32771]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32772]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32773]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32774]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32775]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32776]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32777]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32778]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32779]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32780]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32781]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32782]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32783]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32784]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32785]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32786]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32787]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32788]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32789]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32790]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32791]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32792]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32793]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32794]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32795]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32796]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32797]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32798]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32799]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32800]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32801]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32802]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32803]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32804]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32805]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32806]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32807]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32808]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32809]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32810]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32811]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32812]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32813]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32814]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32815]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32816]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32817]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32818]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32819]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32820]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32821]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32822]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32823]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32824]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32825]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32826]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32827]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32828]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32829]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32830]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32831]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32832]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32833]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32834]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32835]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32836]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32837]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32838]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32839]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32840]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32841]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32842]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32843]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32844]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32845]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32846]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32847]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32848]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32849]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32850]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32851]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32852]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32853]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32854]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32855]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32856]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32857]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32858]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32859]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32860]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32861]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32862]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32863]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32864]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32865]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32866]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32867]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32868]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32869]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32870]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32871]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32872]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32873]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32874]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32875]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32876]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32877]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32878]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32879]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32880]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32881]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32882]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32883]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32884]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32885]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32886]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32887]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32888]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32889]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32890]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32891]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32892]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32893]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32894]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32895]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32896]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32897]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32898]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32899]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32900]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32901]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32902]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32903]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32904]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32905]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32906]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32907]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32908]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32909]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32910]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32911]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32912]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32913]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32914]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32915]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32916]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32917]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32918]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32919]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32920]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32921]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32922]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32923]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32924]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32925]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32926]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32927]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32928]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32929]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32930]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32931]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32932]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32933]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32934]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32935]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32936]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32937]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32938]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32939]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32940]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32941]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32942]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32943]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32944]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32945]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32946]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32947]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32948]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32949]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32950]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32951]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32952]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32953]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32954]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32955]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32956]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32957]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32958]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32959]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32960]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32961]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32962]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32963]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32964]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32965]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32966]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32967]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32968]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32969]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32970]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32971]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32972]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32973]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32974]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32975]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32976]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32977]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32978]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32979]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32980]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32981]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32982]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32983]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32984]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32985]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32986]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32987]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32988]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32989]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32990]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32991]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32992]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32993]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32994]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32995]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32996]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32997]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32998]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[32999]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33000]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33001]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33002]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33003]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33004]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33005]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33006]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33007]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33008]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33009]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33010]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33011]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33012]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33013]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33014]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33015]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33016]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33017]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33018]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33019]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33020]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33021]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33022]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33023]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33024]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33025]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33026]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33027]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33028]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33029]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33030]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33031]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33032]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33033]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33034]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33035]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33036]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33037]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33038]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33039]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33040]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33041]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33042]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33043]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33044]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33045]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33046]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33047]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33048]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33049]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33050]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33051]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33052]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33053]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33054]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33055]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33056]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33057]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33058]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33059]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33060]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33061]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33062]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33063]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33064]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33065]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33066]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33067]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33068]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33069]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33070]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33071]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33072]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33073]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33074]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33075]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33076]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33077]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33078]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33079]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33080]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33081]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33082]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33083]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33084]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33085]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33086]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33087]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33088]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33089]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33090]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33091]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33092]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33093]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33094]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33095]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33096]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33097]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33098]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33099]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33100]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33101]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33102]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33103]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33104]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33105]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33106]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33107]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33108]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33109]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33110]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33111]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33112]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33113]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33114]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33115]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33116]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33117]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33118]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33119]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33120]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33121]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33122]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33123]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33124]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33125]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33126]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33127]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33128]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33129]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33130]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33131]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33132]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33133]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33134]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33135]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33136]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33137]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33138]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33139]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33140]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33141]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33142]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33143]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33144]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33145]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33146]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33147]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33148]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33149]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33150]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33151]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33152]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33153]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33154]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33155]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33156]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33157]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33158]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33159]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33160]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33161]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33162]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33163]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33164]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33165]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33166]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33167]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33168]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33169]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33170]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33171]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33172]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33173]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33174]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33175]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33176]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33177]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33178]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33179]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33180]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33181]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33182]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33183]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33184]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33185]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33186]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33187]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33188]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33189]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33190]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33191]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33192]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33193]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33194]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33195]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33196]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33197]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33198]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33199]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33200]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33201]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33202]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33203]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33204]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33205]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33206]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33207]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33208]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33209]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33210]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33211]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33212]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33213]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33214]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33215]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33216]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33217]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33218]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33219]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33220]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33221]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33222]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33223]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33224]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33225]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33226]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33227]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33228]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33229]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33230]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33231]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33232]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33233]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33234]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33235]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33236]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33237]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33238]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33239]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33240]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33241]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33242]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33243]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33244]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33245]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33246]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33247]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33248]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33249]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33250]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33251]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33252]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33253]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33254]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33255]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33256]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33257]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33258]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33259]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33260]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33261]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33262]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33263]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33264]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33265]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33266]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33267]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33268]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33269]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33270]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33271]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33272]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33273]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33274]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33275]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33276]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33277]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33278]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33279]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33280]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33281]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33282]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33283]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33284]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33285]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33286]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33287]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33288]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33289]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33290]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33291]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33292]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33293]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33294]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33295]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33296]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33297]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33298]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33299]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33300]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33301]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33302]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33303]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33304]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33305]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33306]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33307]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33308]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33309]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33310]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33311]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33312]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33313]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33314]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33315]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33316]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33317]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33318]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33319]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33320]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33321]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33322]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33323]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33324]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33325]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33326]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33327]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33328]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33329]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33330]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33331]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33332]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33333]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33334]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33335]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33336]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33337]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33338]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33339]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33340]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33341]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33342]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33343]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33344]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33345]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33346]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33347]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33348]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33349]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33350]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33351]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33352]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33353]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33354]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33355]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33356]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33357]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33358]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33359]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33360]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33361]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33362]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33363]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33364]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33365]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33366]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33367]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33368]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33369]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33370]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33371]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33372]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33373]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33374]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33375]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33376]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33377]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33378]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33379]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33380]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33381]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33382]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33383]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33384]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33385]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33386]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33387]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33388]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33389]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33390]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33391]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33392]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33393]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33394]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33395]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33396]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33397]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33398]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33399]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33400]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33401]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33402]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33403]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33404]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33405]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33406]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33407]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33408]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33409]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33410]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33411]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33412]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33413]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33414]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33415]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33416]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33417]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33418]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33419]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33420]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33421]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33422]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33423]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33424]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33425]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33426]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33427]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33428]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33429]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33430]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33431]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33432]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33433]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33434]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33435]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33436]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33437]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33438]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33439]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33440]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33441]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33442]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33443]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33444]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33445]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33446]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33447]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33448]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33449]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33450]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33451]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33452]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33453]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33454]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33455]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33456]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33457]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33458]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33459]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33460]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33461]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33462]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33463]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33464]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33465]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33466]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33467]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33468]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33469]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33470]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33471]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33472]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33473]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33474]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33475]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33476]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33477]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33478]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33479]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33480]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33481]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33482]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33483]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33484]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33485]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33486]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33487]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33488]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33489]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33490]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33491]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33492]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33493]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33494]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33495]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33496]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33497]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33498]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33499]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33500]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33501]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33502]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33503]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33504]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33505]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33506]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33507]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33508]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33509]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33510]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33511]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33512]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33513]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33514]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33515]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33516]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33517]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33518]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33519]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33520]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33521]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33522]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33523]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33524]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33525]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33526]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33527]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33528]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33529]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33530]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33531]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33532]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33533]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33534]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33535]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33536]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33537]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33538]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33539]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33540]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33541]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33542]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33543]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33544]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33545]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33546]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33547]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33548]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33549]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33550]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33551]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33552]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33553]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33554]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33555]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33556]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33557]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33558]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33559]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33560]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33561]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33562]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33563]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33564]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33565]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33566]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33567]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33568]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33569]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33570]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33571]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33572]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33573]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33574]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33575]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33576]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33577]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33578]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33579]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33580]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33581]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33582]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33583]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33584]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33585]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33586]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33587]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33588]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33589]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33590]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33591]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33592]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33593]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33594]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33595]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33596]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33597]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33598]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33599]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33600]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33601]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33602]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33603]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33604]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33605]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33606]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33607]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33608]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33609]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33610]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33611]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33612]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33613]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33614]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33615]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33616]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33617]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33618]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33619]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33620]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33621]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33622]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33623]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33624]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33625]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33626]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33627]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33628]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33629]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33630]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33631]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33632]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33633]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33634]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33635]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33636]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33637]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33638]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33639]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33640]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33641]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33642]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33643]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33644]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33645]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33646]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33647]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33648]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33649]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33650]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33651]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33652]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33653]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33654]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33655]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33656]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33657]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33658]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33659]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33660]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33661]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33662]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33663]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33664]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33665]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33666]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33667]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33668]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33669]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33670]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33671]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33672]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33673]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33674]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33675]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33676]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33677]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33678]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33679]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33680]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33681]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33682]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33683]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33684]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33685]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33686]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33687]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33688]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33689]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33690]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33691]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33692]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33693]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33694]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33695]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33696]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33697]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33698]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33699]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33700]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33701]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33702]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33703]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33704]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33705]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33706]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33707]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33708]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33709]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33710]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33711]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33712]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33713]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33714]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33715]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33716]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33717]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33718]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33719]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33720]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33721]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33722]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33723]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33724]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33725]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33726]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33727]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33728]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33729]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33730]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33731]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33732]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33733]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33734]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33735]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33736]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33737]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33738]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33739]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33740]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33741]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33742]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33743]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33744]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33745]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33746]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33747]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33748]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33749]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33750]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33751]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33752]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33753]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33754]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33755]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33756]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33757]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33758]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33759]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33760]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33761]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33762]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33763]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33764]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33765]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33766]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33767]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33768]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33769]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33770]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33771]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33772]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33773]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33774]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33775]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33776]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33777]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33778]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33779]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33780]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33781]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33782]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33783]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33784]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33785]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33786]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33787]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33788]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33789]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33790]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33791]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33792]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33793]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33794]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33795]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33796]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33797]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33798]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33799]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33800]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33801]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33802]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33803]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33804]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33805]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33806]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33807]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33808]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33809]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33810]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33811]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33812]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33813]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33814]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33815]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33816]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33817]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33818]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33819]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33820]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33821]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33822]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33823]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33824]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33825]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33826]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33827]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33828]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33829]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33830]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33831]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33832]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33833]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33834]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33835]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33836]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33837]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33838]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33839]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33840]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33841]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33842]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33843]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33844]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33845]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33846]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33847]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33848]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33849]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33850]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33851]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33852]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33853]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33854]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33855]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33856]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33857]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33858]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33859]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33860]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33861]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33862]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33863]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33864]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33865]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33866]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33867]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33868]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33869]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33870]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33871]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33872]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33873]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33874]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33875]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33876]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33877]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33878]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33879]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33880]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33881]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33882]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33883]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33884]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33885]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33886]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33887]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33888]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33889]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33890]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33891]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33892]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33893]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33894]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33895]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33896]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33897]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33898]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33899]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33900]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33901]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33902]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33903]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33904]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33905]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33906]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33907]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33908]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33909]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33910]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33911]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33912]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33913]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33914]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33915]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33916]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33917]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33918]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33919]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33920]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33921]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33922]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33923]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33924]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33925]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33926]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33927]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33928]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33929]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33930]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33931]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33932]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33933]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33934]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33935]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33936]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33937]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33938]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33939]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33940]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33941]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33942]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33943]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33944]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33945]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33946]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33947]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33948]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33949]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33950]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33951]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33952]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33953]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33954]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33955]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33956]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33957]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33958]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33959]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33960]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33961]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33962]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33963]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33964]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33965]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33966]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33967]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33968]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33969]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33970]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33971]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33972]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33973]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33974]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33975]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33976]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33977]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33978]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33979]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33980]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33981]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33982]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33983]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33984]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33985]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33986]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33987]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33988]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33989]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33990]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33991]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33992]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33993]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33994]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33995]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33996]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33997]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33998]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[33999]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34000]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34001]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34002]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34003]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34004]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34005]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34006]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34007]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34008]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34009]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34010]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34011]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34012]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34013]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34014]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34015]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34016]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34017]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34018]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34019]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34020]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34021]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34022]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34023]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34024]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34025]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34026]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34027]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34028]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34029]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34030]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34031]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34032]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34033]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34034]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34035]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34036]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34037]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34038]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34039]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34040]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34041]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34042]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34043]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34044]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34045]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34046]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34047]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34048]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34049]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34050]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34051]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34052]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34053]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34054]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34055]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34056]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34057]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34058]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34059]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34060]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34061]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34062]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34063]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34064]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34065]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34066]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34067]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34068]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34069]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34070]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34071]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34072]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34073]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34074]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34075]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34076]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34077]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34078]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34079]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34080]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34081]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34082]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34083]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34084]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34085]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34086]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34087]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34088]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34089]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34090]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34091]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34092]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34093]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34094]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34095]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34096]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34097]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34098]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34099]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34100]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34101]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34102]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34103]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34104]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34105]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34106]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34107]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34108]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34109]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34110]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34111]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34112]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34113]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34114]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34115]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34116]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34117]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34118]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34119]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34120]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34121]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34122]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34123]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34124]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34125]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34126]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34127]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34128]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34129]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34130]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34131]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34132]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34133]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34134]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34135]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34136]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34137]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34138]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34139]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34140]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34141]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34142]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34143]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34144]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34145]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34146]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34147]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34148]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34149]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34150]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34151]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34152]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34153]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34154]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34155]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34156]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34157]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34158]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34159]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34160]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34161]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34162]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34163]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34164]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34165]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34166]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34167]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34168]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34169]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34170]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34171]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34172]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34173]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34174]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34175]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34176]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34177]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34178]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34179]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34180]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34181]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34182]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34183]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34184]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34185]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34186]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34187]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34188]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34189]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34190]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34191]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34192]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34193]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34194]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34195]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34196]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34197]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34198]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34199]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34200]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34201]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34202]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34203]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34204]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34205]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34206]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34207]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34208]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34209]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34210]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34211]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34212]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34213]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34214]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34215]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34216]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34217]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34218]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34219]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34220]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34221]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34222]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34223]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34224]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34225]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34226]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34227]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34228]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34229]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34230]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34231]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34232]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34233]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34234]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34235]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34236]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34237]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34238]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34239]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34240]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34241]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34242]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34243]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34244]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34245]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34246]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34247]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34248]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34249]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34250]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34251]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34252]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34253]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34254]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34255]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34256]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34257]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34258]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34259]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34260]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34261]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34262]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34263]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34264]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34265]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34266]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34267]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34268]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34269]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34270]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34271]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34272]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34273]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34274]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34275]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34276]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34277]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34278]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34279]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34280]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34281]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34282]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34283]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34284]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34285]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34286]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34287]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34288]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34289]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34290]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34291]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34292]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34293]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34294]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34295]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34296]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34297]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34298]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34299]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34300]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34301]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34302]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34303]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34304]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34305]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34306]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34307]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34308]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34309]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34310]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34311]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34312]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34313]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34314]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34315]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34316]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34317]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34318]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34319]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34320]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34321]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34322]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34323]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34324]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34325]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34326]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34327]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34328]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34329]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34330]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34331]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34332]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34333]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34334]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34335]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34336]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34337]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34338]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34339]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34340]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34341]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34342]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34343]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34344]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34345]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34346]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34347]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34348]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34349]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34350]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34351]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34352]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34353]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34354]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34355]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34356]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34357]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34358]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34359]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34360]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34361]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34362]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34363]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34364]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34365]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34366]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34367]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34368]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34369]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34370]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34371]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34372]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34373]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34374]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34375]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34376]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34377]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34378]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34379]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34380]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34381]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34382]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34383]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34384]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34385]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34386]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34387]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34388]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34389]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34390]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34391]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34392]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34393]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34394]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34395]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34396]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34397]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34398]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34399]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34400]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34401]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34402]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34403]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34404]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34405]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34406]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34407]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34408]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34409]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34410]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34411]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34412]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34413]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34414]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34415]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34416]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34417]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34418]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34419]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34420]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34421]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34422]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34423]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34424]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34425]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34426]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34427]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34428]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34429]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34430]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34431]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34432]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34433]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34434]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34435]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34436]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34437]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34438]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34439]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34440]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34441]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34442]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34443]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34444]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34445]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34446]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34447]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34448]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34449]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34450]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34451]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34452]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34453]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34454]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34455]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34456]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34457]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34458]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34459]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34460]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34461]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34462]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34463]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34464]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34465]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34466]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34467]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34468]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34469]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34470]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34471]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34472]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34473]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34474]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34475]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34476]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34477]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34478]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34479]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34480]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34481]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34482]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34483]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34484]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34485]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34486]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34487]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34488]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34489]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34490]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34491]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34492]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34493]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34494]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34495]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34496]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34497]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34498]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34499]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34500]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34501]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34502]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34503]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34504]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34505]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34506]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34507]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34508]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34509]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34510]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34511]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34512]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34513]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34514]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34515]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34516]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34517]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34518]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34519]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34520]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34521]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34522]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34523]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34524]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34525]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34526]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34527]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34528]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34529]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34530]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34531]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34532]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34533]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34534]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34535]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34536]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34537]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34538]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34539]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34540]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34541]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34542]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34543]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34544]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34545]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34546]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34547]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34548]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34549]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34550]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34551]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34552]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34553]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34554]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34555]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34556]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34557]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34558]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34559]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34560]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34561]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34562]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34563]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34564]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34565]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34566]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34567]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34568]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34569]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34570]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34571]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34572]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34573]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34574]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34575]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34576]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34577]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34578]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34579]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34580]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34581]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34582]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34583]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34584]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34585]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34586]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34587]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34588]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34589]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34590]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34591]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34592]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34593]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34594]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34595]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34596]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34597]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34598]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34599]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34600]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34601]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34602]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34603]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34604]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34605]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34606]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34607]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34608]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34609]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34610]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34611]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34612]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34613]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34614]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34615]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34616]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34617]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34618]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34619]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34620]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34621]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34622]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34623]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34624]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34625]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34626]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34627]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34628]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34629]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34630]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34631]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34632]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34633]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34634]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34635]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34636]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34637]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34638]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34639]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34640]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34641]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34642]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34643]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34644]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34645]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34646]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34647]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34648]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34649]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34650]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34651]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34652]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34653]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34654]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34655]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34656]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34657]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34658]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34659]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34660]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34661]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34662]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34663]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34664]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34665]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34666]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34667]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34668]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34669]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34670]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34671]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34672]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34673]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34674]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34675]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34676]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34677]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34678]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34679]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34680]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34681]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34682]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34683]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34684]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34685]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34686]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34687]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34688]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34689]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34690]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34691]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34692]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34693]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34694]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34695]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34696]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34697]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34698]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34699]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34700]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34701]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34702]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34703]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34704]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34705]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34706]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34707]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34708]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34709]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34710]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34711]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34712]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34713]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34714]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34715]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34716]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34717]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34718]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34719]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34720]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34721]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34722]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34723]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34724]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34725]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34726]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34727]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34728]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34729]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34730]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34731]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34732]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34733]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34734]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34735]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34736]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34737]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34738]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34739]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34740]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34741]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34742]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34743]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34744]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34745]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34746]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34747]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34748]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34749]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34750]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34751]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34752]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34753]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34754]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34755]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34756]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34757]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34758]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34759]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34760]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34761]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34762]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34763]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34764]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34765]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34766]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34767]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34768]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34769]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34770]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34771]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34772]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34773]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34774]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34775]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34776]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34777]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34778]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34779]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34780]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34781]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34782]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34783]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34784]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34785]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34786]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34787]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34788]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34789]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34790]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34791]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34792]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34793]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34794]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34795]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34796]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34797]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34798]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34799]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34800]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34801]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34802]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34803]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34804]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34805]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34806]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34807]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34808]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34809]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34810]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34811]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34812]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34813]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34814]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34815]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34816]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34817]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34818]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34819]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34820]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34821]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34822]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34823]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34824]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34825]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34826]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34827]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34828]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34829]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34830]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34831]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34832]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34833]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34834]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34835]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34836]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34837]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34838]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34839]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34840]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34841]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34842]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34843]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34844]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34845]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34846]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34847]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34848]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34849]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34850]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34851]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34852]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34853]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34854]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34855]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34856]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34857]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34858]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34859]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34860]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34861]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34862]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34863]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34864]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34865]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34866]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34867]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34868]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34869]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34870]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34871]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34872]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34873]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34874]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34875]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34876]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34877]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34878]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34879]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34880]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34881]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34882]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34883]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34884]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34885]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34886]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34887]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34888]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34889]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34890]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34891]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34892]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34893]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34894]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34895]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34896]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34897]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34898]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34899]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34900]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34901]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34902]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34903]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34904]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34905]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34906]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34907]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34908]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34909]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34910]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34911]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34912]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34913]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34914]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34915]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34916]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34917]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34918]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34919]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34920]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34921]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34922]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34923]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34924]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34925]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34926]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34927]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34928]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34929]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34930]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34931]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34932]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34933]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34934]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34935]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34936]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34937]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34938]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34939]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34940]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34941]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34942]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34943]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34944]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34945]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34946]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34947]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34948]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34949]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34950]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34951]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34952]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34953]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34954]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34955]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34956]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34957]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34958]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34959]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34960]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34961]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34962]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34963]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34964]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34965]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34966]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34967]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34968]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34969]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34970]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34971]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34972]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34973]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34974]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34975]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34976]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34977]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34978]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34979]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34980]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34981]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34982]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34983]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34984]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34985]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34986]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34987]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34988]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34989]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34990]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34991]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34992]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34993]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34994]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34995]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34996]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34997]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34998]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[34999]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n",
            "[35000]\ttraining's l2: 5.46978e-05\ttraining's l1: 0.00176364\tvalid_1's l2: 6.74843e-05\tvalid_1's l1: 0.00177464\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "datetime.timedelta(seconds=683, microseconds=251718)"
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_lgbm = lgbm.predict(x_test)\n",
        "lgbm.score(x_test, y_test)"
      ],
      "metadata": {
        "id": "ElRjOHQ2MnyT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee226676-ba1c-4946-de78-b1d103b1414d"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5677903903005823"
            ]
          },
          "metadata": {},
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rmse,R2,MAE,MSE,RMSLE,max_error_= metrics(y_test,y_pred_lgbm)\n",
        "print(R2)"
      ],
      "metadata": {
        "id": "HrOM-x3WMKFn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e50956aa-5d05-4bb0-e91b-0286915a5733"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.5677903903005823\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dict_info = {'Model': [], 'RMSE': [], 'R2': [],'MAE': [], 'RMSLE': [],'max_error_':[]}\n",
        "\n",
        "rmse,R2,MAE,MSE,RMSLE,max_error_= metrics(y_test,y_pred_lgbm)\n",
        "\n",
        "dict_info['Model'].append('Lightgbm')\n",
        "dict_info['RMSE'].append(rmse)\n",
        "dict_info['R2'].append(R2)\n",
        "dict_info['MAE'].append(MAE)\n",
        "dict_info['RMSLE'].append(RMSLE)\n",
        "dict_info['max_error_'].append(max_error_)"
      ],
      "metadata": {
        "id": "QXYkT-U7dRaP"
      },
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZdW6I6LQI9uz"
      },
      "source": [
        "###XGBoost model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "id": "e3mKpHc_JMDg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f13a207-c414-4872-b73c-0655cac677b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0]\tvalidation_0-mae:0.471931\tvalidation_1-mae:0.471954\n",
            "[1]\tvalidation_0-mae:0.448341\tvalidation_1-mae:0.448359\n",
            "[2]\tvalidation_0-mae:0.425928\tvalidation_1-mae:0.425947\n",
            "[3]\tvalidation_0-mae:0.404635\tvalidation_1-mae:0.404651\n",
            "[4]\tvalidation_0-mae:0.384407\tvalidation_1-mae:0.384424\n",
            "[5]\tvalidation_0-mae:0.365191\tvalidation_1-mae:0.365208\n",
            "[6]\tvalidation_0-mae:0.346936\tvalidation_1-mae:0.346958\n",
            "[7]\tvalidation_0-mae:0.329592\tvalidation_1-mae:0.329618\n",
            "[8]\tvalidation_0-mae:0.313117\tvalidation_1-mae:0.313148\n",
            "[9]\tvalidation_0-mae:0.297464\tvalidation_1-mae:0.297494\n",
            "[10]\tvalidation_0-mae:0.282596\tvalidation_1-mae:0.282624\n",
            "[11]\tvalidation_0-mae:0.268471\tvalidation_1-mae:0.2685\n",
            "[12]\tvalidation_0-mae:0.255052\tvalidation_1-mae:0.25508\n",
            "[13]\tvalidation_0-mae:0.242304\tvalidation_1-mae:0.242333\n",
            "[14]\tvalidation_0-mae:0.230194\tvalidation_1-mae:0.230222\n",
            "[15]\tvalidation_0-mae:0.218687\tvalidation_1-mae:0.218718\n",
            "[16]\tvalidation_0-mae:0.207757\tvalidation_1-mae:0.207787\n",
            "[17]\tvalidation_0-mae:0.197372\tvalidation_1-mae:0.197404\n",
            "[18]\tvalidation_0-mae:0.187505\tvalidation_1-mae:0.187541\n",
            "[19]\tvalidation_0-mae:0.178133\tvalidation_1-mae:0.178172\n",
            "[20]\tvalidation_0-mae:0.169232\tvalidation_1-mae:0.169275\n",
            "[21]\tvalidation_0-mae:0.160773\tvalidation_1-mae:0.160819\n",
            "[22]\tvalidation_0-mae:0.152739\tvalidation_1-mae:0.152783\n",
            "[23]\tvalidation_0-mae:0.145106\tvalidation_1-mae:0.145152\n",
            "[24]\tvalidation_0-mae:0.137855\tvalidation_1-mae:0.137902\n",
            "[25]\tvalidation_0-mae:0.130966\tvalidation_1-mae:0.131015\n",
            "[26]\tvalidation_0-mae:0.124422\tvalidation_1-mae:0.124473\n",
            "[27]\tvalidation_0-mae:0.118206\tvalidation_1-mae:0.11826\n",
            "[28]\tvalidation_0-mae:0.112302\tvalidation_1-mae:0.112357\n",
            "[29]\tvalidation_0-mae:0.106695\tvalidation_1-mae:0.106753\n",
            "[30]\tvalidation_0-mae:0.101369\tvalidation_1-mae:0.101431\n",
            "[31]\tvalidation_0-mae:0.096307\tvalidation_1-mae:0.09637\n",
            "[32]\tvalidation_0-mae:0.0915\tvalidation_1-mae:0.091566\n",
            "[33]\tvalidation_0-mae:0.086933\tvalidation_1-mae:0.087004\n",
            "[34]\tvalidation_0-mae:0.082597\tvalidation_1-mae:0.08267\n",
            "[35]\tvalidation_0-mae:0.078479\tvalidation_1-mae:0.078555\n",
            "[36]\tvalidation_0-mae:0.074566\tvalidation_1-mae:0.074643\n",
            "[37]\tvalidation_0-mae:0.070848\tvalidation_1-mae:0.070927\n",
            "[38]\tvalidation_0-mae:0.067318\tvalidation_1-mae:0.067398\n",
            "[39]\tvalidation_0-mae:0.063965\tvalidation_1-mae:0.064047\n",
            "[40]\tvalidation_0-mae:0.060782\tvalidation_1-mae:0.060867\n",
            "[41]\tvalidation_0-mae:0.057756\tvalidation_1-mae:0.057843\n",
            "[42]\tvalidation_0-mae:0.054882\tvalidation_1-mae:0.054972\n",
            "[43]\tvalidation_0-mae:0.052151\tvalidation_1-mae:0.052245\n",
            "[44]\tvalidation_0-mae:0.049558\tvalidation_1-mae:0.049655\n",
            "[45]\tvalidation_0-mae:0.047095\tvalidation_1-mae:0.047195\n",
            "[46]\tvalidation_0-mae:0.044756\tvalidation_1-mae:0.044859\n",
            "[47]\tvalidation_0-mae:0.042534\tvalidation_1-mae:0.04264\n",
            "[48]\tvalidation_0-mae:0.040422\tvalidation_1-mae:0.040532\n",
            "[49]\tvalidation_0-mae:0.038419\tvalidation_1-mae:0.038533\n",
            "[50]\tvalidation_0-mae:0.036519\tvalidation_1-mae:0.036636\n",
            "[51]\tvalidation_0-mae:0.03471\tvalidation_1-mae:0.034832\n",
            "[52]\tvalidation_0-mae:0.032995\tvalidation_1-mae:0.033122\n",
            "[53]\tvalidation_0-mae:0.031364\tvalidation_1-mae:0.031495\n",
            "[54]\tvalidation_0-mae:0.029818\tvalidation_1-mae:0.029954\n",
            "[55]\tvalidation_0-mae:0.028348\tvalidation_1-mae:0.028489\n",
            "[56]\tvalidation_0-mae:0.02695\tvalidation_1-mae:0.027094\n",
            "[57]\tvalidation_0-mae:0.025624\tvalidation_1-mae:0.025773\n",
            "[58]\tvalidation_0-mae:0.024367\tvalidation_1-mae:0.024519\n",
            "[59]\tvalidation_0-mae:0.023174\tvalidation_1-mae:0.02333\n",
            "[60]\tvalidation_0-mae:0.022037\tvalidation_1-mae:0.022196\n",
            "[61]\tvalidation_0-mae:0.020963\tvalidation_1-mae:0.021124\n",
            "[62]\tvalidation_0-mae:0.019937\tvalidation_1-mae:0.020101\n",
            "[63]\tvalidation_0-mae:0.018964\tvalidation_1-mae:0.019132\n",
            "[64]\tvalidation_0-mae:0.018042\tvalidation_1-mae:0.018215\n",
            "[65]\tvalidation_0-mae:0.017166\tvalidation_1-mae:0.017342\n",
            "[66]\tvalidation_0-mae:0.016337\tvalidation_1-mae:0.016516\n",
            "[67]\tvalidation_0-mae:0.015548\tvalidation_1-mae:0.015731\n",
            "[68]\tvalidation_0-mae:0.014797\tvalidation_1-mae:0.014983\n",
            "[69]\tvalidation_0-mae:0.014083\tvalidation_1-mae:0.014272\n",
            "[70]\tvalidation_0-mae:0.013409\tvalidation_1-mae:0.013601\n",
            "[71]\tvalidation_0-mae:0.012765\tvalidation_1-mae:0.012961\n",
            "[72]\tvalidation_0-mae:0.012155\tvalidation_1-mae:0.012353\n",
            "[73]\tvalidation_0-mae:0.011574\tvalidation_1-mae:0.011775\n",
            "[74]\tvalidation_0-mae:0.011024\tvalidation_1-mae:0.011227\n",
            "[75]\tvalidation_0-mae:0.010504\tvalidation_1-mae:0.010709\n",
            "[76]\tvalidation_0-mae:0.010009\tvalidation_1-mae:0.010215\n",
            "[77]\tvalidation_0-mae:0.009538\tvalidation_1-mae:0.009746\n",
            "[78]\tvalidation_0-mae:0.009088\tvalidation_1-mae:0.009298\n",
            "[79]\tvalidation_0-mae:0.008668\tvalidation_1-mae:0.008879\n",
            "[80]\tvalidation_0-mae:0.008268\tvalidation_1-mae:0.008479\n",
            "[81]\tvalidation_0-mae:0.007888\tvalidation_1-mae:0.0081\n",
            "[82]\tvalidation_0-mae:0.007528\tvalidation_1-mae:0.007741\n",
            "[83]\tvalidation_0-mae:0.007185\tvalidation_1-mae:0.007399\n",
            "[84]\tvalidation_0-mae:0.006858\tvalidation_1-mae:0.007073\n",
            "[85]\tvalidation_0-mae:0.006548\tvalidation_1-mae:0.006766\n",
            "[86]\tvalidation_0-mae:0.006258\tvalidation_1-mae:0.006476\n",
            "[87]\tvalidation_0-mae:0.005979\tvalidation_1-mae:0.006199\n",
            "[88]\tvalidation_0-mae:0.005716\tvalidation_1-mae:0.005938\n",
            "[89]\tvalidation_0-mae:0.005466\tvalidation_1-mae:0.00569\n",
            "[90]\tvalidation_0-mae:0.005229\tvalidation_1-mae:0.005454\n",
            "[91]\tvalidation_0-mae:0.005004\tvalidation_1-mae:0.005231\n",
            "[92]\tvalidation_0-mae:0.00479\tvalidation_1-mae:0.00502\n",
            "[93]\tvalidation_0-mae:0.00459\tvalidation_1-mae:0.00482\n",
            "[94]\tvalidation_0-mae:0.004401\tvalidation_1-mae:0.004634\n",
            "[95]\tvalidation_0-mae:0.004218\tvalidation_1-mae:0.004454\n",
            "[96]\tvalidation_0-mae:0.00405\tvalidation_1-mae:0.004288\n",
            "[97]\tvalidation_0-mae:0.003888\tvalidation_1-mae:0.004127\n",
            "[98]\tvalidation_0-mae:0.003734\tvalidation_1-mae:0.003975\n",
            "[99]\tvalidation_0-mae:0.003591\tvalidation_1-mae:0.003833\n",
            "[100]\tvalidation_0-mae:0.003451\tvalidation_1-mae:0.003696\n",
            "[101]\tvalidation_0-mae:0.00332\tvalidation_1-mae:0.003567\n",
            "[102]\tvalidation_0-mae:0.003198\tvalidation_1-mae:0.003446\n",
            "[103]\tvalidation_0-mae:0.003082\tvalidation_1-mae:0.003332\n",
            "[104]\tvalidation_0-mae:0.002973\tvalidation_1-mae:0.003225\n",
            "[105]\tvalidation_0-mae:0.002866\tvalidation_1-mae:0.00312\n",
            "[106]\tvalidation_0-mae:0.002767\tvalidation_1-mae:0.003021\n",
            "[107]\tvalidation_0-mae:0.002674\tvalidation_1-mae:0.002929\n",
            "[108]\tvalidation_0-mae:0.002585\tvalidation_1-mae:0.002842\n",
            "[109]\tvalidation_0-mae:0.002499\tvalidation_1-mae:0.00276\n",
            "[110]\tvalidation_0-mae:0.00242\tvalidation_1-mae:0.002682\n",
            "[111]\tvalidation_0-mae:0.002347\tvalidation_1-mae:0.00261\n",
            "[112]\tvalidation_0-mae:0.002277\tvalidation_1-mae:0.002541\n",
            "[113]\tvalidation_0-mae:0.00221\tvalidation_1-mae:0.002477\n",
            "[114]\tvalidation_0-mae:0.002148\tvalidation_1-mae:0.002416\n",
            "[115]\tvalidation_0-mae:0.002089\tvalidation_1-mae:0.002357\n",
            "[116]\tvalidation_0-mae:0.002033\tvalidation_1-mae:0.002303\n",
            "[117]\tvalidation_0-mae:0.00198\tvalidation_1-mae:0.002251\n",
            "[118]\tvalidation_0-mae:0.001928\tvalidation_1-mae:0.002201\n",
            "[119]\tvalidation_0-mae:0.001882\tvalidation_1-mae:0.002155\n",
            "[120]\tvalidation_0-mae:0.001838\tvalidation_1-mae:0.002112\n",
            "[121]\tvalidation_0-mae:0.001795\tvalidation_1-mae:0.002071\n",
            "[122]\tvalidation_0-mae:0.001757\tvalidation_1-mae:0.002033\n",
            "[123]\tvalidation_0-mae:0.001722\tvalidation_1-mae:0.001999\n",
            "[124]\tvalidation_0-mae:0.001687\tvalidation_1-mae:0.001965\n",
            "[125]\tvalidation_0-mae:0.001654\tvalidation_1-mae:0.001934\n",
            "[126]\tvalidation_0-mae:0.001625\tvalidation_1-mae:0.001906\n",
            "[127]\tvalidation_0-mae:0.001596\tvalidation_1-mae:0.001877\n",
            "[128]\tvalidation_0-mae:0.001567\tvalidation_1-mae:0.001849\n",
            "[129]\tvalidation_0-mae:0.001542\tvalidation_1-mae:0.001825\n",
            "[130]\tvalidation_0-mae:0.001517\tvalidation_1-mae:0.001801\n",
            "[131]\tvalidation_0-mae:0.001494\tvalidation_1-mae:0.001779\n",
            "[132]\tvalidation_0-mae:0.001471\tvalidation_1-mae:0.001758\n",
            "[133]\tvalidation_0-mae:0.001449\tvalidation_1-mae:0.001737\n",
            "[134]\tvalidation_0-mae:0.00143\tvalidation_1-mae:0.00172\n",
            "[135]\tvalidation_0-mae:0.001413\tvalidation_1-mae:0.001703\n",
            "[136]\tvalidation_0-mae:0.001396\tvalidation_1-mae:0.001688\n",
            "[137]\tvalidation_0-mae:0.001381\tvalidation_1-mae:0.001673\n",
            "[138]\tvalidation_0-mae:0.001367\tvalidation_1-mae:0.001659\n",
            "[139]\tvalidation_0-mae:0.001355\tvalidation_1-mae:0.001648\n",
            "[140]\tvalidation_0-mae:0.001341\tvalidation_1-mae:0.001635\n",
            "[141]\tvalidation_0-mae:0.001331\tvalidation_1-mae:0.001625\n",
            "[142]\tvalidation_0-mae:0.00132\tvalidation_1-mae:0.001615\n",
            "[143]\tvalidation_0-mae:0.001309\tvalidation_1-mae:0.001605\n",
            "[144]\tvalidation_0-mae:0.0013\tvalidation_1-mae:0.001597\n",
            "[145]\tvalidation_0-mae:0.00129\tvalidation_1-mae:0.001588\n",
            "[146]\tvalidation_0-mae:0.001282\tvalidation_1-mae:0.00158\n",
            "[147]\tvalidation_0-mae:0.001274\tvalidation_1-mae:0.001573\n",
            "[148]\tvalidation_0-mae:0.001267\tvalidation_1-mae:0.001566\n",
            "[149]\tvalidation_0-mae:0.00126\tvalidation_1-mae:0.00156\n",
            "[150]\tvalidation_0-mae:0.001254\tvalidation_1-mae:0.001555\n",
            "[151]\tvalidation_0-mae:0.001248\tvalidation_1-mae:0.00155\n",
            "[152]\tvalidation_0-mae:0.001243\tvalidation_1-mae:0.001545\n",
            "[153]\tvalidation_0-mae:0.001236\tvalidation_1-mae:0.001541\n",
            "[154]\tvalidation_0-mae:0.00123\tvalidation_1-mae:0.001536\n",
            "[155]\tvalidation_0-mae:0.001226\tvalidation_1-mae:0.001532\n",
            "[156]\tvalidation_0-mae:0.00122\tvalidation_1-mae:0.001528\n",
            "[157]\tvalidation_0-mae:0.001215\tvalidation_1-mae:0.001524\n",
            "[158]\tvalidation_0-mae:0.00121\tvalidation_1-mae:0.001521\n",
            "[159]\tvalidation_0-mae:0.001206\tvalidation_1-mae:0.001518\n",
            "[160]\tvalidation_0-mae:0.0012\tvalidation_1-mae:0.001512\n",
            "[161]\tvalidation_0-mae:0.001197\tvalidation_1-mae:0.00151\n",
            "[162]\tvalidation_0-mae:0.001193\tvalidation_1-mae:0.001507\n",
            "[163]\tvalidation_0-mae:0.001187\tvalidation_1-mae:0.001503\n",
            "[164]\tvalidation_0-mae:0.001184\tvalidation_1-mae:0.001501\n",
            "[165]\tvalidation_0-mae:0.001182\tvalidation_1-mae:0.001499\n",
            "[166]\tvalidation_0-mae:0.001179\tvalidation_1-mae:0.001497\n",
            "[167]\tvalidation_0-mae:0.001176\tvalidation_1-mae:0.001496\n",
            "[168]\tvalidation_0-mae:0.001174\tvalidation_1-mae:0.001494\n",
            "[169]\tvalidation_0-mae:0.001171\tvalidation_1-mae:0.001492\n",
            "[170]\tvalidation_0-mae:0.001169\tvalidation_1-mae:0.001491\n",
            "[171]\tvalidation_0-mae:0.001167\tvalidation_1-mae:0.00149\n",
            "[172]\tvalidation_0-mae:0.001166\tvalidation_1-mae:0.001489\n",
            "[173]\tvalidation_0-mae:0.001163\tvalidation_1-mae:0.001487\n",
            "[174]\tvalidation_0-mae:0.00116\tvalidation_1-mae:0.001485\n",
            "[175]\tvalidation_0-mae:0.001158\tvalidation_1-mae:0.001484\n",
            "[176]\tvalidation_0-mae:0.001157\tvalidation_1-mae:0.001483\n",
            "[177]\tvalidation_0-mae:0.001155\tvalidation_1-mae:0.001482\n",
            "[178]\tvalidation_0-mae:0.001153\tvalidation_1-mae:0.001481\n",
            "[179]\tvalidation_0-mae:0.001152\tvalidation_1-mae:0.00148\n",
            "[180]\tvalidation_0-mae:0.00115\tvalidation_1-mae:0.001479\n",
            "[181]\tvalidation_0-mae:0.001149\tvalidation_1-mae:0.001479\n",
            "[182]\tvalidation_0-mae:0.001147\tvalidation_1-mae:0.001478\n",
            "[183]\tvalidation_0-mae:0.001145\tvalidation_1-mae:0.001476\n",
            "[184]\tvalidation_0-mae:0.001143\tvalidation_1-mae:0.001475\n",
            "[185]\tvalidation_0-mae:0.001142\tvalidation_1-mae:0.001474\n",
            "[186]\tvalidation_0-mae:0.001141\tvalidation_1-mae:0.001475\n",
            "[187]\tvalidation_0-mae:0.001139\tvalidation_1-mae:0.001474\n",
            "[188]\tvalidation_0-mae:0.001136\tvalidation_1-mae:0.001471\n",
            "[189]\tvalidation_0-mae:0.001133\tvalidation_1-mae:0.001471\n",
            "[190]\tvalidation_0-mae:0.001132\tvalidation_1-mae:0.00147\n",
            "[191]\tvalidation_0-mae:0.001131\tvalidation_1-mae:0.001469\n",
            "[192]\tvalidation_0-mae:0.00113\tvalidation_1-mae:0.001468\n",
            "[193]\tvalidation_0-mae:0.001128\tvalidation_1-mae:0.001468\n",
            "[194]\tvalidation_0-mae:0.001126\tvalidation_1-mae:0.001467\n",
            "[195]\tvalidation_0-mae:0.001125\tvalidation_1-mae:0.001467\n",
            "[196]\tvalidation_0-mae:0.001123\tvalidation_1-mae:0.001466\n",
            "[197]\tvalidation_0-mae:0.001122\tvalidation_1-mae:0.001466\n",
            "[198]\tvalidation_0-mae:0.00112\tvalidation_1-mae:0.001465\n",
            "[199]\tvalidation_0-mae:0.001119\tvalidation_1-mae:0.001465\n",
            "[200]\tvalidation_0-mae:0.001118\tvalidation_1-mae:0.001464\n",
            "[201]\tvalidation_0-mae:0.001117\tvalidation_1-mae:0.001463\n",
            "[202]\tvalidation_0-mae:0.001115\tvalidation_1-mae:0.001463\n",
            "[203]\tvalidation_0-mae:0.001114\tvalidation_1-mae:0.001462\n",
            "[204]\tvalidation_0-mae:0.001112\tvalidation_1-mae:0.001461\n",
            "[205]\tvalidation_0-mae:0.001111\tvalidation_1-mae:0.001461\n",
            "[206]\tvalidation_0-mae:0.001109\tvalidation_1-mae:0.00146\n",
            "[207]\tvalidation_0-mae:0.001108\tvalidation_1-mae:0.001459\n",
            "[208]\tvalidation_0-mae:0.001107\tvalidation_1-mae:0.001458\n",
            "[209]\tvalidation_0-mae:0.001105\tvalidation_1-mae:0.001458\n",
            "[210]\tvalidation_0-mae:0.001104\tvalidation_1-mae:0.001458\n",
            "[211]\tvalidation_0-mae:0.001102\tvalidation_1-mae:0.001456\n",
            "[212]\tvalidation_0-mae:0.001099\tvalidation_1-mae:0.001454\n",
            "[213]\tvalidation_0-mae:0.001098\tvalidation_1-mae:0.001453\n",
            "[214]\tvalidation_0-mae:0.001096\tvalidation_1-mae:0.001453\n",
            "[215]\tvalidation_0-mae:0.001096\tvalidation_1-mae:0.001453\n",
            "[216]\tvalidation_0-mae:0.001094\tvalidation_1-mae:0.001452\n",
            "[217]\tvalidation_0-mae:0.001092\tvalidation_1-mae:0.001452\n",
            "[218]\tvalidation_0-mae:0.001091\tvalidation_1-mae:0.001451\n",
            "[219]\tvalidation_0-mae:0.00109\tvalidation_1-mae:0.00145\n",
            "[220]\tvalidation_0-mae:0.001089\tvalidation_1-mae:0.00145\n",
            "[221]\tvalidation_0-mae:0.001089\tvalidation_1-mae:0.001449\n",
            "[222]\tvalidation_0-mae:0.001088\tvalidation_1-mae:0.001449\n",
            "[223]\tvalidation_0-mae:0.001087\tvalidation_1-mae:0.001449\n",
            "[224]\tvalidation_0-mae:0.001085\tvalidation_1-mae:0.001448\n",
            "[225]\tvalidation_0-mae:0.001085\tvalidation_1-mae:0.001448\n",
            "[226]\tvalidation_0-mae:0.001084\tvalidation_1-mae:0.001447\n",
            "[227]\tvalidation_0-mae:0.001081\tvalidation_1-mae:0.001446\n",
            "[228]\tvalidation_0-mae:0.001081\tvalidation_1-mae:0.001446\n",
            "[229]\tvalidation_0-mae:0.001079\tvalidation_1-mae:0.001445\n",
            "[230]\tvalidation_0-mae:0.001079\tvalidation_1-mae:0.001445\n",
            "[231]\tvalidation_0-mae:0.001078\tvalidation_1-mae:0.001445\n",
            "[232]\tvalidation_0-mae:0.001078\tvalidation_1-mae:0.001445\n",
            "[233]\tvalidation_0-mae:0.001077\tvalidation_1-mae:0.001444\n",
            "[234]\tvalidation_0-mae:0.001075\tvalidation_1-mae:0.001444\n",
            "[235]\tvalidation_0-mae:0.001075\tvalidation_1-mae:0.001444\n",
            "[236]\tvalidation_0-mae:0.001074\tvalidation_1-mae:0.001444\n",
            "[237]\tvalidation_0-mae:0.001074\tvalidation_1-mae:0.001444\n",
            "[238]\tvalidation_0-mae:0.001073\tvalidation_1-mae:0.001444\n",
            "[239]\tvalidation_0-mae:0.001072\tvalidation_1-mae:0.001443\n",
            "[240]\tvalidation_0-mae:0.001071\tvalidation_1-mae:0.001443\n",
            "[241]\tvalidation_0-mae:0.00107\tvalidation_1-mae:0.001442\n",
            "[242]\tvalidation_0-mae:0.001069\tvalidation_1-mae:0.001443\n",
            "[243]\tvalidation_0-mae:0.001068\tvalidation_1-mae:0.001442\n",
            "[244]\tvalidation_0-mae:0.001067\tvalidation_1-mae:0.001442\n",
            "[245]\tvalidation_0-mae:0.001066\tvalidation_1-mae:0.001442\n",
            "[246]\tvalidation_0-mae:0.001065\tvalidation_1-mae:0.001442\n",
            "[247]\tvalidation_0-mae:0.001064\tvalidation_1-mae:0.001441\n",
            "[248]\tvalidation_0-mae:0.001063\tvalidation_1-mae:0.00144\n",
            "[249]\tvalidation_0-mae:0.001062\tvalidation_1-mae:0.001439\n",
            "[250]\tvalidation_0-mae:0.001061\tvalidation_1-mae:0.001439\n",
            "[251]\tvalidation_0-mae:0.00106\tvalidation_1-mae:0.001439\n",
            "[252]\tvalidation_0-mae:0.00106\tvalidation_1-mae:0.001439\n",
            "[253]\tvalidation_0-mae:0.001058\tvalidation_1-mae:0.001438\n",
            "[254]\tvalidation_0-mae:0.001058\tvalidation_1-mae:0.001438\n",
            "[255]\tvalidation_0-mae:0.001055\tvalidation_1-mae:0.001437\n",
            "[256]\tvalidation_0-mae:0.001055\tvalidation_1-mae:0.001437\n",
            "[257]\tvalidation_0-mae:0.001053\tvalidation_1-mae:0.001437\n",
            "[258]\tvalidation_0-mae:0.001052\tvalidation_1-mae:0.001436\n",
            "[259]\tvalidation_0-mae:0.00105\tvalidation_1-mae:0.001435\n",
            "[260]\tvalidation_0-mae:0.001049\tvalidation_1-mae:0.001435\n",
            "[261]\tvalidation_0-mae:0.001049\tvalidation_1-mae:0.001435\n",
            "[262]\tvalidation_0-mae:0.001048\tvalidation_1-mae:0.001434\n",
            "[263]\tvalidation_0-mae:0.001047\tvalidation_1-mae:0.001434\n",
            "[264]\tvalidation_0-mae:0.001044\tvalidation_1-mae:0.001431\n",
            "[265]\tvalidation_0-mae:0.001044\tvalidation_1-mae:0.001432\n",
            "[266]\tvalidation_0-mae:0.001043\tvalidation_1-mae:0.001432\n",
            "[267]\tvalidation_0-mae:0.001043\tvalidation_1-mae:0.001432\n",
            "[268]\tvalidation_0-mae:0.001042\tvalidation_1-mae:0.001431\n",
            "[269]\tvalidation_0-mae:0.00104\tvalidation_1-mae:0.001431\n",
            "[270]\tvalidation_0-mae:0.001039\tvalidation_1-mae:0.001431\n",
            "[271]\tvalidation_0-mae:0.001038\tvalidation_1-mae:0.001432\n",
            "[272]\tvalidation_0-mae:0.001038\tvalidation_1-mae:0.001432\n",
            "[273]\tvalidation_0-mae:0.001037\tvalidation_1-mae:0.001432\n",
            "[274]\tvalidation_0-mae:0.001035\tvalidation_1-mae:0.001431\n",
            "[275]\tvalidation_0-mae:0.001034\tvalidation_1-mae:0.00143\n",
            "[276]\tvalidation_0-mae:0.001032\tvalidation_1-mae:0.001429\n",
            "[277]\tvalidation_0-mae:0.001031\tvalidation_1-mae:0.001429\n",
            "[278]\tvalidation_0-mae:0.001031\tvalidation_1-mae:0.001429\n",
            "[279]\tvalidation_0-mae:0.00103\tvalidation_1-mae:0.001429\n",
            "[280]\tvalidation_0-mae:0.001028\tvalidation_1-mae:0.001429\n",
            "[281]\tvalidation_0-mae:0.001027\tvalidation_1-mae:0.001428\n",
            "[282]\tvalidation_0-mae:0.001026\tvalidation_1-mae:0.001428\n",
            "[283]\tvalidation_0-mae:0.001025\tvalidation_1-mae:0.001428\n",
            "[284]\tvalidation_0-mae:0.001024\tvalidation_1-mae:0.001428\n",
            "[285]\tvalidation_0-mae:0.001024\tvalidation_1-mae:0.001427\n",
            "[286]\tvalidation_0-mae:0.001023\tvalidation_1-mae:0.001427\n",
            "[287]\tvalidation_0-mae:0.001023\tvalidation_1-mae:0.001427\n",
            "[288]\tvalidation_0-mae:0.001023\tvalidation_1-mae:0.001428\n",
            "[289]\tvalidation_0-mae:0.001022\tvalidation_1-mae:0.001428\n",
            "[290]\tvalidation_0-mae:0.001021\tvalidation_1-mae:0.001427\n",
            "[291]\tvalidation_0-mae:0.001021\tvalidation_1-mae:0.001427\n",
            "[292]\tvalidation_0-mae:0.001019\tvalidation_1-mae:0.001426\n",
            "[293]\tvalidation_0-mae:0.001018\tvalidation_1-mae:0.001426\n",
            "[294]\tvalidation_0-mae:0.001017\tvalidation_1-mae:0.001425\n",
            "[295]\tvalidation_0-mae:0.001016\tvalidation_1-mae:0.001425\n",
            "[296]\tvalidation_0-mae:0.001015\tvalidation_1-mae:0.001424\n",
            "[297]\tvalidation_0-mae:0.001014\tvalidation_1-mae:0.001423\n",
            "[298]\tvalidation_0-mae:0.001013\tvalidation_1-mae:0.001423\n",
            "[299]\tvalidation_0-mae:0.001013\tvalidation_1-mae:0.001422\n",
            "[300]\tvalidation_0-mae:0.00101\tvalidation_1-mae:0.00142\n",
            "[301]\tvalidation_0-mae:0.001009\tvalidation_1-mae:0.00142\n",
            "[302]\tvalidation_0-mae:0.001008\tvalidation_1-mae:0.00142\n",
            "[303]\tvalidation_0-mae:0.001007\tvalidation_1-mae:0.00142\n",
            "[304]\tvalidation_0-mae:0.001007\tvalidation_1-mae:0.00142\n",
            "[305]\tvalidation_0-mae:0.001006\tvalidation_1-mae:0.00142\n",
            "[306]\tvalidation_0-mae:0.001005\tvalidation_1-mae:0.00142\n",
            "[307]\tvalidation_0-mae:0.001004\tvalidation_1-mae:0.00142\n",
            "[308]\tvalidation_0-mae:0.001003\tvalidation_1-mae:0.001419\n",
            "[309]\tvalidation_0-mae:0.001002\tvalidation_1-mae:0.001419\n",
            "[310]\tvalidation_0-mae:0.001001\tvalidation_1-mae:0.001419\n",
            "[311]\tvalidation_0-mae:0.001\tvalidation_1-mae:0.001419\n",
            "[312]\tvalidation_0-mae:0.000999\tvalidation_1-mae:0.001418\n",
            "[313]\tvalidation_0-mae:0.000998\tvalidation_1-mae:0.001418\n",
            "[314]\tvalidation_0-mae:0.000998\tvalidation_1-mae:0.001418\n",
            "[315]\tvalidation_0-mae:0.000996\tvalidation_1-mae:0.001418\n",
            "[316]\tvalidation_0-mae:0.000995\tvalidation_1-mae:0.001417\n",
            "[317]\tvalidation_0-mae:0.000994\tvalidation_1-mae:0.001417\n",
            "[318]\tvalidation_0-mae:0.000993\tvalidation_1-mae:0.001417\n",
            "[319]\tvalidation_0-mae:0.000992\tvalidation_1-mae:0.001416\n",
            "[320]\tvalidation_0-mae:0.000991\tvalidation_1-mae:0.001416\n",
            "[321]\tvalidation_0-mae:0.00099\tvalidation_1-mae:0.001416\n",
            "[322]\tvalidation_0-mae:0.00099\tvalidation_1-mae:0.001416\n",
            "[323]\tvalidation_0-mae:0.000989\tvalidation_1-mae:0.001416\n",
            "[324]\tvalidation_0-mae:0.000988\tvalidation_1-mae:0.001416\n",
            "[325]\tvalidation_0-mae:0.000987\tvalidation_1-mae:0.001415\n",
            "[326]\tvalidation_0-mae:0.000986\tvalidation_1-mae:0.001415\n",
            "[327]\tvalidation_0-mae:0.000985\tvalidation_1-mae:0.001415\n",
            "[328]\tvalidation_0-mae:0.000984\tvalidation_1-mae:0.001414\n",
            "[329]\tvalidation_0-mae:0.000984\tvalidation_1-mae:0.001414\n",
            "[330]\tvalidation_0-mae:0.000983\tvalidation_1-mae:0.001414\n",
            "[331]\tvalidation_0-mae:0.000983\tvalidation_1-mae:0.001414\n",
            "[332]\tvalidation_0-mae:0.000981\tvalidation_1-mae:0.001413\n",
            "[333]\tvalidation_0-mae:0.00098\tvalidation_1-mae:0.001412\n",
            "[334]\tvalidation_0-mae:0.00098\tvalidation_1-mae:0.001412\n",
            "[335]\tvalidation_0-mae:0.000979\tvalidation_1-mae:0.001412\n",
            "[336]\tvalidation_0-mae:0.000978\tvalidation_1-mae:0.001412\n",
            "[337]\tvalidation_0-mae:0.000977\tvalidation_1-mae:0.001411\n",
            "[338]\tvalidation_0-mae:0.000977\tvalidation_1-mae:0.001411\n",
            "[339]\tvalidation_0-mae:0.000976\tvalidation_1-mae:0.001411\n",
            "[340]\tvalidation_0-mae:0.000975\tvalidation_1-mae:0.00141\n",
            "[341]\tvalidation_0-mae:0.000973\tvalidation_1-mae:0.001409\n",
            "[342]\tvalidation_0-mae:0.000972\tvalidation_1-mae:0.001409\n",
            "[343]\tvalidation_0-mae:0.000971\tvalidation_1-mae:0.001409\n",
            "[344]\tvalidation_0-mae:0.000971\tvalidation_1-mae:0.001409\n",
            "[345]\tvalidation_0-mae:0.00097\tvalidation_1-mae:0.001409\n",
            "[346]\tvalidation_0-mae:0.000969\tvalidation_1-mae:0.001408\n",
            "[347]\tvalidation_0-mae:0.000969\tvalidation_1-mae:0.001409\n",
            "[348]\tvalidation_0-mae:0.000968\tvalidation_1-mae:0.001408\n",
            "[349]\tvalidation_0-mae:0.000968\tvalidation_1-mae:0.001408\n",
            "[350]\tvalidation_0-mae:0.000967\tvalidation_1-mae:0.001408\n",
            "[351]\tvalidation_0-mae:0.000966\tvalidation_1-mae:0.001408\n",
            "[352]\tvalidation_0-mae:0.000964\tvalidation_1-mae:0.001406\n",
            "[353]\tvalidation_0-mae:0.000964\tvalidation_1-mae:0.001406\n",
            "[354]\tvalidation_0-mae:0.000963\tvalidation_1-mae:0.001406\n",
            "[355]\tvalidation_0-mae:0.000962\tvalidation_1-mae:0.001406\n",
            "[356]\tvalidation_0-mae:0.000961\tvalidation_1-mae:0.001406\n",
            "[357]\tvalidation_0-mae:0.000961\tvalidation_1-mae:0.001405\n",
            "[358]\tvalidation_0-mae:0.00096\tvalidation_1-mae:0.001405\n",
            "[359]\tvalidation_0-mae:0.00096\tvalidation_1-mae:0.001405\n",
            "[360]\tvalidation_0-mae:0.000959\tvalidation_1-mae:0.001405\n",
            "[361]\tvalidation_0-mae:0.000959\tvalidation_1-mae:0.001405\n",
            "[362]\tvalidation_0-mae:0.000958\tvalidation_1-mae:0.001405\n",
            "[363]\tvalidation_0-mae:0.000957\tvalidation_1-mae:0.001404\n",
            "[364]\tvalidation_0-mae:0.000957\tvalidation_1-mae:0.001404\n",
            "[365]\tvalidation_0-mae:0.000956\tvalidation_1-mae:0.001404\n",
            "[366]\tvalidation_0-mae:0.000955\tvalidation_1-mae:0.001404\n",
            "[367]\tvalidation_0-mae:0.000955\tvalidation_1-mae:0.001404\n",
            "[368]\tvalidation_0-mae:0.000954\tvalidation_1-mae:0.001404\n",
            "[369]\tvalidation_0-mae:0.000953\tvalidation_1-mae:0.001403\n",
            "[370]\tvalidation_0-mae:0.000952\tvalidation_1-mae:0.001403\n",
            "[371]\tvalidation_0-mae:0.000952\tvalidation_1-mae:0.001403\n",
            "[372]\tvalidation_0-mae:0.000951\tvalidation_1-mae:0.001403\n",
            "[373]\tvalidation_0-mae:0.000951\tvalidation_1-mae:0.001402\n",
            "[374]\tvalidation_0-mae:0.000949\tvalidation_1-mae:0.001401\n",
            "[375]\tvalidation_0-mae:0.000948\tvalidation_1-mae:0.001401\n",
            "[376]\tvalidation_0-mae:0.000948\tvalidation_1-mae:0.001401\n",
            "[377]\tvalidation_0-mae:0.000947\tvalidation_1-mae:0.001401\n",
            "[378]\tvalidation_0-mae:0.000947\tvalidation_1-mae:0.001401\n",
            "[379]\tvalidation_0-mae:0.000946\tvalidation_1-mae:0.001401\n",
            "[380]\tvalidation_0-mae:0.000945\tvalidation_1-mae:0.0014\n",
            "[381]\tvalidation_0-mae:0.000944\tvalidation_1-mae:0.0014\n",
            "[382]\tvalidation_0-mae:0.000944\tvalidation_1-mae:0.0014\n",
            "[383]\tvalidation_0-mae:0.000943\tvalidation_1-mae:0.0014\n",
            "[384]\tvalidation_0-mae:0.000943\tvalidation_1-mae:0.0014\n",
            "[385]\tvalidation_0-mae:0.000942\tvalidation_1-mae:0.001399\n",
            "[386]\tvalidation_0-mae:0.000942\tvalidation_1-mae:0.001399\n",
            "[387]\tvalidation_0-mae:0.000941\tvalidation_1-mae:0.001399\n",
            "[388]\tvalidation_0-mae:0.00094\tvalidation_1-mae:0.001399\n",
            "[389]\tvalidation_0-mae:0.000939\tvalidation_1-mae:0.001398\n",
            "[390]\tvalidation_0-mae:0.000938\tvalidation_1-mae:0.001398\n",
            "[391]\tvalidation_0-mae:0.000938\tvalidation_1-mae:0.001398\n",
            "[392]\tvalidation_0-mae:0.000937\tvalidation_1-mae:0.001398\n",
            "[393]\tvalidation_0-mae:0.000937\tvalidation_1-mae:0.001398\n",
            "[394]\tvalidation_0-mae:0.000936\tvalidation_1-mae:0.001398\n",
            "[395]\tvalidation_0-mae:0.000936\tvalidation_1-mae:0.001397\n",
            "[396]\tvalidation_0-mae:0.000935\tvalidation_1-mae:0.001398\n",
            "[397]\tvalidation_0-mae:0.000934\tvalidation_1-mae:0.001398\n",
            "[398]\tvalidation_0-mae:0.000933\tvalidation_1-mae:0.001397\n",
            "[399]\tvalidation_0-mae:0.000932\tvalidation_1-mae:0.001397\n",
            "[400]\tvalidation_0-mae:0.000932\tvalidation_1-mae:0.001397\n",
            "[401]\tvalidation_0-mae:0.000931\tvalidation_1-mae:0.001397\n",
            "[402]\tvalidation_0-mae:0.000931\tvalidation_1-mae:0.001397\n",
            "[403]\tvalidation_0-mae:0.000931\tvalidation_1-mae:0.001398\n",
            "[404]\tvalidation_0-mae:0.00093\tvalidation_1-mae:0.001397\n",
            "[405]\tvalidation_0-mae:0.000929\tvalidation_1-mae:0.001397\n",
            "[406]\tvalidation_0-mae:0.000929\tvalidation_1-mae:0.001397\n",
            "[407]\tvalidation_0-mae:0.000928\tvalidation_1-mae:0.001397\n",
            "[408]\tvalidation_0-mae:0.000928\tvalidation_1-mae:0.001397\n",
            "[409]\tvalidation_0-mae:0.000926\tvalidation_1-mae:0.001395\n",
            "[410]\tvalidation_0-mae:0.000925\tvalidation_1-mae:0.001395\n",
            "[411]\tvalidation_0-mae:0.000924\tvalidation_1-mae:0.001395\n",
            "[412]\tvalidation_0-mae:0.000924\tvalidation_1-mae:0.001395\n",
            "[413]\tvalidation_0-mae:0.000923\tvalidation_1-mae:0.001395\n",
            "[414]\tvalidation_0-mae:0.000922\tvalidation_1-mae:0.001395\n",
            "[415]\tvalidation_0-mae:0.000922\tvalidation_1-mae:0.001395\n",
            "[416]\tvalidation_0-mae:0.000921\tvalidation_1-mae:0.001395\n",
            "[417]\tvalidation_0-mae:0.00092\tvalidation_1-mae:0.001394\n",
            "[418]\tvalidation_0-mae:0.00092\tvalidation_1-mae:0.001394\n",
            "[419]\tvalidation_0-mae:0.00092\tvalidation_1-mae:0.001394\n",
            "[420]\tvalidation_0-mae:0.000919\tvalidation_1-mae:0.001394\n",
            "[421]\tvalidation_0-mae:0.000918\tvalidation_1-mae:0.001394\n",
            "[422]\tvalidation_0-mae:0.000917\tvalidation_1-mae:0.001394\n",
            "[423]\tvalidation_0-mae:0.000916\tvalidation_1-mae:0.001394\n",
            "[424]\tvalidation_0-mae:0.000916\tvalidation_1-mae:0.001394\n",
            "[425]\tvalidation_0-mae:0.000914\tvalidation_1-mae:0.001392\n",
            "[426]\tvalidation_0-mae:0.000914\tvalidation_1-mae:0.001392\n",
            "[427]\tvalidation_0-mae:0.000913\tvalidation_1-mae:0.001391\n",
            "[428]\tvalidation_0-mae:0.000912\tvalidation_1-mae:0.001391\n",
            "[429]\tvalidation_0-mae:0.000911\tvalidation_1-mae:0.00139\n",
            "[430]\tvalidation_0-mae:0.00091\tvalidation_1-mae:0.001391\n",
            "[431]\tvalidation_0-mae:0.000909\tvalidation_1-mae:0.00139\n",
            "[432]\tvalidation_0-mae:0.000908\tvalidation_1-mae:0.00139\n",
            "[433]\tvalidation_0-mae:0.000908\tvalidation_1-mae:0.00139\n",
            "[434]\tvalidation_0-mae:0.000907\tvalidation_1-mae:0.00139\n",
            "[435]\tvalidation_0-mae:0.000906\tvalidation_1-mae:0.00139\n",
            "[436]\tvalidation_0-mae:0.000906\tvalidation_1-mae:0.00139\n",
            "[437]\tvalidation_0-mae:0.000905\tvalidation_1-mae:0.001389\n",
            "[438]\tvalidation_0-mae:0.000905\tvalidation_1-mae:0.001389\n",
            "[439]\tvalidation_0-mae:0.000904\tvalidation_1-mae:0.001389\n",
            "[440]\tvalidation_0-mae:0.000903\tvalidation_1-mae:0.001389\n",
            "[441]\tvalidation_0-mae:0.000901\tvalidation_1-mae:0.001388\n",
            "[442]\tvalidation_0-mae:0.0009\tvalidation_1-mae:0.001388\n",
            "[443]\tvalidation_0-mae:0.0009\tvalidation_1-mae:0.001388\n",
            "[444]\tvalidation_0-mae:0.000899\tvalidation_1-mae:0.001387\n",
            "[445]\tvalidation_0-mae:0.000899\tvalidation_1-mae:0.001387\n",
            "[446]\tvalidation_0-mae:0.000898\tvalidation_1-mae:0.001387\n",
            "[447]\tvalidation_0-mae:0.000897\tvalidation_1-mae:0.001387\n",
            "[448]\tvalidation_0-mae:0.000896\tvalidation_1-mae:0.001386\n",
            "[449]\tvalidation_0-mae:0.000895\tvalidation_1-mae:0.001386\n",
            "[450]\tvalidation_0-mae:0.000895\tvalidation_1-mae:0.001386\n",
            "[451]\tvalidation_0-mae:0.000894\tvalidation_1-mae:0.001386\n",
            "[452]\tvalidation_0-mae:0.000893\tvalidation_1-mae:0.001386\n",
            "[453]\tvalidation_0-mae:0.000892\tvalidation_1-mae:0.001386\n",
            "[454]\tvalidation_0-mae:0.000892\tvalidation_1-mae:0.001386\n",
            "[455]\tvalidation_0-mae:0.000891\tvalidation_1-mae:0.001385\n",
            "[456]\tvalidation_0-mae:0.000891\tvalidation_1-mae:0.001385\n",
            "[457]\tvalidation_0-mae:0.00089\tvalidation_1-mae:0.001385\n",
            "[458]\tvalidation_0-mae:0.000889\tvalidation_1-mae:0.001385\n",
            "[459]\tvalidation_0-mae:0.000889\tvalidation_1-mae:0.001385\n",
            "[460]\tvalidation_0-mae:0.000889\tvalidation_1-mae:0.001385\n",
            "[461]\tvalidation_0-mae:0.000889\tvalidation_1-mae:0.001385\n",
            "[462]\tvalidation_0-mae:0.000888\tvalidation_1-mae:0.001385\n",
            "[463]\tvalidation_0-mae:0.000887\tvalidation_1-mae:0.001385\n",
            "[464]\tvalidation_0-mae:0.000886\tvalidation_1-mae:0.001384\n",
            "[465]\tvalidation_0-mae:0.000886\tvalidation_1-mae:0.001384\n",
            "[466]\tvalidation_0-mae:0.000885\tvalidation_1-mae:0.001384\n",
            "[467]\tvalidation_0-mae:0.000885\tvalidation_1-mae:0.001384\n",
            "[468]\tvalidation_0-mae:0.000884\tvalidation_1-mae:0.001384\n",
            "[469]\tvalidation_0-mae:0.000883\tvalidation_1-mae:0.001384\n",
            "[470]\tvalidation_0-mae:0.000883\tvalidation_1-mae:0.001384\n",
            "[471]\tvalidation_0-mae:0.000882\tvalidation_1-mae:0.001384\n",
            "[472]\tvalidation_0-mae:0.000882\tvalidation_1-mae:0.001384\n",
            "[473]\tvalidation_0-mae:0.000882\tvalidation_1-mae:0.001384\n",
            "[474]\tvalidation_0-mae:0.000881\tvalidation_1-mae:0.001384\n",
            "[475]\tvalidation_0-mae:0.000881\tvalidation_1-mae:0.001384\n",
            "[476]\tvalidation_0-mae:0.00088\tvalidation_1-mae:0.001383\n",
            "[477]\tvalidation_0-mae:0.00088\tvalidation_1-mae:0.001383\n",
            "[478]\tvalidation_0-mae:0.00088\tvalidation_1-mae:0.001383\n",
            "[479]\tvalidation_0-mae:0.00088\tvalidation_1-mae:0.001383\n",
            "[480]\tvalidation_0-mae:0.000879\tvalidation_1-mae:0.001383\n",
            "[481]\tvalidation_0-mae:0.000878\tvalidation_1-mae:0.001383\n",
            "[482]\tvalidation_0-mae:0.000878\tvalidation_1-mae:0.001383\n",
            "[483]\tvalidation_0-mae:0.000877\tvalidation_1-mae:0.001383\n",
            "[484]\tvalidation_0-mae:0.000877\tvalidation_1-mae:0.001383\n",
            "[485]\tvalidation_0-mae:0.000876\tvalidation_1-mae:0.001382\n",
            "[486]\tvalidation_0-mae:0.000876\tvalidation_1-mae:0.001383\n",
            "[487]\tvalidation_0-mae:0.000875\tvalidation_1-mae:0.001382\n",
            "[488]\tvalidation_0-mae:0.000875\tvalidation_1-mae:0.001382\n",
            "[489]\tvalidation_0-mae:0.000874\tvalidation_1-mae:0.001382\n",
            "[490]\tvalidation_0-mae:0.000873\tvalidation_1-mae:0.001381\n",
            "[491]\tvalidation_0-mae:0.000873\tvalidation_1-mae:0.001381\n",
            "[492]\tvalidation_0-mae:0.000871\tvalidation_1-mae:0.001381\n",
            "[493]\tvalidation_0-mae:0.000871\tvalidation_1-mae:0.001381\n",
            "[494]\tvalidation_0-mae:0.00087\tvalidation_1-mae:0.001381\n",
            "[495]\tvalidation_0-mae:0.000869\tvalidation_1-mae:0.00138\n",
            "[496]\tvalidation_0-mae:0.000869\tvalidation_1-mae:0.00138\n",
            "[497]\tvalidation_0-mae:0.000868\tvalidation_1-mae:0.00138\n",
            "[498]\tvalidation_0-mae:0.000867\tvalidation_1-mae:0.00138\n",
            "[499]\tvalidation_0-mae:0.000867\tvalidation_1-mae:0.00138\n",
            "[500]\tvalidation_0-mae:0.000866\tvalidation_1-mae:0.00138\n",
            "[501]\tvalidation_0-mae:0.000866\tvalidation_1-mae:0.00138\n",
            "[502]\tvalidation_0-mae:0.000865\tvalidation_1-mae:0.00138\n",
            "[503]\tvalidation_0-mae:0.000865\tvalidation_1-mae:0.00138\n",
            "[504]\tvalidation_0-mae:0.000865\tvalidation_1-mae:0.00138\n",
            "[505]\tvalidation_0-mae:0.000865\tvalidation_1-mae:0.00138\n",
            "[506]\tvalidation_0-mae:0.000864\tvalidation_1-mae:0.00138\n",
            "[507]\tvalidation_0-mae:0.000864\tvalidation_1-mae:0.00138\n",
            "[508]\tvalidation_0-mae:0.000863\tvalidation_1-mae:0.001379\n",
            "[509]\tvalidation_0-mae:0.000862\tvalidation_1-mae:0.001379\n",
            "[510]\tvalidation_0-mae:0.000861\tvalidation_1-mae:0.001379\n",
            "[511]\tvalidation_0-mae:0.00086\tvalidation_1-mae:0.001379\n",
            "[512]\tvalidation_0-mae:0.00086\tvalidation_1-mae:0.001379\n",
            "[513]\tvalidation_0-mae:0.000859\tvalidation_1-mae:0.001379\n",
            "[514]\tvalidation_0-mae:0.000858\tvalidation_1-mae:0.001378\n",
            "[515]\tvalidation_0-mae:0.000858\tvalidation_1-mae:0.001378\n",
            "[516]\tvalidation_0-mae:0.000857\tvalidation_1-mae:0.001378\n",
            "[517]\tvalidation_0-mae:0.000857\tvalidation_1-mae:0.001378\n",
            "[518]\tvalidation_0-mae:0.000856\tvalidation_1-mae:0.001378\n",
            "[519]\tvalidation_0-mae:0.000855\tvalidation_1-mae:0.001378\n",
            "[520]\tvalidation_0-mae:0.000855\tvalidation_1-mae:0.001378\n",
            "[521]\tvalidation_0-mae:0.000855\tvalidation_1-mae:0.001378\n",
            "[522]\tvalidation_0-mae:0.000855\tvalidation_1-mae:0.001378\n",
            "[523]\tvalidation_0-mae:0.000854\tvalidation_1-mae:0.001378\n",
            "[524]\tvalidation_0-mae:0.000854\tvalidation_1-mae:0.001377\n",
            "[525]\tvalidation_0-mae:0.000853\tvalidation_1-mae:0.001377\n",
            "[526]\tvalidation_0-mae:0.000853\tvalidation_1-mae:0.001377\n",
            "[527]\tvalidation_0-mae:0.000852\tvalidation_1-mae:0.001377\n",
            "[528]\tvalidation_0-mae:0.000852\tvalidation_1-mae:0.001377\n",
            "[529]\tvalidation_0-mae:0.000851\tvalidation_1-mae:0.001377\n",
            "[530]\tvalidation_0-mae:0.000851\tvalidation_1-mae:0.001376\n",
            "[531]\tvalidation_0-mae:0.00085\tvalidation_1-mae:0.001376\n",
            "[532]\tvalidation_0-mae:0.00085\tvalidation_1-mae:0.001376\n",
            "[533]\tvalidation_0-mae:0.000849\tvalidation_1-mae:0.001376\n",
            "[534]\tvalidation_0-mae:0.000848\tvalidation_1-mae:0.001376\n",
            "[535]\tvalidation_0-mae:0.000848\tvalidation_1-mae:0.001376\n",
            "[536]\tvalidation_0-mae:0.000848\tvalidation_1-mae:0.001376\n",
            "[537]\tvalidation_0-mae:0.000847\tvalidation_1-mae:0.001375\n",
            "[538]\tvalidation_0-mae:0.000847\tvalidation_1-mae:0.001375\n",
            "[539]\tvalidation_0-mae:0.000846\tvalidation_1-mae:0.001375\n",
            "[540]\tvalidation_0-mae:0.000846\tvalidation_1-mae:0.001375\n",
            "[541]\tvalidation_0-mae:0.000845\tvalidation_1-mae:0.001374\n",
            "[542]\tvalidation_0-mae:0.000845\tvalidation_1-mae:0.001373\n",
            "[543]\tvalidation_0-mae:0.000844\tvalidation_1-mae:0.001373\n",
            "[544]\tvalidation_0-mae:0.000843\tvalidation_1-mae:0.001373\n",
            "[545]\tvalidation_0-mae:0.000843\tvalidation_1-mae:0.001373\n",
            "[546]\tvalidation_0-mae:0.000842\tvalidation_1-mae:0.001372\n",
            "[547]\tvalidation_0-mae:0.000841\tvalidation_1-mae:0.001372\n",
            "[548]\tvalidation_0-mae:0.000841\tvalidation_1-mae:0.001372\n",
            "[549]\tvalidation_0-mae:0.00084\tvalidation_1-mae:0.001372\n",
            "[550]\tvalidation_0-mae:0.00084\tvalidation_1-mae:0.001372\n",
            "[551]\tvalidation_0-mae:0.00084\tvalidation_1-mae:0.001372\n",
            "[552]\tvalidation_0-mae:0.00084\tvalidation_1-mae:0.001372\n",
            "[553]\tvalidation_0-mae:0.000839\tvalidation_1-mae:0.001372\n",
            "[554]\tvalidation_0-mae:0.000838\tvalidation_1-mae:0.001371\n",
            "[555]\tvalidation_0-mae:0.000838\tvalidation_1-mae:0.001372\n",
            "[556]\tvalidation_0-mae:0.000837\tvalidation_1-mae:0.001372\n",
            "[557]\tvalidation_0-mae:0.000836\tvalidation_1-mae:0.001371\n",
            "[558]\tvalidation_0-mae:0.000836\tvalidation_1-mae:0.001372\n",
            "[559]\tvalidation_0-mae:0.000836\tvalidation_1-mae:0.001372\n",
            "[560]\tvalidation_0-mae:0.000835\tvalidation_1-mae:0.001371\n",
            "[561]\tvalidation_0-mae:0.000835\tvalidation_1-mae:0.001371\n",
            "[562]\tvalidation_0-mae:0.000834\tvalidation_1-mae:0.001371\n",
            "[563]\tvalidation_0-mae:0.000834\tvalidation_1-mae:0.001371\n",
            "[564]\tvalidation_0-mae:0.000833\tvalidation_1-mae:0.001371\n",
            "[565]\tvalidation_0-mae:0.000833\tvalidation_1-mae:0.001371\n",
            "[566]\tvalidation_0-mae:0.000832\tvalidation_1-mae:0.001371\n",
            "[567]\tvalidation_0-mae:0.000831\tvalidation_1-mae:0.001371\n",
            "[568]\tvalidation_0-mae:0.00083\tvalidation_1-mae:0.00137\n",
            "[569]\tvalidation_0-mae:0.00083\tvalidation_1-mae:0.00137\n",
            "[570]\tvalidation_0-mae:0.000829\tvalidation_1-mae:0.00137\n",
            "[571]\tvalidation_0-mae:0.000828\tvalidation_1-mae:0.001369\n",
            "[572]\tvalidation_0-mae:0.000827\tvalidation_1-mae:0.001369\n",
            "[573]\tvalidation_0-mae:0.000827\tvalidation_1-mae:0.001369\n",
            "[574]\tvalidation_0-mae:0.000827\tvalidation_1-mae:0.001369\n",
            "[575]\tvalidation_0-mae:0.000826\tvalidation_1-mae:0.001369\n",
            "[576]\tvalidation_0-mae:0.000826\tvalidation_1-mae:0.001369\n",
            "[577]\tvalidation_0-mae:0.000826\tvalidation_1-mae:0.001369\n",
            "[578]\tvalidation_0-mae:0.000825\tvalidation_1-mae:0.001369\n",
            "[579]\tvalidation_0-mae:0.000825\tvalidation_1-mae:0.001369\n",
            "[580]\tvalidation_0-mae:0.000824\tvalidation_1-mae:0.001369\n",
            "[581]\tvalidation_0-mae:0.000824\tvalidation_1-mae:0.001368\n",
            "[582]\tvalidation_0-mae:0.000824\tvalidation_1-mae:0.001368\n",
            "[583]\tvalidation_0-mae:0.000823\tvalidation_1-mae:0.001368\n",
            "[584]\tvalidation_0-mae:0.000823\tvalidation_1-mae:0.001368\n",
            "[585]\tvalidation_0-mae:0.000823\tvalidation_1-mae:0.001368\n",
            "[586]\tvalidation_0-mae:0.000822\tvalidation_1-mae:0.001368\n",
            "[587]\tvalidation_0-mae:0.000822\tvalidation_1-mae:0.001368\n",
            "[588]\tvalidation_0-mae:0.000821\tvalidation_1-mae:0.001368\n",
            "[589]\tvalidation_0-mae:0.000821\tvalidation_1-mae:0.001368\n",
            "[590]\tvalidation_0-mae:0.00082\tvalidation_1-mae:0.001368\n",
            "[591]\tvalidation_0-mae:0.00082\tvalidation_1-mae:0.001368\n",
            "[592]\tvalidation_0-mae:0.000819\tvalidation_1-mae:0.001368\n",
            "[593]\tvalidation_0-mae:0.000819\tvalidation_1-mae:0.001368\n",
            "[594]\tvalidation_0-mae:0.000819\tvalidation_1-mae:0.001368\n",
            "[595]\tvalidation_0-mae:0.000818\tvalidation_1-mae:0.001368\n",
            "[596]\tvalidation_0-mae:0.000818\tvalidation_1-mae:0.001368\n",
            "[597]\tvalidation_0-mae:0.000818\tvalidation_1-mae:0.001368\n",
            "[598]\tvalidation_0-mae:0.000818\tvalidation_1-mae:0.001368\n",
            "[599]\tvalidation_0-mae:0.000817\tvalidation_1-mae:0.001368\n",
            "[600]\tvalidation_0-mae:0.000817\tvalidation_1-mae:0.001368\n",
            "[601]\tvalidation_0-mae:0.000817\tvalidation_1-mae:0.001368\n",
            "[602]\tvalidation_0-mae:0.000816\tvalidation_1-mae:0.001368\n",
            "[603]\tvalidation_0-mae:0.000816\tvalidation_1-mae:0.001368\n",
            "[604]\tvalidation_0-mae:0.000816\tvalidation_1-mae:0.001368\n",
            "[605]\tvalidation_0-mae:0.000815\tvalidation_1-mae:0.001368\n",
            "[606]\tvalidation_0-mae:0.000815\tvalidation_1-mae:0.001367\n",
            "[607]\tvalidation_0-mae:0.000814\tvalidation_1-mae:0.001367\n",
            "[608]\tvalidation_0-mae:0.000813\tvalidation_1-mae:0.001367\n",
            "[609]\tvalidation_0-mae:0.000813\tvalidation_1-mae:0.001367\n",
            "[610]\tvalidation_0-mae:0.000813\tvalidation_1-mae:0.001367\n",
            "[611]\tvalidation_0-mae:0.000813\tvalidation_1-mae:0.001367\n",
            "[612]\tvalidation_0-mae:0.000812\tvalidation_1-mae:0.001367\n",
            "[613]\tvalidation_0-mae:0.000811\tvalidation_1-mae:0.001367\n",
            "[614]\tvalidation_0-mae:0.000811\tvalidation_1-mae:0.001367\n",
            "[615]\tvalidation_0-mae:0.000811\tvalidation_1-mae:0.001367\n",
            "[616]\tvalidation_0-mae:0.00081\tvalidation_1-mae:0.001367\n",
            "[617]\tvalidation_0-mae:0.00081\tvalidation_1-mae:0.001367\n",
            "[618]\tvalidation_0-mae:0.000809\tvalidation_1-mae:0.001367\n",
            "[619]\tvalidation_0-mae:0.000809\tvalidation_1-mae:0.001367\n",
            "[620]\tvalidation_0-mae:0.000808\tvalidation_1-mae:0.001366\n",
            "[621]\tvalidation_0-mae:0.000808\tvalidation_1-mae:0.001366\n",
            "[622]\tvalidation_0-mae:0.000808\tvalidation_1-mae:0.001367\n",
            "[623]\tvalidation_0-mae:0.000807\tvalidation_1-mae:0.001366\n",
            "[624]\tvalidation_0-mae:0.000807\tvalidation_1-mae:0.001366\n",
            "[625]\tvalidation_0-mae:0.000806\tvalidation_1-mae:0.001366\n",
            "[626]\tvalidation_0-mae:0.000806\tvalidation_1-mae:0.001366\n",
            "[627]\tvalidation_0-mae:0.000806\tvalidation_1-mae:0.001366\n",
            "[628]\tvalidation_0-mae:0.000805\tvalidation_1-mae:0.001366\n",
            "[629]\tvalidation_0-mae:0.000804\tvalidation_1-mae:0.001366\n",
            "[630]\tvalidation_0-mae:0.000804\tvalidation_1-mae:0.001366\n",
            "[631]\tvalidation_0-mae:0.000803\tvalidation_1-mae:0.001366\n",
            "[632]\tvalidation_0-mae:0.000802\tvalidation_1-mae:0.001366\n",
            "[633]\tvalidation_0-mae:0.000802\tvalidation_1-mae:0.001366\n",
            "[634]\tvalidation_0-mae:0.000801\tvalidation_1-mae:0.001366\n",
            "[635]\tvalidation_0-mae:0.000801\tvalidation_1-mae:0.001366\n",
            "[636]\tvalidation_0-mae:0.000801\tvalidation_1-mae:0.001366\n",
            "[637]\tvalidation_0-mae:0.000799\tvalidation_1-mae:0.001365\n",
            "[638]\tvalidation_0-mae:0.000799\tvalidation_1-mae:0.001365\n",
            "[639]\tvalidation_0-mae:0.000799\tvalidation_1-mae:0.001365\n",
            "[640]\tvalidation_0-mae:0.000798\tvalidation_1-mae:0.001365\n",
            "[641]\tvalidation_0-mae:0.000797\tvalidation_1-mae:0.001365\n",
            "[642]\tvalidation_0-mae:0.000796\tvalidation_1-mae:0.001364\n",
            "[643]\tvalidation_0-mae:0.000795\tvalidation_1-mae:0.001364\n",
            "[644]\tvalidation_0-mae:0.000795\tvalidation_1-mae:0.001364\n",
            "[645]\tvalidation_0-mae:0.000794\tvalidation_1-mae:0.001364\n",
            "[646]\tvalidation_0-mae:0.000794\tvalidation_1-mae:0.001364\n",
            "[647]\tvalidation_0-mae:0.000794\tvalidation_1-mae:0.001364\n",
            "[648]\tvalidation_0-mae:0.000793\tvalidation_1-mae:0.001364\n",
            "[649]\tvalidation_0-mae:0.000793\tvalidation_1-mae:0.001364\n",
            "[650]\tvalidation_0-mae:0.000793\tvalidation_1-mae:0.001364\n",
            "[651]\tvalidation_0-mae:0.000792\tvalidation_1-mae:0.001364\n",
            "[652]\tvalidation_0-mae:0.000792\tvalidation_1-mae:0.001364\n",
            "[653]\tvalidation_0-mae:0.000791\tvalidation_1-mae:0.001364\n",
            "[654]\tvalidation_0-mae:0.000791\tvalidation_1-mae:0.001364\n",
            "[655]\tvalidation_0-mae:0.00079\tvalidation_1-mae:0.001364\n",
            "[656]\tvalidation_0-mae:0.00079\tvalidation_1-mae:0.001364\n",
            "[657]\tvalidation_0-mae:0.000789\tvalidation_1-mae:0.001364\n",
            "[658]\tvalidation_0-mae:0.000789\tvalidation_1-mae:0.001364\n",
            "[659]\tvalidation_0-mae:0.000789\tvalidation_1-mae:0.001364\n",
            "[660]\tvalidation_0-mae:0.000788\tvalidation_1-mae:0.001364\n",
            "[661]\tvalidation_0-mae:0.000788\tvalidation_1-mae:0.001363\n",
            "[662]\tvalidation_0-mae:0.000787\tvalidation_1-mae:0.001363\n",
            "[663]\tvalidation_0-mae:0.000787\tvalidation_1-mae:0.001363\n",
            "[664]\tvalidation_0-mae:0.000787\tvalidation_1-mae:0.001363\n",
            "[665]\tvalidation_0-mae:0.000786\tvalidation_1-mae:0.001363\n",
            "[666]\tvalidation_0-mae:0.000786\tvalidation_1-mae:0.001363\n",
            "[667]\tvalidation_0-mae:0.000786\tvalidation_1-mae:0.001363\n",
            "[668]\tvalidation_0-mae:0.000785\tvalidation_1-mae:0.001363\n",
            "[669]\tvalidation_0-mae:0.000785\tvalidation_1-mae:0.001363\n",
            "[670]\tvalidation_0-mae:0.000785\tvalidation_1-mae:0.001363\n",
            "[671]\tvalidation_0-mae:0.000784\tvalidation_1-mae:0.001363\n",
            "[672]\tvalidation_0-mae:0.000783\tvalidation_1-mae:0.001363\n",
            "[673]\tvalidation_0-mae:0.000783\tvalidation_1-mae:0.001363\n",
            "[674]\tvalidation_0-mae:0.000782\tvalidation_1-mae:0.001362\n",
            "[675]\tvalidation_0-mae:0.000781\tvalidation_1-mae:0.001362\n",
            "[676]\tvalidation_0-mae:0.000781\tvalidation_1-mae:0.001362\n",
            "[677]\tvalidation_0-mae:0.000781\tvalidation_1-mae:0.001362\n",
            "[678]\tvalidation_0-mae:0.000781\tvalidation_1-mae:0.001362\n",
            "[679]\tvalidation_0-mae:0.00078\tvalidation_1-mae:0.001362\n",
            "[680]\tvalidation_0-mae:0.000779\tvalidation_1-mae:0.001362\n",
            "[681]\tvalidation_0-mae:0.000779\tvalidation_1-mae:0.001362\n",
            "[682]\tvalidation_0-mae:0.000778\tvalidation_1-mae:0.001362\n",
            "[683]\tvalidation_0-mae:0.000778\tvalidation_1-mae:0.001361\n",
            "[684]\tvalidation_0-mae:0.000777\tvalidation_1-mae:0.001361\n",
            "[685]\tvalidation_0-mae:0.000777\tvalidation_1-mae:0.001361\n",
            "[686]\tvalidation_0-mae:0.000777\tvalidation_1-mae:0.001361\n",
            "[687]\tvalidation_0-mae:0.000777\tvalidation_1-mae:0.001361\n",
            "[688]\tvalidation_0-mae:0.000776\tvalidation_1-mae:0.001361\n",
            "[689]\tvalidation_0-mae:0.000776\tvalidation_1-mae:0.001361\n",
            "[690]\tvalidation_0-mae:0.000776\tvalidation_1-mae:0.001361\n",
            "[691]\tvalidation_0-mae:0.000775\tvalidation_1-mae:0.001361\n",
            "[692]\tvalidation_0-mae:0.000774\tvalidation_1-mae:0.00136\n",
            "[693]\tvalidation_0-mae:0.000774\tvalidation_1-mae:0.00136\n",
            "[694]\tvalidation_0-mae:0.000773\tvalidation_1-mae:0.00136\n",
            "[695]\tvalidation_0-mae:0.000772\tvalidation_1-mae:0.00136\n",
            "[696]\tvalidation_0-mae:0.000772\tvalidation_1-mae:0.00136\n",
            "[697]\tvalidation_0-mae:0.000772\tvalidation_1-mae:0.00136\n",
            "[698]\tvalidation_0-mae:0.000771\tvalidation_1-mae:0.00136\n",
            "[699]\tvalidation_0-mae:0.000771\tvalidation_1-mae:0.00136\n",
            "[700]\tvalidation_0-mae:0.00077\tvalidation_1-mae:0.001359\n",
            "[701]\tvalidation_0-mae:0.000769\tvalidation_1-mae:0.001359\n",
            "[702]\tvalidation_0-mae:0.000769\tvalidation_1-mae:0.001359\n",
            "[703]\tvalidation_0-mae:0.000769\tvalidation_1-mae:0.001359\n",
            "[704]\tvalidation_0-mae:0.000768\tvalidation_1-mae:0.001359\n",
            "[705]\tvalidation_0-mae:0.000768\tvalidation_1-mae:0.001359\n",
            "[706]\tvalidation_0-mae:0.000768\tvalidation_1-mae:0.001358\n",
            "[707]\tvalidation_0-mae:0.000767\tvalidation_1-mae:0.001358\n",
            "[708]\tvalidation_0-mae:0.000767\tvalidation_1-mae:0.001358\n",
            "[709]\tvalidation_0-mae:0.000766\tvalidation_1-mae:0.001358\n",
            "[710]\tvalidation_0-mae:0.000766\tvalidation_1-mae:0.001358\n",
            "[711]\tvalidation_0-mae:0.000766\tvalidation_1-mae:0.001358\n",
            "[712]\tvalidation_0-mae:0.000766\tvalidation_1-mae:0.001358\n",
            "[713]\tvalidation_0-mae:0.000765\tvalidation_1-mae:0.001358\n",
            "[714]\tvalidation_0-mae:0.000765\tvalidation_1-mae:0.001358\n",
            "[715]\tvalidation_0-mae:0.000765\tvalidation_1-mae:0.001358\n",
            "[716]\tvalidation_0-mae:0.000765\tvalidation_1-mae:0.001358\n",
            "[717]\tvalidation_0-mae:0.000764\tvalidation_1-mae:0.001357\n",
            "[718]\tvalidation_0-mae:0.000764\tvalidation_1-mae:0.001357\n",
            "[719]\tvalidation_0-mae:0.000763\tvalidation_1-mae:0.001357\n",
            "[720]\tvalidation_0-mae:0.000763\tvalidation_1-mae:0.001357\n",
            "[721]\tvalidation_0-mae:0.000762\tvalidation_1-mae:0.001357\n",
            "[722]\tvalidation_0-mae:0.000762\tvalidation_1-mae:0.001356\n",
            "[723]\tvalidation_0-mae:0.000761\tvalidation_1-mae:0.001356\n",
            "[724]\tvalidation_0-mae:0.000761\tvalidation_1-mae:0.001356\n",
            "[725]\tvalidation_0-mae:0.00076\tvalidation_1-mae:0.001356\n",
            "[726]\tvalidation_0-mae:0.00076\tvalidation_1-mae:0.001356\n",
            "[727]\tvalidation_0-mae:0.00076\tvalidation_1-mae:0.001356\n",
            "[728]\tvalidation_0-mae:0.000759\tvalidation_1-mae:0.001356\n",
            "[729]\tvalidation_0-mae:0.000759\tvalidation_1-mae:0.001356\n",
            "[730]\tvalidation_0-mae:0.000759\tvalidation_1-mae:0.001356\n",
            "[731]\tvalidation_0-mae:0.000758\tvalidation_1-mae:0.001356\n",
            "[732]\tvalidation_0-mae:0.000757\tvalidation_1-mae:0.001356\n",
            "[733]\tvalidation_0-mae:0.000757\tvalidation_1-mae:0.001356\n",
            "[734]\tvalidation_0-mae:0.000757\tvalidation_1-mae:0.001356\n",
            "[735]\tvalidation_0-mae:0.000756\tvalidation_1-mae:0.001356\n",
            "[736]\tvalidation_0-mae:0.000756\tvalidation_1-mae:0.001356\n",
            "[737]\tvalidation_0-mae:0.000755\tvalidation_1-mae:0.001356\n",
            "[738]\tvalidation_0-mae:0.000755\tvalidation_1-mae:0.001355\n",
            "[739]\tvalidation_0-mae:0.000754\tvalidation_1-mae:0.001355\n",
            "[740]\tvalidation_0-mae:0.000754\tvalidation_1-mae:0.001355\n",
            "[741]\tvalidation_0-mae:0.000754\tvalidation_1-mae:0.001355\n",
            "[742]\tvalidation_0-mae:0.000754\tvalidation_1-mae:0.001355\n",
            "[743]\tvalidation_0-mae:0.000753\tvalidation_1-mae:0.001355\n",
            "[744]\tvalidation_0-mae:0.000753\tvalidation_1-mae:0.001355\n",
            "[745]\tvalidation_0-mae:0.000752\tvalidation_1-mae:0.001355\n",
            "[746]\tvalidation_0-mae:0.000752\tvalidation_1-mae:0.001355\n",
            "[747]\tvalidation_0-mae:0.000751\tvalidation_1-mae:0.001355\n",
            "[748]\tvalidation_0-mae:0.000751\tvalidation_1-mae:0.001355\n",
            "[749]\tvalidation_0-mae:0.00075\tvalidation_1-mae:0.001355\n",
            "[750]\tvalidation_0-mae:0.00075\tvalidation_1-mae:0.001355\n",
            "[751]\tvalidation_0-mae:0.000749\tvalidation_1-mae:0.001355\n",
            "[752]\tvalidation_0-mae:0.000749\tvalidation_1-mae:0.001355\n",
            "[753]\tvalidation_0-mae:0.000749\tvalidation_1-mae:0.001355\n",
            "[754]\tvalidation_0-mae:0.000748\tvalidation_1-mae:0.001355\n",
            "[755]\tvalidation_0-mae:0.000748\tvalidation_1-mae:0.001354\n",
            "[756]\tvalidation_0-mae:0.000747\tvalidation_1-mae:0.001354\n",
            "[757]\tvalidation_0-mae:0.000747\tvalidation_1-mae:0.001354\n",
            "[758]\tvalidation_0-mae:0.000746\tvalidation_1-mae:0.001354\n",
            "[759]\tvalidation_0-mae:0.000746\tvalidation_1-mae:0.001354\n",
            "[760]\tvalidation_0-mae:0.000746\tvalidation_1-mae:0.001354\n",
            "[761]\tvalidation_0-mae:0.000746\tvalidation_1-mae:0.001354\n",
            "[762]\tvalidation_0-mae:0.000745\tvalidation_1-mae:0.001354\n",
            "[763]\tvalidation_0-mae:0.000745\tvalidation_1-mae:0.001354\n",
            "[764]\tvalidation_0-mae:0.000745\tvalidation_1-mae:0.001353\n",
            "[765]\tvalidation_0-mae:0.000744\tvalidation_1-mae:0.001353\n",
            "[766]\tvalidation_0-mae:0.000744\tvalidation_1-mae:0.001353\n",
            "[767]\tvalidation_0-mae:0.000744\tvalidation_1-mae:0.001353\n",
            "[768]\tvalidation_0-mae:0.000743\tvalidation_1-mae:0.001353\n",
            "[769]\tvalidation_0-mae:0.000743\tvalidation_1-mae:0.001353\n",
            "[770]\tvalidation_0-mae:0.000743\tvalidation_1-mae:0.001353\n",
            "[771]\tvalidation_0-mae:0.000743\tvalidation_1-mae:0.001353\n",
            "[772]\tvalidation_0-mae:0.000742\tvalidation_1-mae:0.001353\n",
            "[773]\tvalidation_0-mae:0.000742\tvalidation_1-mae:0.001353\n",
            "[774]\tvalidation_0-mae:0.000742\tvalidation_1-mae:0.001353\n",
            "[775]\tvalidation_0-mae:0.000741\tvalidation_1-mae:0.001352\n",
            "[776]\tvalidation_0-mae:0.00074\tvalidation_1-mae:0.001352\n",
            "[777]\tvalidation_0-mae:0.00074\tvalidation_1-mae:0.001352\n",
            "[778]\tvalidation_0-mae:0.000739\tvalidation_1-mae:0.001352\n",
            "[779]\tvalidation_0-mae:0.000739\tvalidation_1-mae:0.001352\n",
            "[780]\tvalidation_0-mae:0.000739\tvalidation_1-mae:0.001352\n",
            "[781]\tvalidation_0-mae:0.000739\tvalidation_1-mae:0.001352\n",
            "[782]\tvalidation_0-mae:0.000738\tvalidation_1-mae:0.001353\n",
            "[783]\tvalidation_0-mae:0.000738\tvalidation_1-mae:0.001352\n",
            "[784]\tvalidation_0-mae:0.000737\tvalidation_1-mae:0.001352\n",
            "[785]\tvalidation_0-mae:0.000737\tvalidation_1-mae:0.001352\n",
            "[786]\tvalidation_0-mae:0.000737\tvalidation_1-mae:0.001352\n",
            "[787]\tvalidation_0-mae:0.000736\tvalidation_1-mae:0.001352\n",
            "[788]\tvalidation_0-mae:0.000736\tvalidation_1-mae:0.001352\n",
            "[789]\tvalidation_0-mae:0.000735\tvalidation_1-mae:0.001352\n",
            "[790]\tvalidation_0-mae:0.000735\tvalidation_1-mae:0.001352\n",
            "[791]\tvalidation_0-mae:0.000735\tvalidation_1-mae:0.001352\n",
            "[792]\tvalidation_0-mae:0.000734\tvalidation_1-mae:0.001352\n",
            "[793]\tvalidation_0-mae:0.000734\tvalidation_1-mae:0.001351\n",
            "[794]\tvalidation_0-mae:0.000733\tvalidation_1-mae:0.001351\n",
            "[795]\tvalidation_0-mae:0.000732\tvalidation_1-mae:0.001351\n",
            "[796]\tvalidation_0-mae:0.000732\tvalidation_1-mae:0.001351\n",
            "[797]\tvalidation_0-mae:0.000731\tvalidation_1-mae:0.001351\n",
            "[798]\tvalidation_0-mae:0.000731\tvalidation_1-mae:0.001351\n",
            "[799]\tvalidation_0-mae:0.00073\tvalidation_1-mae:0.001351\n",
            "[800]\tvalidation_0-mae:0.00073\tvalidation_1-mae:0.001351\n",
            "[801]\tvalidation_0-mae:0.000729\tvalidation_1-mae:0.001351\n",
            "[802]\tvalidation_0-mae:0.000729\tvalidation_1-mae:0.001351\n",
            "[803]\tvalidation_0-mae:0.000729\tvalidation_1-mae:0.001351\n",
            "[804]\tvalidation_0-mae:0.000728\tvalidation_1-mae:0.001351\n",
            "[805]\tvalidation_0-mae:0.000728\tvalidation_1-mae:0.001351\n",
            "[806]\tvalidation_0-mae:0.000728\tvalidation_1-mae:0.001351\n",
            "[807]\tvalidation_0-mae:0.000727\tvalidation_1-mae:0.001351\n",
            "[808]\tvalidation_0-mae:0.000727\tvalidation_1-mae:0.001351\n",
            "[809]\tvalidation_0-mae:0.000727\tvalidation_1-mae:0.00135\n",
            "[810]\tvalidation_0-mae:0.000727\tvalidation_1-mae:0.00135\n",
            "[811]\tvalidation_0-mae:0.000726\tvalidation_1-mae:0.00135\n",
            "[812]\tvalidation_0-mae:0.000726\tvalidation_1-mae:0.00135\n",
            "[813]\tvalidation_0-mae:0.000725\tvalidation_1-mae:0.00135\n",
            "[814]\tvalidation_0-mae:0.000725\tvalidation_1-mae:0.00135\n",
            "[815]\tvalidation_0-mae:0.000724\tvalidation_1-mae:0.00135\n",
            "[816]\tvalidation_0-mae:0.000724\tvalidation_1-mae:0.00135\n",
            "[817]\tvalidation_0-mae:0.000724\tvalidation_1-mae:0.00135\n",
            "[818]\tvalidation_0-mae:0.000723\tvalidation_1-mae:0.00135\n",
            "[819]\tvalidation_0-mae:0.000723\tvalidation_1-mae:0.001349\n",
            "[820]\tvalidation_0-mae:0.000722\tvalidation_1-mae:0.001349\n",
            "[821]\tvalidation_0-mae:0.000722\tvalidation_1-mae:0.001349\n",
            "[822]\tvalidation_0-mae:0.000721\tvalidation_1-mae:0.001349\n",
            "[823]\tvalidation_0-mae:0.000721\tvalidation_1-mae:0.001349\n",
            "[824]\tvalidation_0-mae:0.000721\tvalidation_1-mae:0.001349\n",
            "[825]\tvalidation_0-mae:0.00072\tvalidation_1-mae:0.001349\n",
            "[826]\tvalidation_0-mae:0.00072\tvalidation_1-mae:0.001349\n",
            "[827]\tvalidation_0-mae:0.000719\tvalidation_1-mae:0.001349\n",
            "[828]\tvalidation_0-mae:0.000718\tvalidation_1-mae:0.001348\n",
            "[829]\tvalidation_0-mae:0.000718\tvalidation_1-mae:0.001348\n",
            "[830]\tvalidation_0-mae:0.000718\tvalidation_1-mae:0.001348\n",
            "[831]\tvalidation_0-mae:0.000718\tvalidation_1-mae:0.001348\n",
            "[832]\tvalidation_0-mae:0.000717\tvalidation_1-mae:0.001348\n",
            "[833]\tvalidation_0-mae:0.000717\tvalidation_1-mae:0.001348\n",
            "[834]\tvalidation_0-mae:0.000717\tvalidation_1-mae:0.001348\n",
            "[835]\tvalidation_0-mae:0.000716\tvalidation_1-mae:0.001348\n",
            "[836]\tvalidation_0-mae:0.000716\tvalidation_1-mae:0.001348\n",
            "[837]\tvalidation_0-mae:0.000716\tvalidation_1-mae:0.001348\n",
            "[838]\tvalidation_0-mae:0.000715\tvalidation_1-mae:0.001348\n",
            "[839]\tvalidation_0-mae:0.000715\tvalidation_1-mae:0.001348\n",
            "[840]\tvalidation_0-mae:0.000715\tvalidation_1-mae:0.001348\n",
            "[841]\tvalidation_0-mae:0.000715\tvalidation_1-mae:0.001348\n",
            "[842]\tvalidation_0-mae:0.000715\tvalidation_1-mae:0.001348\n",
            "[843]\tvalidation_0-mae:0.000714\tvalidation_1-mae:0.001348\n",
            "[844]\tvalidation_0-mae:0.000714\tvalidation_1-mae:0.001348\n",
            "[845]\tvalidation_0-mae:0.000714\tvalidation_1-mae:0.001348\n",
            "[846]\tvalidation_0-mae:0.000713\tvalidation_1-mae:0.001347\n",
            "[847]\tvalidation_0-mae:0.000713\tvalidation_1-mae:0.001347\n",
            "[848]\tvalidation_0-mae:0.000712\tvalidation_1-mae:0.001347\n",
            "[849]\tvalidation_0-mae:0.000712\tvalidation_1-mae:0.001347\n",
            "[850]\tvalidation_0-mae:0.000712\tvalidation_1-mae:0.001348\n",
            "[851]\tvalidation_0-mae:0.000711\tvalidation_1-mae:0.001347\n",
            "[852]\tvalidation_0-mae:0.000711\tvalidation_1-mae:0.001347\n",
            "[853]\tvalidation_0-mae:0.00071\tvalidation_1-mae:0.001347\n",
            "[854]\tvalidation_0-mae:0.00071\tvalidation_1-mae:0.001347\n",
            "[855]\tvalidation_0-mae:0.00071\tvalidation_1-mae:0.001347\n",
            "[856]\tvalidation_0-mae:0.000709\tvalidation_1-mae:0.001347\n",
            "[857]\tvalidation_0-mae:0.000709\tvalidation_1-mae:0.001347\n",
            "[858]\tvalidation_0-mae:0.000709\tvalidation_1-mae:0.001347\n",
            "[859]\tvalidation_0-mae:0.000709\tvalidation_1-mae:0.001347\n",
            "[860]\tvalidation_0-mae:0.000709\tvalidation_1-mae:0.001347\n",
            "[861]\tvalidation_0-mae:0.000708\tvalidation_1-mae:0.001347\n",
            "[862]\tvalidation_0-mae:0.000708\tvalidation_1-mae:0.001347\n",
            "[863]\tvalidation_0-mae:0.000708\tvalidation_1-mae:0.001347\n",
            "[864]\tvalidation_0-mae:0.000707\tvalidation_1-mae:0.001347\n",
            "[865]\tvalidation_0-mae:0.000707\tvalidation_1-mae:0.001347\n",
            "[866]\tvalidation_0-mae:0.000707\tvalidation_1-mae:0.001347\n",
            "[867]\tvalidation_0-mae:0.000706\tvalidation_1-mae:0.001347\n",
            "[868]\tvalidation_0-mae:0.000706\tvalidation_1-mae:0.001347\n",
            "[869]\tvalidation_0-mae:0.000706\tvalidation_1-mae:0.001347\n",
            "[870]\tvalidation_0-mae:0.000706\tvalidation_1-mae:0.001347\n",
            "[871]\tvalidation_0-mae:0.000706\tvalidation_1-mae:0.001347\n",
            "[872]\tvalidation_0-mae:0.000705\tvalidation_1-mae:0.001346\n",
            "[873]\tvalidation_0-mae:0.000705\tvalidation_1-mae:0.001346\n",
            "[874]\tvalidation_0-mae:0.000705\tvalidation_1-mae:0.001346\n",
            "[875]\tvalidation_0-mae:0.000705\tvalidation_1-mae:0.001346\n",
            "[876]\tvalidation_0-mae:0.000704\tvalidation_1-mae:0.001346\n",
            "[877]\tvalidation_0-mae:0.000704\tvalidation_1-mae:0.001346\n",
            "[878]\tvalidation_0-mae:0.000703\tvalidation_1-mae:0.001346\n",
            "[879]\tvalidation_0-mae:0.000703\tvalidation_1-mae:0.001346\n",
            "[880]\tvalidation_0-mae:0.000703\tvalidation_1-mae:0.001346\n",
            "[881]\tvalidation_0-mae:0.000702\tvalidation_1-mae:0.001346\n",
            "[882]\tvalidation_0-mae:0.000702\tvalidation_1-mae:0.001346\n",
            "[883]\tvalidation_0-mae:0.000701\tvalidation_1-mae:0.001346\n",
            "[884]\tvalidation_0-mae:0.000701\tvalidation_1-mae:0.001346\n",
            "[885]\tvalidation_0-mae:0.0007\tvalidation_1-mae:0.001346\n",
            "[886]\tvalidation_0-mae:0.0007\tvalidation_1-mae:0.001346\n",
            "[887]\tvalidation_0-mae:0.000699\tvalidation_1-mae:0.001346\n",
            "[888]\tvalidation_0-mae:0.000699\tvalidation_1-mae:0.001345\n",
            "[889]\tvalidation_0-mae:0.000699\tvalidation_1-mae:0.001345\n",
            "[890]\tvalidation_0-mae:0.000698\tvalidation_1-mae:0.001345\n",
            "[891]\tvalidation_0-mae:0.000698\tvalidation_1-mae:0.001345\n",
            "[892]\tvalidation_0-mae:0.000698\tvalidation_1-mae:0.001345\n",
            "[893]\tvalidation_0-mae:0.000697\tvalidation_1-mae:0.001345\n",
            "[894]\tvalidation_0-mae:0.000697\tvalidation_1-mae:0.001345\n",
            "[895]\tvalidation_0-mae:0.000696\tvalidation_1-mae:0.001345\n",
            "[896]\tvalidation_0-mae:0.000695\tvalidation_1-mae:0.001344\n",
            "[897]\tvalidation_0-mae:0.000695\tvalidation_1-mae:0.001344\n",
            "[898]\tvalidation_0-mae:0.000694\tvalidation_1-mae:0.001344\n",
            "[899]\tvalidation_0-mae:0.000694\tvalidation_1-mae:0.001344\n",
            "[900]\tvalidation_0-mae:0.000694\tvalidation_1-mae:0.001344\n",
            "[901]\tvalidation_0-mae:0.000693\tvalidation_1-mae:0.001344\n",
            "[902]\tvalidation_0-mae:0.000693\tvalidation_1-mae:0.001344\n",
            "[903]\tvalidation_0-mae:0.000693\tvalidation_1-mae:0.001344\n",
            "[904]\tvalidation_0-mae:0.000693\tvalidation_1-mae:0.001344\n",
            "[905]\tvalidation_0-mae:0.000692\tvalidation_1-mae:0.001344\n",
            "[906]\tvalidation_0-mae:0.000692\tvalidation_1-mae:0.001344\n",
            "[907]\tvalidation_0-mae:0.000691\tvalidation_1-mae:0.001344\n",
            "[908]\tvalidation_0-mae:0.000691\tvalidation_1-mae:0.001344\n",
            "[909]\tvalidation_0-mae:0.000691\tvalidation_1-mae:0.001344\n",
            "[910]\tvalidation_0-mae:0.00069\tvalidation_1-mae:0.001343\n",
            "[911]\tvalidation_0-mae:0.00069\tvalidation_1-mae:0.001343\n",
            "[912]\tvalidation_0-mae:0.000689\tvalidation_1-mae:0.001343\n",
            "[913]\tvalidation_0-mae:0.000689\tvalidation_1-mae:0.001343\n",
            "[914]\tvalidation_0-mae:0.000689\tvalidation_1-mae:0.001343\n",
            "[915]\tvalidation_0-mae:0.000688\tvalidation_1-mae:0.001343\n",
            "[916]\tvalidation_0-mae:0.000688\tvalidation_1-mae:0.001343\n",
            "[917]\tvalidation_0-mae:0.000688\tvalidation_1-mae:0.001343\n",
            "[918]\tvalidation_0-mae:0.000688\tvalidation_1-mae:0.001343\n",
            "[919]\tvalidation_0-mae:0.000687\tvalidation_1-mae:0.001343\n",
            "[920]\tvalidation_0-mae:0.000687\tvalidation_1-mae:0.001343\n",
            "[921]\tvalidation_0-mae:0.000687\tvalidation_1-mae:0.001343\n",
            "[922]\tvalidation_0-mae:0.000687\tvalidation_1-mae:0.001343\n",
            "[923]\tvalidation_0-mae:0.000686\tvalidation_1-mae:0.001342\n",
            "[924]\tvalidation_0-mae:0.000686\tvalidation_1-mae:0.001342\n",
            "[925]\tvalidation_0-mae:0.000685\tvalidation_1-mae:0.001342\n",
            "[926]\tvalidation_0-mae:0.000685\tvalidation_1-mae:0.001342\n",
            "[927]\tvalidation_0-mae:0.000685\tvalidation_1-mae:0.001342\n",
            "[928]\tvalidation_0-mae:0.000684\tvalidation_1-mae:0.001342\n",
            "[929]\tvalidation_0-mae:0.000684\tvalidation_1-mae:0.001342\n",
            "[930]\tvalidation_0-mae:0.000684\tvalidation_1-mae:0.001343\n",
            "[931]\tvalidation_0-mae:0.000683\tvalidation_1-mae:0.001342\n",
            "[932]\tvalidation_0-mae:0.000683\tvalidation_1-mae:0.001342\n",
            "[933]\tvalidation_0-mae:0.000683\tvalidation_1-mae:0.001342\n",
            "[934]\tvalidation_0-mae:0.000682\tvalidation_1-mae:0.001342\n",
            "[935]\tvalidation_0-mae:0.000681\tvalidation_1-mae:0.001342\n",
            "[936]\tvalidation_0-mae:0.000681\tvalidation_1-mae:0.001342\n",
            "[937]\tvalidation_0-mae:0.000681\tvalidation_1-mae:0.001342\n",
            "[938]\tvalidation_0-mae:0.00068\tvalidation_1-mae:0.001342\n",
            "[939]\tvalidation_0-mae:0.00068\tvalidation_1-mae:0.001342\n",
            "[940]\tvalidation_0-mae:0.00068\tvalidation_1-mae:0.001341\n",
            "[941]\tvalidation_0-mae:0.000679\tvalidation_1-mae:0.001341\n",
            "[942]\tvalidation_0-mae:0.000679\tvalidation_1-mae:0.001341\n",
            "[943]\tvalidation_0-mae:0.000679\tvalidation_1-mae:0.001341\n",
            "[944]\tvalidation_0-mae:0.000678\tvalidation_1-mae:0.001341\n",
            "[945]\tvalidation_0-mae:0.000678\tvalidation_1-mae:0.001341\n",
            "[946]\tvalidation_0-mae:0.000678\tvalidation_1-mae:0.001341\n",
            "[947]\tvalidation_0-mae:0.000677\tvalidation_1-mae:0.001341\n",
            "[948]\tvalidation_0-mae:0.000677\tvalidation_1-mae:0.001341\n",
            "[949]\tvalidation_0-mae:0.000676\tvalidation_1-mae:0.001341\n",
            "[950]\tvalidation_0-mae:0.000676\tvalidation_1-mae:0.001341\n",
            "[951]\tvalidation_0-mae:0.000676\tvalidation_1-mae:0.001341\n",
            "[952]\tvalidation_0-mae:0.000675\tvalidation_1-mae:0.001341\n",
            "[953]\tvalidation_0-mae:0.000675\tvalidation_1-mae:0.001341\n",
            "[954]\tvalidation_0-mae:0.000674\tvalidation_1-mae:0.001341\n",
            "[955]\tvalidation_0-mae:0.000674\tvalidation_1-mae:0.001341\n",
            "[956]\tvalidation_0-mae:0.000674\tvalidation_1-mae:0.001341\n",
            "[957]\tvalidation_0-mae:0.000674\tvalidation_1-mae:0.001341\n",
            "[958]\tvalidation_0-mae:0.000673\tvalidation_1-mae:0.00134\n",
            "[959]\tvalidation_0-mae:0.000673\tvalidation_1-mae:0.001341\n",
            "[960]\tvalidation_0-mae:0.000673\tvalidation_1-mae:0.00134\n",
            "[961]\tvalidation_0-mae:0.000673\tvalidation_1-mae:0.001341\n",
            "[962]\tvalidation_0-mae:0.000672\tvalidation_1-mae:0.00134\n",
            "[963]\tvalidation_0-mae:0.000671\tvalidation_1-mae:0.00134\n",
            "[964]\tvalidation_0-mae:0.000671\tvalidation_1-mae:0.00134\n",
            "[965]\tvalidation_0-mae:0.000671\tvalidation_1-mae:0.00134\n",
            "[966]\tvalidation_0-mae:0.000671\tvalidation_1-mae:0.00134\n",
            "[967]\tvalidation_0-mae:0.000671\tvalidation_1-mae:0.00134\n",
            "[968]\tvalidation_0-mae:0.000671\tvalidation_1-mae:0.00134\n",
            "[969]\tvalidation_0-mae:0.00067\tvalidation_1-mae:0.00134\n",
            "[970]\tvalidation_0-mae:0.00067\tvalidation_1-mae:0.00134\n",
            "[971]\tvalidation_0-mae:0.000669\tvalidation_1-mae:0.00134\n",
            "[972]\tvalidation_0-mae:0.000669\tvalidation_1-mae:0.00134\n",
            "[973]\tvalidation_0-mae:0.000669\tvalidation_1-mae:0.00134\n",
            "[974]\tvalidation_0-mae:0.000668\tvalidation_1-mae:0.00134\n",
            "[975]\tvalidation_0-mae:0.000668\tvalidation_1-mae:0.00134\n",
            "[976]\tvalidation_0-mae:0.000667\tvalidation_1-mae:0.00134\n",
            "[977]\tvalidation_0-mae:0.000667\tvalidation_1-mae:0.00134\n",
            "[978]\tvalidation_0-mae:0.000667\tvalidation_1-mae:0.00134\n",
            "[979]\tvalidation_0-mae:0.000667\tvalidation_1-mae:0.00134\n",
            "[980]\tvalidation_0-mae:0.000666\tvalidation_1-mae:0.00134\n",
            "[981]\tvalidation_0-mae:0.000666\tvalidation_1-mae:0.00134\n",
            "[982]\tvalidation_0-mae:0.000666\tvalidation_1-mae:0.00134\n",
            "[983]\tvalidation_0-mae:0.000665\tvalidation_1-mae:0.00134\n",
            "[984]\tvalidation_0-mae:0.000665\tvalidation_1-mae:0.001339\n",
            "[985]\tvalidation_0-mae:0.000665\tvalidation_1-mae:0.001339\n",
            "[986]\tvalidation_0-mae:0.000664\tvalidation_1-mae:0.001339\n",
            "[987]\tvalidation_0-mae:0.000664\tvalidation_1-mae:0.001339\n",
            "[988]\tvalidation_0-mae:0.000664\tvalidation_1-mae:0.001339\n",
            "[989]\tvalidation_0-mae:0.000663\tvalidation_1-mae:0.001339\n",
            "[990]\tvalidation_0-mae:0.000663\tvalidation_1-mae:0.001339\n",
            "[991]\tvalidation_0-mae:0.000663\tvalidation_1-mae:0.001339\n",
            "[992]\tvalidation_0-mae:0.000663\tvalidation_1-mae:0.001339\n",
            "[993]\tvalidation_0-mae:0.000662\tvalidation_1-mae:0.001339\n",
            "[994]\tvalidation_0-mae:0.000662\tvalidation_1-mae:0.001339\n",
            "[995]\tvalidation_0-mae:0.000662\tvalidation_1-mae:0.001339\n",
            "[996]\tvalidation_0-mae:0.000661\tvalidation_1-mae:0.001339\n",
            "[997]\tvalidation_0-mae:0.000661\tvalidation_1-mae:0.001339\n",
            "[998]\tvalidation_0-mae:0.000661\tvalidation_1-mae:0.001339\n",
            "[999]\tvalidation_0-mae:0.000661\tvalidation_1-mae:0.001339\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBRegressor(colsample_bytree=0.5, enable_categorical=True, learning_rate=0.05,\n",
              "             max_depth=6, n_estimators=1000, objective='reg:squarederror',\n",
              "             subsample=0.7)"
            ]
          },
          "metadata": {},
          "execution_count": 110
        }
      ],
      "source": [
        "from xgboost import XGBRegressor\n",
        "\n",
        "xgb_model = XGBRegressor(\n",
        "        enable_categorical=True,\n",
        "        objective = 'reg:squarederror',\n",
        "        colsample_bytree = 0.5,\n",
        "        learning_rate = 0.05,\n",
        "        max_depth = 6,\n",
        "        min_child_weight = 1,\n",
        "        n_estimators = 1000,\n",
        "        subsample = 0.7)\n",
        "\n",
        "xgb_model.fit(x_train, y_train,eval_set=[(x_train, y_train), (x_test, y_test)], eval_metric='mae')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_W2vec_xgboost = xgb_model.predict(x_test)\n",
        "xgb_model.score(x_test, y_test)"
      ],
      "metadata": {
        "id": "YOzRyti_HwrO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1deb81c-3fe1-42e3-d236-f69605371d70"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6484845265831959"
            ]
          },
          "metadata": {},
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xgb_model.score(x_test, y_test)"
      ],
      "metadata": {
        "id": "RZH0rdM_HeG3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32bcfa44-ad76-4c7a-d4fd-bdf9ecde63a0"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6484845265831959"
            ]
          },
          "metadata": {},
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rmse,R2,MAE,MSE,RMSLE,max_error_= metrics(y_test,y_pred_W2vec_xgboost)\n",
        "\n",
        "dict_info['Model'].append('XGboost')\n",
        "dict_info['RMSE'].append(rmse)\n",
        "dict_info['R2'].append(R2)\n",
        "dict_info['MAE'].append(MAE)\n",
        "dict_info['RMSLE'].append(RMSLE)\n",
        "dict_info['max_error_'].append(max_error_)"
      ],
      "metadata": {
        "id": "ri786OiU_13q"
      },
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Random Forest"
      ],
      "metadata": {
        "id": "rKLg2Kg5AbfK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# utils.hyperparameterTuning_RandomForest(x_train_w2v_df,y_train_w2v_df)\n",
        "rnd_clf = RandomForestRegressor(n_estimators=20, min_samples_split=10, min_samples_leaf=4,max_features='sqrt',max_depth=10,bootstrap=True)\n",
        "rnd_clf.fit(x_train, y_train)\n",
        "y_pred_w2vec_rnd = rnd_clf.predict(x_test)"
      ],
      "metadata": {
        "id": "Vzt1DURiAc5l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9570217-6f14-4828-b10f-30c1c0f7cabf"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:1692: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:1692: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
            "  FutureWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rmse,R2,MAE,MSE,RMSLE,max_error_= metrics(y_test,y_pred_w2vec_rnd)\n",
        "print(R2)\n",
        "\n",
        "dict_info['Model'].append('Random Forest')\n",
        "dict_info['RMSE'].append(rmse)\n",
        "dict_info['R2'].append(R2)\n",
        "dict_info['MAE'].append(MAE)\n",
        "dict_info['RMSLE'].append(RMSLE)\n",
        "dict_info['max_error_'].append(max_error_)"
      ],
      "metadata": {
        "id": "tJXN6RqGAncK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c67f39a-e393-44e4-b8f0-9b72a139be9a"
      },
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.4384221921648912\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MLP"
      ],
      "metadata": {
        "id": "UIM992uHArif"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neural_network import MLPRegressor\n",
        "mlp_GS = MLPRegressor(activation='relu',alpha=0.001,hidden_layer_sizes=(50, 50, 50),learning_rate='constant',solver='adam')\n",
        "mlp_GS.fit(x_train, y_train)\n",
        "y_pred_w2vec_mlp = mlp_GS.predict(x_test)"
      ],
      "metadata": {
        "id": "jm_Z8wABAtr9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2d4e00a-872a-4e42-c635-cca03a688c48"
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:1692: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:1692: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
            "  FutureWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rmse,R2,MAE,MSE,RMSLE,max_error_= metrics(y_test,y_pred_w2vec_mlp)\n",
        "\n",
        "dict_info['Model'].append('MLP')\n",
        "dict_info['RMSE'].append(rmse)\n",
        "dict_info['R2'].append(R2)\n",
        "dict_info['MAE'].append(MAE)\n",
        "dict_info['RMSLE'].append(RMSLE)\n",
        "dict_info['max_error_'].append(max_error_)"
      ],
      "metadata": {
        "id": "XwRQyahsA3KW"
      },
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SVC"
      ],
      "metadata": {
        "id": "Zvy0n-35A5Au"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import LinearSVR\n",
        "svr= LinearSVR(C=1.0, dual=True, epsilon=1.5, fit_intercept=True,intercept_scaling=1.0, loss='epsilon_insensitive', max_iter=1000,tol=0.0001, verbose=0)\n",
        "svr.fit(x_train, y_train)\n",
        "y_pred_w2vec_SVR = svr.predict(x_test)"
      ],
      "metadata": {
        "id": "UJkQBHXiA6Dd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d321b4ca-c3a7-400f-87f3-241420b7b57f"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:1692: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:1692: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
            "  FutureWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rmse,R2,MAE,MSE,RMSLE,max_error_= metrics(y_test,y_pred_w2vec_SVR)\n",
        "\n",
        "dict_info['Model'].append('SVR')\n",
        "dict_info['RMSE'].append(rmse)\n",
        "dict_info['R2'].append(R2)\n",
        "dict_info['MAE'].append(MAE)\n",
        "dict_info['RMSLE'].append(RMSLE)\n",
        "dict_info['max_error_'].append(max_error_)"
      ],
      "metadata": {
        "id": "LLJomRQaBFDx"
      },
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dfData = pd.DataFrame(dict_info)\n",
        "dfData"
      ],
      "metadata": {
        "id": "f0MjQ6yOBE6Q",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "5d1c6fe4-4584-4490-9b24-852e00a76212"
      },
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           Model      RMSE        R2       MAE     RMSLE  max_error_\n",
              "0       Lightgbm  0.008215  0.567790  0.001775 -4.801808    0.525262\n",
              "1        XGboost  0.007408  0.648485  0.001338 -4.905136    0.528714\n",
              "2  Random Forest  0.009364  0.438422  0.002144 -4.670888    0.595959\n",
              "3            MLP  0.010070  0.350565  0.003266 -4.598211    0.566379\n",
              "4            SVR  0.012907 -0.066904  0.003232 -4.350005    0.639221"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f5ea1b9d-62af-4837-a49a-93c5f8f54242\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>RMSE</th>\n",
              "      <th>R2</th>\n",
              "      <th>MAE</th>\n",
              "      <th>RMSLE</th>\n",
              "      <th>max_error_</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Lightgbm</td>\n",
              "      <td>0.008215</td>\n",
              "      <td>0.567790</td>\n",
              "      <td>0.001775</td>\n",
              "      <td>-4.801808</td>\n",
              "      <td>0.525262</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>XGboost</td>\n",
              "      <td>0.007408</td>\n",
              "      <td>0.648485</td>\n",
              "      <td>0.001338</td>\n",
              "      <td>-4.905136</td>\n",
              "      <td>0.528714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Random Forest</td>\n",
              "      <td>0.009364</td>\n",
              "      <td>0.438422</td>\n",
              "      <td>0.002144</td>\n",
              "      <td>-4.670888</td>\n",
              "      <td>0.595959</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>MLP</td>\n",
              "      <td>0.010070</td>\n",
              "      <td>0.350565</td>\n",
              "      <td>0.003266</td>\n",
              "      <td>-4.598211</td>\n",
              "      <td>0.566379</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>SVR</td>\n",
              "      <td>0.012907</td>\n",
              "      <td>-0.066904</td>\n",
              "      <td>0.003232</td>\n",
              "      <td>-4.350005</td>\n",
              "      <td>0.639221</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f5ea1b9d-62af-4837-a49a-93c5f8f54242')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f5ea1b9d-62af-4837-a49a-93c5f8f54242 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f5ea1b9d-62af-4837-a49a-93c5f8f54242');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 120
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "CV_features_Model_Building.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}