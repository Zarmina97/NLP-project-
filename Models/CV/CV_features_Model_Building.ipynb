{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gO5K_gGvDsQX"
      },
      "source": [
        "##CV features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "UPGY-89r9Vqn"
      },
      "outputs": [
        {
          "ename": "ImportError",
          "evalue": "No module named 'sklearn.__check_build._check_build'\n___________________________________________________________________________\nContents of c:\\Users\\jyoti\\anaconda3\\envs\\newInsta\\lib\\site-packages\\sklearn\\__check_build:\nsetup.py                  _check_build.cp310-win_amd64.pyd__init__.py\n__pycache__\n___________________________________________________________________________\nIt seems that scikit-learn has not been built correctly.\n\nIf you have installed scikit-learn from source, please do not forget\nto build the package before using it: run `python setup.py install` or\n`make` in the source directory.\n\nIf you have used an installer, please check that it is suited for your\nPython version, your operating system and your platform.",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "File \u001b[1;32mc:\\Users\\jyoti\\anaconda3\\envs\\newInsta\\lib\\site-packages\\sklearn\\__check_build\\__init__.py:48\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/jyoti/anaconda3/envs/newInsta/lib/site-packages/sklearn/__check_build/__init__.py?line=46'>47</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> <a href='file:///c%3A/Users/jyoti/anaconda3/envs/newInsta/lib/site-packages/sklearn/__check_build/__init__.py?line=47'>48</a>\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_check_build\u001b[39;00m \u001b[39mimport\u001b[39;00m check_build  \u001b[39m# noqa\u001b[39;00m\n\u001b[0;32m     <a href='file:///c%3A/Users/jyoti/anaconda3/envs/newInsta/lib/site-packages/sklearn/__check_build/__init__.py?line=48'>49</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mImportError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'sklearn.__check_build._check_build'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[1;32mc:\\Users\\jyoti\\Desktop\\NLP\\NLP_project\\NLP-project-\\Models\\CV\\CV_features_Model_Building.ipynb Cell 2'\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jyoti/Desktop/NLP/NLP_project/NLP-project-/Models/CV/CV_features_Model_Building.ipynb#ch0000001?line=10'>11</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtqdm\u001b[39;00m \u001b[39mimport\u001b[39;00m tqdm \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jyoti/Desktop/NLP/NLP_project/NLP-project-/Models/CV/CV_features_Model_Building.ipynb#ch0000001?line=11'>12</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mfunctools\u001b[39;00m \u001b[39mimport\u001b[39;00m reduce\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/jyoti/Desktop/NLP/NLP_project/NLP-project-/Models/CV/CV_features_Model_Building.ipynb#ch0000001?line=12'>13</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmanifold\u001b[39;00m \u001b[39mimport\u001b[39;00m TSNE\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jyoti/Desktop/NLP/NLP_project/NLP-project-/Models/CV/CV_features_Model_Building.ipynb#ch0000001?line=13'>14</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mcollections\u001b[39;00m \u001b[39mimport\u001b[39;00m defaultdict\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jyoti/Desktop/NLP/NLP_project/NLP-project-/Models/CV/CV_features_Model_Building.ipynb#ch0000001?line=14'>15</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mgensim\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodels\u001b[39;00m \u001b[39mimport\u001b[39;00m FastText\n",
            "File \u001b[1;32mc:\\Users\\jyoti\\anaconda3\\envs\\newInsta\\lib\\site-packages\\sklearn\\__init__.py:81\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/jyoti/anaconda3/envs/newInsta/lib/site-packages/sklearn/__init__.py?line=69'>70</a>\u001b[0m     \u001b[39m# We are not importing the rest of scikit-learn during the build\u001b[39;00m\n\u001b[0;32m     <a href='file:///c%3A/Users/jyoti/anaconda3/envs/newInsta/lib/site-packages/sklearn/__init__.py?line=70'>71</a>\u001b[0m     \u001b[39m# process, as it may not be compiled yet\u001b[39;00m\n\u001b[0;32m     <a href='file:///c%3A/Users/jyoti/anaconda3/envs/newInsta/lib/site-packages/sklearn/__init__.py?line=71'>72</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/jyoti/anaconda3/envs/newInsta/lib/site-packages/sklearn/__init__.py?line=77'>78</a>\u001b[0m     \u001b[39m# later is linked to the OpenMP runtime to make it possible to introspect\u001b[39;00m\n\u001b[0;32m     <a href='file:///c%3A/Users/jyoti/anaconda3/envs/newInsta/lib/site-packages/sklearn/__init__.py?line=78'>79</a>\u001b[0m     \u001b[39m# it and importing it first would fail if the OpenMP dll cannot be found.\u001b[39;00m\n\u001b[0;32m     <a href='file:///c%3A/Users/jyoti/anaconda3/envs/newInsta/lib/site-packages/sklearn/__init__.py?line=79'>80</a>\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m _distributor_init  \u001b[39m# noqa: F401\u001b[39;00m\n\u001b[1;32m---> <a href='file:///c%3A/Users/jyoti/anaconda3/envs/newInsta/lib/site-packages/sklearn/__init__.py?line=80'>81</a>\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m __check_build  \u001b[39m# noqa: F401\u001b[39;00m\n\u001b[0;32m     <a href='file:///c%3A/Users/jyoti/anaconda3/envs/newInsta/lib/site-packages/sklearn/__init__.py?line=81'>82</a>\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mbase\u001b[39;00m \u001b[39mimport\u001b[39;00m clone\n\u001b[0;32m     <a href='file:///c%3A/Users/jyoti/anaconda3/envs/newInsta/lib/site-packages/sklearn/__init__.py?line=82'>83</a>\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_show_versions\u001b[39;00m \u001b[39mimport\u001b[39;00m show_versions\n",
            "File \u001b[1;32mc:\\Users\\jyoti\\anaconda3\\envs\\newInsta\\lib\\site-packages\\sklearn\\__check_build\\__init__.py:50\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/jyoti/anaconda3/envs/newInsta/lib/site-packages/sklearn/__check_build/__init__.py?line=47'>48</a>\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_check_build\u001b[39;00m \u001b[39mimport\u001b[39;00m check_build  \u001b[39m# noqa\u001b[39;00m\n\u001b[0;32m     <a href='file:///c%3A/Users/jyoti/anaconda3/envs/newInsta/lib/site-packages/sklearn/__check_build/__init__.py?line=48'>49</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mImportError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m---> <a href='file:///c%3A/Users/jyoti/anaconda3/envs/newInsta/lib/site-packages/sklearn/__check_build/__init__.py?line=49'>50</a>\u001b[0m     raise_build_error(e)\n",
            "File \u001b[1;32mc:\\Users\\jyoti\\anaconda3\\envs\\newInsta\\lib\\site-packages\\sklearn\\__check_build\\__init__.py:31\u001b[0m, in \u001b[0;36mraise_build_error\u001b[1;34m(e)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/jyoti/anaconda3/envs/newInsta/lib/site-packages/sklearn/__check_build/__init__.py?line=28'>29</a>\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     <a href='file:///c%3A/Users/jyoti/anaconda3/envs/newInsta/lib/site-packages/sklearn/__check_build/__init__.py?line=29'>30</a>\u001b[0m             dir_content\u001b[39m.\u001b[39mappend(filename \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> <a href='file:///c%3A/Users/jyoti/anaconda3/envs/newInsta/lib/site-packages/sklearn/__check_build/__init__.py?line=30'>31</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mImportError\u001b[39;00m(\n\u001b[0;32m     <a href='file:///c%3A/Users/jyoti/anaconda3/envs/newInsta/lib/site-packages/sklearn/__check_build/__init__.py?line=31'>32</a>\u001b[0m         \u001b[39m\"\"\"%s\u001b[39;00m\n\u001b[0;32m     <a href='file:///c%3A/Users/jyoti/anaconda3/envs/newInsta/lib/site-packages/sklearn/__check_build/__init__.py?line=32'>33</a>\u001b[0m \u001b[39m___________________________________________________________________________\u001b[39;00m\n\u001b[0;32m     <a href='file:///c%3A/Users/jyoti/anaconda3/envs/newInsta/lib/site-packages/sklearn/__check_build/__init__.py?line=33'>34</a>\u001b[0m \u001b[39mContents of %s:\u001b[39;00m\n\u001b[0;32m     <a href='file:///c%3A/Users/jyoti/anaconda3/envs/newInsta/lib/site-packages/sklearn/__check_build/__init__.py?line=34'>35</a>\u001b[0m \u001b[39m%s\u001b[39;00m\n\u001b[0;32m     <a href='file:///c%3A/Users/jyoti/anaconda3/envs/newInsta/lib/site-packages/sklearn/__check_build/__init__.py?line=35'>36</a>\u001b[0m \u001b[39m___________________________________________________________________________\u001b[39;00m\n\u001b[0;32m     <a href='file:///c%3A/Users/jyoti/anaconda3/envs/newInsta/lib/site-packages/sklearn/__check_build/__init__.py?line=36'>37</a>\u001b[0m \u001b[39mIt seems that scikit-learn has not been built correctly.\u001b[39;00m\n\u001b[0;32m     <a href='file:///c%3A/Users/jyoti/anaconda3/envs/newInsta/lib/site-packages/sklearn/__check_build/__init__.py?line=37'>38</a>\u001b[0m \n\u001b[0;32m     <a href='file:///c%3A/Users/jyoti/anaconda3/envs/newInsta/lib/site-packages/sklearn/__check_build/__init__.py?line=38'>39</a>\u001b[0m \u001b[39mIf you have installed scikit-learn from source, please do not forget\u001b[39;00m\n\u001b[0;32m     <a href='file:///c%3A/Users/jyoti/anaconda3/envs/newInsta/lib/site-packages/sklearn/__check_build/__init__.py?line=39'>40</a>\u001b[0m \u001b[39mto build the package before using it: run `python setup.py install` or\u001b[39;00m\n\u001b[0;32m     <a href='file:///c%3A/Users/jyoti/anaconda3/envs/newInsta/lib/site-packages/sklearn/__check_build/__init__.py?line=40'>41</a>\u001b[0m \u001b[39m`make` in the source directory.\u001b[39;00m\n\u001b[0;32m     <a href='file:///c%3A/Users/jyoti/anaconda3/envs/newInsta/lib/site-packages/sklearn/__check_build/__init__.py?line=41'>42</a>\u001b[0m \u001b[39m%s\"\"\"\u001b[39;00m\n\u001b[0;32m     <a href='file:///c%3A/Users/jyoti/anaconda3/envs/newInsta/lib/site-packages/sklearn/__check_build/__init__.py?line=42'>43</a>\u001b[0m         \u001b[39m%\u001b[39m (e, local_dir, \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(dir_content)\u001b[39m.\u001b[39mstrip(), msg)\n\u001b[0;32m     <a href='file:///c%3A/Users/jyoti/anaconda3/envs/newInsta/lib/site-packages/sklearn/__check_build/__init__.py?line=43'>44</a>\u001b[0m     )\n",
            "\u001b[1;31mImportError\u001b[0m: No module named 'sklearn.__check_build._check_build'\n___________________________________________________________________________\nContents of c:\\Users\\jyoti\\anaconda3\\envs\\newInsta\\lib\\site-packages\\sklearn\\__check_build:\nsetup.py                  _check_build.cp310-win_amd64.pyd__init__.py\n__pycache__\n___________________________________________________________________________\nIt seems that scikit-learn has not been built correctly.\n\nIf you have installed scikit-learn from source, please do not forget\nto build the package before using it: run `python setup.py install` or\n`make` in the source directory.\n\nIf you have used an installer, please check that it is suited for your\nPython version, your operating system and your platform."
          ]
        }
      ],
      "source": [
        "import re\n",
        "import logging \n",
        "import gensim\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "import xgboost as xgb \n",
        "from time import time \n",
        "import pandas as pd\n",
        "from tqdm import tqdm \n",
        "from functools import reduce\n",
        "from sklearn.manifold import TSNE\n",
        "from collections import defaultdict\n",
        "from gensim.models import FastText\n",
        "from sklearn.metrics import r2_score\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.model_selection import train_test_split\n",
        "logging.basicConfig(format=\"%(levelname)s - %(asctime)s: %(message)s\", datefmt= '%H:%M:%S', level=logging.INFO)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "path='C:\\\\Users\\\\jyoti\\\\Desktop\\\\NLP\\\\NLP_project\\\\NLP-project-\\\\'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "N7N0EfaKNLZf"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\jyoti\\anaconda3\\envs\\nlp\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3229: DtypeWarning: Columns (49) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  interactivity=interactivity, compiler=compiler, result=result)\n"
          ]
        }
      ],
      "source": [
        "df = pd.read_csv(path+ \"Dataset\\\\df_final_cv.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "# df.drop(['Unnamed: 0'], axis = 1,inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "k0BV3Au1RiDV"
      },
      "outputs": [],
      "source": [
        "df.drop(df.columns.difference(['tags','confidence_score','accent_color','is_bw','dominant_colors','bg_color','fore_color','likes']), 1, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>likes</th>\n",
              "      <th>tags</th>\n",
              "      <th>confidence_score</th>\n",
              "      <th>accent_color</th>\n",
              "      <th>is_bw</th>\n",
              "      <th>dominant_colors</th>\n",
              "      <th>bg_color</th>\n",
              "      <th>fore_color</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>29.0</td>\n",
              "      <td>['text', 'font', 'graphics', 'screenshot', 'gr...</td>\n",
              "      <td>[0.9980798959732056, 0.9481294751167297, 0.881...</td>\n",
              "      <td>(0.788235294117647, 0.00784313725490196, 0.007...</td>\n",
              "      <td>0</td>\n",
              "      <td>[(1.0, 0.7529411764705882, 0.796078431372549)]</td>\n",
              "      <td>(1.0, 0.7529411764705882, 0.796078431372549)</td>\n",
              "      <td>(1.0, 0.7529411764705882, 0.796078431372549)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>44.0</td>\n",
              "      <td>['dessert', 'baked goods', 'baking', 'snack', ...</td>\n",
              "      <td>[0.9897554516792297, 0.987897515296936, 0.9828...</td>\n",
              "      <td>(0.6901960784313725, 0.14901960784313725, 0.10...</td>\n",
              "      <td>0</td>\n",
              "      <td>[(0.6470588235294118, 0.16470588235294117, 0.1...</td>\n",
              "      <td>(0.6470588235294118, 0.16470588235294117, 0.16...</td>\n",
              "      <td>(0.0, 0.0, 0.0)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>209.0</td>\n",
              "      <td>['food', 'fruit', 'baked goods', 'breakfast', ...</td>\n",
              "      <td>[0.9808361530303955, 0.9546540379524231, 0.947...</td>\n",
              "      <td>(0.6588235294117647, 0.4392156862745098, 0.141...</td>\n",
              "      <td>0</td>\n",
              "      <td>[(0.6470588235294118, 0.16470588235294117, 0.1...</td>\n",
              "      <td>(0.6470588235294118, 0.16470588235294117, 0.16...</td>\n",
              "      <td>(0.6470588235294118, 0.16470588235294117, 0.16...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>95.0</td>\n",
              "      <td>['food', 'bread', 'fast food', 'bun', 'america...</td>\n",
              "      <td>[0.9958561658859253, 0.981575608253479, 0.9799...</td>\n",
              "      <td>(0.24313725490196078, 0.12549019607843137, 0.0...</td>\n",
              "      <td>0</td>\n",
              "      <td>[(0.6470588235294118, 0.16470588235294117, 0.1...</td>\n",
              "      <td>(0.6470588235294118, 0.16470588235294117, 0.16...</td>\n",
              "      <td>(0.6470588235294118, 0.16470588235294117, 0.16...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>101.0</td>\n",
              "      <td>['text', 'font', 'design', 'yellow', 'graphics...</td>\n",
              "      <td>[0.9993002414703369, 0.9640201926231384, 0.951...</td>\n",
              "      <td>(0.792156862745098, 0.7372549019607844, 0.0039...</td>\n",
              "      <td>0</td>\n",
              "      <td>[(1.0, 1.0, 0.0)]</td>\n",
              "      <td>(1.0, 1.0, 0.0)</td>\n",
              "      <td>(1.0, 1.0, 0.0)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88511</th>\n",
              "      <td>8.0</td>\n",
              "      <td>['text', 'food', 'snack']</td>\n",
              "      <td>[0.9999812841415405, 0.9580191373825073, 0.915...</td>\n",
              "      <td>(0.6588235294117647, 0.00784313725490196, 0.71...</td>\n",
              "      <td>0</td>\n",
              "      <td>[(0.5019607843137255, 0.0, 0.5019607843137255)...</td>\n",
              "      <td>(0.5019607843137255, 0.0, 0.5019607843137255)</td>\n",
              "      <td>(0.5019607843137255, 0.5019607843137255, 0.501...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88512</th>\n",
              "      <td>9.0</td>\n",
              "      <td>['text', 'poster', 'cartoon']</td>\n",
              "      <td>[0.9999863505363464, 0.9184243679046631, 0.910...</td>\n",
              "      <td>(0.01568627450980392, 0.5098039215686274, 0.78...</td>\n",
              "      <td>0</td>\n",
              "      <td>[(1.0, 1.0, 1.0)]</td>\n",
              "      <td>(1.0, 1.0, 1.0)</td>\n",
              "      <td>(1.0, 1.0, 1.0)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88513</th>\n",
              "      <td>11.0</td>\n",
              "      <td>['text', 'yellow', 'packaging and labeling', '...</td>\n",
              "      <td>[0.9997624158859253, 0.9444339871406555, 0.854...</td>\n",
              "      <td>(0.01568627450980392, 0.2235294117647059, 0.43...</td>\n",
              "      <td>0</td>\n",
              "      <td>[(1.0, 1.0, 0.0), (0.0, 0.0, 1.0)]</td>\n",
              "      <td>(0.0, 0.0, 1.0)</td>\n",
              "      <td>(1.0, 1.0, 0.0)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88514</th>\n",
              "      <td>NaN</td>\n",
              "      <td>['sport', 'person', 'barbell', 'physical fitne...</td>\n",
              "      <td>[0.9959811568260193, 0.9808116555213928, 0.971...</td>\n",
              "      <td>(0.6862745098039216, 0.5215686274509804, 0.109...</td>\n",
              "      <td>0</td>\n",
              "      <td>[(1.0, 1.0, 1.0)]</td>\n",
              "      <td>(1.0, 1.0, 1.0)</td>\n",
              "      <td>(1.0, 1.0, 1.0)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88515</th>\n",
              "      <td>NaN</td>\n",
              "      <td>['cosmetics', 'toiletry', 'eyelash', 'skin', '...</td>\n",
              "      <td>[0.974940299987793, 0.9452543258666992, 0.9450...</td>\n",
              "      <td>(0.6705882352941176, 0.27058823529411763, 0.12...</td>\n",
              "      <td>0</td>\n",
              "      <td>[(1.0, 0.7529411764705882, 0.796078431372549),...</td>\n",
              "      <td>(1.0, 1.0, 1.0)</td>\n",
              "      <td>(1.0, 0.7529411764705882, 0.796078431372549)</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>88516 rows × 8 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       likes                                               tags  \\\n",
              "0       29.0  ['text', 'font', 'graphics', 'screenshot', 'gr...   \n",
              "1       44.0  ['dessert', 'baked goods', 'baking', 'snack', ...   \n",
              "2      209.0  ['food', 'fruit', 'baked goods', 'breakfast', ...   \n",
              "3       95.0  ['food', 'bread', 'fast food', 'bun', 'america...   \n",
              "4      101.0  ['text', 'font', 'design', 'yellow', 'graphics...   \n",
              "...      ...                                                ...   \n",
              "88511    8.0                          ['text', 'food', 'snack']   \n",
              "88512    9.0                      ['text', 'poster', 'cartoon']   \n",
              "88513   11.0  ['text', 'yellow', 'packaging and labeling', '...   \n",
              "88514    NaN  ['sport', 'person', 'barbell', 'physical fitne...   \n",
              "88515    NaN  ['cosmetics', 'toiletry', 'eyelash', 'skin', '...   \n",
              "\n",
              "                                        confidence_score  \\\n",
              "0      [0.9980798959732056, 0.9481294751167297, 0.881...   \n",
              "1      [0.9897554516792297, 0.987897515296936, 0.9828...   \n",
              "2      [0.9808361530303955, 0.9546540379524231, 0.947...   \n",
              "3      [0.9958561658859253, 0.981575608253479, 0.9799...   \n",
              "4      [0.9993002414703369, 0.9640201926231384, 0.951...   \n",
              "...                                                  ...   \n",
              "88511  [0.9999812841415405, 0.9580191373825073, 0.915...   \n",
              "88512  [0.9999863505363464, 0.9184243679046631, 0.910...   \n",
              "88513  [0.9997624158859253, 0.9444339871406555, 0.854...   \n",
              "88514  [0.9959811568260193, 0.9808116555213928, 0.971...   \n",
              "88515  [0.974940299987793, 0.9452543258666992, 0.9450...   \n",
              "\n",
              "                                            accent_color  is_bw  \\\n",
              "0      (0.788235294117647, 0.00784313725490196, 0.007...      0   \n",
              "1      (0.6901960784313725, 0.14901960784313725, 0.10...      0   \n",
              "2      (0.6588235294117647, 0.4392156862745098, 0.141...      0   \n",
              "3      (0.24313725490196078, 0.12549019607843137, 0.0...      0   \n",
              "4      (0.792156862745098, 0.7372549019607844, 0.0039...      0   \n",
              "...                                                  ...    ...   \n",
              "88511  (0.6588235294117647, 0.00784313725490196, 0.71...      0   \n",
              "88512  (0.01568627450980392, 0.5098039215686274, 0.78...      0   \n",
              "88513  (0.01568627450980392, 0.2235294117647059, 0.43...      0   \n",
              "88514  (0.6862745098039216, 0.5215686274509804, 0.109...      0   \n",
              "88515  (0.6705882352941176, 0.27058823529411763, 0.12...      0   \n",
              "\n",
              "                                         dominant_colors  \\\n",
              "0         [(1.0, 0.7529411764705882, 0.796078431372549)]   \n",
              "1      [(0.6470588235294118, 0.16470588235294117, 0.1...   \n",
              "2      [(0.6470588235294118, 0.16470588235294117, 0.1...   \n",
              "3      [(0.6470588235294118, 0.16470588235294117, 0.1...   \n",
              "4                                      [(1.0, 1.0, 0.0)]   \n",
              "...                                                  ...   \n",
              "88511  [(0.5019607843137255, 0.0, 0.5019607843137255)...   \n",
              "88512                                  [(1.0, 1.0, 1.0)]   \n",
              "88513                 [(1.0, 1.0, 0.0), (0.0, 0.0, 1.0)]   \n",
              "88514                                  [(1.0, 1.0, 1.0)]   \n",
              "88515  [(1.0, 0.7529411764705882, 0.796078431372549),...   \n",
              "\n",
              "                                                bg_color  \\\n",
              "0           (1.0, 0.7529411764705882, 0.796078431372549)   \n",
              "1      (0.6470588235294118, 0.16470588235294117, 0.16...   \n",
              "2      (0.6470588235294118, 0.16470588235294117, 0.16...   \n",
              "3      (0.6470588235294118, 0.16470588235294117, 0.16...   \n",
              "4                                        (1.0, 1.0, 0.0)   \n",
              "...                                                  ...   \n",
              "88511      (0.5019607843137255, 0.0, 0.5019607843137255)   \n",
              "88512                                    (1.0, 1.0, 1.0)   \n",
              "88513                                    (0.0, 0.0, 1.0)   \n",
              "88514                                    (1.0, 1.0, 1.0)   \n",
              "88515                                    (1.0, 1.0, 1.0)   \n",
              "\n",
              "                                              fore_color  \n",
              "0           (1.0, 0.7529411764705882, 0.796078431372549)  \n",
              "1                                        (0.0, 0.0, 0.0)  \n",
              "2      (0.6470588235294118, 0.16470588235294117, 0.16...  \n",
              "3      (0.6470588235294118, 0.16470588235294117, 0.16...  \n",
              "4                                        (1.0, 1.0, 0.0)  \n",
              "...                                                  ...  \n",
              "88511  (0.5019607843137255, 0.5019607843137255, 0.501...  \n",
              "88512                                    (1.0, 1.0, 1.0)  \n",
              "88513                                    (1.0, 1.0, 0.0)  \n",
              "88514                                    (1.0, 1.0, 1.0)  \n",
              "88515       (1.0, 0.7529411764705882, 0.796078431372549)  \n",
              "\n",
              "[88516 rows x 8 columns]"
            ]
          },
          "execution_count": 64,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "ySQ05ib6D-2O",
        "outputId": "81ceb393-a2d9-4e41-f456-97ccd5003c4f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Total Missing Values</th>\n",
              "      <th>Missing %</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>likes</th>\n",
              "      <td>2</td>\n",
              "      <td>0.002259</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>tags</th>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>confidence_score</th>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>accent_color</th>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>is_bw</th>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>dominant_colors</th>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>bg_color</th>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>fore_color</th>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                  Total Missing Values  Missing %\n",
              "likes                                2   0.002259\n",
              "tags                                 0   0.000000\n",
              "confidence_score                     0   0.000000\n",
              "accent_color                         0   0.000000\n",
              "is_bw                                0   0.000000\n",
              "dominant_colors                      0   0.000000\n",
              "bg_color                             0   0.000000\n",
              "fore_color                           0   0.000000"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#calculating missing values in the dataset\n",
        "missing_values = df.isnull().sum()\n",
        "missing_per = (missing_values/df.shape[0])*100\n",
        "missing_table = pd.concat([missing_values,missing_per], axis=1, ignore_index=True) \n",
        "missing_table.rename(columns={0:'Total Missing Values',1:'Missing %'}, inplace=True)\n",
        "missing_table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "NFwMDejGFY-V"
      },
      "outputs": [],
      "source": [
        "#fill the missing values with zero\n",
        "df['likes'] = df['likes'].fillna(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Br5JtQkWSAd-"
      },
      "outputs": [],
      "source": [
        "df1=df[:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z43faC01a3Ll",
        "outputId": "689b307c-a608-41f4-f7fd-3787ec164830"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Pre-processing text...\n",
            "[Debug] Before:\n",
            "0    ['text', 'font', 'graphics', 'screenshot', 'gr...\n",
            "1    ['dessert', 'baked goods', 'baking', 'snack', ...\n",
            "2    ['food', 'fruit', 'baked goods', 'breakfast', ...\n",
            "3    ['food', 'bread', 'fast food', 'bun', 'america...\n",
            "4    ['text', 'font', 'design', 'yellow', 'graphics...\n",
            "5    ['snack', 'baked goods', 'baking', 'dessert', ...\n",
            "6    ['dessert', 'baked goods', 'baking', 'sweetnes...\n",
            "7    ['text', 'food', 'shelf', 'countertop', 'indoo...\n",
            "8    ['text', 'table', 'food', 'bakery', 'clothing'...\n",
            "9    ['baked goods', 'sweetness', 'food', 'baking',...\n",
            "Name: tags, dtype: object\n",
            "[Debug] After:\n",
            "0    text ,  font ,  graphics ,  screenshot ,  grap...\n",
            "1    dessert ,  baked goods ,  baking ,  snack ,  f...\n",
            "2    food ,  fruit ,  baked goods ,  breakfast ,  c...\n",
            "3    food ,  bread ,  fast food ,  bun ,  american ...\n",
            "4    text ,  font ,  design ,  yellow ,  graphics ,...\n",
            "5    snack ,  baked goods ,  baking ,  dessert ,  b...\n",
            "6    dessert ,  baked goods ,  baking ,  sweetness ...\n",
            "7    text ,  food ,  shelf ,  countertop ,  indoor ...\n",
            "8    text ,  table ,  food ,  bakery ,  clothing , ...\n",
            "9    baked goods ,  sweetness ,  food ,  baking ,  ...\n",
            "Name: tags, dtype: object\n",
            "\n",
            "Pre-processing completed!\n"
          ]
        }
      ],
      "source": [
        "REPLACE_BY_SPACE_RE = re.compile('[^a-zA-Z_0-9,.]')\n",
        "\n",
        "def strip_text(text: str) -> str:\n",
        "    \"\"\"\n",
        "    Removes any left or right spacing (including carriage return) from text.\n",
        "    Example:\n",
        "    Input: '  This assignment is cool\\n'\n",
        "    Output: 'This assignment is cool'\n",
        "    \"\"\"\n",
        "\n",
        "    return text.strip()\n",
        "\n",
        "\n",
        "def replace_br(text: str) -> str:\n",
        "    \"\"\"\n",
        "    Replaces br characters\n",
        "    \"\"\"\n",
        "\n",
        "    return text.replace(\"'\", \"\")\n",
        "\n",
        "\n",
        "def replace_special_characters(text: str) -> str:\n",
        "    \"\"\"\n",
        "    Replaces special characters, such as paranthesis,\n",
        "    with spacing character\n",
        "    \"\"\"\n",
        "\n",
        "    return REPLACE_BY_SPACE_RE.sub(' ', text)\n",
        "\n",
        "\n",
        "from typing import List, Callable, Dict\n",
        "\n",
        "PREPROCESSING_PIPELINE = [\n",
        "                          replace_special_characters,\n",
        "                          strip_text\n",
        "                          ]\n",
        "\n",
        "\n",
        "\n",
        "def text_prepare(text: str, filter_methods: List[Callable[[str], str]] = None) -> str:\n",
        "    \"\"\"\n",
        "    Applies a list of pre-processing functions in sequence (reduce).\n",
        "    Note that the order is important here!\n",
        "    \"\"\"\n",
        "    filter_methods = filter_methods if filter_methods is not None else PREPROCESSING_PIPELINE\n",
        "    return reduce(lambda txt, f: f(txt), filter_methods, text)\n",
        "\n",
        "# Pre-processing\n",
        "\n",
        "print('Pre-processing text...')\n",
        "print('[Debug] Before:\\n{}'.format(df1.tags[:10]))\n",
        "\n",
        "L=['tags','confidence_score','accent_color','dominant_colors','bg_color','fore_color']\n",
        "\n",
        "A=['tags']\n",
        "\n",
        "for i in L:\n",
        "  df1[i]=df1[i].apply(lambda txt: text_prepare(str(txt)[1:-1]))\n",
        "\n",
        "\n",
        "\n",
        "print('[Debug] After:\\n{}'.format(df1.tags[:10]))\n",
        "print()\n",
        "\n",
        "print(\"Pre-processing completed!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 988
        },
        "id": "bnJgDxCV87dy",
        "outputId": "36ff0bd7-a6d7-40a5-b741-34da4f95f8c4"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>likes</th>\n",
              "      <th>tags</th>\n",
              "      <th>confidence_score</th>\n",
              "      <th>accent_color</th>\n",
              "      <th>is_bw</th>\n",
              "      <th>dominant_colors</th>\n",
              "      <th>bg_color</th>\n",
              "      <th>fore_color</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>29.0</td>\n",
              "      <td>text ,  font ,  graphics ,  screenshot ,  grap...</td>\n",
              "      <td>0.9980798959732056, 0.9481294751167297, 0.8818...</td>\n",
              "      <td>0.788235294117647, 0.00784313725490196, 0.0078...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0, 0.7529411764705882, 0.796078431372549</td>\n",
              "      <td>1.0, 0.7529411764705882, 0.796078431372549</td>\n",
              "      <td>1.0, 0.7529411764705882, 0.796078431372549</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>44.0</td>\n",
              "      <td>dessert ,  baked goods ,  baking ,  snack ,  f...</td>\n",
              "      <td>0.9897554516792297, 0.987897515296936, 0.98287...</td>\n",
              "      <td>0.6901960784313725, 0.14901960784313725, 0.105...</td>\n",
              "      <td>0</td>\n",
              "      <td>0.6470588235294118, 0.16470588235294117, 0.164...</td>\n",
              "      <td>0.6470588235294118, 0.16470588235294117, 0.164...</td>\n",
              "      <td>0.0, 0.0, 0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>209.0</td>\n",
              "      <td>food ,  fruit ,  baked goods ,  breakfast ,  c...</td>\n",
              "      <td>0.9808361530303955, 0.9546540379524231, 0.9477...</td>\n",
              "      <td>0.6588235294117647, 0.4392156862745098, 0.1411...</td>\n",
              "      <td>0</td>\n",
              "      <td>0.6470588235294118, 0.16470588235294117, 0.164...</td>\n",
              "      <td>0.6470588235294118, 0.16470588235294117, 0.164...</td>\n",
              "      <td>0.6470588235294118, 0.16470588235294117, 0.164...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>95.0</td>\n",
              "      <td>food ,  bread ,  fast food ,  bun ,  american ...</td>\n",
              "      <td>0.9958561658859253, 0.981575608253479, 0.97992...</td>\n",
              "      <td>0.24313725490196078, 0.12549019607843137, 0.07...</td>\n",
              "      <td>0</td>\n",
              "      <td>0.6470588235294118, 0.16470588235294117, 0.164...</td>\n",
              "      <td>0.6470588235294118, 0.16470588235294117, 0.164...</td>\n",
              "      <td>0.6470588235294118, 0.16470588235294117, 0.164...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>101.0</td>\n",
              "      <td>text ,  font ,  design ,  yellow ,  graphics ,...</td>\n",
              "      <td>0.9993002414703369, 0.9640201926231384, 0.9513...</td>\n",
              "      <td>0.792156862745098, 0.7372549019607844, 0.00392...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0, 1.0, 0.0</td>\n",
              "      <td>1.0, 1.0, 0.0</td>\n",
              "      <td>1.0, 1.0, 0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88511</th>\n",
              "      <td>8.0</td>\n",
              "      <td>text ,  food ,  snack</td>\n",
              "      <td>0.9999812841415405, 0.9580191373825073, 0.9157...</td>\n",
              "      <td>0.6588235294117647, 0.00784313725490196, 0.713...</td>\n",
              "      <td>0</td>\n",
              "      <td>0.5019607843137255, 0.0, 0.5019607843137255 , ...</td>\n",
              "      <td>0.5019607843137255, 0.0, 0.5019607843137255</td>\n",
              "      <td>0.5019607843137255, 0.5019607843137255, 0.5019...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88512</th>\n",
              "      <td>9.0</td>\n",
              "      <td>text ,  poster ,  cartoon</td>\n",
              "      <td>0.9999863505363464, 0.9184243679046631, 0.9104...</td>\n",
              "      <td>0.01568627450980392, 0.5098039215686274, 0.780...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0, 1.0, 1.0</td>\n",
              "      <td>1.0, 1.0, 1.0</td>\n",
              "      <td>1.0, 1.0, 1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88513</th>\n",
              "      <td>11.0</td>\n",
              "      <td>text ,  yellow ,  packaging and labeling ,  fo...</td>\n",
              "      <td>0.9997624158859253, 0.9444339871406555, 0.8540...</td>\n",
              "      <td>0.01568627450980392, 0.2235294117647059, 0.439...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0, 1.0, 0.0 ,  0.0, 0.0, 1.0</td>\n",
              "      <td>0.0, 0.0, 1.0</td>\n",
              "      <td>1.0, 1.0, 0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88514</th>\n",
              "      <td>0.0</td>\n",
              "      <td>sport ,  person ,  barbell ,  physical fitness...</td>\n",
              "      <td>0.9959811568260193, 0.9808116555213928, 0.9714...</td>\n",
              "      <td>0.6862745098039216, 0.5215686274509804, 0.1098...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0, 1.0, 1.0</td>\n",
              "      <td>1.0, 1.0, 1.0</td>\n",
              "      <td>1.0, 1.0, 1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88515</th>\n",
              "      <td>0.0</td>\n",
              "      <td>cosmetics ,  toiletry ,  eyelash ,  skin ,  pe...</td>\n",
              "      <td>0.974940299987793, 0.9452543258666992, 0.94509...</td>\n",
              "      <td>0.6705882352941176, 0.27058823529411763, 0.125...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0, 0.7529411764705882, 0.796078431372549 ,  ...</td>\n",
              "      <td>1.0, 1.0, 1.0</td>\n",
              "      <td>1.0, 0.7529411764705882, 0.796078431372549</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>88516 rows × 8 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       likes                                               tags  \\\n",
              "0       29.0  text ,  font ,  graphics ,  screenshot ,  grap...   \n",
              "1       44.0  dessert ,  baked goods ,  baking ,  snack ,  f...   \n",
              "2      209.0  food ,  fruit ,  baked goods ,  breakfast ,  c...   \n",
              "3       95.0  food ,  bread ,  fast food ,  bun ,  american ...   \n",
              "4      101.0  text ,  font ,  design ,  yellow ,  graphics ,...   \n",
              "...      ...                                                ...   \n",
              "88511    8.0                              text ,  food ,  snack   \n",
              "88512    9.0                          text ,  poster ,  cartoon   \n",
              "88513   11.0  text ,  yellow ,  packaging and labeling ,  fo...   \n",
              "88514    0.0  sport ,  person ,  barbell ,  physical fitness...   \n",
              "88515    0.0  cosmetics ,  toiletry ,  eyelash ,  skin ,  pe...   \n",
              "\n",
              "                                        confidence_score  \\\n",
              "0      0.9980798959732056, 0.9481294751167297, 0.8818...   \n",
              "1      0.9897554516792297, 0.987897515296936, 0.98287...   \n",
              "2      0.9808361530303955, 0.9546540379524231, 0.9477...   \n",
              "3      0.9958561658859253, 0.981575608253479, 0.97992...   \n",
              "4      0.9993002414703369, 0.9640201926231384, 0.9513...   \n",
              "...                                                  ...   \n",
              "88511  0.9999812841415405, 0.9580191373825073, 0.9157...   \n",
              "88512  0.9999863505363464, 0.9184243679046631, 0.9104...   \n",
              "88513  0.9997624158859253, 0.9444339871406555, 0.8540...   \n",
              "88514  0.9959811568260193, 0.9808116555213928, 0.9714...   \n",
              "88515  0.974940299987793, 0.9452543258666992, 0.94509...   \n",
              "\n",
              "                                            accent_color  is_bw  \\\n",
              "0      0.788235294117647, 0.00784313725490196, 0.0078...      0   \n",
              "1      0.6901960784313725, 0.14901960784313725, 0.105...      0   \n",
              "2      0.6588235294117647, 0.4392156862745098, 0.1411...      0   \n",
              "3      0.24313725490196078, 0.12549019607843137, 0.07...      0   \n",
              "4      0.792156862745098, 0.7372549019607844, 0.00392...      0   \n",
              "...                                                  ...    ...   \n",
              "88511  0.6588235294117647, 0.00784313725490196, 0.713...      0   \n",
              "88512  0.01568627450980392, 0.5098039215686274, 0.780...      0   \n",
              "88513  0.01568627450980392, 0.2235294117647059, 0.439...      0   \n",
              "88514  0.6862745098039216, 0.5215686274509804, 0.1098...      0   \n",
              "88515  0.6705882352941176, 0.27058823529411763, 0.125...      0   \n",
              "\n",
              "                                         dominant_colors  \\\n",
              "0             1.0, 0.7529411764705882, 0.796078431372549   \n",
              "1      0.6470588235294118, 0.16470588235294117, 0.164...   \n",
              "2      0.6470588235294118, 0.16470588235294117, 0.164...   \n",
              "3      0.6470588235294118, 0.16470588235294117, 0.164...   \n",
              "4                                          1.0, 1.0, 0.0   \n",
              "...                                                  ...   \n",
              "88511  0.5019607843137255, 0.0, 0.5019607843137255 , ...   \n",
              "88512                                      1.0, 1.0, 1.0   \n",
              "88513                     1.0, 1.0, 0.0 ,  0.0, 0.0, 1.0   \n",
              "88514                                      1.0, 1.0, 1.0   \n",
              "88515  1.0, 0.7529411764705882, 0.796078431372549 ,  ...   \n",
              "\n",
              "                                                bg_color  \\\n",
              "0             1.0, 0.7529411764705882, 0.796078431372549   \n",
              "1      0.6470588235294118, 0.16470588235294117, 0.164...   \n",
              "2      0.6470588235294118, 0.16470588235294117, 0.164...   \n",
              "3      0.6470588235294118, 0.16470588235294117, 0.164...   \n",
              "4                                          1.0, 1.0, 0.0   \n",
              "...                                                  ...   \n",
              "88511        0.5019607843137255, 0.0, 0.5019607843137255   \n",
              "88512                                      1.0, 1.0, 1.0   \n",
              "88513                                      0.0, 0.0, 1.0   \n",
              "88514                                      1.0, 1.0, 1.0   \n",
              "88515                                      1.0, 1.0, 1.0   \n",
              "\n",
              "                                              fore_color  \n",
              "0             1.0, 0.7529411764705882, 0.796078431372549  \n",
              "1                                          0.0, 0.0, 0.0  \n",
              "2      0.6470588235294118, 0.16470588235294117, 0.164...  \n",
              "3      0.6470588235294118, 0.16470588235294117, 0.164...  \n",
              "4                                          1.0, 1.0, 0.0  \n",
              "...                                                  ...  \n",
              "88511  0.5019607843137255, 0.5019607843137255, 0.5019...  \n",
              "88512                                      1.0, 1.0, 1.0  \n",
              "88513                                      1.0, 1.0, 0.0  \n",
              "88514                                      1.0, 1.0, 1.0  \n",
              "88515         1.0, 0.7529411764705882, 0.796078431372549  \n",
              "\n",
              "[88516 rows x 8 columns]"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>likes</th>\n",
              "      <th>tags</th>\n",
              "      <th>confidence_score</th>\n",
              "      <th>accent_color</th>\n",
              "      <th>is_bw</th>\n",
              "      <th>dominant_colors</th>\n",
              "      <th>bg_color</th>\n",
              "      <th>fore_color</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>29.0</td>\n",
              "      <td>text ,  font ,  graphics ,  screenshot ,  grap...</td>\n",
              "      <td>0.9980798959732056, 0.9481294751167297, 0.8818...</td>\n",
              "      <td>0.788235294117647, 0.00784313725490196, 0.0078...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0, 0.7529411764705882, 0.796078431372549</td>\n",
              "      <td>1.0, 0.7529411764705882, 0.796078431372549</td>\n",
              "      <td>1.0, 0.7529411764705882, 0.796078431372549</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>44.0</td>\n",
              "      <td>dessert ,  baked goods ,  baking ,  snack ,  f...</td>\n",
              "      <td>0.9897554516792297, 0.987897515296936, 0.98287...</td>\n",
              "      <td>0.6901960784313725, 0.14901960784313725, 0.105...</td>\n",
              "      <td>0</td>\n",
              "      <td>0.6470588235294118, 0.16470588235294117, 0.164...</td>\n",
              "      <td>0.6470588235294118, 0.16470588235294117, 0.164...</td>\n",
              "      <td>0.0, 0.0, 0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>209.0</td>\n",
              "      <td>food ,  fruit ,  baked goods ,  breakfast ,  c...</td>\n",
              "      <td>0.9808361530303955, 0.9546540379524231, 0.9477...</td>\n",
              "      <td>0.6588235294117647, 0.4392156862745098, 0.1411...</td>\n",
              "      <td>0</td>\n",
              "      <td>0.6470588235294118, 0.16470588235294117, 0.164...</td>\n",
              "      <td>0.6470588235294118, 0.16470588235294117, 0.164...</td>\n",
              "      <td>0.6470588235294118, 0.16470588235294117, 0.164...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>95.0</td>\n",
              "      <td>food ,  bread ,  fast food ,  bun ,  american ...</td>\n",
              "      <td>0.9958561658859253, 0.981575608253479, 0.97992...</td>\n",
              "      <td>0.24313725490196078, 0.12549019607843137, 0.07...</td>\n",
              "      <td>0</td>\n",
              "      <td>0.6470588235294118, 0.16470588235294117, 0.164...</td>\n",
              "      <td>0.6470588235294118, 0.16470588235294117, 0.164...</td>\n",
              "      <td>0.6470588235294118, 0.16470588235294117, 0.164...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>101.0</td>\n",
              "      <td>text ,  font ,  design ,  yellow ,  graphics ,...</td>\n",
              "      <td>0.9993002414703369, 0.9640201926231384, 0.9513...</td>\n",
              "      <td>0.792156862745098, 0.7372549019607844, 0.00392...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0, 1.0, 0.0</td>\n",
              "      <td>1.0, 1.0, 0.0</td>\n",
              "      <td>1.0, 1.0, 0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88511</th>\n",
              "      <td>8.0</td>\n",
              "      <td>text ,  food ,  snack</td>\n",
              "      <td>0.9999812841415405, 0.9580191373825073, 0.9157...</td>\n",
              "      <td>0.6588235294117647, 0.00784313725490196, 0.713...</td>\n",
              "      <td>0</td>\n",
              "      <td>0.5019607843137255, 0.0, 0.5019607843137255 , ...</td>\n",
              "      <td>0.5019607843137255, 0.0, 0.5019607843137255</td>\n",
              "      <td>0.5019607843137255, 0.5019607843137255, 0.5019...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88512</th>\n",
              "      <td>9.0</td>\n",
              "      <td>text ,  poster ,  cartoon</td>\n",
              "      <td>0.9999863505363464, 0.9184243679046631, 0.9104...</td>\n",
              "      <td>0.01568627450980392, 0.5098039215686274, 0.780...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0, 1.0, 1.0</td>\n",
              "      <td>1.0, 1.0, 1.0</td>\n",
              "      <td>1.0, 1.0, 1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88513</th>\n",
              "      <td>11.0</td>\n",
              "      <td>text ,  yellow ,  packaging and labeling ,  fo...</td>\n",
              "      <td>0.9997624158859253, 0.9444339871406555, 0.8540...</td>\n",
              "      <td>0.01568627450980392, 0.2235294117647059, 0.439...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0, 1.0, 0.0 ,  0.0, 0.0, 1.0</td>\n",
              "      <td>0.0, 0.0, 1.0</td>\n",
              "      <td>1.0, 1.0, 0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88514</th>\n",
              "      <td>0.0</td>\n",
              "      <td>sport ,  person ,  barbell ,  physical fitness...</td>\n",
              "      <td>0.9959811568260193, 0.9808116555213928, 0.9714...</td>\n",
              "      <td>0.6862745098039216, 0.5215686274509804, 0.1098...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0, 1.0, 1.0</td>\n",
              "      <td>1.0, 1.0, 1.0</td>\n",
              "      <td>1.0, 1.0, 1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88515</th>\n",
              "      <td>0.0</td>\n",
              "      <td>cosmetics ,  toiletry ,  eyelash ,  skin ,  pe...</td>\n",
              "      <td>0.974940299987793, 0.9452543258666992, 0.94509...</td>\n",
              "      <td>0.6705882352941176, 0.27058823529411763, 0.125...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0, 0.7529411764705882, 0.796078431372549 ,  ...</td>\n",
              "      <td>1.0, 1.0, 1.0</td>\n",
              "      <td>1.0, 0.7529411764705882, 0.796078431372549</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>88516 rows × 8 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       likes                                               tags  \\\n",
              "0       29.0  text ,  font ,  graphics ,  screenshot ,  grap...   \n",
              "1       44.0  dessert ,  baked goods ,  baking ,  snack ,  f...   \n",
              "2      209.0  food ,  fruit ,  baked goods ,  breakfast ,  c...   \n",
              "3       95.0  food ,  bread ,  fast food ,  bun ,  american ...   \n",
              "4      101.0  text ,  font ,  design ,  yellow ,  graphics ,...   \n",
              "...      ...                                                ...   \n",
              "88511    8.0                              text ,  food ,  snack   \n",
              "88512    9.0                          text ,  poster ,  cartoon   \n",
              "88513   11.0  text ,  yellow ,  packaging and labeling ,  fo...   \n",
              "88514    0.0  sport ,  person ,  barbell ,  physical fitness...   \n",
              "88515    0.0  cosmetics ,  toiletry ,  eyelash ,  skin ,  pe...   \n",
              "\n",
              "                                        confidence_score  \\\n",
              "0      0.9980798959732056, 0.9481294751167297, 0.8818...   \n",
              "1      0.9897554516792297, 0.987897515296936, 0.98287...   \n",
              "2      0.9808361530303955, 0.9546540379524231, 0.9477...   \n",
              "3      0.9958561658859253, 0.981575608253479, 0.97992...   \n",
              "4      0.9993002414703369, 0.9640201926231384, 0.9513...   \n",
              "...                                                  ...   \n",
              "88511  0.9999812841415405, 0.9580191373825073, 0.9157...   \n",
              "88512  0.9999863505363464, 0.9184243679046631, 0.9104...   \n",
              "88513  0.9997624158859253, 0.9444339871406555, 0.8540...   \n",
              "88514  0.9959811568260193, 0.9808116555213928, 0.9714...   \n",
              "88515  0.974940299987793, 0.9452543258666992, 0.94509...   \n",
              "\n",
              "                                            accent_color  is_bw  \\\n",
              "0      0.788235294117647, 0.00784313725490196, 0.0078...      0   \n",
              "1      0.6901960784313725, 0.14901960784313725, 0.105...      0   \n",
              "2      0.6588235294117647, 0.4392156862745098, 0.1411...      0   \n",
              "3      0.24313725490196078, 0.12549019607843137, 0.07...      0   \n",
              "4      0.792156862745098, 0.7372549019607844, 0.00392...      0   \n",
              "...                                                  ...    ...   \n",
              "88511  0.6588235294117647, 0.00784313725490196, 0.713...      0   \n",
              "88512  0.01568627450980392, 0.5098039215686274, 0.780...      0   \n",
              "88513  0.01568627450980392, 0.2235294117647059, 0.439...      0   \n",
              "88514  0.6862745098039216, 0.5215686274509804, 0.1098...      0   \n",
              "88515  0.6705882352941176, 0.27058823529411763, 0.125...      0   \n",
              "\n",
              "                                         dominant_colors  \\\n",
              "0             1.0, 0.7529411764705882, 0.796078431372549   \n",
              "1      0.6470588235294118, 0.16470588235294117, 0.164...   \n",
              "2      0.6470588235294118, 0.16470588235294117, 0.164...   \n",
              "3      0.6470588235294118, 0.16470588235294117, 0.164...   \n",
              "4                                          1.0, 1.0, 0.0   \n",
              "...                                                  ...   \n",
              "88511  0.5019607843137255, 0.0, 0.5019607843137255 , ...   \n",
              "88512                                      1.0, 1.0, 1.0   \n",
              "88513                     1.0, 1.0, 0.0 ,  0.0, 0.0, 1.0   \n",
              "88514                                      1.0, 1.0, 1.0   \n",
              "88515  1.0, 0.7529411764705882, 0.796078431372549 ,  ...   \n",
              "\n",
              "                                                bg_color  \\\n",
              "0             1.0, 0.7529411764705882, 0.796078431372549   \n",
              "1      0.6470588235294118, 0.16470588235294117, 0.164...   \n",
              "2      0.6470588235294118, 0.16470588235294117, 0.164...   \n",
              "3      0.6470588235294118, 0.16470588235294117, 0.164...   \n",
              "4                                          1.0, 1.0, 0.0   \n",
              "...                                                  ...   \n",
              "88511        0.5019607843137255, 0.0, 0.5019607843137255   \n",
              "88512                                      1.0, 1.0, 1.0   \n",
              "88513                                      0.0, 0.0, 1.0   \n",
              "88514                                      1.0, 1.0, 1.0   \n",
              "88515                                      1.0, 1.0, 1.0   \n",
              "\n",
              "                                              fore_color  \n",
              "0             1.0, 0.7529411764705882, 0.796078431372549  \n",
              "1                                          0.0, 0.0, 0.0  \n",
              "2      0.6470588235294118, 0.16470588235294117, 0.164...  \n",
              "3      0.6470588235294118, 0.16470588235294117, 0.164...  \n",
              "4                                          1.0, 1.0, 0.0  \n",
              "...                                                  ...  \n",
              "88511  0.5019607843137255, 0.5019607843137255, 0.5019...  \n",
              "88512                                      1.0, 1.0, 1.0  \n",
              "88513                                      1.0, 1.0, 0.0  \n",
              "88514                                      1.0, 1.0, 1.0  \n",
              "88515         1.0, 0.7529411764705882, 0.796078431372549  \n",
              "\n",
              "[88516 rows x 8 columns]"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "Kalj66ZKYH5y"
      },
      "outputs": [],
      "source": [
        "# for i in df1['confidence_score']:\n",
        "\n",
        "def convert_str2int(i):\n",
        "  n = []\n",
        "  y = i.split(', ')\n",
        "  if len(y[0]) == 0:\n",
        "    return []\n",
        "  for j in range(len(y)):\n",
        "    n.append(float(y[j]))\n",
        "  return n\n",
        "\n",
        "df1['confidence_score'] = df1['confidence_score'].apply(convert_str2int)\n",
        "df1['accent_color'] = df1['accent_color'].apply(convert_str2int)\n",
        "df1['dominant_colors'] = df1['dominant_colors'].apply(convert_str2int)\n",
        "df1['bg_color'] = df1['bg_color'].apply(convert_str2int)\n",
        "df1['fore_color'] = df1['fore_color'].apply(convert_str2int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "7XVPCQW59Aq0",
        "outputId": "5a5c9702-2b8e-4534-e321-54b681632129"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>likes</th>\n",
              "      <th>tags</th>\n",
              "      <th>confidence_score</th>\n",
              "      <th>accent_color</th>\n",
              "      <th>is_bw</th>\n",
              "      <th>dominant_colors</th>\n",
              "      <th>bg_color</th>\n",
              "      <th>fore_color</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>29.0</td>\n",
              "      <td>text ,  font ,  graphics ,  screenshot ,  grap...</td>\n",
              "      <td>[0.9980798959732056, 0.9481294751167297, 0.881...</td>\n",
              "      <td>[0.788235294117647, 0.00784313725490196, 0.007...</td>\n",
              "      <td>0</td>\n",
              "      <td>[1.0, 0.7529411764705882, 0.796078431372549]</td>\n",
              "      <td>[1.0, 0.7529411764705882, 0.796078431372549]</td>\n",
              "      <td>[1.0, 0.7529411764705882, 0.796078431372549]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>44.0</td>\n",
              "      <td>dessert ,  baked goods ,  baking ,  snack ,  f...</td>\n",
              "      <td>[0.9897554516792297, 0.987897515296936, 0.9828...</td>\n",
              "      <td>[0.6901960784313725, 0.14901960784313725, 0.10...</td>\n",
              "      <td>0</td>\n",
              "      <td>[0.6470588235294118, 0.16470588235294117, 0.16...</td>\n",
              "      <td>[0.6470588235294118, 0.16470588235294117, 0.16...</td>\n",
              "      <td>[0.0, 0.0, 0.0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>209.0</td>\n",
              "      <td>food ,  fruit ,  baked goods ,  breakfast ,  c...</td>\n",
              "      <td>[0.9808361530303955, 0.9546540379524231, 0.947...</td>\n",
              "      <td>[0.6588235294117647, 0.4392156862745098, 0.141...</td>\n",
              "      <td>0</td>\n",
              "      <td>[0.6470588235294118, 0.16470588235294117, 0.16...</td>\n",
              "      <td>[0.6470588235294118, 0.16470588235294117, 0.16...</td>\n",
              "      <td>[0.6470588235294118, 0.16470588235294117, 0.16...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>95.0</td>\n",
              "      <td>food ,  bread ,  fast food ,  bun ,  american ...</td>\n",
              "      <td>[0.9958561658859253, 0.981575608253479, 0.9799...</td>\n",
              "      <td>[0.24313725490196078, 0.12549019607843137, 0.0...</td>\n",
              "      <td>0</td>\n",
              "      <td>[0.6470588235294118, 0.16470588235294117, 0.16...</td>\n",
              "      <td>[0.6470588235294118, 0.16470588235294117, 0.16...</td>\n",
              "      <td>[0.6470588235294118, 0.16470588235294117, 0.16...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>101.0</td>\n",
              "      <td>text ,  font ,  design ,  yellow ,  graphics ,...</td>\n",
              "      <td>[0.9993002414703369, 0.9640201926231384, 0.951...</td>\n",
              "      <td>[0.792156862745098, 0.7372549019607844, 0.0039...</td>\n",
              "      <td>0</td>\n",
              "      <td>[1.0, 1.0, 0.0]</td>\n",
              "      <td>[1.0, 1.0, 0.0]</td>\n",
              "      <td>[1.0, 1.0, 0.0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88511</th>\n",
              "      <td>8.0</td>\n",
              "      <td>text ,  food ,  snack</td>\n",
              "      <td>[0.9999812841415405, 0.9580191373825073, 0.915...</td>\n",
              "      <td>[0.6588235294117647, 0.00784313725490196, 0.71...</td>\n",
              "      <td>0</td>\n",
              "      <td>[0.5019607843137255, 0.0, 0.5019607843137255, ...</td>\n",
              "      <td>[0.5019607843137255, 0.0, 0.5019607843137255]</td>\n",
              "      <td>[0.5019607843137255, 0.5019607843137255, 0.501...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88512</th>\n",
              "      <td>9.0</td>\n",
              "      <td>text ,  poster ,  cartoon</td>\n",
              "      <td>[0.9999863505363464, 0.9184243679046631, 0.910...</td>\n",
              "      <td>[0.01568627450980392, 0.5098039215686274, 0.78...</td>\n",
              "      <td>0</td>\n",
              "      <td>[1.0, 1.0, 1.0]</td>\n",
              "      <td>[1.0, 1.0, 1.0]</td>\n",
              "      <td>[1.0, 1.0, 1.0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88513</th>\n",
              "      <td>11.0</td>\n",
              "      <td>text ,  yellow ,  packaging and labeling ,  fo...</td>\n",
              "      <td>[0.9997624158859253, 0.9444339871406555, 0.854...</td>\n",
              "      <td>[0.01568627450980392, 0.2235294117647059, 0.43...</td>\n",
              "      <td>0</td>\n",
              "      <td>[1.0, 1.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
              "      <td>[0.0, 0.0, 1.0]</td>\n",
              "      <td>[1.0, 1.0, 0.0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88514</th>\n",
              "      <td>0.0</td>\n",
              "      <td>sport ,  person ,  barbell ,  physical fitness...</td>\n",
              "      <td>[0.9959811568260193, 0.9808116555213928, 0.971...</td>\n",
              "      <td>[0.6862745098039216, 0.5215686274509804, 0.109...</td>\n",
              "      <td>0</td>\n",
              "      <td>[1.0, 1.0, 1.0]</td>\n",
              "      <td>[1.0, 1.0, 1.0]</td>\n",
              "      <td>[1.0, 1.0, 1.0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88515</th>\n",
              "      <td>0.0</td>\n",
              "      <td>cosmetics ,  toiletry ,  eyelash ,  skin ,  pe...</td>\n",
              "      <td>[0.974940299987793, 0.9452543258666992, 0.9450...</td>\n",
              "      <td>[0.6705882352941176, 0.27058823529411763, 0.12...</td>\n",
              "      <td>0</td>\n",
              "      <td>[1.0, 0.7529411764705882, 0.796078431372549, 0...</td>\n",
              "      <td>[1.0, 1.0, 1.0]</td>\n",
              "      <td>[1.0, 0.7529411764705882, 0.796078431372549]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>88516 rows × 8 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       likes                                               tags  \\\n",
              "0       29.0  text ,  font ,  graphics ,  screenshot ,  grap...   \n",
              "1       44.0  dessert ,  baked goods ,  baking ,  snack ,  f...   \n",
              "2      209.0  food ,  fruit ,  baked goods ,  breakfast ,  c...   \n",
              "3       95.0  food ,  bread ,  fast food ,  bun ,  american ...   \n",
              "4      101.0  text ,  font ,  design ,  yellow ,  graphics ,...   \n",
              "...      ...                                                ...   \n",
              "88511    8.0                              text ,  food ,  snack   \n",
              "88512    9.0                          text ,  poster ,  cartoon   \n",
              "88513   11.0  text ,  yellow ,  packaging and labeling ,  fo...   \n",
              "88514    0.0  sport ,  person ,  barbell ,  physical fitness...   \n",
              "88515    0.0  cosmetics ,  toiletry ,  eyelash ,  skin ,  pe...   \n",
              "\n",
              "                                        confidence_score  \\\n",
              "0      [0.9980798959732056, 0.9481294751167297, 0.881...   \n",
              "1      [0.9897554516792297, 0.987897515296936, 0.9828...   \n",
              "2      [0.9808361530303955, 0.9546540379524231, 0.947...   \n",
              "3      [0.9958561658859253, 0.981575608253479, 0.9799...   \n",
              "4      [0.9993002414703369, 0.9640201926231384, 0.951...   \n",
              "...                                                  ...   \n",
              "88511  [0.9999812841415405, 0.9580191373825073, 0.915...   \n",
              "88512  [0.9999863505363464, 0.9184243679046631, 0.910...   \n",
              "88513  [0.9997624158859253, 0.9444339871406555, 0.854...   \n",
              "88514  [0.9959811568260193, 0.9808116555213928, 0.971...   \n",
              "88515  [0.974940299987793, 0.9452543258666992, 0.9450...   \n",
              "\n",
              "                                            accent_color  is_bw  \\\n",
              "0      [0.788235294117647, 0.00784313725490196, 0.007...      0   \n",
              "1      [0.6901960784313725, 0.14901960784313725, 0.10...      0   \n",
              "2      [0.6588235294117647, 0.4392156862745098, 0.141...      0   \n",
              "3      [0.24313725490196078, 0.12549019607843137, 0.0...      0   \n",
              "4      [0.792156862745098, 0.7372549019607844, 0.0039...      0   \n",
              "...                                                  ...    ...   \n",
              "88511  [0.6588235294117647, 0.00784313725490196, 0.71...      0   \n",
              "88512  [0.01568627450980392, 0.5098039215686274, 0.78...      0   \n",
              "88513  [0.01568627450980392, 0.2235294117647059, 0.43...      0   \n",
              "88514  [0.6862745098039216, 0.5215686274509804, 0.109...      0   \n",
              "88515  [0.6705882352941176, 0.27058823529411763, 0.12...      0   \n",
              "\n",
              "                                         dominant_colors  \\\n",
              "0           [1.0, 0.7529411764705882, 0.796078431372549]   \n",
              "1      [0.6470588235294118, 0.16470588235294117, 0.16...   \n",
              "2      [0.6470588235294118, 0.16470588235294117, 0.16...   \n",
              "3      [0.6470588235294118, 0.16470588235294117, 0.16...   \n",
              "4                                        [1.0, 1.0, 0.0]   \n",
              "...                                                  ...   \n",
              "88511  [0.5019607843137255, 0.0, 0.5019607843137255, ...   \n",
              "88512                                    [1.0, 1.0, 1.0]   \n",
              "88513                     [1.0, 1.0, 0.0, 0.0, 0.0, 1.0]   \n",
              "88514                                    [1.0, 1.0, 1.0]   \n",
              "88515  [1.0, 0.7529411764705882, 0.796078431372549, 0...   \n",
              "\n",
              "                                                bg_color  \\\n",
              "0           [1.0, 0.7529411764705882, 0.796078431372549]   \n",
              "1      [0.6470588235294118, 0.16470588235294117, 0.16...   \n",
              "2      [0.6470588235294118, 0.16470588235294117, 0.16...   \n",
              "3      [0.6470588235294118, 0.16470588235294117, 0.16...   \n",
              "4                                        [1.0, 1.0, 0.0]   \n",
              "...                                                  ...   \n",
              "88511      [0.5019607843137255, 0.0, 0.5019607843137255]   \n",
              "88512                                    [1.0, 1.0, 1.0]   \n",
              "88513                                    [0.0, 0.0, 1.0]   \n",
              "88514                                    [1.0, 1.0, 1.0]   \n",
              "88515                                    [1.0, 1.0, 1.0]   \n",
              "\n",
              "                                              fore_color  \n",
              "0           [1.0, 0.7529411764705882, 0.796078431372549]  \n",
              "1                                        [0.0, 0.0, 0.0]  \n",
              "2      [0.6470588235294118, 0.16470588235294117, 0.16...  \n",
              "3      [0.6470588235294118, 0.16470588235294117, 0.16...  \n",
              "4                                        [1.0, 1.0, 0.0]  \n",
              "...                                                  ...  \n",
              "88511  [0.5019607843137255, 0.5019607843137255, 0.501...  \n",
              "88512                                    [1.0, 1.0, 1.0]  \n",
              "88513                                    [1.0, 1.0, 0.0]  \n",
              "88514                                    [1.0, 1.0, 1.0]  \n",
              "88515       [1.0, 0.7529411764705882, 0.796078431372549]  \n",
              "\n",
              "[88516 rows x 8 columns]"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gqQtfQRFWnB8",
        "outputId": "840c4d95-04f8-4730-b3eb-175075fe2cff"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['text ',\n",
              " ' font ',\n",
              " ' graphics ',\n",
              " ' screenshot ',\n",
              " ' graphic design ',\n",
              " ' design ',\n",
              " ' typography']"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def convert_str2list(i):\n",
        "  n = []\n",
        "  y = i.split(', ')\n",
        "  for j in range(len(y)):\n",
        "    n.append(str(y[j]))\n",
        "  return n\n",
        "df1['tags'] = df['tags'].apply(convert_str2list)\n",
        "df1['tags'][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bi7yKyHlzX5l",
        "outputId": "119693c8-fa9d-4512-da3d-b9deed30b44d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[0.9938297271728516,\n",
              " 0.9784528613090515,\n",
              " 0.977806806564331,\n",
              " 0.966992974281311,\n",
              " 0.9616279602050781,\n",
              " 0.9515609741210938,\n",
              " 0.9280351400375366,\n",
              " 0.912075936794281,\n",
              " 0.9083282947540283,\n",
              " 0.9079588651657104,\n",
              " 0.8951475620269775,\n",
              " 0.8874362707138062,\n",
              " 0.8836393356323242,\n",
              " 0.8746436834335327,\n",
              " 0.8713182210922241,\n",
              " 0.8668385744094849,\n",
              " 0.8426526784896851,\n",
              " 0.786042332649231,\n",
              " 0.5681669116020203]"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df1['confidence_score'][6]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "_oMjJJjIepvW"
      },
      "outputs": [],
      "source": [
        "def trim_lowConfidence_tags(tag_column):\n",
        "  for scoreList in df1['confidence_score']:\n",
        "    for score_index in range(len(scoreList)):\n",
        "      if scoreList[score_index]<0.5:\n",
        "        return tag_column[:score_index]\n",
        "\n",
        "df1['tags'] = df1['tags'].apply(trim_lowConfidence_tags)  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "lkwMwfyezuCd"
      },
      "outputs": [],
      "source": [
        "df1.drop('confidence_score',1,inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 780
        },
        "id": "DbCwM3oXz3hO",
        "outputId": "83ad0176-66bf-44e0-efe5-0921473be0b9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[0.6470588235294118,\n",
              " 0.16470588235294117,\n",
              " 0.16470588235294117,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0]"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df1.dominant_colors[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qG2M7A_C32NR",
        "outputId": "5deb69b0-ae7b-4ba5-f896-c6b132e089ec"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0         [1.0, 0.7529411764705882, 0.796078431372549]\n",
              "1    [0.6470588235294118, 0.16470588235294117, 0.16...\n",
              "2    [0.6470588235294118, 0.16470588235294117, 0.16...\n",
              "Name: dominant_colors, dtype: object"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df1['dominant_colors'][:3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "D1XGUWcl0U1d"
      },
      "outputs": [],
      "source": [
        "def separate_column(column):\n",
        "  if len(column)>0:\n",
        "    return column[0]\n",
        "  else:\n",
        "    return []\n",
        "\n",
        "df1['dominant_colors_R'] = df1['dominant_colors'].apply(separate_column)  \n",
        "df1['accent_color_R'] = df1['accent_color'].apply(separate_column)  \n",
        "df1['bg_color_R'] = df1['bg_color'].apply(separate_column)  \n",
        "df1['fore_color_R'] = df1['fore_color'].apply(separate_column)  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "FYF1IoNz7nrz"
      },
      "outputs": [],
      "source": [
        "def separate_column(column):\n",
        "  if len(column)>0:\n",
        "    return column[1]\n",
        "  else:\n",
        "    return []\n",
        "\n",
        "df1['dominant_colors_G'] = df1['dominant_colors'].apply(separate_column)  \n",
        "df1['accent_color_G'] = df1['accent_color'].apply(separate_column)  \n",
        "df1['bg_color_G'] = df1['bg_color'].apply(separate_column)  \n",
        "df1['fore_color_G'] = df1['fore_color'].apply(separate_column)  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "2MTUJIJv79hm"
      },
      "outputs": [],
      "source": [
        "def separate_column(column):\n",
        "  if len(column)>0:\n",
        "    return column[2]\n",
        "  else:\n",
        "    return []\n",
        "\n",
        "df1['dominant_colors_B'] = df1['dominant_colors'].apply(separate_column)  \n",
        "df1['accent_color_B'] = df1['accent_color'].apply(separate_column)  \n",
        "df1['bg_color_B'] = df1['bg_color'].apply(separate_column)  \n",
        "df1['fore_color_B'] = df1['fore_color'].apply(separate_column)  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "HNULNiBeGB9i",
        "outputId": "b4d30239-0e17-495b-eb53-a6cbc265284c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>likes</th>\n",
              "      <th>tags</th>\n",
              "      <th>accent_color</th>\n",
              "      <th>is_bw</th>\n",
              "      <th>dominant_colors</th>\n",
              "      <th>bg_color</th>\n",
              "      <th>fore_color</th>\n",
              "      <th>dominant_colors_R</th>\n",
              "      <th>accent_color_R</th>\n",
              "      <th>bg_color_R</th>\n",
              "      <th>fore_color_R</th>\n",
              "      <th>dominant_colors_G</th>\n",
              "      <th>accent_color_G</th>\n",
              "      <th>bg_color_G</th>\n",
              "      <th>fore_color_G</th>\n",
              "      <th>dominant_colors_B</th>\n",
              "      <th>accent_color_B</th>\n",
              "      <th>bg_color_B</th>\n",
              "      <th>fore_color_B</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>29.0</td>\n",
              "      <td>[text ,  font ,  graphics ,  screenshot ,  gra...</td>\n",
              "      <td>[0.788235294117647, 0.00784313725490196, 0.007...</td>\n",
              "      <td>0</td>\n",
              "      <td>[1.0, 0.7529411764705882, 0.796078431372549]</td>\n",
              "      <td>[1.0, 0.7529411764705882, 0.796078431372549]</td>\n",
              "      <td>[1.0, 0.7529411764705882, 0.796078431372549]</td>\n",
              "      <td>1</td>\n",
              "      <td>0.788235</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.752941</td>\n",
              "      <td>0.007843</td>\n",
              "      <td>0.752941</td>\n",
              "      <td>0.752941</td>\n",
              "      <td>0.796078</td>\n",
              "      <td>0.007843</td>\n",
              "      <td>0.796078</td>\n",
              "      <td>0.796078</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>44.0</td>\n",
              "      <td>[dessert ,  baked goods ,  baking ,  snack ,  ...</td>\n",
              "      <td>[0.6901960784313725, 0.14901960784313725, 0.10...</td>\n",
              "      <td>0</td>\n",
              "      <td>[0.6470588235294118, 0.16470588235294117, 0.16...</td>\n",
              "      <td>[0.6470588235294118, 0.16470588235294117, 0.16...</td>\n",
              "      <td>[0.0, 0.0, 0.0]</td>\n",
              "      <td>0.647059</td>\n",
              "      <td>0.690196</td>\n",
              "      <td>0.647059</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.164706</td>\n",
              "      <td>0.149020</td>\n",
              "      <td>0.164706</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.164706</td>\n",
              "      <td>0.105882</td>\n",
              "      <td>0.164706</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>209.0</td>\n",
              "      <td>[food ,  fruit ,  baked goods ,  breakfast ,  ...</td>\n",
              "      <td>[0.6588235294117647, 0.4392156862745098, 0.141...</td>\n",
              "      <td>0</td>\n",
              "      <td>[0.6470588235294118, 0.16470588235294117, 0.16...</td>\n",
              "      <td>[0.6470588235294118, 0.16470588235294117, 0.16...</td>\n",
              "      <td>[0.6470588235294118, 0.16470588235294117, 0.16...</td>\n",
              "      <td>0.647059</td>\n",
              "      <td>0.658824</td>\n",
              "      <td>0.647059</td>\n",
              "      <td>0.647059</td>\n",
              "      <td>0.164706</td>\n",
              "      <td>0.439216</td>\n",
              "      <td>0.164706</td>\n",
              "      <td>0.164706</td>\n",
              "      <td>0.164706</td>\n",
              "      <td>0.141176</td>\n",
              "      <td>0.164706</td>\n",
              "      <td>0.164706</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>95.0</td>\n",
              "      <td>[food ,  bread ,  fast food ,  bun ,  american...</td>\n",
              "      <td>[0.24313725490196078, 0.12549019607843137, 0.0...</td>\n",
              "      <td>0</td>\n",
              "      <td>[0.6470588235294118, 0.16470588235294117, 0.16...</td>\n",
              "      <td>[0.6470588235294118, 0.16470588235294117, 0.16...</td>\n",
              "      <td>[0.6470588235294118, 0.16470588235294117, 0.16...</td>\n",
              "      <td>0.647059</td>\n",
              "      <td>0.243137</td>\n",
              "      <td>0.647059</td>\n",
              "      <td>0.647059</td>\n",
              "      <td>0.164706</td>\n",
              "      <td>0.125490</td>\n",
              "      <td>0.164706</td>\n",
              "      <td>0.164706</td>\n",
              "      <td>0.164706</td>\n",
              "      <td>0.070588</td>\n",
              "      <td>0.164706</td>\n",
              "      <td>0.164706</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>101.0</td>\n",
              "      <td>[text ,  font ,  design ,  yellow ,  graphics ...</td>\n",
              "      <td>[0.792156862745098, 0.7372549019607844, 0.0039...</td>\n",
              "      <td>0</td>\n",
              "      <td>[1.0, 1.0, 0.0]</td>\n",
              "      <td>[1.0, 1.0, 0.0]</td>\n",
              "      <td>[1.0, 1.0, 0.0]</td>\n",
              "      <td>1</td>\n",
              "      <td>0.792157</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>0.737255</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0.003922</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88511</th>\n",
              "      <td>8.0</td>\n",
              "      <td>[text ,  food ,  snack]</td>\n",
              "      <td>[0.6588235294117647, 0.00784313725490196, 0.71...</td>\n",
              "      <td>0</td>\n",
              "      <td>[0.5019607843137255, 0.0, 0.5019607843137255, ...</td>\n",
              "      <td>[0.5019607843137255, 0.0, 0.5019607843137255]</td>\n",
              "      <td>[0.5019607843137255, 0.5019607843137255, 0.501...</td>\n",
              "      <td>0.501961</td>\n",
              "      <td>0.658824</td>\n",
              "      <td>0.501961</td>\n",
              "      <td>0.501961</td>\n",
              "      <td>0</td>\n",
              "      <td>0.007843</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.501961</td>\n",
              "      <td>0.501961</td>\n",
              "      <td>0.713725</td>\n",
              "      <td>0.501961</td>\n",
              "      <td>0.501961</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88512</th>\n",
              "      <td>9.0</td>\n",
              "      <td>[text ,  poster ,  cartoon]</td>\n",
              "      <td>[0.01568627450980392, 0.5098039215686274, 0.78...</td>\n",
              "      <td>0</td>\n",
              "      <td>[1.0, 1.0, 1.0]</td>\n",
              "      <td>[1.0, 1.0, 1.0]</td>\n",
              "      <td>[1.0, 1.0, 1.0]</td>\n",
              "      <td>1</td>\n",
              "      <td>0.015686</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>0.509804</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>0.780392</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88513</th>\n",
              "      <td>11.0</td>\n",
              "      <td>[text ,  yellow ,  packaging and labeling ,  f...</td>\n",
              "      <td>[0.01568627450980392, 0.2235294117647059, 0.43...</td>\n",
              "      <td>0</td>\n",
              "      <td>[1.0, 1.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
              "      <td>[0.0, 0.0, 1.0]</td>\n",
              "      <td>[1.0, 1.0, 0.0]</td>\n",
              "      <td>1</td>\n",
              "      <td>0.015686</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>0.223529</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0.439216</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88514</th>\n",
              "      <td>0.0</td>\n",
              "      <td>[sport ,  person ,  barbell ,  physical fitnes...</td>\n",
              "      <td>[0.6862745098039216, 0.5215686274509804, 0.109...</td>\n",
              "      <td>0</td>\n",
              "      <td>[1.0, 1.0, 1.0]</td>\n",
              "      <td>[1.0, 1.0, 1.0]</td>\n",
              "      <td>[1.0, 1.0, 1.0]</td>\n",
              "      <td>1</td>\n",
              "      <td>0.686275</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>0.521569</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>0.109804</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88515</th>\n",
              "      <td>0.0</td>\n",
              "      <td>[cosmetics ,  toiletry ,  eyelash ,  skin ,  p...</td>\n",
              "      <td>[0.6705882352941176, 0.27058823529411763, 0.12...</td>\n",
              "      <td>0</td>\n",
              "      <td>[1.0, 0.7529411764705882, 0.796078431372549, 0...</td>\n",
              "      <td>[1.0, 1.0, 1.0]</td>\n",
              "      <td>[1.0, 0.7529411764705882, 0.796078431372549]</td>\n",
              "      <td>1</td>\n",
              "      <td>0.670588</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.752941</td>\n",
              "      <td>0.270588</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.752941</td>\n",
              "      <td>0.796078</td>\n",
              "      <td>0.125490</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.796078</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>88516 rows × 19 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       likes                                               tags  \\\n",
              "0       29.0  [text ,  font ,  graphics ,  screenshot ,  gra...   \n",
              "1       44.0  [dessert ,  baked goods ,  baking ,  snack ,  ...   \n",
              "2      209.0  [food ,  fruit ,  baked goods ,  breakfast ,  ...   \n",
              "3       95.0  [food ,  bread ,  fast food ,  bun ,  american...   \n",
              "4      101.0  [text ,  font ,  design ,  yellow ,  graphics ...   \n",
              "...      ...                                                ...   \n",
              "88511    8.0                            [text ,  food ,  snack]   \n",
              "88512    9.0                        [text ,  poster ,  cartoon]   \n",
              "88513   11.0  [text ,  yellow ,  packaging and labeling ,  f...   \n",
              "88514    0.0  [sport ,  person ,  barbell ,  physical fitnes...   \n",
              "88515    0.0  [cosmetics ,  toiletry ,  eyelash ,  skin ,  p...   \n",
              "\n",
              "                                            accent_color  is_bw  \\\n",
              "0      [0.788235294117647, 0.00784313725490196, 0.007...      0   \n",
              "1      [0.6901960784313725, 0.14901960784313725, 0.10...      0   \n",
              "2      [0.6588235294117647, 0.4392156862745098, 0.141...      0   \n",
              "3      [0.24313725490196078, 0.12549019607843137, 0.0...      0   \n",
              "4      [0.792156862745098, 0.7372549019607844, 0.0039...      0   \n",
              "...                                                  ...    ...   \n",
              "88511  [0.6588235294117647, 0.00784313725490196, 0.71...      0   \n",
              "88512  [0.01568627450980392, 0.5098039215686274, 0.78...      0   \n",
              "88513  [0.01568627450980392, 0.2235294117647059, 0.43...      0   \n",
              "88514  [0.6862745098039216, 0.5215686274509804, 0.109...      0   \n",
              "88515  [0.6705882352941176, 0.27058823529411763, 0.12...      0   \n",
              "\n",
              "                                         dominant_colors  \\\n",
              "0           [1.0, 0.7529411764705882, 0.796078431372549]   \n",
              "1      [0.6470588235294118, 0.16470588235294117, 0.16...   \n",
              "2      [0.6470588235294118, 0.16470588235294117, 0.16...   \n",
              "3      [0.6470588235294118, 0.16470588235294117, 0.16...   \n",
              "4                                        [1.0, 1.0, 0.0]   \n",
              "...                                                  ...   \n",
              "88511  [0.5019607843137255, 0.0, 0.5019607843137255, ...   \n",
              "88512                                    [1.0, 1.0, 1.0]   \n",
              "88513                     [1.0, 1.0, 0.0, 0.0, 0.0, 1.0]   \n",
              "88514                                    [1.0, 1.0, 1.0]   \n",
              "88515  [1.0, 0.7529411764705882, 0.796078431372549, 0...   \n",
              "\n",
              "                                                bg_color  \\\n",
              "0           [1.0, 0.7529411764705882, 0.796078431372549]   \n",
              "1      [0.6470588235294118, 0.16470588235294117, 0.16...   \n",
              "2      [0.6470588235294118, 0.16470588235294117, 0.16...   \n",
              "3      [0.6470588235294118, 0.16470588235294117, 0.16...   \n",
              "4                                        [1.0, 1.0, 0.0]   \n",
              "...                                                  ...   \n",
              "88511      [0.5019607843137255, 0.0, 0.5019607843137255]   \n",
              "88512                                    [1.0, 1.0, 1.0]   \n",
              "88513                                    [0.0, 0.0, 1.0]   \n",
              "88514                                    [1.0, 1.0, 1.0]   \n",
              "88515                                    [1.0, 1.0, 1.0]   \n",
              "\n",
              "                                              fore_color dominant_colors_R  \\\n",
              "0           [1.0, 0.7529411764705882, 0.796078431372549]                 1   \n",
              "1                                        [0.0, 0.0, 0.0]          0.647059   \n",
              "2      [0.6470588235294118, 0.16470588235294117, 0.16...          0.647059   \n",
              "3      [0.6470588235294118, 0.16470588235294117, 0.16...          0.647059   \n",
              "4                                        [1.0, 1.0, 0.0]                 1   \n",
              "...                                                  ...               ...   \n",
              "88511  [0.5019607843137255, 0.5019607843137255, 0.501...          0.501961   \n",
              "88512                                    [1.0, 1.0, 1.0]                 1   \n",
              "88513                                    [1.0, 1.0, 0.0]                 1   \n",
              "88514                                    [1.0, 1.0, 1.0]                 1   \n",
              "88515       [1.0, 0.7529411764705882, 0.796078431372549]                 1   \n",
              "\n",
              "       accent_color_R  bg_color_R  fore_color_R dominant_colors_G  \\\n",
              "0            0.788235    1.000000      1.000000          0.752941   \n",
              "1            0.690196    0.647059      0.000000          0.164706   \n",
              "2            0.658824    0.647059      0.647059          0.164706   \n",
              "3            0.243137    0.647059      0.647059          0.164706   \n",
              "4            0.792157    1.000000      1.000000                 1   \n",
              "...               ...         ...           ...               ...   \n",
              "88511        0.658824    0.501961      0.501961                 0   \n",
              "88512        0.015686    1.000000      1.000000                 1   \n",
              "88513        0.015686    0.000000      1.000000                 1   \n",
              "88514        0.686275    1.000000      1.000000                 1   \n",
              "88515        0.670588    1.000000      1.000000          0.752941   \n",
              "\n",
              "       accent_color_G  bg_color_G  fore_color_G dominant_colors_B  \\\n",
              "0            0.007843    0.752941      0.752941          0.796078   \n",
              "1            0.149020    0.164706      0.000000          0.164706   \n",
              "2            0.439216    0.164706      0.164706          0.164706   \n",
              "3            0.125490    0.164706      0.164706          0.164706   \n",
              "4            0.737255    1.000000      1.000000                 0   \n",
              "...               ...         ...           ...               ...   \n",
              "88511        0.007843    0.000000      0.501961          0.501961   \n",
              "88512        0.509804    1.000000      1.000000                 1   \n",
              "88513        0.223529    0.000000      1.000000                 0   \n",
              "88514        0.521569    1.000000      1.000000                 1   \n",
              "88515        0.270588    1.000000      0.752941          0.796078   \n",
              "\n",
              "       accent_color_B  bg_color_B  fore_color_B  \n",
              "0            0.007843    0.796078      0.796078  \n",
              "1            0.105882    0.164706      0.000000  \n",
              "2            0.141176    0.164706      0.164706  \n",
              "3            0.070588    0.164706      0.164706  \n",
              "4            0.003922    0.000000      0.000000  \n",
              "...               ...         ...           ...  \n",
              "88511        0.713725    0.501961      0.501961  \n",
              "88512        0.780392    1.000000      1.000000  \n",
              "88513        0.439216    1.000000      0.000000  \n",
              "88514        0.109804    1.000000      1.000000  \n",
              "88515        0.125490    1.000000      0.796078  \n",
              "\n",
              "[88516 rows x 19 columns]"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "DOfR-uGM6z81"
      },
      "outputs": [],
      "source": [
        "dropped = ['accent_color', 'dominant_colors', 'bg_color','fore_color']\n",
        "data = df1.drop(dropped,axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>204</th>\n",
              "      <th>205</th>\n",
              "      <th>206</th>\n",
              "      <th>207</th>\n",
              "      <th>208</th>\n",
              "      <th>209</th>\n",
              "      <th>210</th>\n",
              "      <th>211</th>\n",
              "      <th>212</th>\n",
              "      <th>213</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.11669320256138842</td>\n",
              "      <td>-0.02748321322724223</td>\n",
              "      <td>-0.18671171832829714</td>\n",
              "      <td>0.13605108934765062</td>\n",
              "      <td>0.041623774236844234</td>\n",
              "      <td>-0.04426240587296585</td>\n",
              "      <td>-0.16804125905036926</td>\n",
              "      <td>0.0029527731239795685</td>\n",
              "      <td>-0.1443632487207651</td>\n",
              "      <td>-0.1326462415357431</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.7529411764705882</td>\n",
              "      <td>0.00784313725490196</td>\n",
              "      <td>0.7529411764705882</td>\n",
              "      <td>0.7529411764705882</td>\n",
              "      <td>0.796078431372549</td>\n",
              "      <td>0.00784313725490196</td>\n",
              "      <td>0.796078431372549</td>\n",
              "      <td>0.796078431372549</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.05400834072913442</td>\n",
              "      <td>0.09934965574315616</td>\n",
              "      <td>-0.2152196911296674</td>\n",
              "      <td>0.02954484788434846</td>\n",
              "      <td>0.06073764116237206</td>\n",
              "      <td>0.14323928326900517</td>\n",
              "      <td>-0.12100933319223779</td>\n",
              "      <td>-0.18622600233980588</td>\n",
              "      <td>-0.13140801593960663</td>\n",
              "      <td>0.15921796445867845</td>\n",
              "      <td>...</td>\n",
              "      <td>0.6470588235294118</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.16470588235294117</td>\n",
              "      <td>0.14901960784313725</td>\n",
              "      <td>0.16470588235294117</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.16470588235294117</td>\n",
              "      <td>0.10588235294117647</td>\n",
              "      <td>0.16470588235294117</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.02925444227692328</td>\n",
              "      <td>0.19349391189844986</td>\n",
              "      <td>-0.20249813701957464</td>\n",
              "      <td>-0.1028827052367361</td>\n",
              "      <td>-0.059571249116408195</td>\n",
              "      <td>0.04836817360238025</td>\n",
              "      <td>-0.08720943400342214</td>\n",
              "      <td>-0.18481898856790444</td>\n",
              "      <td>-0.13208241447022087</td>\n",
              "      <td>0.19195087803037544</td>\n",
              "      <td>...</td>\n",
              "      <td>0.6470588235294118</td>\n",
              "      <td>0.6470588235294118</td>\n",
              "      <td>0.16470588235294117</td>\n",
              "      <td>0.4392156862745098</td>\n",
              "      <td>0.16470588235294117</td>\n",
              "      <td>0.16470588235294117</td>\n",
              "      <td>0.16470588235294117</td>\n",
              "      <td>0.1411764705882353</td>\n",
              "      <td>0.16470588235294117</td>\n",
              "      <td>0.16470588235294117</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.07980210549301571</td>\n",
              "      <td>0.20305788061685032</td>\n",
              "      <td>-0.16652481506268182</td>\n",
              "      <td>-0.0060051475134160785</td>\n",
              "      <td>-0.1397709906101227</td>\n",
              "      <td>0.03020856488082144</td>\n",
              "      <td>-0.00533743587632974</td>\n",
              "      <td>-0.11638561534022705</td>\n",
              "      <td>-0.14578692979800204</td>\n",
              "      <td>0.1541647789378961</td>\n",
              "      <td>...</td>\n",
              "      <td>0.6470588235294118</td>\n",
              "      <td>0.6470588235294118</td>\n",
              "      <td>0.16470588235294117</td>\n",
              "      <td>0.12549019607843137</td>\n",
              "      <td>0.16470588235294117</td>\n",
              "      <td>0.16470588235294117</td>\n",
              "      <td>0.16470588235294117</td>\n",
              "      <td>0.07058823529411765</td>\n",
              "      <td>0.16470588235294117</td>\n",
              "      <td>0.16470588235294117</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.09868416807148606</td>\n",
              "      <td>-0.0001471476862207055</td>\n",
              "      <td>-0.209817468887195</td>\n",
              "      <td>0.15010760573204607</td>\n",
              "      <td>0.03032800830260385</td>\n",
              "      <td>-0.059315741586033255</td>\n",
              "      <td>-0.12231099046766758</td>\n",
              "      <td>0.007357252994552255</td>\n",
              "      <td>-0.17132411850616336</td>\n",
              "      <td>-0.09631121065467596</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.7372549019607844</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00392156862745098</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88511</th>\n",
              "      <td>0.10904438731571038</td>\n",
              "      <td>0.23766749103864035</td>\n",
              "      <td>-0.22817798455556235</td>\n",
              "      <td>0.09054082135359447</td>\n",
              "      <td>0.06305411458015442</td>\n",
              "      <td>0.04986237486203512</td>\n",
              "      <td>-0.15475784987211227</td>\n",
              "      <td>-0.12897060811519623</td>\n",
              "      <td>-0.13423940539360046</td>\n",
              "      <td>0.1439950962861379</td>\n",
              "      <td>...</td>\n",
              "      <td>0.5019607843137255</td>\n",
              "      <td>0.5019607843137255</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00784313725490196</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.5019607843137255</td>\n",
              "      <td>0.5019607843137255</td>\n",
              "      <td>0.7137254901960784</td>\n",
              "      <td>0.5019607843137255</td>\n",
              "      <td>0.5019607843137255</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88512</th>\n",
              "      <td>0.13867605229218802</td>\n",
              "      <td>-0.0037125994761784873</td>\n",
              "      <td>-0.2738087773323059</td>\n",
              "      <td>0.17919704814751944</td>\n",
              "      <td>0.06553142269452412</td>\n",
              "      <td>0.055552112559477486</td>\n",
              "      <td>-0.13970170666774115</td>\n",
              "      <td>0.012120584646860758</td>\n",
              "      <td>-0.0706338385740916</td>\n",
              "      <td>-0.17047056555747986</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.5098039215686274</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.7803921568627451</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88513</th>\n",
              "      <td>-0.12987129162583086</td>\n",
              "      <td>0.1158151196108924</td>\n",
              "      <td>-0.3315940300623576</td>\n",
              "      <td>-0.07978270658188397</td>\n",
              "      <td>0.13186225212282604</td>\n",
              "      <td>-0.06317237267891566</td>\n",
              "      <td>-0.13333137623137897</td>\n",
              "      <td>-0.025478681549429893</td>\n",
              "      <td>-0.23176068564256033</td>\n",
              "      <td>0.033702126807636686</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.2235294117647059</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.4392156862745098</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88514</th>\n",
              "      <td>0.11238148869438605</td>\n",
              "      <td>-0.11996569819748401</td>\n",
              "      <td>-0.1949817560951818</td>\n",
              "      <td>0.07207865224812518</td>\n",
              "      <td>0.01519832055677067</td>\n",
              "      <td>-0.0688453597439961</td>\n",
              "      <td>0.021324452046643603</td>\n",
              "      <td>-0.1681436273862015</td>\n",
              "      <td>-0.1679826631803404</td>\n",
              "      <td>-0.025150730046020312</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.5215686274509804</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.10980392156862745</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88515</th>\n",
              "      <td>-0.10381378567424314</td>\n",
              "      <td>0.029001310596178317</td>\n",
              "      <td>-0.09941506331208451</td>\n",
              "      <td>-0.06024009092100736</td>\n",
              "      <td>-0.02461500099763788</td>\n",
              "      <td>0.047251107331750725</td>\n",
              "      <td>-0.04436174658095014</td>\n",
              "      <td>-0.07977554298423488</td>\n",
              "      <td>-0.11874080102505355</td>\n",
              "      <td>-0.06739141946208888</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.7529411764705882</td>\n",
              "      <td>0.27058823529411763</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.7529411764705882</td>\n",
              "      <td>0.796078431372549</td>\n",
              "      <td>0.12549019607843137</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.796078431372549</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>88516 rows × 214 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                        0                       1                     2    \\\n",
              "0       0.11669320256138842    -0.02748321322724223  -0.18671171832829714   \n",
              "1       0.05400834072913442     0.09934965574315616   -0.2152196911296674   \n",
              "2       0.02925444227692328     0.19349391189844986  -0.20249813701957464   \n",
              "3      -0.07980210549301571     0.20305788061685032  -0.16652481506268182   \n",
              "4       0.09868416807148606  -0.0001471476862207055    -0.209817468887195   \n",
              "...                     ...                     ...                   ...   \n",
              "88511   0.10904438731571038     0.23766749103864035  -0.22817798455556235   \n",
              "88512   0.13867605229218802  -0.0037125994761784873   -0.2738087773323059   \n",
              "88513  -0.12987129162583086      0.1158151196108924   -0.3315940300623576   \n",
              "88514   0.11238148869438605    -0.11996569819748401   -0.1949817560951818   \n",
              "88515  -0.10381378567424314    0.029001310596178317  -0.09941506331208451   \n",
              "\n",
              "                          3                      4                      5    \\\n",
              "0         0.13605108934765062   0.041623774236844234   -0.04426240587296585   \n",
              "1         0.02954484788434846    0.06073764116237206    0.14323928326900517   \n",
              "2         -0.1028827052367361  -0.059571249116408195    0.04836817360238025   \n",
              "3      -0.0060051475134160785    -0.1397709906101227    0.03020856488082144   \n",
              "4         0.15010760573204607    0.03032800830260385  -0.059315741586033255   \n",
              "...                       ...                    ...                    ...   \n",
              "88511     0.09054082135359447    0.06305411458015442    0.04986237486203512   \n",
              "88512     0.17919704814751944    0.06553142269452412   0.055552112559477486   \n",
              "88513    -0.07978270658188397    0.13186225212282604   -0.06317237267891566   \n",
              "88514     0.07207865224812518    0.01519832055677067    -0.0688453597439961   \n",
              "88515    -0.06024009092100736   -0.02461500099763788   0.047251107331750725   \n",
              "\n",
              "                        6                      7                     8    \\\n",
              "0      -0.16804125905036926  0.0029527731239795685   -0.1443632487207651   \n",
              "1      -0.12100933319223779   -0.18622600233980588  -0.13140801593960663   \n",
              "2      -0.08720943400342214   -0.18481898856790444  -0.13208241447022087   \n",
              "3      -0.00533743587632974   -0.11638561534022705  -0.14578692979800204   \n",
              "4      -0.12231099046766758   0.007357252994552255  -0.17132411850616336   \n",
              "...                     ...                    ...                   ...   \n",
              "88511  -0.15475784987211227   -0.12897060811519623  -0.13423940539360046   \n",
              "88512  -0.13970170666774115   0.012120584646860758   -0.0706338385740916   \n",
              "88513  -0.13333137623137897  -0.025478681549429893  -0.23176068564256033   \n",
              "88514  0.021324452046643603    -0.1681436273862015   -0.1679826631803404   \n",
              "88515  -0.04436174658095014   -0.07977554298423488  -0.11874080102505355   \n",
              "\n",
              "                         9    ...                 204                 205  \\\n",
              "0        -0.1326462415357431  ...                 1.0                 1.0   \n",
              "1        0.15921796445867845  ...  0.6470588235294118                 0.0   \n",
              "2        0.19195087803037544  ...  0.6470588235294118  0.6470588235294118   \n",
              "3         0.1541647789378961  ...  0.6470588235294118  0.6470588235294118   \n",
              "4       -0.09631121065467596  ...                 1.0                 1.0   \n",
              "...                      ...  ...                 ...                 ...   \n",
              "88511     0.1439950962861379  ...  0.5019607843137255  0.5019607843137255   \n",
              "88512   -0.17047056555747986  ...                 1.0                 1.0   \n",
              "88513   0.033702126807636686  ...                 0.0                 1.0   \n",
              "88514  -0.025150730046020312  ...                 1.0                 1.0   \n",
              "88515   -0.06739141946208888  ...                 1.0                 1.0   \n",
              "\n",
              "                       206                  207                  208  \\\n",
              "0       0.7529411764705882  0.00784313725490196   0.7529411764705882   \n",
              "1      0.16470588235294117  0.14901960784313725  0.16470588235294117   \n",
              "2      0.16470588235294117   0.4392156862745098  0.16470588235294117   \n",
              "3      0.16470588235294117  0.12549019607843137  0.16470588235294117   \n",
              "4                      1.0   0.7372549019607844                  1.0   \n",
              "...                    ...                  ...                  ...   \n",
              "88511                  0.0  0.00784313725490196                  0.0   \n",
              "88512                  1.0   0.5098039215686274                  1.0   \n",
              "88513                  1.0   0.2235294117647059                  0.0   \n",
              "88514                  1.0   0.5215686274509804                  1.0   \n",
              "88515   0.7529411764705882  0.27058823529411763                  1.0   \n",
              "\n",
              "                       209                  210                  211  \\\n",
              "0       0.7529411764705882    0.796078431372549  0.00784313725490196   \n",
              "1                      0.0  0.16470588235294117  0.10588235294117647   \n",
              "2      0.16470588235294117  0.16470588235294117   0.1411764705882353   \n",
              "3      0.16470588235294117  0.16470588235294117  0.07058823529411765   \n",
              "4                      1.0                  0.0  0.00392156862745098   \n",
              "...                    ...                  ...                  ...   \n",
              "88511   0.5019607843137255   0.5019607843137255   0.7137254901960784   \n",
              "88512                  1.0                  1.0   0.7803921568627451   \n",
              "88513                  1.0                  0.0   0.4392156862745098   \n",
              "88514                  1.0                  1.0  0.10980392156862745   \n",
              "88515   0.7529411764705882    0.796078431372549  0.12549019607843137   \n",
              "\n",
              "                       212                  213  \n",
              "0        0.796078431372549    0.796078431372549  \n",
              "1      0.16470588235294117                  0.0  \n",
              "2      0.16470588235294117  0.16470588235294117  \n",
              "3      0.16470588235294117  0.16470588235294117  \n",
              "4                      0.0                  0.0  \n",
              "...                    ...                  ...  \n",
              "88511   0.5019607843137255   0.5019607843137255  \n",
              "88512                  1.0                  1.0  \n",
              "88513                  1.0                  0.0  \n",
              "88514                  1.0                  1.0  \n",
              "88515                  1.0    0.796078431372549  \n",
              "\n",
              "[88516 rows x 214 columns]"
            ]
          },
          "execution_count": 66,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "I_0uQ3vCGdvj",
        "outputId": "533752f9-36d3-47dd-f535-2f995bfe08ef"
      },
      "outputs": [],
      "source": [
        "d2=data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>likes</th>\n",
              "      <th>tags</th>\n",
              "      <th>is_bw</th>\n",
              "      <th>dominant_colors_R</th>\n",
              "      <th>accent_color_R</th>\n",
              "      <th>bg_color_R</th>\n",
              "      <th>fore_color_R</th>\n",
              "      <th>dominant_colors_G</th>\n",
              "      <th>accent_color_G</th>\n",
              "      <th>bg_color_G</th>\n",
              "      <th>fore_color_G</th>\n",
              "      <th>dominant_colors_B</th>\n",
              "      <th>accent_color_B</th>\n",
              "      <th>bg_color_B</th>\n",
              "      <th>fore_color_B</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>29.0</td>\n",
              "      <td>[text ,  font ,  graphics ,  screenshot ,  gra...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.788235</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.752941</td>\n",
              "      <td>0.007843</td>\n",
              "      <td>0.752941</td>\n",
              "      <td>0.752941</td>\n",
              "      <td>0.796078</td>\n",
              "      <td>0.007843</td>\n",
              "      <td>0.796078</td>\n",
              "      <td>0.796078</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>44.0</td>\n",
              "      <td>[dessert ,  baked goods ,  baking ,  snack ,  ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0.647059</td>\n",
              "      <td>0.690196</td>\n",
              "      <td>0.647059</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.164706</td>\n",
              "      <td>0.149020</td>\n",
              "      <td>0.164706</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.164706</td>\n",
              "      <td>0.105882</td>\n",
              "      <td>0.164706</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>209.0</td>\n",
              "      <td>[food ,  fruit ,  baked goods ,  breakfast ,  ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0.647059</td>\n",
              "      <td>0.658824</td>\n",
              "      <td>0.647059</td>\n",
              "      <td>0.647059</td>\n",
              "      <td>0.164706</td>\n",
              "      <td>0.439216</td>\n",
              "      <td>0.164706</td>\n",
              "      <td>0.164706</td>\n",
              "      <td>0.164706</td>\n",
              "      <td>0.141176</td>\n",
              "      <td>0.164706</td>\n",
              "      <td>0.164706</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>95.0</td>\n",
              "      <td>[food ,  bread ,  fast food ,  bun ,  american...</td>\n",
              "      <td>0</td>\n",
              "      <td>0.647059</td>\n",
              "      <td>0.243137</td>\n",
              "      <td>0.647059</td>\n",
              "      <td>0.647059</td>\n",
              "      <td>0.164706</td>\n",
              "      <td>0.125490</td>\n",
              "      <td>0.164706</td>\n",
              "      <td>0.164706</td>\n",
              "      <td>0.164706</td>\n",
              "      <td>0.070588</td>\n",
              "      <td>0.164706</td>\n",
              "      <td>0.164706</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>101.0</td>\n",
              "      <td>[text ,  font ,  design ,  yellow ,  graphics ...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.792157</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>0.737255</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0.003922</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88511</th>\n",
              "      <td>8.0</td>\n",
              "      <td>[text ,  food ,  snack]</td>\n",
              "      <td>0</td>\n",
              "      <td>0.501961</td>\n",
              "      <td>0.658824</td>\n",
              "      <td>0.501961</td>\n",
              "      <td>0.501961</td>\n",
              "      <td>0</td>\n",
              "      <td>0.007843</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.501961</td>\n",
              "      <td>0.501961</td>\n",
              "      <td>0.713725</td>\n",
              "      <td>0.501961</td>\n",
              "      <td>0.501961</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88512</th>\n",
              "      <td>9.0</td>\n",
              "      <td>[text ,  poster ,  cartoon]</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.015686</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>0.509804</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>0.780392</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88513</th>\n",
              "      <td>11.0</td>\n",
              "      <td>[text ,  yellow ,  packaging and labeling ,  f...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.015686</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>0.223529</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0.439216</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88514</th>\n",
              "      <td>0.0</td>\n",
              "      <td>[sport ,  person ,  barbell ,  physical fitnes...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.686275</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>0.521569</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>0.109804</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88515</th>\n",
              "      <td>0.0</td>\n",
              "      <td>[cosmetics ,  toiletry ,  eyelash ,  skin ,  p...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.670588</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.752941</td>\n",
              "      <td>0.270588</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.752941</td>\n",
              "      <td>0.796078</td>\n",
              "      <td>0.125490</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.796078</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>88516 rows × 15 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       likes                                               tags  is_bw  \\\n",
              "0       29.0  [text ,  font ,  graphics ,  screenshot ,  gra...      0   \n",
              "1       44.0  [dessert ,  baked goods ,  baking ,  snack ,  ...      0   \n",
              "2      209.0  [food ,  fruit ,  baked goods ,  breakfast ,  ...      0   \n",
              "3       95.0  [food ,  bread ,  fast food ,  bun ,  american...      0   \n",
              "4      101.0  [text ,  font ,  design ,  yellow ,  graphics ...      0   \n",
              "...      ...                                                ...    ...   \n",
              "88511    8.0                            [text ,  food ,  snack]      0   \n",
              "88512    9.0                        [text ,  poster ,  cartoon]      0   \n",
              "88513   11.0  [text ,  yellow ,  packaging and labeling ,  f...      0   \n",
              "88514    0.0  [sport ,  person ,  barbell ,  physical fitnes...      0   \n",
              "88515    0.0  [cosmetics ,  toiletry ,  eyelash ,  skin ,  p...      0   \n",
              "\n",
              "      dominant_colors_R  accent_color_R  bg_color_R  fore_color_R  \\\n",
              "0                     1        0.788235    1.000000      1.000000   \n",
              "1              0.647059        0.690196    0.647059      0.000000   \n",
              "2              0.647059        0.658824    0.647059      0.647059   \n",
              "3              0.647059        0.243137    0.647059      0.647059   \n",
              "4                     1        0.792157    1.000000      1.000000   \n",
              "...                 ...             ...         ...           ...   \n",
              "88511          0.501961        0.658824    0.501961      0.501961   \n",
              "88512                 1        0.015686    1.000000      1.000000   \n",
              "88513                 1        0.015686    0.000000      1.000000   \n",
              "88514                 1        0.686275    1.000000      1.000000   \n",
              "88515                 1        0.670588    1.000000      1.000000   \n",
              "\n",
              "      dominant_colors_G  accent_color_G  bg_color_G  fore_color_G  \\\n",
              "0              0.752941        0.007843    0.752941      0.752941   \n",
              "1              0.164706        0.149020    0.164706      0.000000   \n",
              "2              0.164706        0.439216    0.164706      0.164706   \n",
              "3              0.164706        0.125490    0.164706      0.164706   \n",
              "4                     1        0.737255    1.000000      1.000000   \n",
              "...                 ...             ...         ...           ...   \n",
              "88511                 0        0.007843    0.000000      0.501961   \n",
              "88512                 1        0.509804    1.000000      1.000000   \n",
              "88513                 1        0.223529    0.000000      1.000000   \n",
              "88514                 1        0.521569    1.000000      1.000000   \n",
              "88515          0.752941        0.270588    1.000000      0.752941   \n",
              "\n",
              "      dominant_colors_B  accent_color_B  bg_color_B  fore_color_B  \n",
              "0              0.796078        0.007843    0.796078      0.796078  \n",
              "1              0.164706        0.105882    0.164706      0.000000  \n",
              "2              0.164706        0.141176    0.164706      0.164706  \n",
              "3              0.164706        0.070588    0.164706      0.164706  \n",
              "4                     0        0.003922    0.000000      0.000000  \n",
              "...                 ...             ...         ...           ...  \n",
              "88511          0.501961        0.713725    0.501961      0.501961  \n",
              "88512                 1        0.780392    1.000000      1.000000  \n",
              "88513                 0        0.439216    1.000000      0.000000  \n",
              "88514                 1        0.109804    1.000000      1.000000  \n",
              "88515          0.796078        0.125490    1.000000      0.796078  \n",
              "\n",
              "[88516 rows x 15 columns]"
            ]
          },
          "execution_count": 68,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "d2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "data2=data.drop('tags',1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "data22=data2.astype('object')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "pandas.core.frame.DataFrame"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(data2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "likes                object\n",
              "is_bw                object\n",
              "dominant_colors_R    object\n",
              "accent_color_R       object\n",
              "bg_color_R           object\n",
              "fore_color_R         object\n",
              "dominant_colors_G    object\n",
              "accent_color_G       object\n",
              "bg_color_G           object\n",
              "fore_color_G         object\n",
              "dominant_colors_B    object\n",
              "accent_color_B       object\n",
              "bg_color_B           object\n",
              "fore_color_B         object\n",
              "dtype: object"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data22.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[',',\n",
              " 'baked',\n",
              " 'goods',\n",
              " ',',\n",
              " 'baking',\n",
              " ',',\n",
              " 'snack',\n",
              " ',',\n",
              " 'food',\n",
              " ',',\n",
              " 'sweetness',\n",
              " ',',\n",
              " 'finger',\n",
              " 'food',\n",
              " ',',\n",
              " 'bakery',\n",
              " ',',\n",
              " 'petit',\n",
              " 'four',\n",
              " ',',\n",
              " 'muffin',\n",
              " ',',\n",
              " 'indoor',\n",
              " ',',\n",
              " 'kue',\n",
              " ',']"
            ]
          },
          "execution_count": 71,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "d2['tags']=d2['tags'].apply(lambda txt: text_prepare(str(txt)[1:-1]))\n",
        "tokenized_tag = d2['tags'].apply(lambda x: x.split()[1:-1])\n",
        "tokenized_tag[1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C_vmSou7hgYK"
      },
      "source": [
        "##FastText"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hQnjzC68hjgE",
        "outputId": "6018e861-71b0-4524-bd8e-19fa4785dbb9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO - 18:07:22: collecting all words and their counts\n",
            "INFO - 18:07:22: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
            "INFO - 18:07:22: PROGRESS: at sentence #10000, processed 184916 words, keeping 2209 word types\n",
            "INFO - 18:07:22: PROGRESS: at sentence #20000, processed 375164 words, keeping 2671 word types\n",
            "INFO - 18:07:22: PROGRESS: at sentence #30000, processed 562939 words, keeping 2938 word types\n",
            "INFO - 18:07:22: PROGRESS: at sentence #40000, processed 754746 words, keeping 3128 word types\n",
            "INFO - 18:07:22: PROGRESS: at sentence #50000, processed 941580 words, keeping 3261 word types\n",
            "INFO - 18:07:22: PROGRESS: at sentence #60000, processed 1134158 words, keeping 3405 word types\n",
            "INFO - 18:07:22: PROGRESS: at sentence #70000, processed 1323170 words, keeping 3506 word types\n",
            "INFO - 18:07:22: PROGRESS: at sentence #80000, processed 1513335 words, keeping 3611 word types\n",
            "INFO - 18:07:23: collected 3667 word types from a corpus of 1673812 raw words and 88516 sentences\n",
            "INFO - 18:07:23: Loading a fresh vocabulary\n",
            "INFO - 18:07:23: min_count=2 retains 3100 unique words (84% of original 3667, drops 567)\n",
            "INFO - 18:07:23: min_count=2 leaves 1673245 word corpus (99% of original 1673812, drops 567)\n",
            "INFO - 18:07:23: deleting the raw counts dictionary of 3667 items\n",
            "INFO - 18:07:23: sample=0.001 downsamples 46 most-common words\n",
            "INFO - 18:07:23: downsampling leaves estimated 741138 word corpus (44.3% of prior 1673245)\n",
            "INFO - 18:07:24: estimated required memory for 3100 words, 31159 buckets and 200 dimensions: 32082480 bytes\n",
            "INFO - 18:07:24: resetting layer weights\n",
            "INFO - 18:07:28: Total number of ngrams is 31159\n",
            "INFO - 18:07:30: training model with 32 workers on 3100 vocabulary and 200 features, using sg=1 hs=0 sample=0.001 negative=10 window=2\n",
            "INFO - 18:07:32: EPOCH 1 - PROGRESS: at 3.04% examples, 10985 words/s, in_qsize 64, out_qsize 1\n",
            "INFO - 18:07:33: EPOCH 1 - PROGRESS: at 28.90% examples, 68469 words/s, in_qsize 59, out_qsize 4\n",
            "INFO - 18:07:35: EPOCH 1 - PROGRESS: at 53.30% examples, 94821 words/s, in_qsize 63, out_qsize 1\n",
            "INFO - 18:07:36: EPOCH 1 - PROGRESS: at 80.53% examples, 113785 words/s, in_qsize 32, out_qsize 1\n",
            "INFO - 18:07:36: worker thread finished; awaiting finish of 31 more threads\n",
            "INFO - 18:07:36: worker thread finished; awaiting finish of 30 more threads\n",
            "INFO - 18:07:36: worker thread finished; awaiting finish of 29 more threads\n",
            "INFO - 18:07:36: worker thread finished; awaiting finish of 28 more threads\n",
            "INFO - 18:07:36: worker thread finished; awaiting finish of 27 more threads\n",
            "INFO - 18:07:36: worker thread finished; awaiting finish of 26 more threads\n",
            "INFO - 18:07:36: worker thread finished; awaiting finish of 25 more threads\n",
            "INFO - 18:07:36: worker thread finished; awaiting finish of 24 more threads\n",
            "INFO - 18:07:36: worker thread finished; awaiting finish of 23 more threads\n",
            "INFO - 18:07:36: worker thread finished; awaiting finish of 22 more threads\n",
            "INFO - 18:07:36: worker thread finished; awaiting finish of 21 more threads\n",
            "INFO - 18:07:36: worker thread finished; awaiting finish of 20 more threads\n",
            "INFO - 18:07:36: worker thread finished; awaiting finish of 19 more threads\n",
            "INFO - 18:07:36: worker thread finished; awaiting finish of 18 more threads\n",
            "INFO - 18:07:36: worker thread finished; awaiting finish of 17 more threads\n",
            "INFO - 18:07:36: worker thread finished; awaiting finish of 16 more threads\n",
            "INFO - 18:07:36: worker thread finished; awaiting finish of 15 more threads\n",
            "INFO - 18:07:36: worker thread finished; awaiting finish of 14 more threads\n",
            "INFO - 18:07:36: worker thread finished; awaiting finish of 13 more threads\n",
            "INFO - 18:07:36: worker thread finished; awaiting finish of 12 more threads\n",
            "INFO - 18:07:36: worker thread finished; awaiting finish of 11 more threads\n",
            "INFO - 18:07:36: worker thread finished; awaiting finish of 10 more threads\n",
            "INFO - 18:07:36: worker thread finished; awaiting finish of 9 more threads\n",
            "INFO - 18:07:36: worker thread finished; awaiting finish of 8 more threads\n",
            "INFO - 18:07:36: worker thread finished; awaiting finish of 7 more threads\n",
            "INFO - 18:07:36: worker thread finished; awaiting finish of 6 more threads\n",
            "INFO - 18:07:36: worker thread finished; awaiting finish of 5 more threads\n",
            "INFO - 18:07:36: worker thread finished; awaiting finish of 4 more threads\n",
            "INFO - 18:07:36: worker thread finished; awaiting finish of 3 more threads\n",
            "INFO - 18:07:36: worker thread finished; awaiting finish of 2 more threads\n",
            "INFO - 18:07:36: worker thread finished; awaiting finish of 1 more threads\n",
            "INFO - 18:07:36: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 18:07:36: EPOCH - 1 : training on 1673812 raw words (741369 effective words) took 5.9s, 125531 effective words/s\n",
            "INFO - 18:07:37: EPOCH 2 - PROGRESS: at 1.81% examples, 12702 words/s, in_qsize 63, out_qsize 0\n",
            "INFO - 18:07:38: EPOCH 2 - PROGRESS: at 24.07% examples, 84780 words/s, in_qsize 62, out_qsize 1\n",
            "INFO - 18:07:40: EPOCH 2 - PROGRESS: at 48.48% examples, 111535 words/s, in_qsize 61, out_qsize 2\n",
            "INFO - 18:07:41: EPOCH 2 - PROGRESS: at 72.79% examples, 127197 words/s, in_qsize 45, out_qsize 1\n",
            "INFO - 18:07:41: worker thread finished; awaiting finish of 31 more threads\n",
            "INFO - 18:07:41: worker thread finished; awaiting finish of 30 more threads\n",
            "INFO - 18:07:41: worker thread finished; awaiting finish of 29 more threads\n",
            "INFO - 18:07:41: worker thread finished; awaiting finish of 28 more threads\n",
            "INFO - 18:07:41: worker thread finished; awaiting finish of 27 more threads\n",
            "INFO - 18:07:41: worker thread finished; awaiting finish of 26 more threads\n",
            "INFO - 18:07:41: worker thread finished; awaiting finish of 25 more threads\n",
            "INFO - 18:07:41: worker thread finished; awaiting finish of 24 more threads\n",
            "INFO - 18:07:41: worker thread finished; awaiting finish of 23 more threads\n",
            "INFO - 18:07:41: worker thread finished; awaiting finish of 22 more threads\n",
            "INFO - 18:07:41: worker thread finished; awaiting finish of 21 more threads\n",
            "INFO - 18:07:41: worker thread finished; awaiting finish of 20 more threads\n",
            "INFO - 18:07:41: worker thread finished; awaiting finish of 19 more threads\n",
            "INFO - 18:07:41: worker thread finished; awaiting finish of 18 more threads\n",
            "INFO - 18:07:41: worker thread finished; awaiting finish of 17 more threads\n",
            "INFO - 18:07:41: worker thread finished; awaiting finish of 16 more threads\n",
            "INFO - 18:07:41: worker thread finished; awaiting finish of 15 more threads\n",
            "INFO - 18:07:41: worker thread finished; awaiting finish of 14 more threads\n",
            "INFO - 18:07:41: worker thread finished; awaiting finish of 13 more threads\n",
            "INFO - 18:07:42: worker thread finished; awaiting finish of 12 more threads\n",
            "INFO - 18:07:42: worker thread finished; awaiting finish of 11 more threads\n",
            "INFO - 18:07:42: worker thread finished; awaiting finish of 10 more threads\n",
            "INFO - 18:07:42: EPOCH 2 - PROGRESS: at 94.47% examples, 133780 words/s, in_qsize 9, out_qsize 1\n",
            "INFO - 18:07:42: worker thread finished; awaiting finish of 9 more threads\n",
            "INFO - 18:07:42: worker thread finished; awaiting finish of 8 more threads\n",
            "INFO - 18:07:42: worker thread finished; awaiting finish of 7 more threads\n",
            "INFO - 18:07:42: worker thread finished; awaiting finish of 6 more threads\n",
            "INFO - 18:07:42: worker thread finished; awaiting finish of 5 more threads\n",
            "INFO - 18:07:42: worker thread finished; awaiting finish of 4 more threads\n",
            "INFO - 18:07:42: worker thread finished; awaiting finish of 3 more threads\n",
            "INFO - 18:07:42: worker thread finished; awaiting finish of 2 more threads\n",
            "INFO - 18:07:42: worker thread finished; awaiting finish of 1 more threads\n",
            "INFO - 18:07:42: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 18:07:42: EPOCH - 2 : training on 1673812 raw words (740574 effective words) took 5.3s, 139265 effective words/s\n",
            "INFO - 18:07:43: EPOCH 3 - PROGRESS: at 2.42% examples, 15043 words/s, in_qsize 63, out_qsize 0\n",
            "INFO - 18:07:44: EPOCH 3 - PROGRESS: at 27.12% examples, 76689 words/s, in_qsize 63, out_qsize 0\n",
            "INFO - 18:07:45: EPOCH 3 - PROGRESS: at 46.07% examples, 91856 words/s, in_qsize 63, out_qsize 0\n",
            "INFO - 18:07:46: EPOCH 3 - PROGRESS: at 55.56% examples, 86779 words/s, in_qsize 60, out_qsize 3\n",
            "INFO - 18:07:48: EPOCH 3 - PROGRESS: at 66.94% examples, 82520 words/s, in_qsize 54, out_qsize 2\n",
            "INFO - 18:07:48: worker thread finished; awaiting finish of 31 more threads\n",
            "INFO - 18:07:48: worker thread finished; awaiting finish of 30 more threads\n",
            "INFO - 18:07:48: worker thread finished; awaiting finish of 29 more threads\n",
            "INFO - 18:07:48: worker thread finished; awaiting finish of 28 more threads\n",
            "INFO - 18:07:48: worker thread finished; awaiting finish of 27 more threads\n",
            "INFO - 18:07:48: worker thread finished; awaiting finish of 26 more threads\n",
            "INFO - 18:07:48: worker thread finished; awaiting finish of 25 more threads\n",
            "INFO - 18:07:48: worker thread finished; awaiting finish of 24 more threads\n",
            "INFO - 18:07:48: worker thread finished; awaiting finish of 23 more threads\n",
            "INFO - 18:07:49: worker thread finished; awaiting finish of 22 more threads\n",
            "INFO - 18:07:49: EPOCH 3 - PROGRESS: at 87.68% examples, 92603 words/s, in_qsize 21, out_qsize 1\n",
            "INFO - 18:07:49: worker thread finished; awaiting finish of 21 more threads\n",
            "INFO - 18:07:49: worker thread finished; awaiting finish of 20 more threads\n",
            "INFO - 18:07:49: worker thread finished; awaiting finish of 19 more threads\n",
            "INFO - 18:07:49: worker thread finished; awaiting finish of 18 more threads\n",
            "INFO - 18:07:49: worker thread finished; awaiting finish of 17 more threads\n",
            "INFO - 18:07:49: worker thread finished; awaiting finish of 16 more threads\n",
            "INFO - 18:07:49: worker thread finished; awaiting finish of 15 more threads\n",
            "INFO - 18:07:49: worker thread finished; awaiting finish of 14 more threads\n",
            "INFO - 18:07:49: worker thread finished; awaiting finish of 13 more threads\n",
            "INFO - 18:07:49: worker thread finished; awaiting finish of 12 more threads\n",
            "INFO - 18:07:49: worker thread finished; awaiting finish of 11 more threads\n",
            "INFO - 18:07:49: worker thread finished; awaiting finish of 10 more threads\n",
            "INFO - 18:07:49: worker thread finished; awaiting finish of 9 more threads\n",
            "INFO - 18:07:49: worker thread finished; awaiting finish of 8 more threads\n",
            "INFO - 18:07:49: worker thread finished; awaiting finish of 7 more threads\n",
            "INFO - 18:07:49: worker thread finished; awaiting finish of 6 more threads\n",
            "INFO - 18:07:49: worker thread finished; awaiting finish of 5 more threads\n",
            "INFO - 18:07:49: worker thread finished; awaiting finish of 4 more threads\n",
            "INFO - 18:07:49: worker thread finished; awaiting finish of 3 more threads\n",
            "INFO - 18:07:49: worker thread finished; awaiting finish of 2 more threads\n",
            "INFO - 18:07:49: worker thread finished; awaiting finish of 1 more threads\n",
            "INFO - 18:07:49: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 18:07:49: EPOCH - 3 : training on 1673812 raw words (741088 effective words) took 7.2s, 103122 effective words/s\n",
            "INFO - 18:07:50: EPOCH 4 - PROGRESS: at 3.02% examples, 15553 words/s, in_qsize 62, out_qsize 1\n",
            "INFO - 18:07:51: EPOCH 4 - PROGRESS: at 22.28% examples, 65947 words/s, in_qsize 61, out_qsize 2\n",
            "INFO - 18:07:53: EPOCH 4 - PROGRESS: at 41.97% examples, 79989 words/s, in_qsize 63, out_qsize 0\n",
            "INFO - 18:07:54: EPOCH 4 - PROGRESS: at 62.21% examples, 84755 words/s, in_qsize 57, out_qsize 6\n",
            "INFO - 18:07:55: worker thread finished; awaiting finish of 31 more threads\n",
            "INFO - 18:07:55: worker thread finished; awaiting finish of 30 more threads\n",
            "INFO - 18:07:55: EPOCH 4 - PROGRESS: at 82.91% examples, 94495 words/s, in_qsize 16, out_qsize 27\n",
            "INFO - 18:07:55: worker thread finished; awaiting finish of 29 more threads\n",
            "INFO - 18:07:56: worker thread finished; awaiting finish of 28 more threads\n",
            "INFO - 18:07:56: worker thread finished; awaiting finish of 27 more threads\n",
            "INFO - 18:07:56: worker thread finished; awaiting finish of 26 more threads\n",
            "INFO - 18:07:56: worker thread finished; awaiting finish of 25 more threads\n",
            "INFO - 18:07:56: worker thread finished; awaiting finish of 24 more threads\n",
            "INFO - 18:07:56: worker thread finished; awaiting finish of 23 more threads\n",
            "INFO - 18:07:56: worker thread finished; awaiting finish of 22 more threads\n",
            "INFO - 18:07:56: worker thread finished; awaiting finish of 21 more threads\n",
            "INFO - 18:07:56: worker thread finished; awaiting finish of 20 more threads\n",
            "INFO - 18:07:56: worker thread finished; awaiting finish of 19 more threads\n",
            "INFO - 18:07:56: worker thread finished; awaiting finish of 18 more threads\n",
            "INFO - 18:07:56: worker thread finished; awaiting finish of 17 more threads\n",
            "INFO - 18:07:56: worker thread finished; awaiting finish of 16 more threads\n",
            "INFO - 18:07:56: worker thread finished; awaiting finish of 15 more threads\n",
            "INFO - 18:07:56: worker thread finished; awaiting finish of 14 more threads\n",
            "INFO - 18:07:56: worker thread finished; awaiting finish of 13 more threads\n",
            "INFO - 18:07:56: worker thread finished; awaiting finish of 12 more threads\n",
            "INFO - 18:07:56: worker thread finished; awaiting finish of 11 more threads\n",
            "INFO - 18:07:56: worker thread finished; awaiting finish of 10 more threads\n",
            "INFO - 18:07:56: worker thread finished; awaiting finish of 9 more threads\n",
            "INFO - 18:07:56: worker thread finished; awaiting finish of 8 more threads\n",
            "INFO - 18:07:56: worker thread finished; awaiting finish of 7 more threads\n",
            "INFO - 18:07:56: worker thread finished; awaiting finish of 6 more threads\n",
            "INFO - 18:07:56: worker thread finished; awaiting finish of 5 more threads\n",
            "INFO - 18:07:56: worker thread finished; awaiting finish of 4 more threads\n",
            "INFO - 18:07:56: worker thread finished; awaiting finish of 3 more threads\n",
            "INFO - 18:07:56: worker thread finished; awaiting finish of 2 more threads\n",
            "INFO - 18:07:56: worker thread finished; awaiting finish of 1 more threads\n",
            "INFO - 18:07:56: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 18:07:56: EPOCH - 4 : training on 1673812 raw words (740811 effective words) took 6.9s, 107894 effective words/s\n",
            "INFO - 18:07:57: EPOCH 5 - PROGRESS: at 6.19% examples, 43478 words/s, in_qsize 63, out_qsize 0\n",
            "INFO - 18:07:58: EPOCH 5 - PROGRESS: at 26.51% examples, 95254 words/s, in_qsize 62, out_qsize 1\n",
            "INFO - 18:07:59: EPOCH 5 - PROGRESS: at 44.30% examples, 103153 words/s, in_qsize 64, out_qsize 0\n",
            "INFO - 18:08:00: EPOCH 5 - PROGRESS: at 63.40% examples, 111345 words/s, in_qsize 60, out_qsize 2\n",
            "INFO - 18:08:01: worker thread finished; awaiting finish of 31 more threads\n",
            "INFO - 18:08:01: worker thread finished; awaiting finish of 30 more threads\n",
            "INFO - 18:08:01: worker thread finished; awaiting finish of 29 more threads\n",
            "INFO - 18:08:01: worker thread finished; awaiting finish of 28 more threads\n",
            "INFO - 18:08:01: EPOCH 5 - PROGRESS: at 84.09% examples, 119623 words/s, in_qsize 26, out_qsize 3\n",
            "INFO - 18:08:01: worker thread finished; awaiting finish of 27 more threads\n",
            "INFO - 18:08:01: worker thread finished; awaiting finish of 26 more threads\n",
            "INFO - 18:08:01: worker thread finished; awaiting finish of 25 more threads\n",
            "INFO - 18:08:02: worker thread finished; awaiting finish of 24 more threads\n",
            "INFO - 18:08:02: worker thread finished; awaiting finish of 23 more threads\n",
            "INFO - 18:08:02: worker thread finished; awaiting finish of 22 more threads\n",
            "INFO - 18:08:02: worker thread finished; awaiting finish of 21 more threads\n",
            "INFO - 18:08:02: worker thread finished; awaiting finish of 20 more threads\n",
            "INFO - 18:08:02: worker thread finished; awaiting finish of 19 more threads\n",
            "INFO - 18:08:02: worker thread finished; awaiting finish of 18 more threads\n",
            "INFO - 18:08:02: worker thread finished; awaiting finish of 17 more threads\n",
            "INFO - 18:08:02: worker thread finished; awaiting finish of 16 more threads\n",
            "INFO - 18:08:02: worker thread finished; awaiting finish of 15 more threads\n",
            "INFO - 18:08:02: worker thread finished; awaiting finish of 14 more threads\n",
            "INFO - 18:08:02: worker thread finished; awaiting finish of 13 more threads\n",
            "INFO - 18:08:02: worker thread finished; awaiting finish of 12 more threads\n",
            "INFO - 18:08:02: worker thread finished; awaiting finish of 11 more threads\n",
            "INFO - 18:08:02: worker thread finished; awaiting finish of 10 more threads\n",
            "INFO - 18:08:02: worker thread finished; awaiting finish of 9 more threads\n",
            "INFO - 18:08:02: worker thread finished; awaiting finish of 8 more threads\n",
            "INFO - 18:08:02: worker thread finished; awaiting finish of 7 more threads\n",
            "INFO - 18:08:02: worker thread finished; awaiting finish of 6 more threads\n",
            "INFO - 18:08:02: worker thread finished; awaiting finish of 5 more threads\n",
            "INFO - 18:08:02: worker thread finished; awaiting finish of 4 more threads\n",
            "INFO - 18:08:02: worker thread finished; awaiting finish of 3 more threads\n",
            "INFO - 18:08:02: worker thread finished; awaiting finish of 2 more threads\n",
            "INFO - 18:08:02: worker thread finished; awaiting finish of 1 more threads\n",
            "INFO - 18:08:02: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 18:08:02: EPOCH - 5 : training on 1673812 raw words (740817 effective words) took 6.0s, 124446 effective words/s\n",
            "INFO - 18:08:02: training on a 8369060 raw words (3704659 effective words) took 31.7s, 116764 effective words/s\n",
            "INFO - 18:08:02: collecting all words and their counts\n",
            "INFO - 18:08:02: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
            "INFO - 18:08:02: PROGRESS: at sentence #10000, processed 184916 words, keeping 2209 word types\n",
            "INFO - 18:08:03: PROGRESS: at sentence #20000, processed 375164 words, keeping 2671 word types\n",
            "INFO - 18:08:03: PROGRESS: at sentence #30000, processed 562939 words, keeping 2938 word types\n",
            "INFO - 18:08:03: PROGRESS: at sentence #40000, processed 754746 words, keeping 3128 word types\n",
            "INFO - 18:08:03: PROGRESS: at sentence #50000, processed 941580 words, keeping 3261 word types\n",
            "INFO - 18:08:03: PROGRESS: at sentence #60000, processed 1134158 words, keeping 3405 word types\n",
            "INFO - 18:08:03: PROGRESS: at sentence #70000, processed 1323170 words, keeping 3506 word types\n",
            "INFO - 18:08:03: PROGRESS: at sentence #80000, processed 1513335 words, keeping 3611 word types\n",
            "INFO - 18:08:03: collected 3667 word types from a corpus of 1673812 raw words and 88516 sentences\n",
            "INFO - 18:08:03: Updating model with new vocabulary\n",
            "INFO - 18:08:03: New added 3100 unique words (45% of original 6767) and increased the count of 3100 pre-existing words (45% of original 6767)\n",
            "INFO - 18:08:03: deleting the raw counts dictionary of 3667 items\n",
            "INFO - 18:08:03: sample=0.001 downsamples 92 most-common words\n",
            "INFO - 18:08:03: downsampling leaves estimated 1482276 word corpus (88.6% of prior 1673245)\n",
            "INFO - 18:08:04: estimated required memory for 3100 words, 31159 buckets and 200 dimensions: 32082480 bytes\n",
            "INFO - 18:08:04: updating layer weights\n",
            "INFO - 18:08:04: Number of new ngrams is 0\n",
            "WARNING - 18:08:04: Effective 'alpha' higher than previous training cycles\n",
            "INFO - 18:08:04: training model with 32 workers on 3100 vocabulary and 200 features, using sg=1 hs=0 sample=0.001 negative=10 window=2\n",
            "INFO - 18:08:07: EPOCH 1 - PROGRESS: at 1.81% examples, 6078 words/s, in_qsize 44, out_qsize 19\n",
            "INFO - 18:08:08: EPOCH 1 - PROGRESS: at 27.76% examples, 60707 words/s, in_qsize 62, out_qsize 1\n",
            "INFO - 18:08:09: EPOCH 1 - PROGRESS: at 46.07% examples, 75627 words/s, in_qsize 64, out_qsize 0\n",
            "INFO - 18:08:10: EPOCH 1 - PROGRESS: at 61.14% examples, 81745 words/s, in_qsize 62, out_qsize 1\n",
            "INFO - 18:08:11: EPOCH 1 - PROGRESS: at 76.95% examples, 86702 words/s, in_qsize 35, out_qsize 4\n",
            "INFO - 18:08:11: worker thread finished; awaiting finish of 31 more threads\n",
            "INFO - 18:08:11: worker thread finished; awaiting finish of 30 more threads\n",
            "INFO - 18:08:11: worker thread finished; awaiting finish of 29 more threads\n",
            "INFO - 18:08:12: worker thread finished; awaiting finish of 28 more threads\n",
            "INFO - 18:08:12: worker thread finished; awaiting finish of 27 more threads\n",
            "INFO - 18:08:12: worker thread finished; awaiting finish of 26 more threads\n",
            "INFO - 18:08:12: worker thread finished; awaiting finish of 25 more threads\n",
            "INFO - 18:08:12: worker thread finished; awaiting finish of 24 more threads\n",
            "INFO - 18:08:12: worker thread finished; awaiting finish of 23 more threads\n",
            "INFO - 18:08:12: worker thread finished; awaiting finish of 22 more threads\n",
            "INFO - 18:08:12: worker thread finished; awaiting finish of 21 more threads\n",
            "INFO - 18:08:12: worker thread finished; awaiting finish of 20 more threads\n",
            "INFO - 18:08:12: worker thread finished; awaiting finish of 19 more threads\n",
            "INFO - 18:08:12: worker thread finished; awaiting finish of 18 more threads\n",
            "INFO - 18:08:12: worker thread finished; awaiting finish of 17 more threads\n",
            "INFO - 18:08:12: worker thread finished; awaiting finish of 16 more threads\n",
            "INFO - 18:08:12: worker thread finished; awaiting finish of 15 more threads\n",
            "INFO - 18:08:12: worker thread finished; awaiting finish of 14 more threads\n",
            "INFO - 18:08:12: worker thread finished; awaiting finish of 13 more threads\n",
            "INFO - 18:08:12: worker thread finished; awaiting finish of 12 more threads\n",
            "INFO - 18:08:12: worker thread finished; awaiting finish of 11 more threads\n",
            "INFO - 18:08:12: worker thread finished; awaiting finish of 10 more threads\n",
            "INFO - 18:08:12: worker thread finished; awaiting finish of 9 more threads\n",
            "INFO - 18:08:12: worker thread finished; awaiting finish of 8 more threads\n",
            "INFO - 18:08:12: worker thread finished; awaiting finish of 7 more threads\n",
            "INFO - 18:08:12: worker thread finished; awaiting finish of 6 more threads\n",
            "INFO - 18:08:12: worker thread finished; awaiting finish of 5 more threads\n",
            "INFO - 18:08:12: worker thread finished; awaiting finish of 4 more threads\n",
            "INFO - 18:08:12: worker thread finished; awaiting finish of 3 more threads\n",
            "INFO - 18:08:12: worker thread finished; awaiting finish of 2 more threads\n",
            "INFO - 18:08:12: worker thread finished; awaiting finish of 1 more threads\n",
            "INFO - 18:08:12: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 18:08:12: EPOCH - 1 : training on 1673812 raw words (741132 effective words) took 7.4s, 99818 effective words/s\n",
            "INFO - 18:08:13: EPOCH 2 - PROGRESS: at 7.22% examples, 49674 words/s, in_qsize 62, out_qsize 1\n",
            "INFO - 18:08:14: EPOCH 2 - PROGRESS: at 30.19% examples, 98752 words/s, in_qsize 62, out_qsize 1\n",
            "INFO - 18:08:15: EPOCH 2 - PROGRESS: at 48.44% examples, 109239 words/s, in_qsize 63, out_qsize 0\n",
            "INFO - 18:08:16: EPOCH 2 - PROGRESS: at 68.66% examples, 118489 words/s, in_qsize 53, out_qsize 0\n",
            "INFO - 18:08:17: EPOCH 2 - PROGRESS: at 81.66% examples, 114423 words/s, in_qsize 30, out_qsize 3\n",
            "INFO - 18:08:18: worker thread finished; awaiting finish of 31 more threads\n",
            "INFO - 18:08:18: worker thread finished; awaiting finish of 30 more threads\n",
            "INFO - 18:08:18: worker thread finished; awaiting finish of 29 more threads\n",
            "INFO - 18:08:18: worker thread finished; awaiting finish of 28 more threads\n",
            "INFO - 18:08:18: worker thread finished; awaiting finish of 27 more threads\n",
            "INFO - 18:08:18: worker thread finished; awaiting finish of 26 more threads\n",
            "INFO - 18:08:18: worker thread finished; awaiting finish of 25 more threads\n",
            "INFO - 18:08:18: worker thread finished; awaiting finish of 24 more threads\n",
            "INFO - 18:08:18: worker thread finished; awaiting finish of 23 more threads\n",
            "INFO - 18:08:18: worker thread finished; awaiting finish of 22 more threads\n",
            "INFO - 18:08:18: worker thread finished; awaiting finish of 21 more threads\n",
            "INFO - 18:08:18: worker thread finished; awaiting finish of 20 more threads\n",
            "INFO - 18:08:18: worker thread finished; awaiting finish of 19 more threads\n",
            "INFO - 18:08:18: worker thread finished; awaiting finish of 18 more threads\n",
            "INFO - 18:08:18: worker thread finished; awaiting finish of 17 more threads\n",
            "INFO - 18:08:18: worker thread finished; awaiting finish of 16 more threads\n",
            "INFO - 18:08:18: worker thread finished; awaiting finish of 15 more threads\n",
            "INFO - 18:08:18: worker thread finished; awaiting finish of 14 more threads\n",
            "INFO - 18:08:18: worker thread finished; awaiting finish of 13 more threads\n",
            "INFO - 18:08:18: worker thread finished; awaiting finish of 12 more threads\n",
            "INFO - 18:08:18: worker thread finished; awaiting finish of 11 more threads\n",
            "INFO - 18:08:18: worker thread finished; awaiting finish of 10 more threads\n",
            "INFO - 18:08:18: worker thread finished; awaiting finish of 9 more threads\n",
            "INFO - 18:08:18: worker thread finished; awaiting finish of 8 more threads\n",
            "INFO - 18:08:18: worker thread finished; awaiting finish of 7 more threads\n",
            "INFO - 18:08:18: worker thread finished; awaiting finish of 6 more threads\n",
            "INFO - 18:08:18: worker thread finished; awaiting finish of 5 more threads\n",
            "INFO - 18:08:18: worker thread finished; awaiting finish of 4 more threads\n",
            "INFO - 18:08:18: worker thread finished; awaiting finish of 3 more threads\n",
            "INFO - 18:08:18: worker thread finished; awaiting finish of 2 more threads\n",
            "INFO - 18:08:18: worker thread finished; awaiting finish of 1 more threads\n",
            "INFO - 18:08:18: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 18:08:18: EPOCH - 2 : training on 1673812 raw words (741232 effective words) took 6.1s, 121732 effective words/s\n",
            "INFO - 18:08:19: EPOCH 3 - PROGRESS: at 8.07% examples, 53337 words/s, in_qsize 63, out_qsize 0\n",
            "INFO - 18:08:20: EPOCH 3 - PROGRESS: at 21.09% examples, 73496 words/s, in_qsize 60, out_qsize 3\n",
            "INFO - 18:08:22: EPOCH 3 - PROGRESS: at 39.06% examples, 89101 words/s, in_qsize 61, out_qsize 2\n",
            "INFO - 18:08:23: EPOCH 3 - PROGRESS: at 61.63% examples, 106606 words/s, in_qsize 63, out_qsize 0\n",
            "INFO - 18:08:24: worker thread finished; awaiting finish of 31 more threads\n",
            "INFO - 18:08:24: EPOCH 3 - PROGRESS: at 82.24% examples, 114812 words/s, in_qsize 30, out_qsize 1\n",
            "INFO - 18:08:24: worker thread finished; awaiting finish of 30 more threads\n",
            "INFO - 18:08:24: worker thread finished; awaiting finish of 29 more threads\n",
            "INFO - 18:08:24: worker thread finished; awaiting finish of 28 more threads\n",
            "INFO - 18:08:24: worker thread finished; awaiting finish of 27 more threads\n",
            "INFO - 18:08:24: worker thread finished; awaiting finish of 26 more threads\n",
            "INFO - 18:08:24: worker thread finished; awaiting finish of 25 more threads\n",
            "INFO - 18:08:24: worker thread finished; awaiting finish of 24 more threads\n",
            "INFO - 18:08:24: worker thread finished; awaiting finish of 23 more threads\n",
            "INFO - 18:08:24: worker thread finished; awaiting finish of 22 more threads\n",
            "INFO - 18:08:24: worker thread finished; awaiting finish of 21 more threads\n",
            "INFO - 18:08:24: worker thread finished; awaiting finish of 20 more threads\n",
            "INFO - 18:08:24: worker thread finished; awaiting finish of 19 more threads\n",
            "INFO - 18:08:24: worker thread finished; awaiting finish of 18 more threads\n",
            "INFO - 18:08:24: worker thread finished; awaiting finish of 17 more threads\n",
            "INFO - 18:08:24: worker thread finished; awaiting finish of 16 more threads\n",
            "INFO - 18:08:24: worker thread finished; awaiting finish of 15 more threads\n",
            "INFO - 18:08:24: worker thread finished; awaiting finish of 14 more threads\n",
            "INFO - 18:08:24: worker thread finished; awaiting finish of 13 more threads\n",
            "INFO - 18:08:24: worker thread finished; awaiting finish of 12 more threads\n",
            "INFO - 18:08:25: worker thread finished; awaiting finish of 11 more threads\n",
            "INFO - 18:08:25: worker thread finished; awaiting finish of 10 more threads\n",
            "INFO - 18:08:25: worker thread finished; awaiting finish of 9 more threads\n",
            "INFO - 18:08:25: worker thread finished; awaiting finish of 8 more threads\n",
            "INFO - 18:08:25: worker thread finished; awaiting finish of 7 more threads\n",
            "INFO - 18:08:25: worker thread finished; awaiting finish of 6 more threads\n",
            "INFO - 18:08:25: worker thread finished; awaiting finish of 5 more threads\n",
            "INFO - 18:08:25: worker thread finished; awaiting finish of 4 more threads\n",
            "INFO - 18:08:25: worker thread finished; awaiting finish of 3 more threads\n",
            "INFO - 18:08:25: worker thread finished; awaiting finish of 2 more threads\n",
            "INFO - 18:08:25: worker thread finished; awaiting finish of 1 more threads\n",
            "INFO - 18:08:25: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 18:08:25: EPOCH - 3 : training on 1673812 raw words (740905 effective words) took 6.3s, 117671 effective words/s\n",
            "INFO - 18:08:26: EPOCH 4 - PROGRESS: at 6.15% examples, 40532 words/s, in_qsize 64, out_qsize 1\n",
            "INFO - 18:08:27: EPOCH 4 - PROGRESS: at 18.21% examples, 61644 words/s, in_qsize 63, out_qsize 0\n",
            "INFO - 18:08:28: EPOCH 4 - PROGRESS: at 36.74% examples, 83793 words/s, in_qsize 63, out_qsize 0\n",
            "INFO - 18:08:29: EPOCH 4 - PROGRESS: at 47.86% examples, 82588 words/s, in_qsize 63, out_qsize 0\n",
            "INFO - 18:08:30: EPOCH 4 - PROGRESS: at 55.19% examples, 76363 words/s, in_qsize 64, out_qsize 0\n",
            "INFO - 18:08:31: EPOCH 4 - PROGRESS: at 73.93% examples, 86736 words/s, in_qsize 44, out_qsize 0\n",
            "INFO - 18:08:32: worker thread finished; awaiting finish of 31 more threads\n",
            "INFO - 18:08:32: worker thread finished; awaiting finish of 30 more threads\n",
            "INFO - 18:08:32: worker thread finished; awaiting finish of 29 more threads\n",
            "INFO - 18:08:32: worker thread finished; awaiting finish of 28 more threads\n",
            "INFO - 18:08:32: worker thread finished; awaiting finish of 27 more threads\n",
            "INFO - 18:08:32: worker thread finished; awaiting finish of 26 more threads\n",
            "INFO - 18:08:32: worker thread finished; awaiting finish of 25 more threads\n",
            "INFO - 18:08:32: EPOCH 4 - PROGRESS: at 85.86% examples, 85997 words/s, in_qsize 19, out_qsize 11\n",
            "INFO - 18:08:33: worker thread finished; awaiting finish of 24 more threads\n",
            "INFO - 18:08:33: worker thread finished; awaiting finish of 23 more threads\n",
            "INFO - 18:08:33: worker thread finished; awaiting finish of 22 more threads\n",
            "INFO - 18:08:33: worker thread finished; awaiting finish of 21 more threads\n",
            "INFO - 18:08:33: worker thread finished; awaiting finish of 20 more threads\n",
            "INFO - 18:08:33: worker thread finished; awaiting finish of 19 more threads\n",
            "INFO - 18:08:33: worker thread finished; awaiting finish of 18 more threads\n",
            "INFO - 18:08:33: worker thread finished; awaiting finish of 17 more threads\n",
            "INFO - 18:08:33: worker thread finished; awaiting finish of 16 more threads\n",
            "INFO - 18:08:33: worker thread finished; awaiting finish of 15 more threads\n",
            "INFO - 18:08:33: worker thread finished; awaiting finish of 14 more threads\n",
            "INFO - 18:08:33: worker thread finished; awaiting finish of 13 more threads\n",
            "INFO - 18:08:33: worker thread finished; awaiting finish of 12 more threads\n",
            "INFO - 18:08:33: worker thread finished; awaiting finish of 11 more threads\n",
            "INFO - 18:08:33: worker thread finished; awaiting finish of 10 more threads\n",
            "INFO - 18:08:33: worker thread finished; awaiting finish of 9 more threads\n",
            "INFO - 18:08:33: worker thread finished; awaiting finish of 8 more threads\n",
            "INFO - 18:08:33: worker thread finished; awaiting finish of 7 more threads\n",
            "INFO - 18:08:33: worker thread finished; awaiting finish of 6 more threads\n",
            "INFO - 18:08:33: worker thread finished; awaiting finish of 5 more threads\n",
            "INFO - 18:08:33: worker thread finished; awaiting finish of 4 more threads\n",
            "INFO - 18:08:33: worker thread finished; awaiting finish of 3 more threads\n",
            "INFO - 18:08:33: worker thread finished; awaiting finish of 2 more threads\n",
            "INFO - 18:08:33: worker thread finished; awaiting finish of 1 more threads\n",
            "INFO - 18:08:33: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 18:08:33: EPOCH - 4 : training on 1673812 raw words (740619 effective words) took 8.1s, 91394 effective words/s\n",
            "INFO - 18:08:35: EPOCH 5 - PROGRESS: at 4.27% examples, 17557 words/s, in_qsize 63, out_qsize 0\n",
            "INFO - 18:08:36: EPOCH 5 - PROGRESS: at 26.49% examples, 65683 words/s, in_qsize 64, out_qsize 0\n",
            "INFO - 18:08:37: EPOCH 5 - PROGRESS: at 46.06% examples, 83810 words/s, in_qsize 63, out_qsize 0\n",
            "INFO - 18:08:38: EPOCH 5 - PROGRESS: at 56.35% examples, 81372 words/s, in_qsize 61, out_qsize 2\n",
            "INFO - 18:08:39: EPOCH 5 - PROGRESS: at 68.66% examples, 83319 words/s, in_qsize 51, out_qsize 2\n",
            "INFO - 18:08:40: worker thread finished; awaiting finish of 31 more threads\n",
            "INFO - 18:08:40: worker thread finished; awaiting finish of 30 more threads\n",
            "INFO - 18:08:40: worker thread finished; awaiting finish of 29 more threads\n",
            "INFO - 18:08:40: worker thread finished; awaiting finish of 28 more threads\n",
            "INFO - 18:08:40: worker thread finished; awaiting finish of 27 more threads\n",
            "INFO - 18:08:40: worker thread finished; awaiting finish of 26 more threads\n",
            "INFO - 18:08:40: worker thread finished; awaiting finish of 25 more threads\n",
            "INFO - 18:08:40: worker thread finished; awaiting finish of 24 more threads\n",
            "INFO - 18:08:40: EPOCH 5 - PROGRESS: at 86.41% examples, 89899 words/s, in_qsize 23, out_qsize 1\n",
            "INFO - 18:08:41: worker thread finished; awaiting finish of 23 more threads\n",
            "INFO - 18:08:41: worker thread finished; awaiting finish of 22 more threads\n",
            "INFO - 18:08:41: worker thread finished; awaiting finish of 21 more threads\n",
            "INFO - 18:08:41: worker thread finished; awaiting finish of 20 more threads\n",
            "INFO - 18:08:41: worker thread finished; awaiting finish of 19 more threads\n",
            "INFO - 18:08:41: worker thread finished; awaiting finish of 18 more threads\n",
            "INFO - 18:08:41: worker thread finished; awaiting finish of 17 more threads\n",
            "INFO - 18:08:41: worker thread finished; awaiting finish of 16 more threads\n",
            "INFO - 18:08:41: worker thread finished; awaiting finish of 15 more threads\n",
            "INFO - 18:08:41: worker thread finished; awaiting finish of 14 more threads\n",
            "INFO - 18:08:41: worker thread finished; awaiting finish of 13 more threads\n",
            "INFO - 18:08:41: worker thread finished; awaiting finish of 12 more threads\n",
            "INFO - 18:08:41: worker thread finished; awaiting finish of 11 more threads\n",
            "INFO - 18:08:41: worker thread finished; awaiting finish of 10 more threads\n",
            "INFO - 18:08:41: worker thread finished; awaiting finish of 9 more threads\n",
            "INFO - 18:08:41: worker thread finished; awaiting finish of 8 more threads\n",
            "INFO - 18:08:41: worker thread finished; awaiting finish of 7 more threads\n",
            "INFO - 18:08:41: worker thread finished; awaiting finish of 6 more threads\n",
            "INFO - 18:08:41: worker thread finished; awaiting finish of 5 more threads\n",
            "INFO - 18:08:41: worker thread finished; awaiting finish of 4 more threads\n",
            "INFO - 18:08:41: worker thread finished; awaiting finish of 3 more threads\n",
            "INFO - 18:08:41: worker thread finished; awaiting finish of 2 more threads\n",
            "INFO - 18:08:41: worker thread finished; awaiting finish of 1 more threads\n",
            "INFO - 18:08:41: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 18:08:41: EPOCH - 5 : training on 1673812 raw words (741074 effective words) took 7.6s, 98152 effective words/s\n",
            "INFO - 18:08:42: EPOCH 6 - PROGRESS: at 3.63% examples, 22715 words/s, in_qsize 62, out_qsize 1\n",
            "INFO - 18:08:43: EPOCH 6 - PROGRESS: at 25.94% examples, 80084 words/s, in_qsize 63, out_qsize 0\n",
            "INFO - 18:08:44: EPOCH 6 - PROGRESS: at 43.79% examples, 88104 words/s, in_qsize 64, out_qsize 2\n",
            "INFO - 18:08:46: EPOCH 6 - PROGRESS: at 46.73% examples, 70399 words/s, in_qsize 64, out_qsize 4\n",
            "INFO - 18:08:47: EPOCH 6 - PROGRESS: at 66.92% examples, 80515 words/s, in_qsize 53, out_qsize 3\n",
            "INFO - 18:08:48: worker thread finished; awaiting finish of 31 more threads\n",
            "INFO - 18:08:48: worker thread finished; awaiting finish of 30 more threads\n",
            "INFO - 18:08:48: worker thread finished; awaiting finish of 29 more threads\n",
            "INFO - 18:08:48: worker thread finished; awaiting finish of 28 more threads\n",
            "INFO - 18:08:48: worker thread finished; awaiting finish of 27 more threads\n",
            "INFO - 18:08:48: worker thread finished; awaiting finish of 26 more threads\n",
            "INFO - 18:08:48: worker thread finished; awaiting finish of 25 more threads\n",
            "INFO - 18:08:48: worker thread finished; awaiting finish of 24 more threads\n",
            "INFO - 18:08:48: worker thread finished; awaiting finish of 23 more threads\n",
            "INFO - 18:08:48: worker thread finished; awaiting finish of 22 more threads\n",
            "INFO - 18:08:48: EPOCH 6 - PROGRESS: at 87.64% examples, 88635 words/s, in_qsize 21, out_qsize 1\n",
            "INFO - 18:08:48: worker thread finished; awaiting finish of 21 more threads\n",
            "INFO - 18:08:48: worker thread finished; awaiting finish of 20 more threads\n",
            "INFO - 18:08:48: worker thread finished; awaiting finish of 19 more threads\n",
            "INFO - 18:08:48: worker thread finished; awaiting finish of 18 more threads\n",
            "INFO - 18:08:48: worker thread finished; awaiting finish of 17 more threads\n",
            "INFO - 18:08:48: worker thread finished; awaiting finish of 16 more threads\n",
            "INFO - 18:08:48: worker thread finished; awaiting finish of 15 more threads\n",
            "INFO - 18:08:48: worker thread finished; awaiting finish of 14 more threads\n",
            "INFO - 18:08:48: worker thread finished; awaiting finish of 13 more threads\n",
            "INFO - 18:08:48: worker thread finished; awaiting finish of 12 more threads\n",
            "INFO - 18:08:48: worker thread finished; awaiting finish of 11 more threads\n",
            "INFO - 18:08:48: worker thread finished; awaiting finish of 10 more threads\n",
            "INFO - 18:08:48: worker thread finished; awaiting finish of 9 more threads\n",
            "INFO - 18:08:48: worker thread finished; awaiting finish of 8 more threads\n",
            "INFO - 18:08:48: worker thread finished; awaiting finish of 7 more threads\n",
            "INFO - 18:08:48: worker thread finished; awaiting finish of 6 more threads\n",
            "INFO - 18:08:48: worker thread finished; awaiting finish of 5 more threads\n",
            "INFO - 18:08:48: worker thread finished; awaiting finish of 4 more threads\n",
            "INFO - 18:08:48: worker thread finished; awaiting finish of 3 more threads\n",
            "INFO - 18:08:48: worker thread finished; awaiting finish of 2 more threads\n",
            "INFO - 18:08:48: worker thread finished; awaiting finish of 1 more threads\n",
            "INFO - 18:08:48: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 18:08:48: EPOCH - 6 : training on 1673812 raw words (741073 effective words) took 7.6s, 97453 effective words/s\n",
            "INFO - 18:08:50: EPOCH 7 - PROGRESS: at 3.00% examples, 19844 words/s, in_qsize 63, out_qsize 0\n",
            "INFO - 18:08:51: EPOCH 7 - PROGRESS: at 24.07% examples, 79063 words/s, in_qsize 63, out_qsize 0\n",
            "INFO - 18:08:52: EPOCH 7 - PROGRESS: at 45.50% examples, 102182 words/s, in_qsize 64, out_qsize 0\n",
            "INFO - 18:08:53: EPOCH 7 - PROGRESS: at 59.93% examples, 102451 words/s, in_qsize 64, out_qsize 0\n",
            "INFO - 18:08:54: EPOCH 7 - PROGRESS: at 66.82% examples, 88304 words/s, in_qsize 39, out_qsize 17\n",
            "INFO - 18:08:55: worker thread finished; awaiting finish of 31 more threads\n",
            "INFO - 18:08:55: worker thread finished; awaiting finish of 30 more threads\n",
            "INFO - 18:08:55: worker thread finished; awaiting finish of 29 more threads\n",
            "INFO - 18:08:55: worker thread finished; awaiting finish of 28 more threads\n",
            "INFO - 18:08:55: worker thread finished; awaiting finish of 27 more threads\n",
            "INFO - 18:08:55: worker thread finished; awaiting finish of 26 more threads\n",
            "INFO - 18:08:55: worker thread finished; awaiting finish of 25 more threads\n",
            "INFO - 18:08:55: worker thread finished; awaiting finish of 24 more threads\n",
            "INFO - 18:08:55: EPOCH 7 - PROGRESS: at 86.48% examples, 93616 words/s, in_qsize 23, out_qsize 1\n",
            "INFO - 18:08:55: worker thread finished; awaiting finish of 23 more threads\n",
            "INFO - 18:08:55: worker thread finished; awaiting finish of 22 more threads\n",
            "INFO - 18:08:55: worker thread finished; awaiting finish of 21 more threads\n",
            "INFO - 18:08:55: worker thread finished; awaiting finish of 20 more threads\n",
            "INFO - 18:08:55: worker thread finished; awaiting finish of 19 more threads\n",
            "INFO - 18:08:55: worker thread finished; awaiting finish of 18 more threads\n",
            "INFO - 18:08:55: worker thread finished; awaiting finish of 17 more threads\n",
            "INFO - 18:08:55: worker thread finished; awaiting finish of 16 more threads\n",
            "INFO - 18:08:55: worker thread finished; awaiting finish of 15 more threads\n",
            "INFO - 18:08:55: worker thread finished; awaiting finish of 14 more threads\n",
            "INFO - 18:08:56: worker thread finished; awaiting finish of 13 more threads\n",
            "INFO - 18:08:56: worker thread finished; awaiting finish of 12 more threads\n",
            "INFO - 18:08:56: worker thread finished; awaiting finish of 11 more threads\n",
            "INFO - 18:08:56: worker thread finished; awaiting finish of 10 more threads\n",
            "INFO - 18:08:56: worker thread finished; awaiting finish of 9 more threads\n",
            "INFO - 18:08:56: worker thread finished; awaiting finish of 8 more threads\n",
            "INFO - 18:08:56: worker thread finished; awaiting finish of 7 more threads\n",
            "INFO - 18:08:56: worker thread finished; awaiting finish of 6 more threads\n",
            "INFO - 18:08:56: worker thread finished; awaiting finish of 5 more threads\n",
            "INFO - 18:08:56: worker thread finished; awaiting finish of 4 more threads\n",
            "INFO - 18:08:56: worker thread finished; awaiting finish of 3 more threads\n",
            "INFO - 18:08:56: worker thread finished; awaiting finish of 2 more threads\n",
            "INFO - 18:08:56: worker thread finished; awaiting finish of 1 more threads\n",
            "INFO - 18:08:56: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 18:08:56: EPOCH - 7 : training on 1673812 raw words (740660 effective words) took 7.1s, 103916 effective words/s\n",
            "INFO - 18:08:57: EPOCH 8 - PROGRESS: at 2.41% examples, 16787 words/s, in_qsize 63, out_qsize 0\n",
            "INFO - 18:08:58: EPOCH 8 - PROGRESS: at 17.03% examples, 59698 words/s, in_qsize 64, out_qsize 1\n",
            "INFO - 18:08:59: EPOCH 8 - PROGRESS: at 24.69% examples, 57606 words/s, in_qsize 64, out_qsize 0\n",
            "INFO - 18:09:01: EPOCH 8 - PROGRESS: at 45.53% examples, 68411 words/s, in_qsize 64, out_qsize 0\n",
            "INFO - 18:09:02: EPOCH 8 - PROGRESS: at 66.94% examples, 82294 words/s, in_qsize 56, out_qsize 0\n",
            "INFO - 18:09:02: worker thread finished; awaiting finish of 31 more threads\n",
            "INFO - 18:09:02: worker thread finished; awaiting finish of 30 more threads\n",
            "INFO - 18:09:02: worker thread finished; awaiting finish of 29 more threads\n",
            "INFO - 18:09:03: worker thread finished; awaiting finish of 28 more threads\n",
            "INFO - 18:09:03: worker thread finished; awaiting finish of 27 more threads\n",
            "INFO - 18:09:03: worker thread finished; awaiting finish of 26 more threads\n",
            "INFO - 18:09:03: worker thread finished; awaiting finish of 25 more threads\n",
            "INFO - 18:09:03: EPOCH 8 - PROGRESS: at 85.86% examples, 88477 words/s, in_qsize 21, out_qsize 7\n",
            "INFO - 18:09:03: worker thread finished; awaiting finish of 24 more threads\n",
            "INFO - 18:09:03: worker thread finished; awaiting finish of 23 more threads\n",
            "INFO - 18:09:03: worker thread finished; awaiting finish of 22 more threads\n",
            "INFO - 18:09:03: worker thread finished; awaiting finish of 21 more threads\n",
            "INFO - 18:09:03: worker thread finished; awaiting finish of 20 more threads\n",
            "INFO - 18:09:03: worker thread finished; awaiting finish of 19 more threads\n",
            "INFO - 18:09:03: worker thread finished; awaiting finish of 18 more threads\n",
            "INFO - 18:09:03: worker thread finished; awaiting finish of 17 more threads\n",
            "INFO - 18:09:03: worker thread finished; awaiting finish of 16 more threads\n",
            "INFO - 18:09:03: worker thread finished; awaiting finish of 15 more threads\n",
            "INFO - 18:09:03: worker thread finished; awaiting finish of 14 more threads\n",
            "INFO - 18:09:03: worker thread finished; awaiting finish of 13 more threads\n",
            "INFO - 18:09:03: worker thread finished; awaiting finish of 12 more threads\n",
            "INFO - 18:09:03: worker thread finished; awaiting finish of 11 more threads\n",
            "INFO - 18:09:03: worker thread finished; awaiting finish of 10 more threads\n",
            "INFO - 18:09:03: worker thread finished; awaiting finish of 9 more threads\n",
            "INFO - 18:09:03: worker thread finished; awaiting finish of 8 more threads\n",
            "INFO - 18:09:03: worker thread finished; awaiting finish of 7 more threads\n",
            "INFO - 18:09:03: worker thread finished; awaiting finish of 6 more threads\n",
            "INFO - 18:09:03: worker thread finished; awaiting finish of 5 more threads\n",
            "INFO - 18:09:03: worker thread finished; awaiting finish of 4 more threads\n",
            "INFO - 18:09:03: worker thread finished; awaiting finish of 3 more threads\n",
            "INFO - 18:09:03: worker thread finished; awaiting finish of 2 more threads\n",
            "INFO - 18:09:03: worker thread finished; awaiting finish of 1 more threads\n",
            "INFO - 18:09:03: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 18:09:03: EPOCH - 8 : training on 1673812 raw words (741406 effective words) took 7.7s, 96333 effective words/s\n",
            "INFO - 18:09:05: EPOCH 9 - PROGRESS: at 1.81% examples, 8110 words/s, in_qsize 63, out_qsize 0\n",
            "INFO - 18:09:06: EPOCH 9 - PROGRESS: at 24.07% examples, 66550 words/s, in_qsize 63, out_qsize 0\n",
            "INFO - 18:09:07: EPOCH 9 - PROGRESS: at 26.53% examples, 51546 words/s, in_qsize 57, out_qsize 6\n",
            "INFO - 18:09:08: EPOCH 9 - PROGRESS: at 46.62% examples, 71297 words/s, in_qsize 62, out_qsize 1\n",
            "INFO - 18:09:10: EPOCH 9 - PROGRESS: at 66.98% examples, 82462 words/s, in_qsize 56, out_qsize 0\n",
            "INFO - 18:09:10: worker thread finished; awaiting finish of 31 more threads\n",
            "INFO - 18:09:11: worker thread finished; awaiting finish of 30 more threads\n",
            "INFO - 18:09:11: EPOCH 9 - PROGRESS: at 82.96% examples, 86761 words/s, in_qsize 26, out_qsize 7\n",
            "INFO - 18:09:11: worker thread finished; awaiting finish of 29 more threads\n",
            "INFO - 18:09:11: worker thread finished; awaiting finish of 28 more threads\n",
            "INFO - 18:09:11: worker thread finished; awaiting finish of 27 more threads\n",
            "INFO - 18:09:11: worker thread finished; awaiting finish of 26 more threads\n",
            "INFO - 18:09:11: worker thread finished; awaiting finish of 25 more threads\n",
            "INFO - 18:09:11: worker thread finished; awaiting finish of 24 more threads\n",
            "INFO - 18:09:11: worker thread finished; awaiting finish of 23 more threads\n",
            "INFO - 18:09:11: worker thread finished; awaiting finish of 22 more threads\n",
            "INFO - 18:09:11: worker thread finished; awaiting finish of 21 more threads\n",
            "INFO - 18:09:11: worker thread finished; awaiting finish of 20 more threads\n",
            "INFO - 18:09:11: worker thread finished; awaiting finish of 19 more threads\n",
            "INFO - 18:09:11: worker thread finished; awaiting finish of 18 more threads\n",
            "INFO - 18:09:11: worker thread finished; awaiting finish of 17 more threads\n",
            "INFO - 18:09:11: worker thread finished; awaiting finish of 16 more threads\n",
            "INFO - 18:09:11: worker thread finished; awaiting finish of 15 more threads\n",
            "INFO - 18:09:11: worker thread finished; awaiting finish of 14 more threads\n",
            "INFO - 18:09:11: worker thread finished; awaiting finish of 13 more threads\n",
            "INFO - 18:09:11: worker thread finished; awaiting finish of 12 more threads\n",
            "INFO - 18:09:11: worker thread finished; awaiting finish of 11 more threads\n",
            "INFO - 18:09:11: worker thread finished; awaiting finish of 10 more threads\n",
            "INFO - 18:09:11: worker thread finished; awaiting finish of 9 more threads\n",
            "INFO - 18:09:11: worker thread finished; awaiting finish of 8 more threads\n",
            "INFO - 18:09:11: worker thread finished; awaiting finish of 7 more threads\n",
            "INFO - 18:09:11: worker thread finished; awaiting finish of 6 more threads\n",
            "INFO - 18:09:11: worker thread finished; awaiting finish of 5 more threads\n",
            "INFO - 18:09:11: worker thread finished; awaiting finish of 4 more threads\n",
            "INFO - 18:09:11: worker thread finished; awaiting finish of 3 more threads\n",
            "INFO - 18:09:11: worker thread finished; awaiting finish of 2 more threads\n",
            "INFO - 18:09:11: worker thread finished; awaiting finish of 1 more threads\n",
            "INFO - 18:09:11: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 18:09:11: EPOCH - 9 : training on 1673812 raw words (741405 effective words) took 7.9s, 94000 effective words/s\n",
            "INFO - 18:09:13: EPOCH 10 - PROGRESS: at 4.27% examples, 27764 words/s, in_qsize 63, out_qsize 0\n",
            "INFO - 18:09:14: EPOCH 10 - PROGRESS: at 24.71% examples, 70063 words/s, in_qsize 61, out_qsize 2\n",
            "INFO - 18:09:16: EPOCH 10 - PROGRESS: at 44.36% examples, 79091 words/s, in_qsize 61, out_qsize 2\n",
            "INFO - 18:09:17: EPOCH 10 - PROGRESS: at 64.62% examples, 88831 words/s, in_qsize 56, out_qsize 4\n",
            "INFO - 18:09:18: worker thread finished; awaiting finish of 31 more threads\n",
            "INFO - 18:09:18: EPOCH 10 - PROGRESS: at 82.24% examples, 93809 words/s, in_qsize 30, out_qsize 1\n",
            "INFO - 18:09:18: worker thread finished; awaiting finish of 30 more threads\n",
            "INFO - 18:09:18: worker thread finished; awaiting finish of 29 more threads\n",
            "INFO - 18:09:18: worker thread finished; awaiting finish of 28 more threads\n",
            "INFO - 18:09:19: worker thread finished; awaiting finish of 27 more threads\n",
            "INFO - 18:09:19: worker thread finished; awaiting finish of 26 more threads\n",
            "INFO - 18:09:19: worker thread finished; awaiting finish of 25 more threads\n",
            "INFO - 18:09:19: worker thread finished; awaiting finish of 24 more threads\n",
            "INFO - 18:09:19: worker thread finished; awaiting finish of 23 more threads\n",
            "INFO - 18:09:19: worker thread finished; awaiting finish of 22 more threads\n",
            "INFO - 18:09:19: worker thread finished; awaiting finish of 21 more threads\n",
            "INFO - 18:09:19: worker thread finished; awaiting finish of 20 more threads\n",
            "INFO - 18:09:19: worker thread finished; awaiting finish of 19 more threads\n",
            "INFO - 18:09:19: worker thread finished; awaiting finish of 18 more threads\n",
            "INFO - 18:09:19: worker thread finished; awaiting finish of 17 more threads\n",
            "INFO - 18:09:19: worker thread finished; awaiting finish of 16 more threads\n",
            "INFO - 18:09:19: worker thread finished; awaiting finish of 15 more threads\n",
            "INFO - 18:09:19: worker thread finished; awaiting finish of 14 more threads\n",
            "INFO - 18:09:19: worker thread finished; awaiting finish of 13 more threads\n",
            "INFO - 18:09:19: worker thread finished; awaiting finish of 12 more threads\n",
            "INFO - 18:09:19: worker thread finished; awaiting finish of 11 more threads\n",
            "INFO - 18:09:19: worker thread finished; awaiting finish of 10 more threads\n",
            "INFO - 18:09:19: worker thread finished; awaiting finish of 9 more threads\n",
            "INFO - 18:09:19: worker thread finished; awaiting finish of 8 more threads\n",
            "INFO - 18:09:19: worker thread finished; awaiting finish of 7 more threads\n",
            "INFO - 18:09:19: worker thread finished; awaiting finish of 6 more threads\n",
            "INFO - 18:09:19: worker thread finished; awaiting finish of 5 more threads\n",
            "INFO - 18:09:19: worker thread finished; awaiting finish of 4 more threads\n",
            "INFO - 18:09:19: worker thread finished; awaiting finish of 3 more threads\n",
            "INFO - 18:09:19: worker thread finished; awaiting finish of 2 more threads\n",
            "INFO - 18:09:19: worker thread finished; awaiting finish of 1 more threads\n",
            "INFO - 18:09:19: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 18:09:19: EPOCH - 10 : training on 1673812 raw words (740783 effective words) took 7.5s, 99151 effective words/s\n",
            "INFO - 18:09:20: EPOCH 11 - PROGRESS: at 3.04% examples, 19465 words/s, in_qsize 63, out_qsize 0\n",
            "INFO - 18:09:21: EPOCH 11 - PROGRESS: at 22.29% examples, 76333 words/s, in_qsize 64, out_qsize 0\n",
            "INFO - 18:09:23: EPOCH 11 - PROGRESS: at 22.90% examples, 50666 words/s, in_qsize 55, out_qsize 8\n",
            "INFO - 18:09:24: EPOCH 11 - PROGRESS: at 42.01% examples, 71404 words/s, in_qsize 63, out_qsize 0\n",
            "INFO - 18:09:25: EPOCH 11 - PROGRESS: at 57.46% examples, 79398 words/s, in_qsize 64, out_qsize 0\n",
            "INFO - 18:09:26: EPOCH 11 - PROGRESS: at 61.66% examples, 70200 words/s, in_qsize 63, out_qsize 0\n",
            "INFO - 18:09:27: EPOCH 11 - PROGRESS: at 81.15% examples, 79146 words/s, in_qsize 32, out_qsize 0\n",
            "INFO - 18:09:27: worker thread finished; awaiting finish of 31 more threads\n",
            "INFO - 18:09:27: worker thread finished; awaiting finish of 30 more threads\n",
            "INFO - 18:09:27: worker thread finished; awaiting finish of 29 more threads\n",
            "INFO - 18:09:27: worker thread finished; awaiting finish of 28 more threads\n",
            "INFO - 18:09:27: worker thread finished; awaiting finish of 27 more threads\n",
            "INFO - 18:09:27: worker thread finished; awaiting finish of 26 more threads\n",
            "INFO - 18:09:27: worker thread finished; awaiting finish of 25 more threads\n",
            "INFO - 18:09:27: worker thread finished; awaiting finish of 24 more threads\n",
            "INFO - 18:09:27: worker thread finished; awaiting finish of 23 more threads\n",
            "INFO - 18:09:27: worker thread finished; awaiting finish of 22 more threads\n",
            "INFO - 18:09:27: worker thread finished; awaiting finish of 21 more threads\n",
            "INFO - 18:09:27: worker thread finished; awaiting finish of 20 more threads\n",
            "INFO - 18:09:27: worker thread finished; awaiting finish of 19 more threads\n",
            "INFO - 18:09:27: worker thread finished; awaiting finish of 18 more threads\n",
            "INFO - 18:09:27: worker thread finished; awaiting finish of 17 more threads\n",
            "INFO - 18:09:27: worker thread finished; awaiting finish of 16 more threads\n",
            "INFO - 18:09:27: worker thread finished; awaiting finish of 15 more threads\n",
            "INFO - 18:09:27: worker thread finished; awaiting finish of 14 more threads\n",
            "INFO - 18:09:27: worker thread finished; awaiting finish of 13 more threads\n",
            "INFO - 18:09:27: worker thread finished; awaiting finish of 12 more threads\n",
            "INFO - 18:09:27: worker thread finished; awaiting finish of 11 more threads\n",
            "INFO - 18:09:27: worker thread finished; awaiting finish of 10 more threads\n",
            "INFO - 18:09:27: worker thread finished; awaiting finish of 9 more threads\n",
            "INFO - 18:09:27: worker thread finished; awaiting finish of 8 more threads\n",
            "INFO - 18:09:27: worker thread finished; awaiting finish of 7 more threads\n",
            "INFO - 18:09:27: worker thread finished; awaiting finish of 6 more threads\n",
            "INFO - 18:09:27: worker thread finished; awaiting finish of 5 more threads\n",
            "INFO - 18:09:27: worker thread finished; awaiting finish of 4 more threads\n",
            "INFO - 18:09:27: worker thread finished; awaiting finish of 3 more threads\n",
            "INFO - 18:09:27: worker thread finished; awaiting finish of 2 more threads\n",
            "INFO - 18:09:27: worker thread finished; awaiting finish of 1 more threads\n",
            "INFO - 18:09:27: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 18:09:27: EPOCH - 11 : training on 1673812 raw words (741425 effective words) took 8.1s, 91253 effective words/s\n",
            "INFO - 18:09:29: EPOCH 12 - PROGRESS: at 5.58% examples, 38488 words/s, in_qsize 60, out_qsize 3\n",
            "INFO - 18:09:30: EPOCH 12 - PROGRESS: at 25.91% examples, 88113 words/s, in_qsize 63, out_qsize 0\n",
            "INFO - 18:09:31: EPOCH 12 - PROGRESS: at 41.42% examples, 94806 words/s, in_qsize 63, out_qsize 4\n",
            "INFO - 18:09:32: EPOCH 12 - PROGRESS: at 55.70% examples, 96167 words/s, in_qsize 62, out_qsize 1\n",
            "INFO - 18:09:33: EPOCH 12 - PROGRESS: at 78.80% examples, 110451 words/s, in_qsize 36, out_qsize 0\n",
            "INFO - 18:09:33: worker thread finished; awaiting finish of 31 more threads\n",
            "INFO - 18:09:33: worker thread finished; awaiting finish of 30 more threads\n",
            "INFO - 18:09:33: worker thread finished; awaiting finish of 29 more threads\n",
            "INFO - 18:09:33: worker thread finished; awaiting finish of 28 more threads\n",
            "INFO - 18:09:33: worker thread finished; awaiting finish of 27 more threads\n",
            "INFO - 18:09:33: worker thread finished; awaiting finish of 26 more threads\n",
            "INFO - 18:09:33: worker thread finished; awaiting finish of 25 more threads\n",
            "INFO - 18:09:34: worker thread finished; awaiting finish of 24 more threads\n",
            "INFO - 18:09:34: worker thread finished; awaiting finish of 23 more threads\n",
            "INFO - 18:09:34: worker thread finished; awaiting finish of 22 more threads\n",
            "INFO - 18:09:34: worker thread finished; awaiting finish of 21 more threads\n",
            "INFO - 18:09:34: worker thread finished; awaiting finish of 20 more threads\n",
            "INFO - 18:09:34: worker thread finished; awaiting finish of 19 more threads\n",
            "INFO - 18:09:34: worker thread finished; awaiting finish of 18 more threads\n",
            "INFO - 18:09:34: worker thread finished; awaiting finish of 17 more threads\n",
            "INFO - 18:09:34: worker thread finished; awaiting finish of 16 more threads\n",
            "INFO - 18:09:34: worker thread finished; awaiting finish of 15 more threads\n",
            "INFO - 18:09:34: worker thread finished; awaiting finish of 14 more threads\n",
            "INFO - 18:09:34: worker thread finished; awaiting finish of 13 more threads\n",
            "INFO - 18:09:34: worker thread finished; awaiting finish of 12 more threads\n",
            "INFO - 18:09:34: worker thread finished; awaiting finish of 11 more threads\n",
            "INFO - 18:09:34: EPOCH 12 - PROGRESS: at 94.24% examples, 110771 words/s, in_qsize 10, out_qsize 1\n",
            "INFO - 18:09:34: worker thread finished; awaiting finish of 10 more threads\n",
            "INFO - 18:09:34: worker thread finished; awaiting finish of 9 more threads\n",
            "INFO - 18:09:34: worker thread finished; awaiting finish of 8 more threads\n",
            "INFO - 18:09:34: worker thread finished; awaiting finish of 7 more threads\n",
            "INFO - 18:09:34: worker thread finished; awaiting finish of 6 more threads\n",
            "INFO - 18:09:34: worker thread finished; awaiting finish of 5 more threads\n",
            "INFO - 18:09:34: worker thread finished; awaiting finish of 4 more threads\n",
            "INFO - 18:09:34: worker thread finished; awaiting finish of 3 more threads\n",
            "INFO - 18:09:34: worker thread finished; awaiting finish of 2 more threads\n",
            "INFO - 18:09:34: worker thread finished; awaiting finish of 1 more threads\n",
            "INFO - 18:09:34: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 18:09:34: EPOCH - 12 : training on 1673812 raw words (741141 effective words) took 6.4s, 115441 effective words/s\n",
            "INFO - 18:09:35: EPOCH 13 - PROGRESS: at 6.69% examples, 45794 words/s, in_qsize 63, out_qsize 0\n",
            "INFO - 18:09:36: EPOCH 13 - PROGRESS: at 21.66% examples, 76782 words/s, in_qsize 63, out_qsize 2\n",
            "INFO - 18:09:37: EPOCH 13 - PROGRESS: at 27.76% examples, 65474 words/s, in_qsize 63, out_qsize 7\n",
            "INFO - 18:09:38: EPOCH 13 - PROGRESS: at 45.57% examples, 80830 words/s, in_qsize 62, out_qsize 1\n",
            "INFO - 18:09:40: EPOCH 13 - PROGRESS: at 65.16% examples, 83817 words/s, in_qsize 53, out_qsize 6\n",
            "INFO - 18:09:40: worker thread finished; awaiting finish of 31 more threads\n",
            "INFO - 18:09:41: worker thread finished; awaiting finish of 30 more threads\n",
            "INFO - 18:09:41: worker thread finished; awaiting finish of 29 more threads\n",
            "INFO - 18:09:41: worker thread finished; awaiting finish of 28 more threads\n",
            "INFO - 18:09:41: worker thread finished; awaiting finish of 27 more threads\n",
            "INFO - 18:09:41: EPOCH 13 - PROGRESS: at 84.72% examples, 87874 words/s, in_qsize 23, out_qsize 7\n",
            "INFO - 18:09:41: worker thread finished; awaiting finish of 26 more threads\n",
            "INFO - 18:09:41: worker thread finished; awaiting finish of 25 more threads\n",
            "INFO - 18:09:41: worker thread finished; awaiting finish of 24 more threads\n",
            "INFO - 18:09:41: worker thread finished; awaiting finish of 23 more threads\n",
            "INFO - 18:09:41: worker thread finished; awaiting finish of 22 more threads\n",
            "INFO - 18:09:41: worker thread finished; awaiting finish of 21 more threads\n",
            "INFO - 18:09:41: worker thread finished; awaiting finish of 20 more threads\n",
            "INFO - 18:09:41: worker thread finished; awaiting finish of 19 more threads\n",
            "INFO - 18:09:41: worker thread finished; awaiting finish of 18 more threads\n",
            "INFO - 18:09:41: worker thread finished; awaiting finish of 17 more threads\n",
            "INFO - 18:09:41: worker thread finished; awaiting finish of 16 more threads\n",
            "INFO - 18:09:41: worker thread finished; awaiting finish of 15 more threads\n",
            "INFO - 18:09:41: worker thread finished; awaiting finish of 14 more threads\n",
            "INFO - 18:09:41: worker thread finished; awaiting finish of 13 more threads\n",
            "INFO - 18:09:41: worker thread finished; awaiting finish of 12 more threads\n",
            "INFO - 18:09:41: worker thread finished; awaiting finish of 11 more threads\n",
            "INFO - 18:09:41: worker thread finished; awaiting finish of 10 more threads\n",
            "INFO - 18:09:41: worker thread finished; awaiting finish of 9 more threads\n",
            "INFO - 18:09:41: worker thread finished; awaiting finish of 8 more threads\n",
            "INFO - 18:09:41: worker thread finished; awaiting finish of 7 more threads\n",
            "INFO - 18:09:42: worker thread finished; awaiting finish of 6 more threads\n",
            "INFO - 18:09:42: worker thread finished; awaiting finish of 5 more threads\n",
            "INFO - 18:09:42: worker thread finished; awaiting finish of 4 more threads\n",
            "INFO - 18:09:42: worker thread finished; awaiting finish of 3 more threads\n",
            "INFO - 18:09:42: worker thread finished; awaiting finish of 2 more threads\n",
            "INFO - 18:09:42: worker thread finished; awaiting finish of 1 more threads\n",
            "INFO - 18:09:42: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 18:09:42: EPOCH - 13 : training on 1673812 raw words (740142 effective words) took 7.6s, 97400 effective words/s\n",
            "INFO - 18:09:43: EPOCH 14 - PROGRESS: at 4.26% examples, 23620 words/s, in_qsize 63, out_qsize 0\n",
            "INFO - 18:09:44: EPOCH 14 - PROGRESS: at 24.70% examples, 74959 words/s, in_qsize 62, out_qsize 1\n",
            "INFO - 18:09:45: EPOCH 14 - PROGRESS: at 39.13% examples, 83792 words/s, in_qsize 64, out_qsize 0\n",
            "INFO - 18:09:46: EPOCH 14 - PROGRESS: at 51.92% examples, 85440 words/s, in_qsize 61, out_qsize 2\n",
            "INFO - 18:09:47: EPOCH 14 - PROGRESS: at 73.94% examples, 98662 words/s, in_qsize 44, out_qsize 0\n",
            "INFO - 18:09:48: worker thread finished; awaiting finish of 31 more threads\n",
            "INFO - 18:09:48: worker thread finished; awaiting finish of 30 more threads\n",
            "INFO - 18:09:48: worker thread finished; awaiting finish of 29 more threads\n",
            "INFO - 18:09:48: worker thread finished; awaiting finish of 28 more threads\n",
            "INFO - 18:09:48: worker thread finished; awaiting finish of 27 more threads\n",
            "INFO - 18:09:48: worker thread finished; awaiting finish of 26 more threads\n",
            "INFO - 18:09:48: worker thread finished; awaiting finish of 25 more threads\n",
            "INFO - 18:09:48: worker thread finished; awaiting finish of 24 more threads\n",
            "INFO - 18:09:48: worker thread finished; awaiting finish of 23 more threads\n",
            "INFO - 18:09:48: worker thread finished; awaiting finish of 22 more threads\n",
            "INFO - 18:09:48: worker thread finished; awaiting finish of 21 more threads\n",
            "INFO - 18:09:48: worker thread finished; awaiting finish of 20 more threads\n",
            "INFO - 18:09:48: worker thread finished; awaiting finish of 19 more threads\n",
            "INFO - 18:09:48: worker thread finished; awaiting finish of 18 more threads\n",
            "INFO - 18:09:48: EPOCH 14 - PROGRESS: at 90.07% examples, 100598 words/s, in_qsize 16, out_qsize 3\n",
            "INFO - 18:09:48: worker thread finished; awaiting finish of 17 more threads\n",
            "INFO - 18:09:48: worker thread finished; awaiting finish of 16 more threads\n",
            "INFO - 18:09:48: worker thread finished; awaiting finish of 15 more threads\n",
            "INFO - 18:09:48: worker thread finished; awaiting finish of 14 more threads\n",
            "INFO - 18:09:48: worker thread finished; awaiting finish of 13 more threads\n",
            "INFO - 18:09:48: worker thread finished; awaiting finish of 12 more threads\n",
            "INFO - 18:09:48: worker thread finished; awaiting finish of 11 more threads\n",
            "INFO - 18:09:48: worker thread finished; awaiting finish of 10 more threads\n",
            "INFO - 18:09:48: worker thread finished; awaiting finish of 9 more threads\n",
            "INFO - 18:09:48: worker thread finished; awaiting finish of 8 more threads\n",
            "INFO - 18:09:48: worker thread finished; awaiting finish of 7 more threads\n",
            "INFO - 18:09:48: worker thread finished; awaiting finish of 6 more threads\n",
            "INFO - 18:09:48: worker thread finished; awaiting finish of 5 more threads\n",
            "INFO - 18:09:48: worker thread finished; awaiting finish of 4 more threads\n",
            "INFO - 18:09:48: worker thread finished; awaiting finish of 3 more threads\n",
            "INFO - 18:09:48: worker thread finished; awaiting finish of 2 more threads\n",
            "INFO - 18:09:48: worker thread finished; awaiting finish of 1 more threads\n",
            "INFO - 18:09:49: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 18:09:49: EPOCH - 14 : training on 1673812 raw words (741245 effective words) took 6.8s, 109475 effective words/s\n",
            "INFO - 18:09:50: EPOCH 15 - PROGRESS: at 3.03% examples, 19073 words/s, in_qsize 62, out_qsize 1\n",
            "INFO - 18:09:51: EPOCH 15 - PROGRESS: at 22.31% examples, 74968 words/s, in_qsize 63, out_qsize 0\n",
            "INFO - 18:09:52: EPOCH 15 - PROGRESS: at 37.91% examples, 87183 words/s, in_qsize 63, out_qsize 0\n",
            "INFO - 18:09:53: EPOCH 15 - PROGRESS: at 53.86% examples, 92372 words/s, in_qsize 63, out_qsize 0\n",
            "INFO - 18:09:54: EPOCH 15 - PROGRESS: at 63.34% examples, 87855 words/s, in_qsize 62, out_qsize 0\n",
            "INFO - 18:09:55: worker thread finished; awaiting finish of 31 more threads\n",
            "INFO - 18:09:55: worker thread finished; awaiting finish of 30 more threads\n",
            "INFO - 18:09:55: EPOCH 15 - PROGRESS: at 82.88% examples, 96512 words/s, in_qsize 29, out_qsize 1\n",
            "INFO - 18:09:55: worker thread finished; awaiting finish of 29 more threads\n",
            "INFO - 18:09:55: worker thread finished; awaiting finish of 28 more threads\n",
            "INFO - 18:09:55: worker thread finished; awaiting finish of 27 more threads\n",
            "INFO - 18:09:55: worker thread finished; awaiting finish of 26 more threads\n",
            "INFO - 18:09:55: worker thread finished; awaiting finish of 25 more threads\n",
            "INFO - 18:09:55: worker thread finished; awaiting finish of 24 more threads\n",
            "INFO - 18:09:55: worker thread finished; awaiting finish of 23 more threads\n",
            "INFO - 18:09:55: worker thread finished; awaiting finish of 22 more threads\n",
            "INFO - 18:09:55: worker thread finished; awaiting finish of 21 more threads\n",
            "INFO - 18:09:55: worker thread finished; awaiting finish of 20 more threads\n",
            "INFO - 18:09:55: worker thread finished; awaiting finish of 19 more threads\n",
            "INFO - 18:09:55: worker thread finished; awaiting finish of 18 more threads\n",
            "INFO - 18:09:55: worker thread finished; awaiting finish of 17 more threads\n",
            "INFO - 18:09:55: worker thread finished; awaiting finish of 16 more threads\n",
            "INFO - 18:09:55: worker thread finished; awaiting finish of 15 more threads\n",
            "INFO - 18:09:55: worker thread finished; awaiting finish of 14 more threads\n",
            "INFO - 18:09:55: worker thread finished; awaiting finish of 13 more threads\n",
            "INFO - 18:09:55: worker thread finished; awaiting finish of 12 more threads\n",
            "INFO - 18:09:55: worker thread finished; awaiting finish of 11 more threads\n",
            "INFO - 18:09:55: worker thread finished; awaiting finish of 10 more threads\n",
            "INFO - 18:09:55: worker thread finished; awaiting finish of 9 more threads\n",
            "INFO - 18:09:55: worker thread finished; awaiting finish of 8 more threads\n",
            "INFO - 18:09:55: worker thread finished; awaiting finish of 7 more threads\n",
            "INFO - 18:09:56: worker thread finished; awaiting finish of 6 more threads\n",
            "INFO - 18:09:56: worker thread finished; awaiting finish of 5 more threads\n",
            "INFO - 18:09:56: worker thread finished; awaiting finish of 4 more threads\n",
            "INFO - 18:09:56: worker thread finished; awaiting finish of 3 more threads\n",
            "INFO - 18:09:56: worker thread finished; awaiting finish of 2 more threads\n",
            "INFO - 18:09:56: worker thread finished; awaiting finish of 1 more threads\n",
            "INFO - 18:09:56: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 18:09:56: EPOCH - 15 : training on 1673812 raw words (741699 effective words) took 7.0s, 106369 effective words/s\n",
            "INFO - 18:09:57: EPOCH 16 - PROGRESS: at 4.30% examples, 29196 words/s, in_qsize 63, out_qsize 0\n",
            "INFO - 18:09:58: EPOCH 16 - PROGRESS: at 22.85% examples, 80727 words/s, in_qsize 63, out_qsize 0\n",
            "INFO - 18:09:59: EPOCH 16 - PROGRESS: at 28.24% examples, 66026 words/s, in_qsize 64, out_qsize 6\n",
            "INFO - 18:10:00: EPOCH 16 - PROGRESS: at 44.40% examples, 76350 words/s, in_qsize 61, out_qsize 2\n",
            "INFO - 18:10:01: EPOCH 16 - PROGRESS: at 63.46% examples, 88639 words/s, in_qsize 62, out_qsize 0\n",
            "INFO - 18:10:02: EPOCH 16 - PROGRESS: at 77.41% examples, 89416 words/s, in_qsize 36, out_qsize 2\n",
            "INFO - 18:10:02: worker thread finished; awaiting finish of 31 more threads\n",
            "INFO - 18:10:02: worker thread finished; awaiting finish of 30 more threads\n",
            "INFO - 18:10:03: worker thread finished; awaiting finish of 29 more threads\n",
            "INFO - 18:10:03: EPOCH 16 - PROGRESS: at 83.44% examples, 82103 words/s, in_qsize 11, out_qsize 35\n",
            "INFO - 18:10:03: worker thread finished; awaiting finish of 28 more threads\n",
            "INFO - 18:10:03: worker thread finished; awaiting finish of 27 more threads\n",
            "INFO - 18:10:03: worker thread finished; awaiting finish of 26 more threads\n",
            "INFO - 18:10:03: worker thread finished; awaiting finish of 25 more threads\n",
            "INFO - 18:10:03: worker thread finished; awaiting finish of 24 more threads\n",
            "INFO - 18:10:03: worker thread finished; awaiting finish of 23 more threads\n",
            "INFO - 18:10:03: worker thread finished; awaiting finish of 22 more threads\n",
            "INFO - 18:10:03: worker thread finished; awaiting finish of 21 more threads\n",
            "INFO - 18:10:03: worker thread finished; awaiting finish of 20 more threads\n",
            "INFO - 18:10:03: worker thread finished; awaiting finish of 19 more threads\n",
            "INFO - 18:10:03: worker thread finished; awaiting finish of 18 more threads\n",
            "INFO - 18:10:03: worker thread finished; awaiting finish of 17 more threads\n",
            "INFO - 18:10:03: worker thread finished; awaiting finish of 16 more threads\n",
            "INFO - 18:10:03: worker thread finished; awaiting finish of 15 more threads\n",
            "INFO - 18:10:03: worker thread finished; awaiting finish of 14 more threads\n",
            "INFO - 18:10:03: worker thread finished; awaiting finish of 13 more threads\n",
            "INFO - 18:10:03: worker thread finished; awaiting finish of 12 more threads\n",
            "INFO - 18:10:03: worker thread finished; awaiting finish of 11 more threads\n",
            "INFO - 18:10:03: worker thread finished; awaiting finish of 10 more threads\n",
            "INFO - 18:10:03: worker thread finished; awaiting finish of 9 more threads\n",
            "INFO - 18:10:03: worker thread finished; awaiting finish of 8 more threads\n",
            "INFO - 18:10:03: worker thread finished; awaiting finish of 7 more threads\n",
            "INFO - 18:10:03: worker thread finished; awaiting finish of 6 more threads\n",
            "INFO - 18:10:03: worker thread finished; awaiting finish of 5 more threads\n",
            "INFO - 18:10:03: worker thread finished; awaiting finish of 4 more threads\n",
            "INFO - 18:10:03: worker thread finished; awaiting finish of 3 more threads\n",
            "INFO - 18:10:03: worker thread finished; awaiting finish of 2 more threads\n",
            "INFO - 18:10:03: worker thread finished; awaiting finish of 1 more threads\n",
            "INFO - 18:10:03: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 18:10:03: EPOCH - 16 : training on 1673812 raw words (740929 effective words) took 7.8s, 94768 effective words/s\n",
            "INFO - 18:10:05: EPOCH 17 - PROGRESS: at 1.84% examples, 7358 words/s, in_qsize 58, out_qsize 12\n",
            "INFO - 18:10:07: EPOCH 17 - PROGRESS: at 24.66% examples, 57994 words/s, in_qsize 61, out_qsize 2\n",
            "INFO - 18:10:08: EPOCH 17 - PROGRESS: at 44.91% examples, 74130 words/s, in_qsize 62, out_qsize 1\n",
            "INFO - 18:10:10: EPOCH 17 - PROGRESS: at 64.67% examples, 80520 words/s, in_qsize 54, out_qsize 6\n",
            "INFO - 18:10:10: worker thread finished; awaiting finish of 31 more threads\n",
            "INFO - 18:10:11: worker thread finished; awaiting finish of 30 more threads\n",
            "INFO - 18:10:11: EPOCH 17 - PROGRESS: at 82.88% examples, 87433 words/s, in_qsize 28, out_qsize 3\n",
            "INFO - 18:10:11: worker thread finished; awaiting finish of 29 more threads\n",
            "INFO - 18:10:11: worker thread finished; awaiting finish of 28 more threads\n",
            "INFO - 18:10:11: worker thread finished; awaiting finish of 27 more threads\n",
            "INFO - 18:10:11: worker thread finished; awaiting finish of 26 more threads\n",
            "INFO - 18:10:11: worker thread finished; awaiting finish of 25 more threads\n",
            "INFO - 18:10:11: worker thread finished; awaiting finish of 24 more threads\n",
            "INFO - 18:10:11: worker thread finished; awaiting finish of 23 more threads\n",
            "INFO - 18:10:11: worker thread finished; awaiting finish of 22 more threads\n",
            "INFO - 18:10:11: worker thread finished; awaiting finish of 21 more threads\n",
            "INFO - 18:10:11: worker thread finished; awaiting finish of 20 more threads\n",
            "INFO - 18:10:11: worker thread finished; awaiting finish of 19 more threads\n",
            "INFO - 18:10:11: worker thread finished; awaiting finish of 18 more threads\n",
            "INFO - 18:10:11: worker thread finished; awaiting finish of 17 more threads\n",
            "INFO - 18:10:11: worker thread finished; awaiting finish of 16 more threads\n",
            "INFO - 18:10:11: worker thread finished; awaiting finish of 15 more threads\n",
            "INFO - 18:10:11: worker thread finished; awaiting finish of 14 more threads\n",
            "INFO - 18:10:12: worker thread finished; awaiting finish of 13 more threads\n",
            "INFO - 18:10:12: worker thread finished; awaiting finish of 12 more threads\n",
            "INFO - 18:10:12: EPOCH 17 - PROGRESS: at 93.35% examples, 86102 words/s, in_qsize 11, out_qsize 1\n",
            "INFO - 18:10:12: worker thread finished; awaiting finish of 11 more threads\n",
            "INFO - 18:10:12: worker thread finished; awaiting finish of 10 more threads\n",
            "INFO - 18:10:12: worker thread finished; awaiting finish of 9 more threads\n",
            "INFO - 18:10:12: worker thread finished; awaiting finish of 8 more threads\n",
            "INFO - 18:10:12: worker thread finished; awaiting finish of 7 more threads\n",
            "INFO - 18:10:12: worker thread finished; awaiting finish of 6 more threads\n",
            "INFO - 18:10:12: worker thread finished; awaiting finish of 5 more threads\n",
            "INFO - 18:10:12: worker thread finished; awaiting finish of 4 more threads\n",
            "INFO - 18:10:12: worker thread finished; awaiting finish of 3 more threads\n",
            "INFO - 18:10:12: worker thread finished; awaiting finish of 2 more threads\n",
            "INFO - 18:10:12: worker thread finished; awaiting finish of 1 more threads\n",
            "INFO - 18:10:12: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 18:10:12: EPOCH - 17 : training on 1673812 raw words (740915 effective words) took 8.2s, 90787 effective words/s\n",
            "INFO - 18:10:13: EPOCH 18 - PROGRESS: at 1.76% examples, 12820 words/s, in_qsize 63, out_qsize 0\n",
            "INFO - 18:10:14: EPOCH 18 - PROGRESS: at 21.10% examples, 75195 words/s, in_qsize 63, out_qsize 0\n",
            "INFO - 18:10:15: EPOCH 18 - PROGRESS: at 26.50% examples, 62520 words/s, in_qsize 62, out_qsize 1\n",
            "INFO - 18:10:16: EPOCH 18 - PROGRESS: at 45.48% examples, 78693 words/s, in_qsize 64, out_qsize 2\n",
            "INFO - 18:10:17: EPOCH 18 - PROGRESS: at 62.84% examples, 87853 words/s, in_qsize 61, out_qsize 2\n",
            "INFO - 18:10:18: EPOCH 18 - PROGRESS: at 78.11% examples, 90680 words/s, in_qsize 37, out_qsize 0\n",
            "INFO - 18:10:18: worker thread finished; awaiting finish of 31 more threads\n",
            "INFO - 18:10:19: worker thread finished; awaiting finish of 30 more threads\n",
            "INFO - 18:10:19: worker thread finished; awaiting finish of 29 more threads\n",
            "INFO - 18:10:19: worker thread finished; awaiting finish of 28 more threads\n",
            "INFO - 18:10:19: worker thread finished; awaiting finish of 27 more threads\n",
            "INFO - 18:10:19: worker thread finished; awaiting finish of 26 more threads\n",
            "INFO - 18:10:19: worker thread finished; awaiting finish of 25 more threads\n",
            "INFO - 18:10:19: EPOCH 18 - PROGRESS: at 85.90% examples, 85629 words/s, in_qsize 21, out_qsize 7\n",
            "INFO - 18:10:19: worker thread finished; awaiting finish of 24 more threads\n",
            "INFO - 18:10:19: worker thread finished; awaiting finish of 23 more threads\n",
            "INFO - 18:10:19: worker thread finished; awaiting finish of 22 more threads\n",
            "INFO - 18:10:19: worker thread finished; awaiting finish of 21 more threads\n",
            "INFO - 18:10:19: worker thread finished; awaiting finish of 20 more threads\n",
            "INFO - 18:10:19: worker thread finished; awaiting finish of 19 more threads\n",
            "INFO - 18:10:19: worker thread finished; awaiting finish of 18 more threads\n",
            "INFO - 18:10:19: worker thread finished; awaiting finish of 17 more threads\n",
            "INFO - 18:10:19: worker thread finished; awaiting finish of 16 more threads\n",
            "INFO - 18:10:19: worker thread finished; awaiting finish of 15 more threads\n",
            "INFO - 18:10:19: worker thread finished; awaiting finish of 14 more threads\n",
            "INFO - 18:10:19: worker thread finished; awaiting finish of 13 more threads\n",
            "INFO - 18:10:19: worker thread finished; awaiting finish of 12 more threads\n",
            "INFO - 18:10:19: worker thread finished; awaiting finish of 11 more threads\n",
            "INFO - 18:10:19: worker thread finished; awaiting finish of 10 more threads\n",
            "INFO - 18:10:19: worker thread finished; awaiting finish of 9 more threads\n",
            "INFO - 18:10:19: worker thread finished; awaiting finish of 8 more threads\n",
            "INFO - 18:10:19: worker thread finished; awaiting finish of 7 more threads\n",
            "INFO - 18:10:19: worker thread finished; awaiting finish of 6 more threads\n",
            "INFO - 18:10:19: worker thread finished; awaiting finish of 5 more threads\n",
            "INFO - 18:10:19: worker thread finished; awaiting finish of 4 more threads\n",
            "INFO - 18:10:19: worker thread finished; awaiting finish of 3 more threads\n",
            "INFO - 18:10:19: worker thread finished; awaiting finish of 2 more threads\n",
            "INFO - 18:10:19: worker thread finished; awaiting finish of 1 more threads\n",
            "INFO - 18:10:20: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 18:10:20: EPOCH - 18 : training on 1673812 raw words (741813 effective words) took 7.7s, 96684 effective words/s\n",
            "INFO - 18:10:21: EPOCH 19 - PROGRESS: at 4.96% examples, 30771 words/s, in_qsize 63, out_qsize 0\n",
            "INFO - 18:10:22: EPOCH 19 - PROGRESS: at 26.50% examples, 90063 words/s, in_qsize 63, out_qsize 0\n",
            "INFO - 18:10:23: EPOCH 19 - PROGRESS: at 35.47% examples, 81889 words/s, in_qsize 62, out_qsize 1\n",
            "INFO - 18:10:24: EPOCH 19 - PROGRESS: at 53.24% examples, 88740 words/s, in_qsize 63, out_qsize 0\n",
            "INFO - 18:10:25: EPOCH 19 - PROGRESS: at 70.93% examples, 95546 words/s, in_qsize 49, out_qsize 0\n",
            "INFO - 18:10:26: worker thread finished; awaiting finish of 31 more threads\n",
            "INFO - 18:10:27: EPOCH 19 - PROGRESS: at 82.39% examples, 90368 words/s, in_qsize 25, out_qsize 11\n",
            "INFO - 18:10:27: worker thread finished; awaiting finish of 30 more threads\n",
            "INFO - 18:10:27: worker thread finished; awaiting finish of 29 more threads\n",
            "INFO - 18:10:27: worker thread finished; awaiting finish of 28 more threads\n",
            "INFO - 18:10:27: worker thread finished; awaiting finish of 27 more threads\n",
            "INFO - 18:10:27: worker thread finished; awaiting finish of 26 more threads\n",
            "INFO - 18:10:27: worker thread finished; awaiting finish of 25 more threads\n",
            "INFO - 18:10:27: worker thread finished; awaiting finish of 24 more threads\n",
            "INFO - 18:10:27: worker thread finished; awaiting finish of 23 more threads\n",
            "INFO - 18:10:27: worker thread finished; awaiting finish of 22 more threads\n",
            "INFO - 18:10:27: worker thread finished; awaiting finish of 21 more threads\n",
            "INFO - 18:10:27: worker thread finished; awaiting finish of 20 more threads\n",
            "INFO - 18:10:27: worker thread finished; awaiting finish of 19 more threads\n",
            "INFO - 18:10:27: worker thread finished; awaiting finish of 18 more threads\n",
            "INFO - 18:10:27: worker thread finished; awaiting finish of 17 more threads\n",
            "INFO - 18:10:27: worker thread finished; awaiting finish of 16 more threads\n",
            "INFO - 18:10:27: worker thread finished; awaiting finish of 15 more threads\n",
            "INFO - 18:10:27: worker thread finished; awaiting finish of 14 more threads\n",
            "INFO - 18:10:27: worker thread finished; awaiting finish of 13 more threads\n",
            "INFO - 18:10:27: worker thread finished; awaiting finish of 12 more threads\n",
            "INFO - 18:10:27: worker thread finished; awaiting finish of 11 more threads\n",
            "INFO - 18:10:27: worker thread finished; awaiting finish of 10 more threads\n",
            "INFO - 18:10:27: worker thread finished; awaiting finish of 9 more threads\n",
            "INFO - 18:10:27: worker thread finished; awaiting finish of 8 more threads\n",
            "INFO - 18:10:27: worker thread finished; awaiting finish of 7 more threads\n",
            "INFO - 18:10:27: worker thread finished; awaiting finish of 6 more threads\n",
            "INFO - 18:10:27: worker thread finished; awaiting finish of 5 more threads\n",
            "INFO - 18:10:27: worker thread finished; awaiting finish of 4 more threads\n",
            "INFO - 18:10:27: worker thread finished; awaiting finish of 3 more threads\n",
            "INFO - 18:10:27: worker thread finished; awaiting finish of 2 more threads\n",
            "INFO - 18:10:27: worker thread finished; awaiting finish of 1 more threads\n",
            "INFO - 18:10:27: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 18:10:27: EPOCH - 19 : training on 1673812 raw words (741356 effective words) took 7.3s, 101766 effective words/s\n",
            "INFO - 18:10:29: EPOCH 20 - PROGRESS: at 6.18% examples, 34031 words/s, in_qsize 63, out_qsize 0\n",
            "INFO - 18:10:30: EPOCH 20 - PROGRESS: at 27.74% examples, 86162 words/s, in_qsize 61, out_qsize 2\n",
            "INFO - 18:10:31: EPOCH 20 - PROGRESS: at 40.20% examples, 88090 words/s, in_qsize 63, out_qsize 0\n",
            "INFO - 18:10:32: EPOCH 20 - PROGRESS: at 61.08% examples, 102197 words/s, in_qsize 60, out_qsize 3\n",
            "INFO - 18:10:33: EPOCH 20 - PROGRESS: at 75.17% examples, 98610 words/s, in_qsize 40, out_qsize 2\n",
            "INFO - 18:10:33: worker thread finished; awaiting finish of 31 more threads\n",
            "INFO - 18:10:33: worker thread finished; awaiting finish of 30 more threads\n",
            "INFO - 18:10:33: worker thread finished; awaiting finish of 29 more threads\n",
            "INFO - 18:10:33: worker thread finished; awaiting finish of 28 more threads\n",
            "INFO - 18:10:33: worker thread finished; awaiting finish of 27 more threads\n",
            "INFO - 18:10:33: worker thread finished; awaiting finish of 26 more threads\n",
            "INFO - 18:10:34: worker thread finished; awaiting finish of 25 more threads\n",
            "INFO - 18:10:34: worker thread finished; awaiting finish of 24 more threads\n",
            "INFO - 18:10:34: worker thread finished; awaiting finish of 23 more threads\n",
            "INFO - 18:10:34: worker thread finished; awaiting finish of 22 more threads\n",
            "INFO - 18:10:34: worker thread finished; awaiting finish of 21 more threads\n",
            "INFO - 18:10:34: worker thread finished; awaiting finish of 20 more threads\n",
            "INFO - 18:10:34: worker thread finished; awaiting finish of 19 more threads\n",
            "INFO - 18:10:34: worker thread finished; awaiting finish of 18 more threads\n",
            "INFO - 18:10:34: worker thread finished; awaiting finish of 17 more threads\n",
            "INFO - 18:10:34: worker thread finished; awaiting finish of 16 more threads\n",
            "INFO - 18:10:34: worker thread finished; awaiting finish of 15 more threads\n",
            "INFO - 18:10:34: worker thread finished; awaiting finish of 14 more threads\n",
            "INFO - 18:10:34: worker thread finished; awaiting finish of 13 more threads\n",
            "INFO - 18:10:34: worker thread finished; awaiting finish of 12 more threads\n",
            "INFO - 18:10:34: EPOCH 20 - PROGRESS: at 93.71% examples, 104304 words/s, in_qsize 11, out_qsize 1\n",
            "INFO - 18:10:34: worker thread finished; awaiting finish of 11 more threads\n",
            "INFO - 18:10:34: worker thread finished; awaiting finish of 10 more threads\n",
            "INFO - 18:10:34: worker thread finished; awaiting finish of 9 more threads\n",
            "INFO - 18:10:34: worker thread finished; awaiting finish of 8 more threads\n",
            "INFO - 18:10:34: worker thread finished; awaiting finish of 7 more threads\n",
            "INFO - 18:10:34: worker thread finished; awaiting finish of 6 more threads\n",
            "INFO - 18:10:34: worker thread finished; awaiting finish of 5 more threads\n",
            "INFO - 18:10:34: worker thread finished; awaiting finish of 4 more threads\n",
            "INFO - 18:10:34: worker thread finished; awaiting finish of 3 more threads\n",
            "INFO - 18:10:34: worker thread finished; awaiting finish of 2 more threads\n",
            "INFO - 18:10:34: worker thread finished; awaiting finish of 1 more threads\n",
            "INFO - 18:10:34: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 18:10:34: EPOCH - 20 : training on 1673812 raw words (740751 effective words) took 6.8s, 109236 effective words/s\n",
            "INFO - 18:10:34: training on a 33476240 raw words (14821705 effective words) took 149.5s, 99116 effective words/s\n"
          ]
        }
      ],
      "source": [
        "modelFastTextSkipGram = FastText(tokenized_tag, \n",
        "                     size=200, # desired no. of features/independent variables\n",
        "                     window=2,  # context window size\n",
        "                     min_count=2, # Ignores all words with total frequency lower than 2.  \n",
        "                     workers=32, # no.of cores\n",
        "                     hs = 0,\n",
        "                     negative = 10, # for negative sampling\n",
        "                     sg=1  # 1 for Skipgram model\n",
        "                     )\n",
        "\n",
        "modelFastTextSkipGram.build_vocab(tokenized_tag, update=True)\n",
        "modelFastTextSkipGram.train(tokenized_tag, total_examples= len(tokenized_tag), epochs=20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO - 18:11:12: saving FastText object under C:\\Users\\jyoti\\Desktop\\NLP\\NLP_project\\NLP-project-\\Save Models\\200_fastText_Skipgram_.model, separately None\n",
            "INFO - 18:11:12: not storing attribute vectors_norm\n",
            "INFO - 18:11:12: not storing attribute vectors_vocab_norm\n",
            "INFO - 18:11:12: not storing attribute vectors_ngrams_norm\n",
            "INFO - 18:11:12: not storing attribute buckets_word\n",
            "INFO - 18:11:13: saved C:\\Users\\jyoti\\Desktop\\NLP\\NLP_project\\NLP-project-\\Save Models\\200_fastText_Skipgram_.model\n"
          ]
        }
      ],
      "source": [
        "modelFastTextSkipGram.save(path+ \"Save Models\\\\200_fastText_Skipgram_.model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('nunatak', 0.740767776966095),\n",
              " ('tagliatelle', 0.7130957841873169),\n",
              " ('3d', 0.6915515065193176),\n",
              " ('alps', 0.6907766461372375),\n",
              " ('crispy', 0.6732327938079834),\n",
              " ('phalaenopsis', 0.6709675788879395),\n",
              " ('mehndi', 0.6667892336845398),\n",
              " ('x', 0.6666353940963745),\n",
              " ('karaage', 0.6663018465042114),\n",
              " ('falafel', 0.6660338640213013)]"
            ]
          },
          "execution_count": 75,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "modelFastTextSkipGram.wv.most_similar(\"Gastroenteritis\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fn-_Wh2ajey1",
        "outputId": "d26fc404-2421-4955-c32f-ca37a06a8951"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('flatbread', 0.7030203342437744),\n",
              " ('manakish', 0.6845539808273315),\n",
              " ('pepperoni', 0.6843120455741882),\n",
              " ('italian', 0.6694173812866211),\n",
              " ('casserole', 0.6623860597610474),\n",
              " ('sicilian', 0.6587257385253906),\n",
              " ('california', 0.6477446556091309),\n",
              " ('macaroni', 0.6166598200798035),\n",
              " ('cheddar', 0.6155270338058472),\n",
              " ('cassolette', 0.6130914688110352)]"
            ]
          },
          "execution_count": 76,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "modelFastTextSkipGram.wv.most_similar(\"pizza\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {},
      "outputs": [],
      "source": [
        "def word_vector(tokens, size,model):\n",
        "    vec = np.zeros(size).reshape((1, size))\n",
        "    count = 0\n",
        "    for word in tokens:\n",
        "        try:\n",
        "            vec += model[word].reshape((1, size))\n",
        "            count += 1.\n",
        "        except KeyError:\n",
        "            continue\n",
        "    if count != 0:\n",
        "        vec /= count\n",
        "    return vec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rCuZeP_Xvg-Y",
        "outputId": "dee3cfd5-4a0c-42d9-dba1-d1552617e7d0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\jyoti\\anaconda3\\envs\\nlp\\lib\\site-packages\\ipykernel_launcher.py:6: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  \n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(88516, 200)"
            ]
          },
          "execution_count": 78,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "fastText_arrays = np.zeros((len(tokenized_tag), 200)) \n",
        "for i in range(len(tokenized_tag)):\n",
        "    fastText_arrays[i,:] = word_vector(tokenized_tag[i], 200,modelFastTextSkipGram)\n",
        "fastText_df = pd.DataFrame(fastText_arrays)\n",
        "fastText_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "pandas.core.frame.DataFrame"
            ]
          },
          "execution_count": 79,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(data2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "4LZOjdwjl3AA"
      },
      "outputs": [],
      "source": [
        "dataset_fastText2 = pd.DataFrame(np.hstack((fastText_df,data22)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>204</th>\n",
              "      <th>205</th>\n",
              "      <th>206</th>\n",
              "      <th>207</th>\n",
              "      <th>208</th>\n",
              "      <th>209</th>\n",
              "      <th>210</th>\n",
              "      <th>211</th>\n",
              "      <th>212</th>\n",
              "      <th>213</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0207659</td>\n",
              "      <td>-0.233643</td>\n",
              "      <td>-0.223695</td>\n",
              "      <td>0.175525</td>\n",
              "      <td>0.156854</td>\n",
              "      <td>-0.00873783</td>\n",
              "      <td>-0.0605019</td>\n",
              "      <td>0.0642362</td>\n",
              "      <td>-0.297105</td>\n",
              "      <td>-0.164832</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.752941</td>\n",
              "      <td>0.00784314</td>\n",
              "      <td>0.752941</td>\n",
              "      <td>0.752941</td>\n",
              "      <td>0.796078</td>\n",
              "      <td>0.00784314</td>\n",
              "      <td>0.796078</td>\n",
              "      <td>0.796078</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.210699</td>\n",
              "      <td>-0.165044</td>\n",
              "      <td>-0.0573634</td>\n",
              "      <td>0.0164191</td>\n",
              "      <td>0.0419501</td>\n",
              "      <td>-0.0900447</td>\n",
              "      <td>-0.157834</td>\n",
              "      <td>-0.137588</td>\n",
              "      <td>-0.0736064</td>\n",
              "      <td>-0.121538</td>\n",
              "      <td>...</td>\n",
              "      <td>0.647059</td>\n",
              "      <td>0</td>\n",
              "      <td>0.164706</td>\n",
              "      <td>0.14902</td>\n",
              "      <td>0.164706</td>\n",
              "      <td>0</td>\n",
              "      <td>0.164706</td>\n",
              "      <td>0.105882</td>\n",
              "      <td>0.164706</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.134274</td>\n",
              "      <td>-0.185613</td>\n",
              "      <td>-0.119694</td>\n",
              "      <td>0.0339838</td>\n",
              "      <td>-0.0216417</td>\n",
              "      <td>-0.00807037</td>\n",
              "      <td>-0.150548</td>\n",
              "      <td>-0.193324</td>\n",
              "      <td>-0.0955016</td>\n",
              "      <td>-0.107727</td>\n",
              "      <td>...</td>\n",
              "      <td>0.647059</td>\n",
              "      <td>0.647059</td>\n",
              "      <td>0.164706</td>\n",
              "      <td>0.439216</td>\n",
              "      <td>0.164706</td>\n",
              "      <td>0.164706</td>\n",
              "      <td>0.164706</td>\n",
              "      <td>0.141176</td>\n",
              "      <td>0.164706</td>\n",
              "      <td>0.164706</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.0426015</td>\n",
              "      <td>-0.228787</td>\n",
              "      <td>-0.0988958</td>\n",
              "      <td>-0.0359875</td>\n",
              "      <td>0.00808325</td>\n",
              "      <td>0.0377704</td>\n",
              "      <td>-0.187283</td>\n",
              "      <td>-0.168977</td>\n",
              "      <td>-0.0970396</td>\n",
              "      <td>-0.0807703</td>\n",
              "      <td>...</td>\n",
              "      <td>0.647059</td>\n",
              "      <td>0.647059</td>\n",
              "      <td>0.164706</td>\n",
              "      <td>0.12549</td>\n",
              "      <td>0.164706</td>\n",
              "      <td>0.164706</td>\n",
              "      <td>0.164706</td>\n",
              "      <td>0.0705882</td>\n",
              "      <td>0.164706</td>\n",
              "      <td>0.164706</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.0107071</td>\n",
              "      <td>-0.19839</td>\n",
              "      <td>-0.20092</td>\n",
              "      <td>0.143079</td>\n",
              "      <td>0.126162</td>\n",
              "      <td>0.00587593</td>\n",
              "      <td>-0.0899024</td>\n",
              "      <td>0.00097935</td>\n",
              "      <td>-0.280599</td>\n",
              "      <td>-0.152933</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.737255</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00392157</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88511</th>\n",
              "      <td>-0.150323</td>\n",
              "      <td>-0.213728</td>\n",
              "      <td>-0.0557028</td>\n",
              "      <td>-0.137019</td>\n",
              "      <td>-0.0675649</td>\n",
              "      <td>-0.0560865</td>\n",
              "      <td>-0.0527602</td>\n",
              "      <td>-0.219713</td>\n",
              "      <td>-0.0837514</td>\n",
              "      <td>-0.136663</td>\n",
              "      <td>...</td>\n",
              "      <td>0.501961</td>\n",
              "      <td>0.501961</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00784314</td>\n",
              "      <td>0</td>\n",
              "      <td>0.501961</td>\n",
              "      <td>0.501961</td>\n",
              "      <td>0.713725</td>\n",
              "      <td>0.501961</td>\n",
              "      <td>0.501961</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88512</th>\n",
              "      <td>0.037114</td>\n",
              "      <td>-0.165513</td>\n",
              "      <td>-0.153659</td>\n",
              "      <td>-0.0058311</td>\n",
              "      <td>0.102352</td>\n",
              "      <td>0.128333</td>\n",
              "      <td>-0.0746</td>\n",
              "      <td>-0.0991168</td>\n",
              "      <td>-0.183549</td>\n",
              "      <td>-0.166253</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.509804</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.780392</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88513</th>\n",
              "      <td>-0.136941</td>\n",
              "      <td>-0.121858</td>\n",
              "      <td>-0.0278116</td>\n",
              "      <td>-0.0606348</td>\n",
              "      <td>-0.137365</td>\n",
              "      <td>0.0663165</td>\n",
              "      <td>0.0572796</td>\n",
              "      <td>-0.00543965</td>\n",
              "      <td>-0.206571</td>\n",
              "      <td>-0.0980717</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.223529</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.439216</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88514</th>\n",
              "      <td>-0.0980418</td>\n",
              "      <td>-0.062092</td>\n",
              "      <td>-0.257851</td>\n",
              "      <td>0.0285083</td>\n",
              "      <td>0.0532889</td>\n",
              "      <td>0.00466773</td>\n",
              "      <td>-0.107588</td>\n",
              "      <td>-0.00226749</td>\n",
              "      <td>-0.172921</td>\n",
              "      <td>-0.160602</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.521569</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.109804</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88515</th>\n",
              "      <td>-0.0370861</td>\n",
              "      <td>-0.289802</td>\n",
              "      <td>-0.0214767</td>\n",
              "      <td>0.0487884</td>\n",
              "      <td>0.16442</td>\n",
              "      <td>0.01812</td>\n",
              "      <td>-0.149996</td>\n",
              "      <td>0.120102</td>\n",
              "      <td>0.0143203</td>\n",
              "      <td>-0.148671</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.752941</td>\n",
              "      <td>0.270588</td>\n",
              "      <td>1</td>\n",
              "      <td>0.752941</td>\n",
              "      <td>0.796078</td>\n",
              "      <td>0.12549</td>\n",
              "      <td>1</td>\n",
              "      <td>0.796078</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>88516 rows × 214 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "             0         1          2          3           4           5    \\\n",
              "0      0.0207659 -0.233643  -0.223695   0.175525    0.156854 -0.00873783   \n",
              "1      -0.210699 -0.165044 -0.0573634  0.0164191   0.0419501  -0.0900447   \n",
              "2      -0.134274 -0.185613  -0.119694  0.0339838  -0.0216417 -0.00807037   \n",
              "3     -0.0426015 -0.228787 -0.0988958 -0.0359875  0.00808325   0.0377704   \n",
              "4     -0.0107071  -0.19839   -0.20092   0.143079    0.126162  0.00587593   \n",
              "...          ...       ...        ...        ...         ...         ...   \n",
              "88511  -0.150323 -0.213728 -0.0557028  -0.137019  -0.0675649  -0.0560865   \n",
              "88512   0.037114 -0.165513  -0.153659 -0.0058311    0.102352    0.128333   \n",
              "88513  -0.136941 -0.121858 -0.0278116 -0.0606348   -0.137365   0.0663165   \n",
              "88514 -0.0980418 -0.062092  -0.257851  0.0285083   0.0532889  0.00466773   \n",
              "88515 -0.0370861 -0.289802 -0.0214767  0.0487884     0.16442     0.01812   \n",
              "\n",
              "             6           7          8          9    ...       204       205  \\\n",
              "0     -0.0605019   0.0642362  -0.297105  -0.164832  ...         1         1   \n",
              "1      -0.157834   -0.137588 -0.0736064  -0.121538  ...  0.647059         0   \n",
              "2      -0.150548   -0.193324 -0.0955016  -0.107727  ...  0.647059  0.647059   \n",
              "3      -0.187283   -0.168977 -0.0970396 -0.0807703  ...  0.647059  0.647059   \n",
              "4     -0.0899024  0.00097935  -0.280599  -0.152933  ...         1         1   \n",
              "...          ...         ...        ...        ...  ...       ...       ...   \n",
              "88511 -0.0527602   -0.219713 -0.0837514  -0.136663  ...  0.501961  0.501961   \n",
              "88512    -0.0746  -0.0991168  -0.183549  -0.166253  ...         1         1   \n",
              "88513  0.0572796 -0.00543965  -0.206571 -0.0980717  ...         0         1   \n",
              "88514  -0.107588 -0.00226749  -0.172921  -0.160602  ...         1         1   \n",
              "88515  -0.149996    0.120102  0.0143203  -0.148671  ...         1         1   \n",
              "\n",
              "            206         207       208       209       210         211  \\\n",
              "0      0.752941  0.00784314  0.752941  0.752941  0.796078  0.00784314   \n",
              "1      0.164706     0.14902  0.164706         0  0.164706    0.105882   \n",
              "2      0.164706    0.439216  0.164706  0.164706  0.164706    0.141176   \n",
              "3      0.164706     0.12549  0.164706  0.164706  0.164706   0.0705882   \n",
              "4             1    0.737255         1         1         0  0.00392157   \n",
              "...         ...         ...       ...       ...       ...         ...   \n",
              "88511         0  0.00784314         0  0.501961  0.501961    0.713725   \n",
              "88512         1    0.509804         1         1         1    0.780392   \n",
              "88513         1    0.223529         0         1         0    0.439216   \n",
              "88514         1    0.521569         1         1         1    0.109804   \n",
              "88515  0.752941    0.270588         1  0.752941  0.796078     0.12549   \n",
              "\n",
              "            212       213  \n",
              "0      0.796078  0.796078  \n",
              "1      0.164706         0  \n",
              "2      0.164706  0.164706  \n",
              "3      0.164706  0.164706  \n",
              "4             0         0  \n",
              "...         ...       ...  \n",
              "88511  0.501961  0.501961  \n",
              "88512         1         1  \n",
              "88513         1         0  \n",
              "88514         1         1  \n",
              "88515         1  0.796078  \n",
              "\n",
              "[88516 rows x 214 columns]"
            ]
          },
          "execution_count": 81,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset_fastText2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BPKV1kN2Cxmz"
      },
      "source": [
        "## Train test split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {},
      "outputs": [],
      "source": [
        "data=dataset_fastText2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {},
      "outputs": [],
      "source": [
        "# from sklearn import preprocessing\n",
        "# w2v_df = pd.DataFrame(data)\n",
        "# data=w2v_df.astype(str)\n",
        "\n",
        "# normalizer = preprocessing.MinMaxScaler(feature_range=(0, 1))\n",
        "# w2v_df = pd.DataFrame(normalizer.fit_transform(data),  columns = data.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {},
      "outputs": [],
      "source": [
        "# data2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {},
      "outputs": [],
      "source": [
        "# #Converting the columns into the float datatype\n",
        "# a=['dominant_colors_R','dominant_colors_G','dominant_colors_B']\n",
        "# for i in a:\n",
        "#   data2[i]= data2[i].astype(str).astype(float)\n",
        "# data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "pandas.core.frame.DataFrame"
            ]
          },
          "execution_count": 86,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0      object\n",
              "1      object\n",
              "2      object\n",
              "3      object\n",
              "4      object\n",
              "        ...  \n",
              "209    object\n",
              "210    object\n",
              "211    object\n",
              "212    object\n",
              "213    object\n",
              "Length: 214, dtype: object"
            ]
          },
          "execution_count": 89,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {},
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "could not convert string to float: '[]'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_5500\\4069746220.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mnormalizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMinMaxScaler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeature_range\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mnormalized_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnormalizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[1;32m~\\anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    850\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    851\u001b[0m             \u001b[1;31m# fit method of arity 1 (unsupervised transformation)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 852\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    853\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    854\u001b[0m             \u001b[1;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    414\u001b[0m         \u001b[1;31m# Reset internal state before fitting\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    415\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 416\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpartial_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    417\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    418\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpartial_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\u001b[0m in \u001b[0;36mpartial_fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    456\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    457\u001b[0m             \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFLOAT_DTYPES\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 458\u001b[1;33m             \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"allow-nan\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    459\u001b[0m         )\n\u001b[0;32m    460\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    564\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Validation should be done on X, y or both.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    565\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 566\u001b[1;33m             \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    567\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    568\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    744\u001b[0m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcasting\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"unsafe\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    745\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 746\u001b[1;33m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    747\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    748\u001b[0m                 raise ValueError(\n",
            "\u001b[1;32m~\\anaconda3\\envs\\nlp\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m   1779\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1780\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1781\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1782\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1783\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__array_wrap__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mValueError\u001b[0m: could not convert string to float: '[]'"
          ]
        }
      ],
      "source": [
        "from sklearn import preprocessing\n",
        "df = pd.DataFrame(data)\n",
        "data=df.astype(str)\n",
        "\n",
        "normalizer = preprocessing.MinMaxScaler(feature_range=(0, 1))\n",
        "normalized_df = pd.DataFrame(normalizer.fit_transform(data),  columns = data.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# from sklearn import preprocessing\n",
        "\n",
        "# bow_data1 = preprocessing.MinMaxScaler(feature_range=(0, 1))\n",
        "# bow_normalized_df = pd.DataFrame(bow_data1.fit_transform(data),  columns = data.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# bow_normalized_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# data.astype(str)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8A7jwzRZFwFt"
      },
      "outputs": [],
      "source": [
        "y=data[200]\n",
        "X1=data.drop(200,1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "pandas.core.frame.DataFrame"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(X1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "pandas.core.series.Series"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(88516,)"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(88516, 213)"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X1.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ht99jtBGCoJR"
      },
      "outputs": [],
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(X1, y, test_size=0.2, random_state=2022)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZdW6I6LQI9uz"
      },
      "source": [
        "###XGBoost model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rPRu8lqoIpaW"
      },
      "outputs": [],
      "source": [
        "# #XGBoost hyper-parameter tuning\n",
        "# def hyperParameterTuning(X_train, y_train):\n",
        "#     param_tuning = {\n",
        "#         'learning_rate': [0.01, 0.1],\n",
        "#         'max_depth': [3, 5, 7, 10],\n",
        "#         'min_child_weight': [1, 3, 5],\n",
        "#         'subsample': [0.5, 0.7],\n",
        "#         'colsample_bytree': [0.5, 0.7],\n",
        "#         'n_estimators' : [100, 200, 500],\n",
        "#         'objective': ['reg:squarederror']\n",
        "#     }\n",
        "\n",
        "#     xgb_model = XGBRegressor()\n",
        "\n",
        "#     gsearch = GridSearchCV(estimator = xgb_model,\n",
        "#                            param_grid = param_tuning,                        \n",
        "#                            #scoring = 'neg_mean_absolute_error', #MAE\n",
        "#                            #scoring = 'neg_mean_squared_error',  #MSE\n",
        "#                            cv = 5,\n",
        "#                            n_jobs = -1,\n",
        "#                            verbose = 1)\n",
        "\n",
        "#     gsearch.fit(X_train,y_train)\n",
        "\n",
        "#     return gsearch.best_params_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 710
        },
        "id": "e3mKpHc_JMDg",
        "outputId": "ffc5e918-6cd1-46e8-ef73-9908d5d2a3e2"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "DataFrame.dtypes for data must be int, float, bool or category.  When\ncategorical type is supplied, DMatrix parameter `enable_categorical` must\nbe set to `True`. Invalid columns:0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_5500\\2061392645.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m         subsample = 0.7)\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[0mxgb_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;31m# y_pred_xgb = xgb_model.fit(x_train, np.ravel(y_train, order='C'))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\envs\\nlp\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marg\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\envs\\nlp\\lib\\site-packages\\xgboost\\sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[0;32m    944\u001b[0m             \u001b[0meval_qid\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    945\u001b[0m             \u001b[0mcreate_dmatrix\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mDMatrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnthread\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 946\u001b[1;33m             \u001b[0menable_categorical\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menable_categorical\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    947\u001b[0m         )\n\u001b[0;32m    948\u001b[0m         \u001b[0mparams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_xgb_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\envs\\nlp\\lib\\site-packages\\xgboost\\sklearn.py\u001b[0m in \u001b[0;36m_wrap_evaluation_matrices\u001b[1;34m(missing, X, y, group, qid, sample_weight, base_margin, feature_weights, eval_set, sample_weight_eval_set, base_margin_eval_set, eval_group, eval_qid, create_dmatrix, enable_categorical)\u001b[0m\n\u001b[0;32m    408\u001b[0m         \u001b[0mfeature_weights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeature_weights\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    409\u001b[0m         \u001b[0mmissing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmissing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 410\u001b[1;33m         \u001b[0menable_categorical\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0menable_categorical\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    411\u001b[0m     )\n\u001b[0;32m    412\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\envs\\nlp\\lib\\site-packages\\xgboost\\sklearn.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(**kwargs)\u001b[0m\n\u001b[0;32m    943\u001b[0m             \u001b[0meval_group\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    944\u001b[0m             \u001b[0meval_qid\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 945\u001b[1;33m             \u001b[0mcreate_dmatrix\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mDMatrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnthread\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    946\u001b[0m             \u001b[0menable_categorical\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menable_categorical\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    947\u001b[0m         )\n",
            "\u001b[1;32m~\\anaconda3\\envs\\nlp\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marg\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\envs\\nlp\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, label, weight, base_margin, missing, silent, feature_names, feature_types, nthread, group, qid, label_lower_bound, label_upper_bound, feature_weights, enable_categorical)\u001b[0m\n\u001b[0;32m    647\u001b[0m             \u001b[0mfeature_names\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeature_names\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    648\u001b[0m             \u001b[0mfeature_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeature_types\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 649\u001b[1;33m             \u001b[0menable_categorical\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0menable_categorical\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    650\u001b[0m         )\n\u001b[0;32m    651\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\envs\\nlp\\lib\\site-packages\\xgboost\\data.py\u001b[0m in \u001b[0;36mdispatch_data_backend\u001b[1;34m(data, missing, threads, feature_names, feature_types, enable_categorical)\u001b[0m\n\u001b[0;32m    895\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0m_is_pandas_df\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    896\u001b[0m         return _from_pandas_df(data, enable_categorical, missing, threads,\n\u001b[1;32m--> 897\u001b[1;33m                                feature_names, feature_types)\n\u001b[0m\u001b[0;32m    898\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0m_is_pandas_series\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    899\u001b[0m         return _from_pandas_series(\n",
            "\u001b[1;32m~\\anaconda3\\envs\\nlp\\lib\\site-packages\\xgboost\\data.py\u001b[0m in \u001b[0;36m_from_pandas_df\u001b[1;34m(data, enable_categorical, missing, nthread, feature_names, feature_types)\u001b[0m\n\u001b[0;32m    344\u001b[0m ) -> Tuple[ctypes.c_void_p, FeatureNames, Optional[List[str]]]:\n\u001b[0;32m    345\u001b[0m     data, feature_names, feature_types = _transform_pandas_df(\n\u001b[1;32m--> 346\u001b[1;33m         \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menable_categorical\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_names\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_types\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    347\u001b[0m     )\n\u001b[0;32m    348\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0m_from_numpy_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmissing\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnthread\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_names\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_types\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\envs\\nlp\\lib\\site-packages\\xgboost\\data.py\u001b[0m in \u001b[0;36m_transform_pandas_df\u001b[1;34m(data, enable_categorical, feature_names, feature_types, meta, meta_type)\u001b[0m\n\u001b[0;32m    281\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    282\u001b[0m     ):\n\u001b[1;32m--> 283\u001b[1;33m         \u001b[0m_invalid_dataframe_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    284\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    285\u001b[0m     \u001b[1;31m# handle feature names\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\envs\\nlp\\lib\\site-packages\\xgboost\\data.py\u001b[0m in \u001b[0;36m_invalid_dataframe_dtype\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    245\u001b[0m \u001b[0mcategorical\u001b[0m \u001b[0mtype\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0msupplied\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDMatrix\u001b[0m \u001b[0mparameter\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0menable_categorical\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mmust\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    246\u001b[0m be set to `True`.\"\"\" + err\n\u001b[1;32m--> 247\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    248\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mValueError\u001b[0m: DataFrame.dtypes for data must be int, float, bool or category.  When\ncategorical type is supplied, DMatrix parameter `enable_categorical` must\nbe set to `True`. Invalid columns:0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213"
          ]
        }
      ],
      "source": [
        "from xgboost import XGBRegressor\n",
        "\n",
        "xgb_model = XGBRegressor(\n",
        "        enable_categorical=True,\n",
        "        objective = 'reg:squarederror',\n",
        "        colsample_bytree = 0.5,\n",
        "        learning_rate = 0.05,\n",
        "        max_depth = 6,\n",
        "        min_child_weight = 1,\n",
        "        n_estimators = 1000,\n",
        "        subsample = 0.7)\n",
        "\n",
        "xgb_model.fit(x_train, y_train)\n",
        "# y_pred_xgb = xgb_model.fit(x_train, np.ravel(y_train, order='C'))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_pred_xgb = xgb_model.predict(x_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ro41FPqJT4CL"
      },
      "outputs": [],
      "source": [
        "rmse = np.sqrt(mean_squared_error(y_test, y_pred_xgb))\n",
        "print(\"RMSE: %f\" % (rmse))\n",
        "R2=r2_score(y_test,y_pred_xgb)\n",
        "print(\"R2 Score: %f\" % (R2))\n",
        "print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3tYCrSl8Vtf4"
      },
      "outputs": [],
      "source": [
        "def plot_feature_importance(importance,names,model_type):\n",
        "\n",
        "#Create arrays from feature importance and feature names\n",
        "  feature_importance = np.array(importance)\n",
        "  feature_names = np.array(names)\n",
        "\n",
        "  #Create a DataFrame using a Dictionary\n",
        "  data={'feature_names':feature_names,'feature_importance':feature_importance}\n",
        "  fi_df = pd.DataFrame(data)\n",
        "\n",
        "  #Sort the DataFrame in order decreasing feature importance\n",
        "  fi_df.sort_values(by=['feature_importance'], ascending=False,inplace=True)\n",
        "\n",
        "  #Define size of bar plot\n",
        "  plt.figure(figsize=(20,20))\n",
        "  #Plot Searborn bar chart\n",
        "  sns.barplot(x=fi_df['feature_importance'], y=fi_df['feature_names'])\n",
        "  #Add chart labels\n",
        "  plt.title(model_type + 'FEATURE IMPORTANCE')\n",
        "  plt.xlabel('FEATURE IMPORTANCE')\n",
        "  plt.ylabel('FEATURE NAMES')\n",
        "\n",
        "plot_feature_importance(xg_reg.feature_importances_,x_train.columns,'XG BOOST')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "CV features Model Building.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "886d5d2b530556012cff849b271299f0b84687e7f7ab1c5229f64e691d612960"
    },
    "kernelspec": {
      "display_name": "Python 3.8.13 ('newInsta')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
