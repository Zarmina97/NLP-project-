{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Doc2Vector + Models.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "aLdW70g80j9c"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import gensim\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.manifold import TSNE\n",
        "%matplotlib inline\n",
        "import re  # For preprocessing\n",
        "import pandas as pd  # For data handling\n",
        "from time import time  # To time our operations\n",
        "from collections import defaultdict  # For word frequency\n",
        "import seaborn as sns\n",
        "import spacy  # For preprocessing\n",
        "\n",
        "import logging  # Setting up the loggings to monitor gensim\n",
        "logging.basicConfig(format=\"%(levelname)s - %(asctime)s: %(message)s\", datefmt= '%H:%M:%S', level=logging.INFO)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv('Base_Model_Final.csv') #target=likes_x"
      ],
      "metadata": {
        "id": "qEjmqJ0g02Kp"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 803
        },
        "id": "pfBPMuOrXDK7",
        "outputId": "d3ed4921-6847-4a84-a869-3d72f60d139e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Unnamed: 0                                            caption  following  \\\n",
              "0           0  ğ——ğ—¶ğ—± ğ˜†ğ—¼ğ˜‚ ğ—¸ğ—»ğ—¼ğ˜„ ğ˜ğ—µğ—®ğ˜ ğ˜†ğ—¼ğ˜‚ ğ—°ğ—®ğ—» ğ˜ğ—²ğ˜€ğ˜ ğ—³ğ—¼ğ—¿ ğ—–ğ—¼ğ˜ƒğ—¶ğ—± ğ˜„ğ—¶ğ˜ğ—µ ...      964.0   \n",
              "1           1  ğ—§ğ—›ğ—”ğ—¡ğ— ğ—¬ğ—¢ğ—¨  We grateful kind words feedback rec...      964.0   \n",
              "2           2  Hand dived Isle Jura scallop smoked roe leek c...      308.0   \n",
              "3           3  Jerusalem Artichoke prepared first dessert mal...      308.0   \n",
              "4           4  Main course seasonal  course menu: Borders Roe...      308.0   \n",
              "\n",
              "   likes_x  posts_count  followers  Hod  mon  tue  wed  ...  \\\n",
              "0     14.0         47.0     1093.0   10    1    0    0  ...   \n",
              "1     12.0         47.0     1093.0   14    0    0    0  ...   \n",
              "2    100.0        343.0     4202.0   17    0    0    0  ...   \n",
              "3     81.0        343.0     4202.0   20    1    0    0  ...   \n",
              "4    146.0        343.0     4202.0   18    0    0    1  ...   \n",
              "\n",
              "   average_five_recent_likes  TextBlob_Analysis  \\\n",
              "0                       13.0                  2   \n",
              "1                       13.0                  2   \n",
              "2                      158.6                  1   \n",
              "3                      158.6                  2   \n",
              "4                      158.6                  2   \n",
              "\n",
              "                                            hashtags  hashcounts  \\\n",
              "0  '#londontesting', '#chelseabridgeclinic', '#lo...           8   \n",
              "1  '#thankyou', '#thankful', '#feedback', '#chlse...           9   \n",
              "2  '#edinburghfoodies', '#edinburghrestaurants', ...          25   \n",
              "3  '#michelin', '#michelinstar', '#michelinuk', '...          28   \n",
              "4  '#michelin', '#michelinstar', '#michelinuk', '...          28   \n",
              "\n",
              "                                 mentions  mention_count  \\\n",
              "0                                     NaN              0   \n",
              "1                                     NaN              0   \n",
              "2                                     NaN              0   \n",
              "3                                     NaN              0   \n",
              "4  '@castlegamescotland', '@wellocksfood'              2   \n",
              "\n",
              "                                               emoji  \\\n",
              "0  ['â±', 'ğŸ“„', 'ğŸ§‘ğŸ»\\u200dâš•ï¸', 'ğŸ‘¨\\u200dğŸ‘©\\u200dğŸ‘§\\u200...   \n",
              "1                                         ['ğŸ‘', 'ğŸ§¡']   \n",
              "2                                                 []   \n",
              "3                                                 []   \n",
              "4                                                 []   \n",
              "\n",
              "                                          emoji_text  emoji_count  \\\n",
              "0  'stopwatch' 'page facing up' 'health worker: l...           10   \n",
              "1                    'clapping hands' 'orange heart'            2   \n",
              "2                                                NaN            0   \n",
              "3                                                NaN            0   \n",
              "4                                                NaN            0   \n",
              "\n",
              "  hashtag_popularity  \n",
              "0        3219.750000  \n",
              "1        5178.333333  \n",
              "2       17663.680000  \n",
              "3       16841.857143  \n",
              "4       16841.857143  \n",
              "\n",
              "[5 rows x 25 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c4a9b1dc-2232-4644-900e-4cd1f5f9bb62\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>caption</th>\n",
              "      <th>following</th>\n",
              "      <th>likes_x</th>\n",
              "      <th>posts_count</th>\n",
              "      <th>followers</th>\n",
              "      <th>Hod</th>\n",
              "      <th>mon</th>\n",
              "      <th>tue</th>\n",
              "      <th>wed</th>\n",
              "      <th>...</th>\n",
              "      <th>average_five_recent_likes</th>\n",
              "      <th>TextBlob_Analysis</th>\n",
              "      <th>hashtags</th>\n",
              "      <th>hashcounts</th>\n",
              "      <th>mentions</th>\n",
              "      <th>mention_count</th>\n",
              "      <th>emoji</th>\n",
              "      <th>emoji_text</th>\n",
              "      <th>emoji_count</th>\n",
              "      <th>hashtag_popularity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>ğ——ğ—¶ğ—± ğ˜†ğ—¼ğ˜‚ ğ—¸ğ—»ğ—¼ğ˜„ ğ˜ğ—µğ—®ğ˜ ğ˜†ğ—¼ğ˜‚ ğ—°ğ—®ğ—» ğ˜ğ—²ğ˜€ğ˜ ğ—³ğ—¼ğ—¿ ğ—–ğ—¼ğ˜ƒğ—¶ğ—± ğ˜„ğ—¶ğ˜ğ—µ ...</td>\n",
              "      <td>964.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>47.0</td>\n",
              "      <td>1093.0</td>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>13.0</td>\n",
              "      <td>2</td>\n",
              "      <td>'#londontesting', '#chelseabridgeclinic', '#lo...</td>\n",
              "      <td>8</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>['â±', 'ğŸ“„', 'ğŸ§‘ğŸ»\\u200dâš•ï¸', 'ğŸ‘¨\\u200dğŸ‘©\\u200dğŸ‘§\\u200...</td>\n",
              "      <td>'stopwatch' 'page facing up' 'health worker: l...</td>\n",
              "      <td>10</td>\n",
              "      <td>3219.750000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>ğ—§ğ—›ğ—”ğ—¡ğ— ğ—¬ğ—¢ğ—¨  We grateful kind words feedback rec...</td>\n",
              "      <td>964.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>47.0</td>\n",
              "      <td>1093.0</td>\n",
              "      <td>14</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>13.0</td>\n",
              "      <td>2</td>\n",
              "      <td>'#thankyou', '#thankful', '#feedback', '#chlse...</td>\n",
              "      <td>9</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>['ğŸ‘', 'ğŸ§¡']</td>\n",
              "      <td>'clapping hands' 'orange heart'</td>\n",
              "      <td>2</td>\n",
              "      <td>5178.333333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Hand dived Isle Jura scallop smoked roe leek c...</td>\n",
              "      <td>308.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>343.0</td>\n",
              "      <td>4202.0</td>\n",
              "      <td>17</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>158.6</td>\n",
              "      <td>1</td>\n",
              "      <td>'#edinburghfoodies', '#edinburghrestaurants', ...</td>\n",
              "      <td>25</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>[]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>17663.680000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Jerusalem Artichoke prepared first dessert mal...</td>\n",
              "      <td>308.0</td>\n",
              "      <td>81.0</td>\n",
              "      <td>343.0</td>\n",
              "      <td>4202.0</td>\n",
              "      <td>20</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>158.6</td>\n",
              "      <td>2</td>\n",
              "      <td>'#michelin', '#michelinstar', '#michelinuk', '...</td>\n",
              "      <td>28</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>[]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>16841.857143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Main course seasonal  course menu: Borders Roe...</td>\n",
              "      <td>308.0</td>\n",
              "      <td>146.0</td>\n",
              "      <td>343.0</td>\n",
              "      <td>4202.0</td>\n",
              "      <td>18</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>158.6</td>\n",
              "      <td>2</td>\n",
              "      <td>'#michelin', '#michelinstar', '#michelinuk', '...</td>\n",
              "      <td>28</td>\n",
              "      <td>'@castlegamescotland', '@wellocksfood'</td>\n",
              "      <td>2</td>\n",
              "      <td>[]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>16841.857143</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 25 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c4a9b1dc-2232-4644-900e-4cd1f5f9bb62')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c4a9b1dc-2232-4644-900e-4cd1f5f9bb62 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c4a9b1dc-2232-4644-900e-4cd1f5f9bb62');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##caption"
      ],
      "metadata": {
        "id": "AkHAoArK1mau"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import multiprocessing\n",
        "from gensim.models import Doc2Vec\n",
        "cores = multiprocessing.cpu_count() # Count the number of cores in a computer\n",
        "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
        "\n",
        "\n",
        "tokenized_caption = df['caption'].apply(lambda x: str(x).split()) # tokenizing \n",
        "\n",
        "sentences = [TaggedDocument(token, 'tag') for token in tokenized_caption]\n",
        "\n",
        "d2v_model = Doc2Vec(min_count=20,\n",
        "                     window=2,\n",
        "                     size=300,\n",
        "                     sample=6e-5, \n",
        "                     alpha=0.03, \n",
        "                     min_alpha=0.0007, \n",
        "                     negative=20,\n",
        "                     workers=cores-1)\n",
        "\n",
        "d2v_model.build_vocab(sentences)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vpiuaW4J09YR",
        "outputId": "0e1aecf0-de0a-4a84-cca2-ed86f7157152"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gensim/models/doc2vec.py:570: UserWarning: The parameter `size` is deprecated, will be removed in 4.0.0, use `vector_size` instead.\n",
            "  warnings.warn(\"The parameter `size` is deprecated, will be removed in 4.0.0, use `vector_size` instead.\")\n",
            "INFO - 15:35:23: collecting all words and their counts\n",
            "INFO - 15:35:23: PROGRESS: at example #0, processed 0 words (0/s), 0 word types, 0 tags\n",
            "INFO - 15:35:23: collected 6718 word types and 3 unique tags from a corpus of 1000 examples and 22620 words\n",
            "INFO - 15:35:23: Loading a fresh vocabulary\n",
            "INFO - 15:35:23: effective_min_count=20 retains 161 unique words (2% of original 6718, drops 6557)\n",
            "INFO - 15:35:23: effective_min_count=20 leaves 6258 word corpus (27% of original 22620, drops 16362)\n",
            "INFO - 15:35:23: deleting the raw counts dictionary of 6718 items\n",
            "INFO - 15:35:23: sample=6e-05 downsamples 161 most-common words\n",
            "INFO - 15:35:23: downsampling leaves estimated 651 word corpus (10.4% of prior 6258)\n",
            "INFO - 15:35:23: estimated required memory for 161 words and 300 dimensions: 471100 bytes\n",
            "INFO - 15:35:23: resetting layer weights\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentences[0:4]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1vkEIfYshIci",
        "outputId": "9dfd8be6-a375-416a-da97-09b424198b4a"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[TaggedDocument(words=['ğ——ğ—¶ğ—±', 'ğ˜†ğ—¼ğ˜‚', 'ğ—¸ğ—»ğ—¼ğ˜„', 'ğ˜ğ—µğ—®ğ˜', 'ğ˜†ğ—¼ğ˜‚', 'ğ—°ğ—®ğ—»', 'ğ˜ğ—²ğ˜€ğ˜', 'ğ—³ğ—¼ğ—¿', 'ğ—–ğ—¼ğ˜ƒğ—¶ğ—±', 'ğ˜„ğ—¶ğ˜ğ—µ', 'ğ—¿ğ—²ğ˜€ğ˜‚ğ—¹ğ˜ğ˜€', 'ğ—¶ğ—»', 'ğ—·ğ˜‚ğ˜€ğ˜', 'ğŸ­ğŸ±', 'ğ—ºğ—¶ğ—»ğ˜‚ğ˜ğ—²', '\\u200d', 'This', 'possible', 'thanks', 'ğ—Ÿğ—®ğ˜ğ—²ğ—¿ğ—®ğ—¹', 'ğ—™ğ—¹ğ—¼ğ˜„', 'ğ—”ğ—»ğ˜ğ—¶ğ—´ğ—²ğ—»', 'ğ—§ğ—²ğ˜€ğ˜ğ—¶ğ—»ğ—´', 'Lateral', 'flow', 'testing', 'fast', 'simple', 'way', 'test', 'people', 'symptoms', 'COVID-', 'may', 'still', 'spreading', 'virus', 'The', 'tests', 'easy', 'use', 'give', 'results', 'within', 'minutes', 'The', 'antigen', 'test', 'perfect', 'solution', 'if:', 'You', 'plan', 'visit', 'family', '\\u200d\\u200d\\u200d', 'You', 'plan', 'visit', 'friend', 'You', 'need', 'meet', 'colleagues', '\\u200d', 'You', 'want', 'test', 'regularly', 'make', 'sure', 'protect', 'loved', 'ones', 'You', 'important', 'occasion', 'forced', 'attend', 'You', 'want', 'know', 'whether', 'virus', 'Protect', 'others', 'around', 'For', 'information', 'DM', 'us'], tags='tag'),\n",
              " TaggedDocument(words=['ğ—§ğ—›ğ—”ğ—¡ğ—', 'ğ—¬ğ—¢ğ—¨', 'We', 'grateful', 'kind', 'words', 'feedback', 'receiving', 'since', 'started', 'providing', 'Testing', 'Travel', 'We', 'continuously', 'working', 'hard', 'help', 'meet', 'expectation', 'whether', 'need', 'get', 'last', 'minute', 'flights', 'wanted', 'reunite', 'family', 'safely', 'Your', 'words', 'paying', 'effort', 'ensure', 'results', 'come', 'time', 'travel', 'meet', 'specific', 'requirements', 'We', 'take', 'opportunity', 'say', 'thank', 'companies', 'trusted', 'us', 'suggesting', 'Clinic', 'clients', 'Thank'], tags='tag'),\n",
              " TaggedDocument(words=['Hand', 'dived', 'Isle', 'Jura', 'scallop', 'smoked', 'roe', 'leek', 'chowder'], tags='tag'),\n",
              " TaggedDocument(words=['Jerusalem', 'Artichoke', 'prepared', 'first', 'dessert', 'malt', 'caramelised', 'yoghurt'], tags='tag')]"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "d2v_model.train(sentences, total_examples= len(df['caption']), epochs=20)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HfQe-OSjf4eH",
        "outputId": "5e1be406-05bf-4d37-d7a1-2a691a6526f1"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO - 15:35:28: training model with 1 workers on 161 vocabulary and 300 features, using sg=0 hs=0 sample=6e-05 negative=20 window=2\n",
            "INFO - 15:35:29: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 15:35:29: EPOCH - 1 : training on 22620 raw words (3665 effective words) took 0.0s, 88186 effective words/s\n",
            "INFO - 15:35:29: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 15:35:29: EPOCH - 2 : training on 22620 raw words (3672 effective words) took 0.0s, 81713 effective words/s\n",
            "INFO - 15:35:29: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 15:35:29: EPOCH - 3 : training on 22620 raw words (3639 effective words) took 0.0s, 88089 effective words/s\n",
            "INFO - 15:35:29: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 15:35:29: EPOCH - 4 : training on 22620 raw words (3658 effective words) took 0.0s, 91147 effective words/s\n",
            "INFO - 15:35:29: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 15:35:29: EPOCH - 5 : training on 22620 raw words (3683 effective words) took 0.0s, 88683 effective words/s\n",
            "INFO - 15:35:29: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 15:35:29: EPOCH - 6 : training on 22620 raw words (3668 effective words) took 0.0s, 88165 effective words/s\n",
            "INFO - 15:35:29: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 15:35:29: EPOCH - 7 : training on 22620 raw words (3616 effective words) took 0.0s, 89475 effective words/s\n",
            "INFO - 15:35:29: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 15:35:29: EPOCH - 8 : training on 22620 raw words (3698 effective words) took 0.0s, 74297 effective words/s\n",
            "INFO - 15:35:29: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 15:35:29: EPOCH - 9 : training on 22620 raw words (3648 effective words) took 0.0s, 85061 effective words/s\n",
            "INFO - 15:35:29: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 15:35:29: EPOCH - 10 : training on 22620 raw words (3660 effective words) took 0.0s, 81452 effective words/s\n",
            "INFO - 15:35:29: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 15:35:29: EPOCH - 11 : training on 22620 raw words (3614 effective words) took 0.0s, 87739 effective words/s\n",
            "INFO - 15:35:29: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 15:35:29: EPOCH - 12 : training on 22620 raw words (3678 effective words) took 0.0s, 76157 effective words/s\n",
            "INFO - 15:35:29: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 15:35:29: EPOCH - 13 : training on 22620 raw words (3650 effective words) took 0.0s, 84087 effective words/s\n",
            "INFO - 15:35:29: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 15:35:29: EPOCH - 14 : training on 22620 raw words (3692 effective words) took 0.1s, 71140 effective words/s\n",
            "INFO - 15:35:29: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 15:35:29: EPOCH - 15 : training on 22620 raw words (3637 effective words) took 0.0s, 90146 effective words/s\n",
            "INFO - 15:35:29: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 15:35:29: EPOCH - 16 : training on 22620 raw words (3615 effective words) took 0.0s, 93025 effective words/s\n",
            "INFO - 15:35:29: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 15:35:29: EPOCH - 17 : training on 22620 raw words (3641 effective words) took 0.0s, 93237 effective words/s\n",
            "INFO - 15:35:29: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 15:35:29: EPOCH - 18 : training on 22620 raw words (3648 effective words) took 0.0s, 76482 effective words/s\n",
            "INFO - 15:35:29: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 15:35:29: EPOCH - 19 : training on 22620 raw words (3633 effective words) took 0.0s, 84878 effective words/s\n",
            "INFO - 15:35:29: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 15:35:29: EPOCH - 20 : training on 22620 raw words (3673 effective words) took 0.0s, 89929 effective words/s\n",
            "INFO - 15:35:29: training on a 452400 raw words (73088 effective words) took 1.0s, 73673 effective words/s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def word_vector(tokens, size):\n",
        "    vec = np.zeros(size).reshape((1, size))\n",
        "    count = 0\n",
        "    for word in tokens:\n",
        "        try:\n",
        "            vec += d2v_model[word].reshape((1, size))\n",
        "            count += 1.\n",
        "        except KeyError:\n",
        "            continue\n",
        "    if count != 0:\n",
        "        vec /= count\n",
        "    return vec"
      ],
      "metadata": {
        "id": "u9LgEIit1RIG"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc2vec_Arrays = np.zeros((len(tokenized_caption), 300)) \n",
        "for i in range(len(tokenized_caption)):\n",
        "    doc2vec_Arrays[i,:] = word_vector(tokenized_caption[i], 300)\n",
        "d2v_df_cap = pd.DataFrame(doc2vec_Arrays)\n",
        "d2v_df_cap.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tTtzUMl01ZQN",
        "outputId": "256808fa-a2c7-403f-fee2-3d6b7b4076d0"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1000, 300)"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##hashtags"
      ],
      "metadata": {
        "id": "Bb46IMKE1tNh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "tokenized_hash = df['hashtags'].apply(lambda x: str(x).split()) # tokenizing \n",
        "\n",
        "sentences = [TaggedDocument(token, 'tag') for token in tokenized_hash]\n",
        "\n",
        "d2v_model = Doc2Vec(min_count=20,\n",
        "                     window=2,\n",
        "                     size=300,\n",
        "                     sample=6e-5, \n",
        "                     alpha=0.03, \n",
        "                     min_alpha=0.0007, \n",
        "                     negative=20,\n",
        "                     workers=cores-1)\n",
        "\n",
        "d2v_model.build_vocab(sentences)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EsEUrBIc1sZ2",
        "outputId": "f8c64502-6f8f-4903-b5d3-c8924a5365df"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gensim/models/doc2vec.py:570: UserWarning: The parameter `size` is deprecated, will be removed in 4.0.0, use `vector_size` instead.\n",
            "  warnings.warn(\"The parameter `size` is deprecated, will be removed in 4.0.0, use `vector_size` instead.\")\n",
            "INFO - 15:34:38: collecting all words and their counts\n",
            "INFO - 15:34:38: PROGRESS: at example #0, processed 0 words (0/s), 0 word types, 0 tags\n",
            "INFO - 15:34:38: collected 1373 word types and 3 unique tags from a corpus of 1000 examples and 7062 words\n",
            "INFO - 15:34:38: Loading a fresh vocabulary\n",
            "INFO - 15:34:38: effective_min_count=20 retains 96 unique words (6% of original 1373, drops 1277)\n",
            "INFO - 15:34:38: effective_min_count=20 leaves 4545 word corpus (64% of original 7062, drops 2517)\n",
            "INFO - 15:34:38: deleting the raw counts dictionary of 1373 items\n",
            "INFO - 15:34:38: sample=6e-05 downsamples 96 most-common words\n",
            "INFO - 15:34:38: downsampling leaves estimated 352 word corpus (7.7% of prior 4545)\n",
            "INFO - 15:34:38: estimated required memory for 96 words and 300 dimensions: 282600 bytes\n",
            "INFO - 15:34:38: resetting layer weights\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "d2v_model.train(sentences, total_examples= len(df['hashtags']), epochs=20)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5MOrvu_Ijn75",
        "outputId": "7b4eb09a-2335-4d06-f75c-d695938cf665"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO - 15:34:43: training model with 1 workers on 96 vocabulary and 300 features, using sg=0 hs=0 sample=6e-05 negative=20 window=2\n",
            "INFO - 15:34:43: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 15:34:43: EPOCH - 1 : training on 7062 raw words (3340 effective words) took 0.0s, 78092 effective words/s\n",
            "INFO - 15:34:43: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 15:34:43: EPOCH - 2 : training on 7062 raw words (3339 effective words) took 0.0s, 89571 effective words/s\n",
            "INFO - 15:34:43: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 15:34:43: EPOCH - 3 : training on 7062 raw words (3327 effective words) took 0.0s, 94848 effective words/s\n",
            "INFO - 15:34:43: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 15:34:43: EPOCH - 4 : training on 7062 raw words (3384 effective words) took 0.0s, 100884 effective words/s\n",
            "INFO - 15:34:43: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 15:34:43: EPOCH - 5 : training on 7062 raw words (3343 effective words) took 0.0s, 91720 effective words/s\n",
            "INFO - 15:34:43: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 15:34:43: EPOCH - 6 : training on 7062 raw words (3331 effective words) took 0.0s, 90361 effective words/s\n",
            "INFO - 15:34:43: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 15:34:43: EPOCH - 7 : training on 7062 raw words (3379 effective words) took 0.0s, 96507 effective words/s\n",
            "INFO - 15:34:43: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 15:34:43: EPOCH - 8 : training on 7062 raw words (3331 effective words) took 0.0s, 96600 effective words/s\n",
            "INFO - 15:34:43: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 15:34:43: EPOCH - 9 : training on 7062 raw words (3347 effective words) took 0.0s, 100840 effective words/s\n",
            "INFO - 15:34:43: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 15:34:43: EPOCH - 10 : training on 7062 raw words (3345 effective words) took 0.0s, 92216 effective words/s\n",
            "INFO - 15:34:43: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 15:34:43: EPOCH - 11 : training on 7062 raw words (3340 effective words) took 0.0s, 96239 effective words/s\n",
            "INFO - 15:34:43: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 15:34:43: EPOCH - 12 : training on 7062 raw words (3363 effective words) took 0.0s, 82833 effective words/s\n",
            "INFO - 15:34:43: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 15:34:43: EPOCH - 13 : training on 7062 raw words (3342 effective words) took 0.0s, 72436 effective words/s\n",
            "INFO - 15:34:43: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 15:34:43: EPOCH - 14 : training on 7062 raw words (3305 effective words) took 0.0s, 91103 effective words/s\n",
            "INFO - 15:34:43: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 15:34:43: EPOCH - 15 : training on 7062 raw words (3358 effective words) took 0.0s, 72071 effective words/s\n",
            "INFO - 15:34:43: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 15:34:43: EPOCH - 16 : training on 7062 raw words (3352 effective words) took 0.0s, 102186 effective words/s\n",
            "INFO - 15:34:43: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 15:34:43: EPOCH - 17 : training on 7062 raw words (3360 effective words) took 0.0s, 93936 effective words/s\n",
            "INFO - 15:34:43: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 15:34:43: EPOCH - 18 : training on 7062 raw words (3354 effective words) took 0.0s, 92224 effective words/s\n",
            "INFO - 15:34:43: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 15:34:43: EPOCH - 19 : training on 7062 raw words (3359 effective words) took 0.0s, 88877 effective words/s\n",
            "INFO - 15:34:43: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 15:34:43: EPOCH - 20 : training on 7062 raw words (3343 effective words) took 0.0s, 75726 effective words/s\n",
            "INFO - 15:34:43: training on a 141240 raw words (66942 effective words) took 0.9s, 74992 effective words/s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc2vec_Arrays = np.zeros((len(tokenized_hash), 300)) \n",
        "for i in range(len(tokenized_hash)):\n",
        "    doc2vec_Arrays[i,:] = word_vector(tokenized_hash[i], 300)\n",
        "d2v_df_hash = pd.DataFrame(doc2vec_Arrays)\n",
        "d2v_df_hash.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d-Ob5hTtjwI3",
        "outputId": "c2128574-21a0-4190-a26f-16d66783c303"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1000, 300)"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##mentions"
      ],
      "metadata": {
        "id": "NjcK4la22Sph"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "tokenized_ment = df['mentions'].apply(lambda x: str(x).split()) # tokenizing \n",
        "\n",
        "sentences = [TaggedDocument(token, 'tag') for token in tokenized_ment]\n",
        "\n",
        "d2v_model = Doc2Vec(min_count=20,\n",
        "                     window=2,\n",
        "                     size=300,\n",
        "                     sample=6e-5, \n",
        "                     alpha=0.03, \n",
        "                     min_alpha=0.0007, \n",
        "                     negative=20,\n",
        "                     workers=cores-1)\n",
        "\n",
        "d2v_model.build_vocab(sentences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ekqCTYwY2WcP",
        "outputId": "7a852c07-64e4-4ec1-eefe-755218d189ad"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gensim/models/doc2vec.py:570: UserWarning: The parameter `size` is deprecated, will be removed in 4.0.0, use `vector_size` instead.\n",
            "  warnings.warn(\"The parameter `size` is deprecated, will be removed in 4.0.0, use `vector_size` instead.\")\n",
            "INFO - 15:34:59: collecting all words and their counts\n",
            "INFO - 15:34:59: PROGRESS: at example #0, processed 0 words (0/s), 0 word types, 0 tags\n",
            "INFO - 15:34:59: collected 343 word types and 3 unique tags from a corpus of 1000 examples and 1209 words\n",
            "INFO - 15:34:59: Loading a fresh vocabulary\n",
            "INFO - 15:34:59: effective_min_count=20 retains 1 unique words (0% of original 343, drops 342)\n",
            "INFO - 15:34:59: effective_min_count=20 leaves 675 word corpus (55% of original 1209, drops 534)\n",
            "INFO - 15:34:59: deleting the raw counts dictionary of 343 items\n",
            "INFO - 15:34:59: sample=6e-05 downsamples 1 most-common words\n",
            "INFO - 15:34:59: downsampling leaves estimated 5 word corpus (0.8% of prior 675)\n",
            "INFO - 15:34:59: estimated required memory for 1 words and 300 dimensions: 7100 bytes\n",
            "INFO - 15:34:59: resetting layer weights\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "d2v_model.train(sentences, total_examples= len(df['mentions']), epochs=20)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T1O0a8FxkBhT",
        "outputId": "35765626-a6a3-441f-d0f9-e84d74b57513"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO - 15:34:05: training model with 1 workers on 1 vocabulary and 300 features, using sg=0 hs=0 sample=6e-05 negative=20 window=2\n",
            "INFO - 15:34:05: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 15:34:05: EPOCH - 1 : training on 1209 raw words (3004 effective words) took 0.1s, 53661 effective words/s\n",
            "INFO - 15:34:06: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 15:34:06: EPOCH - 2 : training on 1209 raw words (3003 effective words) took 0.1s, 40424 effective words/s\n",
            "INFO - 15:34:06: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 15:34:06: EPOCH - 3 : training on 1209 raw words (3007 effective words) took 0.1s, 49453 effective words/s\n",
            "INFO - 15:34:06: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 15:34:06: EPOCH - 4 : training on 1209 raw words (3007 effective words) took 0.1s, 59097 effective words/s\n",
            "INFO - 15:34:06: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 15:34:06: EPOCH - 5 : training on 1209 raw words (3006 effective words) took 0.1s, 59517 effective words/s\n",
            "INFO - 15:34:06: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 15:34:06: EPOCH - 6 : training on 1209 raw words (3005 effective words) took 0.1s, 49644 effective words/s\n",
            "INFO - 15:34:06: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 15:34:06: EPOCH - 7 : training on 1209 raw words (3007 effective words) took 0.1s, 60039 effective words/s\n",
            "INFO - 15:34:06: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 15:34:06: EPOCH - 8 : training on 1209 raw words (3008 effective words) took 0.1s, 52836 effective words/s\n",
            "INFO - 15:34:06: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 15:34:06: EPOCH - 9 : training on 1209 raw words (3007 effective words) took 0.1s, 56303 effective words/s\n",
            "INFO - 15:34:06: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 15:34:06: EPOCH - 10 : training on 1209 raw words (3009 effective words) took 0.1s, 59324 effective words/s\n",
            "INFO - 15:34:06: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 15:34:06: EPOCH - 11 : training on 1209 raw words (3005 effective words) took 0.1s, 55467 effective words/s\n",
            "INFO - 15:34:06: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 15:34:06: EPOCH - 12 : training on 1209 raw words (3004 effective words) took 0.1s, 58948 effective words/s\n",
            "INFO - 15:34:06: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 15:34:06: EPOCH - 13 : training on 1209 raw words (3004 effective words) took 0.1s, 49789 effective words/s\n",
            "INFO - 15:34:06: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 15:34:06: EPOCH - 14 : training on 1209 raw words (3007 effective words) took 0.1s, 55143 effective words/s\n",
            "INFO - 15:34:06: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 15:34:06: EPOCH - 15 : training on 1209 raw words (3001 effective words) took 0.1s, 53839 effective words/s\n",
            "INFO - 15:34:06: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 15:34:06: EPOCH - 16 : training on 1209 raw words (3008 effective words) took 0.1s, 57224 effective words/s\n",
            "INFO - 15:34:06: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 15:34:06: EPOCH - 17 : training on 1209 raw words (3002 effective words) took 0.1s, 55276 effective words/s\n",
            "INFO - 15:34:07: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 15:34:07: EPOCH - 18 : training on 1209 raw words (3006 effective words) took 0.1s, 45533 effective words/s\n",
            "INFO - 15:34:07: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 15:34:07: EPOCH - 19 : training on 1209 raw words (3004 effective words) took 0.1s, 49269 effective words/s\n",
            "INFO - 15:34:07: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 15:34:07: EPOCH - 20 : training on 1209 raw words (3011 effective words) took 0.1s, 59451 effective words/s\n",
            "INFO - 15:34:07: training on a 24180 raw words (60115 effective words) took 1.3s, 47158 effective words/s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc2vec_Arrays = np.zeros((len(tokenized_ment), 300)) \n",
        "for i in range(len(tokenized_ment)):\n",
        "    doc2vec_Arrays[i,:] = word_vector(tokenized_ment[i], 300)\n",
        "d2v_df_ment = pd.DataFrame(doc2vec_Arrays)\n",
        "d2v_df_ment.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jQIzA4S-kHb4",
        "outputId": "25456f3b-be6c-40ce-8c25-27d7e3b4511f"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1000, 300)"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##emojis text"
      ],
      "metadata": {
        "id": "KDvR2u-C21Pr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "tokenized_emo = df['emoji_text'].apply(lambda x: str(x).split()) # tokenizing \n",
        "\n",
        "sentences = [TaggedDocument(token, 'tag') for token in tokenized_emo]\n",
        "\n",
        "d2v_model = Doc2Vec(min_count=20,\n",
        "                     window=2,\n",
        "                     size=300,\n",
        "                     sample=6e-5, \n",
        "                     alpha=0.03, \n",
        "                     min_alpha=0.0007, \n",
        "                     negative=20,\n",
        "                     workers=cores-1)\n",
        "\n",
        "d2v_model.build_vocab(sentences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CBCBF9lK20ra",
        "outputId": "cefe4ea6-34f4-49a7-c464-8e08d004eb22"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gensim/models/doc2vec.py:570: UserWarning: The parameter `size` is deprecated, will be removed in 4.0.0, use `vector_size` instead.\n",
            "  warnings.warn(\"The parameter `size` is deprecated, will be removed in 4.0.0, use `vector_size` instead.\")\n",
            "INFO - 15:36:04: collecting all words and their counts\n",
            "INFO - 15:36:04: PROGRESS: at example #0, processed 0 words (0/s), 0 word types, 0 tags\n",
            "INFO - 15:36:04: collected 452 word types and 3 unique tags from a corpus of 1000 examples and 4162 words\n",
            "INFO - 15:36:04: Loading a fresh vocabulary\n",
            "INFO - 15:36:04: effective_min_count=20 retains 42 unique words (9% of original 452, drops 410)\n",
            "INFO - 15:36:04: effective_min_count=20 leaves 2522 word corpus (60% of original 4162, drops 1640)\n",
            "INFO - 15:36:04: deleting the raw counts dictionary of 452 items\n",
            "INFO - 15:36:04: sample=6e-05 downsamples 42 most-common words\n",
            "INFO - 15:36:04: downsampling leaves estimated 125 word corpus (5.0% of prior 2522)\n",
            "INFO - 15:36:04: estimated required memory for 42 words and 300 dimensions: 126000 bytes\n",
            "INFO - 15:36:04: resetting layer weights\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "d2v_model.train(sentences, total_examples= len(df['emoji_text']), epochs=20)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xp5aYvkskjJt",
        "outputId": "350190c1-39c5-407f-9c30-62ec95fb4091"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO - 15:36:20: training model with 1 workers on 42 vocabulary and 300 features, using sg=0 hs=0 sample=6e-05 negative=20 window=2\n",
            "INFO - 15:36:20: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 15:36:20: EPOCH - 1 : training on 4162 raw words (3103 effective words) took 0.1s, 45645 effective words/s\n",
            "INFO - 15:36:20: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 15:36:20: EPOCH - 2 : training on 4162 raw words (3119 effective words) took 0.1s, 52893 effective words/s\n",
            "INFO - 15:36:20: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 15:36:20: EPOCH - 3 : training on 4162 raw words (3116 effective words) took 0.1s, 48388 effective words/s\n",
            "INFO - 15:36:20: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 15:36:20: EPOCH - 4 : training on 4162 raw words (3147 effective words) took 0.1s, 50911 effective words/s\n",
            "INFO - 15:36:20: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 15:36:20: EPOCH - 5 : training on 4162 raw words (3134 effective words) took 0.1s, 50952 effective words/s\n",
            "INFO - 15:36:20: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 15:36:20: EPOCH - 6 : training on 4162 raw words (3118 effective words) took 0.1s, 46973 effective words/s\n",
            "INFO - 15:36:20: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 15:36:20: EPOCH - 7 : training on 4162 raw words (3109 effective words) took 0.1s, 50481 effective words/s\n",
            "INFO - 15:36:20: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 15:36:20: EPOCH - 8 : training on 4162 raw words (3118 effective words) took 0.1s, 50307 effective words/s\n",
            "INFO - 15:36:20: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 15:36:20: EPOCH - 9 : training on 4162 raw words (3122 effective words) took 0.1s, 45613 effective words/s\n",
            "INFO - 15:36:20: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 15:36:20: EPOCH - 10 : training on 4162 raw words (3134 effective words) took 0.1s, 45612 effective words/s\n",
            "INFO - 15:36:20: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 15:36:20: EPOCH - 11 : training on 4162 raw words (3129 effective words) took 0.1s, 46690 effective words/s\n",
            "INFO - 15:36:21: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 15:36:21: EPOCH - 12 : training on 4162 raw words (3104 effective words) took 0.1s, 49792 effective words/s\n",
            "INFO - 15:36:21: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 15:36:21: EPOCH - 13 : training on 4162 raw words (3110 effective words) took 0.1s, 47304 effective words/s\n",
            "INFO - 15:36:21: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 15:36:21: EPOCH - 14 : training on 4162 raw words (3134 effective words) took 0.1s, 48242 effective words/s\n",
            "INFO - 15:36:21: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 15:36:21: EPOCH - 15 : training on 4162 raw words (3116 effective words) took 0.1s, 41039 effective words/s\n",
            "INFO - 15:36:21: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 15:36:21: EPOCH - 16 : training on 4162 raw words (3119 effective words) took 0.1s, 47290 effective words/s\n",
            "INFO - 15:36:21: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 15:36:21: EPOCH - 17 : training on 4162 raw words (3142 effective words) took 0.1s, 51056 effective words/s\n",
            "INFO - 15:36:21: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 15:36:21: EPOCH - 18 : training on 4162 raw words (3113 effective words) took 0.1s, 49951 effective words/s\n",
            "INFO - 15:36:21: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 15:36:21: EPOCH - 19 : training on 4162 raw words (3113 effective words) took 0.1s, 50923 effective words/s\n",
            "INFO - 15:36:21: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 15:36:21: EPOCH - 20 : training on 4162 raw words (3122 effective words) took 0.1s, 47316 effective words/s\n",
            "INFO - 15:36:21: training on a 83240 raw words (62422 effective words) took 1.5s, 41204 effective words/s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc2vec_Arrays = np.zeros((len(tokenized_emo), 300)) \n",
        "for i in range(len(tokenized_emo)):\n",
        "    doc2vec_Arrays[i,:] = word_vector(tokenized_emo[i], 300)\n",
        "d2v_df_emo = pd.DataFrame(doc2vec_Arrays)\n",
        "d2v_df_emo.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JzUj6XNy3D1u",
        "outputId": "772a9989-506f-42ef-e809-e2e036a65c4d"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1000, 300)"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "d2v_Df = pd.DataFrame(np.hstack((d2v_df_cap,d2v_df_hash,d2v_df_ment,d2v_df_emo, df)))"
      ],
      "metadata": {
        "id": "yXCvFAPx3RdP"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for col in d2v_Df.columns:\n",
        "  print(type(col))"
      ],
      "metadata": {
        "id": "Rjlc8EJGIaTV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "d2v_Df.head()"
      ],
      "metadata": {
        "id": "S6fplAE0lAam"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dropped = [1201,1217,1217,1219,1221,1222]\n",
        "d2v_df = d2v_Df.drop(dropped,axis=1)\n",
        "d2v_df"
      ],
      "metadata": {
        "id": "5EFfalof3tcr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import preprocessing\n",
        "df = pd.DataFrame(d2v_df)\n",
        "data=df.astype(str)\n",
        "\n",
        "normalizer = preprocessing.MinMaxScaler(feature_range=(0, 1))\n",
        "normalized_df = pd.DataFrame(normalizer.fit_transform(data),  columns = data.columns)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "nna7gZyF3925"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = d2v_df[1203]          #Target Variable\n",
        "X = d2v_df.drop(1202,1)   #Feature Matrix\n",
        "X=pd.DataFrame(X)\n",
        "y=pd.DataFrame(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KK7XoJAGGgq2",
        "outputId": "554486c1-f7fd-4b2c-d9a2-14b9d2a662bc"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
            "  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " It seems like new version of xgboost do not accept the datatype of Object. So they should be converted to numeric"
      ],
      "metadata": {
        "id": "N-6xMhyHPjZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in X.columns:\n",
        "  X[i]=pd.to_numeric(X[i])"
      ],
      "metadata": {
        "id": "IUX-arQkMEvm"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in y.columns:\n",
        "  y[i]=pd.to_numeric(y[i])"
      ],
      "metadata": {
        "id": "8ZtaCs38M8I3"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
      ],
      "metadata": {
        "id": "VzXOeB3V4wDf"
      },
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_train.dtypes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mmCcbkDPLrfl",
        "outputId": "17e80eaa-abd4-4cc3-8626-258532db6629"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0       float64\n",
            "1       float64\n",
            "2       float64\n",
            "3       float64\n",
            "4       float64\n",
            "         ...   \n",
            "1216      int64\n",
            "1218      int64\n",
            "1220      int64\n",
            "1223      int64\n",
            "1224    float64\n",
            "Length: 1219, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#XGBoost"
      ],
      "metadata": {
        "id": "RmDdgxeqPyX6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "\n",
        "model = xgb.XGBRegressor()\n",
        "parameters = {'nthread':[4],\n",
        "              'objective':['reg:linear'],\n",
        "              'learning_rate': [.03, 0.05, .07], #so called `eta` value\n",
        "              'max_depth': [5, 6, 7],\n",
        "              'min_child_weight': [4],\n",
        "              'silent': [1],\n",
        "              'subsample': [0.7],\n",
        "              'colsample_bytree': [0.7],\n",
        "              'n_estimators': [500]}\n",
        "\n",
        "model_grid = GridSearchCV(model,parameters,cv = 2,n_jobs = 5, verbose=True)\n",
        "\n",
        "model_grid.fit(x_train, y_train)\n",
        "\n",
        "model_grid.best_score_\n",
        "model_grid.best_params_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ydZ8U4YB5Cd5",
        "outputId": "fce10cc9-f5a1-4c5f-f4e1-b531438924c0"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 2 folds for each of 9 candidates, totalling 18 fits\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'colsample_bytree': 0.7,\n",
              " 'learning_rate': 0.03,\n",
              " 'max_depth': 5,\n",
              " 'min_child_weight': 4,\n",
              " 'n_estimators': 500,\n",
              " 'nthread': 4,\n",
              " 'objective': 'reg:linear',\n",
              " 'silent': 1,\n",
              " 'subsample': 0.7}"
            ]
          },
          "metadata": {},
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xg_reg = xgb.XGBRegressor(objective ='reg:linear', colsample_bytree = 0.7, learning_rate = 0.03,max_depth = 5, min_child_weight=4,nthread = 4, n_estimators = 500,silent=1,subsample=0.7)\n"
      ],
      "metadata": {
        "id": "90AF9k9xNywS"
      },
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xg_reg.fit(x_train, y_train)\n",
        "y_pred = xg_reg.predict(x_test)"
      ],
      "metadata": {
        "id": "k7Hl9qCTN7S8"
      },
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "print(\"RMSE: %f\" % (rmse))\n",
        "\n",
        "R2=r2_score(y_test,y_pred)\n",
        "print(\"R2 Score: %f\" % (R2))\n",
        "print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DxmBBgE9N9Ii",
        "outputId": "01f47453-e81a-4f6d-fa29-70c5ed96fb32"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE: 34.647125\n",
            "R2 Score: 0.986748\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_feature_importance(importance,names,model_type):\n",
        "\n",
        "#Create arrays from feature importance and feature names\n",
        "  feature_importance = np.array(importance)\n",
        "  feature_names = np.array(names)\n",
        "\n",
        "  #Create a DataFrame using a Dictionary\n",
        "  data={'feature_names':feature_names,'feature_importance':feature_importance}\n",
        "  fi_df = pd.DataFrame(data)\n",
        "\n",
        "  #Sort the DataFrame in order decreasing feature importance\n",
        "  fi_df.sort_values(by=['feature_importance'], ascending=False,inplace=True)\n",
        "\n",
        "  #Define size of bar plot\n",
        "  plt.figure(figsize=(20,20))\n",
        "  #Plot Searborn bar chart\n",
        "  sns.barplot(x=fi_df['feature_importance'], y=fi_df['feature_names'])\n",
        "  #Add chart labels\n",
        "  plt.title(model_type + 'FEATURE IMPORTANCE')\n",
        "  plt.xlabel('FEATURE IMPORTANCE')\n",
        "  plt.ylabel('FEATURE NAMES')"
      ],
      "metadata": {
        "id": "mtLLqTkrOV3v"
      },
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_feature_importance(xg_reg.feature_importances_,x_train.columns,'XG BOOST')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "hOFUFShLOXs6",
        "outputId": "8d6be6f3-7072-49d7-8900-6d86ed45bc65"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1440x1440 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Random Forest"
      ],
      "metadata": {
        "id": "-zSZw-IBOc11"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "\n",
        "model_rand = RandomForestRegressor()\n",
        "\n",
        "\n",
        "n_estimators = [5,20,50,100] # number of trees in the random forest\n",
        "max_features = ['auto', 'sqrt'] # number of features in consideration at every split\n",
        "max_depth = [int(x) for x in np.linspace(10, 120, num = 12)] # maximum number of levels allowed in each decision tree\n",
        "min_samples_split = [2, 6, 10] # minimum sample number to split a node\n",
        "min_samples_leaf = [1, 3, 4] # minimum sample number that can be stored in a leaf node\n",
        "bootstrap = [True, False] # method used to sample data points\n",
        "\n",
        "random_grid = {'n_estimators': n_estimators,\n",
        "\n",
        "'max_features': max_features,\n",
        "'max_depth': max_depth,\n",
        "'min_samples_split': min_samples_split,\n",
        "'min_samples_leaf': min_samples_leaf,\n",
        "'bootstrap': bootstrap}\n",
        "\n",
        "\n",
        "rf_random = RandomizedSearchCV(estimator = model_rand,param_distributions = random_grid,n_iter = 100, cv = 5, verbose=2, random_state=35, n_jobs = -1)\n",
        "\n",
        "\n",
        "rf_random.fit(x_train, y_train)\n",
        "\n",
        "# model_rand.best_score_\n",
        "print ('Random grid: ', random_grid, '\\n')\n",
        "\n",
        "# print the best parameters\n",
        "print ('Best Parameters: ', rf_random.best_params_, ' \\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cWQefI-Y_2c2",
        "outputId": "6a68dcd9-ed28-4bba-85b7-7ad0535f18c0"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py:926: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  self.best_estimator_.fit(X, y, **fit_params)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random grid:  {'n_estimators': [5, 20, 50, 100], 'max_features': ['auto', 'sqrt'], 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, 120], 'min_samples_split': [2, 6, 10], 'min_samples_leaf': [1, 3, 4], 'bootstrap': [True, False]} \n",
            "\n",
            "Best Parameters:  {'n_estimators': 5, 'min_samples_split': 6, 'min_samples_leaf': 3, 'max_features': 'auto', 'max_depth': 40, 'bootstrap': False}  \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print ('Best Parameters: ', rf_random.best_params_, ' \\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "luz20lp6OiWV",
        "outputId": "2140c4b8-6626-46b9-c16a-c1f4569b2149"
      },
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters:  {'n_estimators': 5, 'min_samples_split': 6, 'min_samples_leaf': 3, 'max_features': 'auto', 'max_depth': 40, 'bootstrap': False}  \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "rnd_clf = RandomForestRegressor(n_estimators=5, min_samples_split=6 , min_samples_leaf=3, max_features='auto',max_depth=40,bootstrap=False)\n",
        "rnd_clf.fit(x_train, y_train)\n",
        "y_pred_rnd_clf = rnd_clf.predict(x_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cMZdvLvKOkwW",
        "outputId": "8a4ee6dd-9e89-4385-fefb-ac031c205b2c"
      },
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  after removing the cwd from sys.path.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_rnd_clf.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WrbuNOiqUmY9",
        "outputId": "a8f2953a-7700-4558-87c0-3994299a69d1"
      },
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(200,)"
            ]
          },
          "metadata": {},
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mse=mean_squared_error(y_test, y_pred_rnd_clf)\n",
        "print('MSE: %f' % (mse))\n",
        "rmse_rnd = np.sqrt(mse)\n",
        "print(\"RMSE: %f\" % (rmse_rnd))\n",
        "\n",
        "R2_rnd=r2_score(y_test,y_pred_rnd_clf)\n",
        "print(\"R2 Score: %f\" % (R2_rnd))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7LCTtQThRtQc",
        "outputId": "4cee08d7-04d1-4942-96db-bf7ad0fba0fc"
      },
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE: 80.153724\n",
            "RMSE: 8.952861\n",
            "R2 Score: 0.999115\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#SVC"
      ],
      "metadata": {
        "id": "f2ofmKKE8TSO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# defining parameter range\n",
        "param_grid = {'C': [0.1, 1, 10, 100, 1000],\n",
        "              'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
        "              'kernel': ['linear', 'poly', 'rbf']}\n",
        " \n",
        "grid = GridSearchCV(SVC(), param_grid, refit = True, verbose = 3)\n",
        " \n",
        "# fitting the model for grid search\n",
        "grid.fit(x_train, y_train)\n",
        "\n",
        "\n",
        "# print best parameter after tuning\n",
        "print(grid.best_params_)\n",
        " \n",
        "# print how our model looks after hyper-parameter tuning\n",
        "print(grid.best_estimator_)"
      ],
      "metadata": {
        "id": "JpR6Flxq8SXt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "svc_clf=SVC(C=1, gamma=0.001, kernel='rbf')\n",
        "svc_clf.fit(x_train, y_train)\n",
        "grid_predictions = grid.predict(x_test)\n",
        " \n",
        "mse=mean_squared_error(y_test, grid_predictions)\n",
        "print('MSE: %f' % (mse))\n",
        "rmse_rnd = np.sqrt(mse)\n",
        "print(\"RMSE: %f\" % (rmse_rnd))\n",
        "\n",
        "R2_rnd=r2_score(y_test, grid_predictions)\n",
        "print(\"R2 Score: %f\" % (R2_rnd))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2_EaHwQ184E3",
        "outputId": "0b9e6fad-21fa-44c3-efc7-110057380986"
      },
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE: 132297.850000\n",
            "RMSE: 363.727714\n",
            "R2 Score: -0.460506\n"
          ]
        }
      ]
    }
  ]
}